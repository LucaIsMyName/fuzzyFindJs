{"version":3,"file":"fuzzyfindjs.min.js","sources":["../../src/core/config.ts","../../src/languages/base/LanguageProcessor.ts","../../src/languages/german/GermanProcessor.ts","../../src/languages/english/EnglishProcessor.ts","../../src/languages/spanish/SpanishProcessor.ts","../../src/languages/french/FrenchProcessor.ts","../../src/languages/index.ts","../../src/algorithms/levenshtein.ts","../../src/core/trie.ts","../../src/algorithms/bm25.ts","../../src/algorithms/bloom-filter.ts","../../src/core/inverted-index.ts","../../src/core/highlighting.ts","../../src/core/cache.ts","../../src/utils/accent-normalization.ts","../../src/core/field-weighting.ts","../../src/utils/stop-words.ts","../../src/utils/word-boundaries.ts","../../src/utils/phrase-parser.ts","../../src/core/phrase-matching.ts","../../src/utils/language-detection.ts","../../src/fql/lexer.ts","../../src/fql/parser.ts","../../src/fql/ast.ts","../../src/fql/executor.ts","../../src/fql/index.ts","../../src/core/index.ts","../../src/core/serialization.ts","../../src/utils/data-indexer.ts","../../src/index.ts"],"sourcesContent":["import type {\n  //\n  FuzzyConfig,\n  FuzzyFeature,\n} from \"./types.js\";\n\n/**\n * Default configuration for FuzzyFindJS\n * Provides sensible defaults that work out of the box\n */\nexport const DEFAULT_CONFIG: FuzzyConfig = {\n  languages: [\"english\"],\n  features: [\"phonetic\", \"compound\", \"synonyms\", \"keyboard-neighbors\", \"partial-words\", \"missing-letters\", \"extra-letters\", \"transpositions\"],\n  performance: \"balanced\",\n  maxResults: 10,\n  minQueryLength: 2,\n  fuzzyThreshold: 0.75,\n  maxEditDistance: 2,\n  ngramSize: 3,\n};\n\n/**\n * Performance-optimized configurations\n */\nexport const PERFORMANCE_CONFIGS: Record<string, Partial<FuzzyConfig>> = {\n  fast: {\n    performance: \"fast\",\n    features: [\"partial-words\", \"missing-letters\"],\n    maxEditDistance: 1,\n    fuzzyThreshold: 0.9,\n    maxResults: 3,\n  },\n  balanced: {\n    performance: \"balanced\",\n    features: [\"phonetic\", \"partial-words\", \"missing-letters\", \"keyboard-neighbors\"],\n    maxEditDistance: 2,\n    fuzzyThreshold: 0.75,\n    maxResults: 5,\n  },\n  comprehensive: {\n    performance: \"comprehensive\",\n    features: [\"phonetic\", \"compound\", \"synonyms\", \"keyboard-neighbors\", \"partial-words\", \"missing-letters\", \"extra-letters\", \"transpositions\"],\n    maxEditDistance: 3,\n    fuzzyThreshold: 0.7,\n    maxResults: 10,\n  },\n};\n\n/**\n * Language-specific feature recommendations\n */\nexport const LANGUAGE_FEATURES: Record<string, FuzzyFeature[]> = {\n  german: [\n    //\n    \"phonetic\",\n    \"compound\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n    \"extra-letters\",\n  ],\n  english: [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n    \"transpositions\",\n  ],\n  spanish: [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n  ],\n  french: [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n  ],\n};\n\n/**\n * Merge user configuration with defaults\n */\nexport function mergeConfig(userConfig: Partial<FuzzyConfig> = {}): FuzzyConfig {\n  const baseConfig = { ...DEFAULT_CONFIG };\n\n  // Apply performance preset if specified\n  if (userConfig.performance && userConfig.performance !== \"balanced\") {\n    const performanceConfig = PERFORMANCE_CONFIGS[userConfig.performance];\n    Object.assign(baseConfig, performanceConfig);\n  }\n\n  // Apply user overrides\n  const mergedConfig = { ...baseConfig, ...userConfig };\n\n  // Auto-adjust features based on languages if not explicitly set\n  if (!userConfig.features && userConfig.languages) {\n    const recommendedFeatures = new Set<FuzzyFeature>();\n\n    for (const lang of userConfig.languages) {\n      const langFeatures = LANGUAGE_FEATURES[lang] || LANGUAGE_FEATURES.english;\n      langFeatures.forEach((feature) => recommendedFeatures.add(feature));\n    }\n\n    mergedConfig.features = Array.from(recommendedFeatures);\n  }\n\n  return mergedConfig;\n}\n\n/**\n * Validate configuration\n */\nexport function validateConfig(config: FuzzyConfig): void {\n  if (config.maxResults < 1) {\n    throw new Error(\"maxResults must be at least 1\");\n  }\n\n  if (config.minQueryLength < 1) {\n    throw new Error(\"minQueryLength must be at least 1\");\n  }\n\n  if (config.fuzzyThreshold < 0 || config.fuzzyThreshold > 1) {\n    throw new Error(\"fuzzyThreshold must be between 0 and 1\");\n  }\n\n  if (config.maxEditDistance < 0) {\n    throw new Error(\"maxEditDistance must be non-negative\");\n  }\n\n  if (config.ngramSize < 2) {\n    throw new Error(\"ngramSize must be at least 2\");\n  }\n\n  if (config.languages.length === 0) {\n    throw new Error(\"At least one language must be specified\");\n  }\n}\n","import type { LanguageProcessor, FuzzyFeature } from \"../../core/types.js\";\n\n/**\n * Abstract base class for language processors\n * Provides common functionality and enforces interface\n */\nexport abstract class BaseLanguageProcessor implements LanguageProcessor {\n  abstract readonly language: string;\n  abstract readonly displayName: string;\n  abstract readonly supportedFeatures: FuzzyFeature[];\n\n  /**\n   * Basic text normalization (override for language-specific behavior)\n   */\n  normalize(text: string): string {\n    return text.toLowerCase().trim().replace(/\\s+/g, \" \");\n  }\n\n  /**\n   * Default phonetic implementation (override for language-specific algorithms)\n   */\n  getPhoneticCode(word: string): string {\n    // Simple soundex-like algorithm as fallback\n    const normalized = this.normalize(word);\n    if (normalized.length === 0) return \"\";\n\n    let code = normalized[0].toUpperCase();\n    const consonantMap: Record<string, string> = {\n      b: \"1\",\n      f: \"1\",\n      p: \"1\",\n      v: \"1\",\n      c: \"2\",\n      g: \"2\",\n      j: \"2\",\n      k: \"2\",\n      q: \"2\",\n      s: \"2\",\n      x: \"2\",\n      z: \"2\",\n      d: \"3\",\n      t: \"3\",\n      l: \"4\",\n      m: \"5\",\n      n: \"5\",\n      r: \"6\",\n    };\n\n    for (let i = 1; i < normalized.length && code.length < 4; i++) {\n      const char = normalized[i];\n      const digit = consonantMap[char];\n      if (digit && digit !== code[code.length - 1]) {\n        code += digit;\n      }\n    }\n\n    return code.padEnd(4, \"0\");\n  }\n\n  /**\n   * Default compound word splitting (override for languages that support it)\n   */\n  splitCompoundWords(word: string): string[] {\n    return [word]; // No splitting by default\n  }\n\n  /**\n   * Generate common word variants\n   */\n  getWordVariants(word: string): string[] {\n    const variants = new Set<string>();\n    const normalized = this.normalize(word);\n\n    variants.add(normalized);\n    variants.add(word); // Original form\n\n    // Add variants without common endings\n    const commonEndings = this.getCommonEndings();\n    for (const ending of commonEndings) {\n      if (normalized.endsWith(ending) && normalized.length > ending.length + 2) {\n        variants.add(normalized.slice(0, -ending.length));\n      }\n    }\n\n    // Add partial variants for longer words\n    if (normalized.length > 4) {\n      for (let i = 3; i < normalized.length; i++) {\n        variants.add(normalized.slice(0, i));\n      }\n    }\n\n    return Array.from(variants);\n  }\n\n  /**\n   * Get common word endings for this language (override for language-specific endings)\n   */\n  protected getCommonEndings(): string[] {\n    return [\n      //\n      \"s\",\n      \"es\",\n      \"ed\",\n      \"ing\",\n      \"er\",\n      \"est\",\n    ];\n  }\n\n  /**\n   * Default synonym lookup (override to provide language-specific synonyms)\n   */\n  getSynonyms(_word: string): string[] {\n    return []; // No built-in synonyms by default\n  }\n\n  /**\n   * Check if two characters are keyboard neighbors\n   */\n  isValidSubstitution(char1: string, char2: string): boolean {\n    const keyboardNeighbors = this.getKeyboardNeighbors();\n    const neighbors = keyboardNeighbors[char1.toLowerCase()];\n    return neighbors ? neighbors.includes(char2.toLowerCase()) : false;\n  }\n\n  /**\n   * Get keyboard neighbor mappings (QWERTY layout by default)\n   */\n  protected getKeyboardNeighbors(): Record<string, string[]> {\n    return {\n      q: [\"w\", \"a\", \"s\"],\n      w: [\"q\", \"e\", \"a\", \"s\", \"d\"],\n      e: [\"w\", \"r\", \"s\", \"d\", \"f\"],\n      r: [\"e\", \"t\", \"d\", \"f\", \"g\"],\n      t: [\"r\", \"y\", \"f\", \"g\", \"h\"],\n      y: [\"t\", \"u\", \"g\", \"h\", \"j\"],\n      u: [\"y\", \"i\", \"h\", \"j\", \"k\"],\n      i: [\"u\", \"o\", \"j\", \"k\", \"l\"],\n      o: [\"i\", \"p\", \"k\", \"l\"],\n      p: [\"o\", \"l\"],\n      a: [\"q\", \"w\", \"s\", \"z\", \"x\"],\n      s: [\"q\", \"w\", \"e\", \"a\", \"d\", \"z\", \"x\", \"c\"],\n      d: [\"w\", \"e\", \"r\", \"s\", \"f\", \"x\", \"c\", \"v\"],\n      f: [\"e\", \"r\", \"t\", \"d\", \"g\", \"c\", \"v\", \"b\"],\n      g: [\"r\", \"t\", \"y\", \"f\", \"h\", \"v\", \"b\", \"n\"],\n      h: [\"t\", \"y\", \"u\", \"g\", \"j\", \"b\", \"n\", \"m\"],\n      j: [\"y\", \"u\", \"i\", \"h\", \"k\", \"n\", \"m\"],\n      k: [\"u\", \"i\", \"o\", \"j\", \"l\", \"m\"],\n      l: [\"i\", \"o\", \"p\", \"k\"],\n      z: [\"a\", \"s\", \"x\"],\n      x: [\"a\", \"s\", \"d\", \"z\", \"c\"],\n      c: [\"s\", \"d\", \"f\", \"x\", \"v\"],\n      v: [\"d\", \"f\", \"g\", \"c\", \"b\"],\n      b: [\"f\", \"g\", \"h\", \"v\", \"n\"],\n      n: [\"g\", \"h\", \"j\", \"b\", \"m\"],\n      m: [\"h\", \"j\", \"k\", \"n\"],\n    };\n  }\n\n  /**\n   * Generate n-grams for partial matching\n   */\n  generateNgrams(word: string, n: number = 3): string[] {\n    const normalized = this.normalize(word);\n    if (normalized.length < n) return [normalized];\n\n    const ngrams: string[] = [];\n    for (let i = 0; i <= normalized.length - n; i++) {\n      ngrams.push(normalized.slice(i, i + n));\n    }\n    return ngrams;\n  }\n\n  /**\n   * Calculate basic edit distance (Levenshtein)\n   */\n  calculateEditDistance(str1: string, str2: string): number {\n    const matrix: number[][] = [];\n    const len1 = str1.length;\n    const len2 = str2.length;\n\n    // Initialize matrix\n    for (let i = 0; i <= len1; i++) {\n      matrix[i] = [i];\n    }\n    for (let j = 0; j <= len2; j++) {\n      matrix[0][j] = j;\n    }\n\n    // Fill matrix\n    for (let i = 1; i <= len1; i++) {\n      for (let j = 1; j <= len2; j++) {\n        const cost = str1[i - 1] === str2[j - 1] ? 0 : 1;\n        matrix[i][j] = Math.min(\n          matrix[i - 1][j] + 1, // deletion\n          matrix[i][j - 1] + 1, // insertion\n          matrix[i - 1][j - 1] + cost // substitution\n        );\n      }\n    }\n\n    return matrix[len1][len2];\n  }\n}\n","import { BaseLanguageProcessor } from \"../base/LanguageProcessor.js\";\nimport type { FuzzyFeature } from \"../../core/types.js\";\n\n/**\n * German language processor with specialized features:\n * - Umlaut normalization (ä, ö, ü, ß)\n * - Compound word splitting\n * - German-specific phonetic matching (Kölner Phonetik)\n * - Common German word endings\n */\nexport class GermanProcessor extends BaseLanguageProcessor {\n  readonly language = \"german\";\n  readonly displayName = \"Deutsch\";\n  readonly supportedFeatures: FuzzyFeature[] = [\"phonetic\", \"compound\", \"synonyms\", \"keyboard-neighbors\", \"partial-words\", \"missing-letters\", \"extra-letters\"];\n\n  /**\n   * German text normalization with umlaut handling\n   */\n  normalize(text: string): string {\n    return (\n      text\n        .toLowerCase()\n        .trim()\n        .replace(/\\s+/g, \" \")\n        // Normalize umlauts\n        .replace(/ä/g, \"ae\")\n        .replace(/ö/g, \"oe\")\n        .replace(/ü/g, \"ue\")\n        .replace(/ß/g, \"ss\")\n    );\n  }\n\n  /**\n   * Kölner Phonetik algorithm for German phonetic matching\n   */\n  getPhoneticCode(word: string): string {\n    const normalized = this.normalize(word);\n    if (normalized.length === 0) return \"\";\n\n    let code = \"\";\n    let prev = \"\";\n\n    for (let i = 0; i < normalized.length; i++) {\n      const char = normalized[i];\n      const next = i < normalized.length - 1 ? normalized[i + 1] : \"\";\n      let digit = \"\";\n\n      switch (char) {\n        case \"a\":\n        case \"e\":\n        case \"i\":\n        case \"j\":\n        case \"o\":\n        case \"u\":\n        case \"y\":\n          digit = \"0\";\n          break;\n        case \"h\":\n          // H is ignored\n          continue;\n        case \"b\":\n        case \"p\":\n          digit = \"1\";\n          break;\n        case \"d\":\n        case \"t\":\n          if (next === \"c\" || next === \"s\" || next === \"z\") {\n            digit = \"8\";\n          } else {\n            digit = \"2\";\n          }\n          break;\n        case \"f\":\n        case \"v\":\n        case \"w\":\n          digit = \"3\";\n          break;\n        case \"g\":\n        case \"k\":\n        case \"q\":\n          digit = \"4\";\n          break;\n        case \"c\":\n          if (i === 0) {\n            if (next === \"a\" || next === \"h\" || next === \"k\" || next === \"l\" || next === \"o\" || next === \"q\" || next === \"r\" || next === \"u\" || next === \"x\") {\n              digit = \"4\";\n            } else {\n              digit = \"8\";\n            }\n          } else {\n            if (prev === \"s\" || prev === \"z\") {\n              digit = \"8\";\n            } else if (next === \"h\") {\n              digit = \"4\";\n            } else if (next === \"k\" || next === \"q\") {\n              digit = \"4\";\n            } else {\n              digit = \"8\";\n            }\n          }\n          break;\n        case \"x\":\n          if (prev === \"c\" || prev === \"k\" || prev === \"q\") {\n            digit = \"8\";\n          } else {\n            digit = \"48\";\n          }\n          break;\n        case \"l\":\n          digit = \"5\";\n          break;\n        case \"m\":\n        case \"n\":\n          digit = \"6\";\n          break;\n        case \"r\":\n          digit = \"7\";\n          break;\n        case \"s\":\n        case \"z\":\n          digit = \"8\";\n          break;\n        default:\n          continue;\n      }\n\n      // Don't add consecutive identical digits\n      if (digit && digit !== prev) {\n        code += digit;\n      }\n      prev = digit;\n    }\n\n    return code || \"0\";\n  }\n\n  /**\n   * German compound word splitting\n   * Uses common German compound patterns and a dictionary approach\n   */\n  splitCompoundWords(word: string): string[] {\n    const normalized = this.normalize(word);\n    if (normalized.length < 6) return [word]; // Too short to be compound\n\n    const parts: string[] = [];\n    const commonPrefixes = this.getCommonPrefixes();\n    const commonSuffixes = this.getCommonSuffixes();\n    const commonWords = this.getCommonWords();\n\n    // Try to find known prefixes\n    for (const prefix of commonPrefixes) {\n      if (normalized.startsWith(prefix) && normalized.length > prefix.length + 3) {\n        const remainder = normalized.slice(prefix.length);\n        parts.push(prefix);\n        parts.push(...this.splitCompoundWords(remainder));\n        break;\n      }\n    }\n\n    if (parts.length === 0) {\n      // Try to find known suffixes\n      for (const suffix of commonSuffixes) {\n        if (normalized.endsWith(suffix) && normalized.length > suffix.length + 3) {\n          const remainder = normalized.slice(0, -suffix.length);\n          parts.push(...this.splitCompoundWords(remainder));\n          parts.push(suffix);\n          break;\n        }\n      }\n    }\n\n    if (parts.length === 0) {\n      // Try to find known words within the compound\n      for (let i = 3; i <= normalized.length - 3; i++) {\n        const leftPart = normalized.slice(0, i);\n        const rightPart = normalized.slice(i);\n\n        if (commonWords.has(leftPart) && rightPart.length >= 3) {\n          parts.push(leftPart);\n          parts.push(...this.splitCompoundWords(rightPart));\n          break;\n        }\n      }\n    }\n\n    return parts.length > 0 ? parts : [word];\n  }\n\n  /**\n   * German word variants including common endings\n   */\n  getWordVariants(word: string): string[] {\n    const variants = new Set<string>();\n    const normalized = this.normalize(word);\n\n    variants.add(normalized);\n    variants.add(word);\n\n    // Add compound word parts\n    const compoundParts = this.splitCompoundWords(word);\n    compoundParts.forEach((part) => variants.add(this.normalize(part)));\n\n    // Add variants without German endings\n    const germanEndings = this.getCommonEndings();\n    for (const ending of germanEndings) {\n      if (normalized.endsWith(ending) && normalized.length > ending.length + 2) {\n        variants.add(normalized.slice(0, -ending.length));\n      }\n    }\n\n    // Add partial variants\n    if (normalized.length > 4) {\n      for (let i = 3; i < normalized.length; i++) {\n        variants.add(normalized.slice(0, i));\n      }\n    }\n\n    return Array.from(variants);\n  }\n\n  /**\n   * German word endings\n   */\n  protected getCommonEndings(): string[] {\n    return [\n      //\n      \"en\",\n      \"e\",\n      \"er\",\n      \"n\",\n      \"r\",\n      \"s\",\n      \"es\",\n      \"t\",\n      \"ung\",\n      \"heit\",\n      \"keit\",\n      \"schaft\",\n      \"chen\",\n      \"lein\",\n      \"lich\",\n      \"ig\",\n      \"isch\",\n      \"bar\",\n      \"los\",\n      \"voll\",\n    ];\n  }\n\n  /**\n   * German synonyms for common words\n   */\n  getSynonyms(word: string): string[] {\n    const synonymMap: Record<string, string[]> = {\n      arzt: [\n        //\n        \"doktor\",\n        \"mediziner\",\n        \"doc\",\n      ],\n      krankenhaus: [\n        //\n        \"spital\",\n        \"klinik\",\n        \"hospital\",\n      ],\n      schule: [\n        //\n        \"bildungseinrichtung\",\n        \"lehranstalt\",\n      ],\n      auto: [\n        //\n        \"wagen\",\n        \"fahrzeug\",\n        \"pkw\",\n      ],\n      haus: [\n        //\n        \"gebaeude\",\n        \"heim\",\n        \"wohnhaus\",\n      ],\n      strasse: [\n        //\n        \"weg\",\n        \"gasse\",\n        \"allee\",\n      ],\n      stadt: [\n        //\n        \"ort\",\n        \"gemeinde\",\n        \"ortschaft\",\n      ],\n      arbeit: [\n        //\n        \"job\",\n        \"beruf\",\n        \"taetigkeit\",\n      ],\n      geld: [\n        //\n        \"waehrung\",\n        \"kapital\",\n        \"finanzen\",\n      ],\n      zeit: [\n        //\n        \"dauer\",\n        \"periode\",\n        \"zeitraum\",\n      ],\n    };\n\n    const normalized = this.normalize(word);\n    return synonymMap[normalized] || [];\n  }\n\n  /**\n   * German keyboard layout (QWERTZ)\n   */\n  protected getKeyboardNeighbors(): Record<string, string[]> {\n    return {\n      q: [\n        //\n        \"w\",\n        \"a\",\n        \"s\",\n      ],\n      w: [\n        //\n        \"q\",\n        \"e\",\n        \"a\",\n        \"s\",\n        \"d\",\n      ],\n      e: [\n        //\n        \"w\",\n        \"r\",\n        \"s\",\n        \"d\",\n        \"f\",\n      ],\n      r: [\n        //\n        \"e\",\n        \"t\",\n        \"d\",\n        \"f\",\n        \"g\",\n      ],\n      t: [\n        //\n        \"r\",\n        \"z\",\n        \"f\",\n        \"g\",\n        \"h\",\n      ],\n      z: [\n        //\n        \"t\",\n        \"u\",\n        \"g\",\n        \"h\",\n        \"j\",\n      ], // QWERTZ difference\n      u: [\n        //\n        \"z\",\n        \"i\",\n        \"h\",\n        \"j\",\n        \"k\",\n      ],\n      i: [\n        //\n        \"u\",\n        \"o\",\n        \"j\",\n        \"k\",\n        \"l\",\n      ],\n      o: [\n        //\n        \"i\",\n        \"p\",\n        \"k\",\n        \"l\",\n        \"oe\",\n      ],\n      p: [\n        //\n        \"o\",\n        \"ue\",\n        \"l\",\n        \"oe\",\n      ],\n      ue: [\n        //\n        \"p\",\n        \"ae\",\n      ], // German umlaut\n      a: [\n        //\n        \"q\",\n        \"w\",\n        \"s\",\n        \"y\",\n        \"x\",\n      ],\n      s: [\n        //\n        \"q\",\n        \"w\",\n        \"e\",\n        \"a\",\n        \"d\",\n        \"y\",\n        \"x\",\n        \"c\",\n      ],\n      d: [\n        //\n        \"w\",\n        \"e\",\n        \"r\",\n        \"s\",\n        \"f\",\n        \"x\",\n        \"c\",\n        \"v\",\n      ],\n      f: [\n        //\n        \"e\",\n        \"r\",\n        \"t\",\n        \"d\",\n        \"g\",\n        \"c\",\n        \"v\",\n        \"b\",\n      ],\n      g: [\n        //\n        \"r\",\n        \"t\",\n        \"z\",\n        \"f\",\n        \"h\",\n        \"v\",\n        \"b\",\n        \"n\",\n      ],\n      h: [\n        //\n        \"t\",\n        \"z\",\n        \"u\",\n        \"g\",\n        \"j\",\n        \"b\",\n        \"n\",\n        \"m\",\n      ],\n      j: [\n        //\n        \"z\",\n        \"u\",\n        \"i\",\n        \"h\",\n        \"k\",\n        \"n\",\n        \"m\",\n      ],\n      k: [\n        //\n        \"u\",\n        \"i\",\n        \"o\",\n        \"j\",\n        \"l\",\n        \"m\",\n      ],\n      l: [\n        //\n        \"i\",\n        \"o\",\n        \"p\",\n        \"k\",\n        \"oe\",\n      ],\n      oe: [\n        //\n        \"o\",\n        \"p\",\n        \"ue\",\n        \"l\",\n        \"ae\",\n      ], // German umlaut\n      ae: [\n        //\n        \"ue\",\n        \"oe\",\n      ], // German umlaut\n      y: [\n        //\n        \"a\",\n        \"s\",\n        \"x\",\n      ], // QWERTZ difference\n      x: [\n        //\n        \"a\",\n        \"s\",\n        \"d\",\n        \"y\",\n        \"c\",\n      ],\n      c: [\n        //\n        \"s\",\n        \"d\",\n        \"f\",\n        \"x\",\n        \"v\",\n      ],\n      v: [\n        //\n        \"d\",\n        \"f\",\n        \"g\",\n        \"c\",\n        \"b\",\n      ],\n      b: [\n        //\n        \"f\",\n        \"g\",\n        \"h\",\n        \"v\",\n        \"n\",\n      ],\n      n: [\n        //\n        \"g\",\n        \"h\",\n        \"j\",\n        \"b\",\n        \"m\",\n      ],\n      m: [\n        //\n        \"h\",\n        \"j\",\n        \"k\",\n        \"n\",\n      ],\n    };\n  }\n\n  /**\n   * Common German prefixes for compound word splitting\n   */\n  private getCommonPrefixes(): string[] {\n    return [\"un\", \"vor\", \"nach\", \"bei\", \"mit\", \"ab\", \"an\", \"auf\", \"aus\", \"ein\", \"gegen\", \"hinter\", \"neben\", \"ueber\", \"unter\", \"zwischen\", \"selbst\"];\n  }\n\n  /**\n   * Common German suffixes for compound word splitting\n   */\n  private getCommonSuffixes(): string[] {\n    return [\"haus\", \"platz\", \"strasse\", \"weg\", \"hof\", \"berg\", \"tal\", \"feld\", \"stadt\", \"dorf\", \"heim\", \"werk\", \"bau\", \"anlage\", \"zentrum\"];\n  }\n\n  /**\n   * Common German words for compound splitting\n   */\n  private getCommonWords(): Set<string> {\n    return new Set([\"kranken\", \"kinder\", \"frauen\", \"maenner\", \"alt\", \"neu\", \"gross\", \"klein\", \"hoch\", \"tief\", \"lang\", \"kurz\", \"breit\", \"schmal\", \"dick\", \"duenn\", \"stark\", \"schwach\", \"schnell\", \"langsam\", \"heiss\", \"kalt\", \"warm\", \"auto\", \"bahn\", \"bus\", \"zug\", \"flug\", \"schiff\", \"rad\", \"motor\", \"wasser\", \"feuer\", \"erde\", \"luft\", \"licht\", \"schatten\", \"sonne\", \"mond\", \"tag\", \"nacht\", \"morgen\", \"abend\", \"mittag\", \"zeit\", \"jahr\", \"monat\"]);\n  }\n}\n","import { BaseLanguageProcessor } from \"../base/LanguageProcessor.js\";\nimport type { FuzzyFeature } from \"../../core/types.js\";\n\n/**\n * English language processor with specialized features:\n * - Metaphone phonetic algorithm\n * - Common English contractions\n * - English-specific word endings\n * - Comprehensive synonym support\n */\nexport class EnglishProcessor extends BaseLanguageProcessor {\n  readonly language = \"english\";\n  readonly displayName = \"English\";\n  readonly supportedFeatures: FuzzyFeature[] = [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n    \"extra-letters\",\n    \"transpositions\",\n  ];\n\n  /**\n   * English text normalization with contraction handling\n   */\n  normalize(text: string): string {\n    return (\n      text\n        .toLowerCase()\n        .trim()\n        .replace(/\\s+/g, \" \")\n        // Handle common contractions\n        .replace(/won't/g, \"will not\")\n        .replace(/can't/g, \"cannot\")\n        .replace(/n't/g, \" not\")\n        .replace(/'re/g, \" are\")\n        .replace(/'ve/g, \" have\")\n        .replace(/'ll/g, \" will\")\n        .replace(/'d/g, \" would\")\n        .replace(/'m/g, \" am\")\n        .replace(/'/g, \"\")\n    ); // Remove remaining apostrophes\n  }\n\n  /**\n   * Simplified Metaphone algorithm for English phonetic matching\n   */\n  getPhoneticCode(word: string): string {\n    const normalized = this.normalize(word).replace(/[^a-z]/g, \"\");\n    if (normalized.length === 0) return \"\";\n\n    let metaphone = \"\";\n    let current = 0;\n    const length = normalized.length;\n\n    // Handle initial letters\n    if (normalized.startsWith(\"gn\") || normalized.startsWith(\"kn\") || normalized.startsWith(\"pn\") || normalized.startsWith(\"wr\")) {\n      current = 1;\n    }\n\n    while (current < length && metaphone.length < 4) {\n      const char = normalized[current];\n      const next = current + 1 < length ? normalized[current + 1] : \"\";\n      const prev = current > 0 ? normalized[current - 1] : \"\";\n\n      switch (char) {\n        case \"a\":\n        case \"e\":\n        case \"i\":\n        case \"o\":\n        case \"u\":\n          if (current === 0) metaphone += char.toUpperCase();\n          break;\n        case \"b\":\n          if (current === length - 1 && prev === \"m\") {\n            // Silent B at end after M\n          } else {\n            metaphone += \"B\";\n          }\n          break;\n        case \"c\":\n          if (next === \"h\") {\n            metaphone += \"X\";\n            current++;\n          } else if (next === \"i\" || next === \"e\" || next === \"y\") {\n            metaphone += \"S\";\n          } else {\n            metaphone += \"K\";\n          }\n          break;\n        case \"d\":\n          if (next === \"g\") {\n            metaphone += \"J\";\n            current++;\n          } else {\n            metaphone += \"T\";\n          }\n          break;\n        case \"f\":\n          metaphone += \"F\";\n          break;\n        case \"g\":\n          if (next === \"h\" && current !== 0) {\n            // Silent GH\n          } else if (next === \"n\") {\n            metaphone += \"N\";\n            current++;\n          } else if (next === \"i\" || next === \"e\" || next === \"y\") {\n            metaphone += \"J\";\n          } else {\n            metaphone += \"K\";\n          }\n          break;\n        case \"h\":\n          if (current === 0 || \"aeiou\".includes(prev) || \"aeiou\".includes(next)) {\n            metaphone += \"H\";\n          }\n          break;\n        case \"j\":\n          metaphone += \"J\";\n          break;\n        case \"k\":\n          if (prev !== \"c\") {\n            metaphone += \"K\";\n          }\n          break;\n        case \"l\":\n          metaphone += \"L\";\n          break;\n        case \"m\":\n          metaphone += \"M\";\n          break;\n        case \"n\":\n          metaphone += \"N\";\n          break;\n        case \"p\":\n          if (next === \"h\") {\n            metaphone += \"F\";\n            current++;\n          } else {\n            metaphone += \"P\";\n          }\n          break;\n        case \"q\":\n          metaphone += \"K\";\n          break;\n        case \"r\":\n          metaphone += \"R\";\n          break;\n        case \"s\":\n          if (next === \"h\") {\n            metaphone += \"X\";\n            current++;\n          } else {\n            metaphone += \"S\";\n          }\n          break;\n        case \"t\":\n          if (next === \"h\") {\n            metaphone += \"0\";\n            current++;\n          } else if (next === \"i\" && current + 2 < length && (normalized[current + 2] === \"a\" || normalized[current + 2] === \"o\")) {\n            metaphone += \"X\";\n          } else {\n            metaphone += \"T\";\n          }\n          break;\n        case \"v\":\n          metaphone += \"F\";\n          break;\n        case \"w\":\n          if (\"aeiou\".includes(next)) {\n            metaphone += \"W\";\n          }\n          break;\n        case \"x\":\n          metaphone += \"KS\";\n          break;\n        case \"y\":\n          if (\"aeiou\".includes(next)) {\n            metaphone += \"Y\";\n          }\n          break;\n        case \"z\":\n          metaphone += \"S\";\n          break;\n      }\n      current++;\n    }\n\n    return metaphone || \"A\";\n  }\n\n  /**\n   * English word variants\n   */\n  getWordVariants(word: string): string[] {\n    const variants = new Set<string>();\n    const normalized = this.normalize(word);\n\n    variants.add(normalized);\n    variants.add(word);\n\n    // Add variants without English endings\n    const englishEndings = this.getCommonEndings();\n    for (const ending of englishEndings) {\n      if (normalized.endsWith(ending) && normalized.length > ending.length + 2) {\n        variants.add(normalized.slice(0, -ending.length));\n      }\n    }\n\n    // Add plural/singular variants\n    if (normalized.endsWith(\"s\") && normalized.length > 3) {\n      variants.add(normalized.slice(0, -1));\n    }\n    if (!normalized.endsWith(\"s\")) {\n      variants.add(normalized + \"s\");\n    }\n\n    // Add -ing/-ed variants\n    if (normalized.endsWith(\"ing\") && normalized.length > 5) {\n      const base = normalized.slice(0, -3);\n      variants.add(base);\n      variants.add(base + \"e\"); // handle dropped 'e'\n    }\n    if (normalized.endsWith(\"ed\") && normalized.length > 4) {\n      const base = normalized.slice(0, -2);\n      variants.add(base);\n      variants.add(base + \"e\"); // handle dropped 'e'\n    }\n\n    // Add partial variants\n    if (normalized.length > 4) {\n      for (let i = 3; i < normalized.length; i++) {\n        variants.add(normalized.slice(0, i));\n      }\n    }\n\n    return Array.from(variants);\n  }\n\n  /**\n   * English word endings\n   */\n  protected getCommonEndings(): string[] {\n    return [\n      //\n      \"s\",\n      \"es\",\n      \"ed\",\n      \"ing\",\n      \"er\",\n      \"est\",\n      \"ly\",\n      \"tion\",\n      \"sion\",\n      \"ness\",\n      \"ment\",\n      \"able\",\n      \"ible\",\n      \"ful\",\n      \"less\",\n      \"ous\",\n      \"ious\",\n      \"al\",\n      \"ial\",\n      \"ic\",\n      \"ive\",\n      \"ary\",\n      \"ery\",\n      \"ory\",\n    ];\n  }\n\n  /**\n   * English synonyms for common words\n   */\n  getSynonyms(word: string): string[] {\n    const synonymMap: Record<string, string[]> = {\n      doctor: [\n        //\n        \"physician\",\n        \"medic\",\n        \"doc\",\n        \"md\",\n      ],\n      hospital: [\n        //\n        \"clinic\",\n        \"medical center\",\n        \"infirmary\",\n      ],\n      school: [\n        //\n        \"academy\",\n        \"institution\",\n        \"college\",\n        \"university\",\n      ],\n      car: [\n        //\n        \"vehicle\",\n        \"automobile\",\n        \"auto\",\n      ],\n      house: [\n        //\n        \"home\",\n        \"residence\",\n        \"dwelling\",\n        \"building\",\n      ],\n      street: [\n        //\n        \"road\",\n        \"avenue\",\n        \"lane\",\n        \"boulevard\",\n      ],\n      city: [\n        //\n        \"town\",\n        \"municipality\",\n        \"urban area\",\n      ],\n      work: [\n        //\n        \"job\",\n        \"employment\",\n        \"occupation\",\n        \"career\",\n      ],\n      money: [\n        //\n        \"cash\",\n        \"currency\",\n        \"funds\",\n        \"capital\",\n      ],\n      time: [\n        //\n        \"duration\",\n        \"period\",\n        \"moment\",\n        \"hour\",\n      ],\n      big: [\n        //\n        \"large\",\n        \"huge\",\n        \"enormous\",\n        \"massive\",\n        \"giant\",\n      ],\n      small: [\n        //\n        \"little\",\n        \"tiny\",\n        \"miniature\",\n        \"petite\",\n      ],\n      fast: [\n        //\n        \"quick\",\n        \"rapid\",\n        \"speedy\",\n        \"swift\",\n      ],\n      slow: [\n        //\n        \"sluggish\",\n        \"gradual\",\n        \"leisurely\",\n      ],\n      good: [\n        //\n        \"excellent\",\n        \"great\",\n        \"wonderful\",\n        \"fine\",\n      ],\n      bad: [\n        //\n        \"poor\",\n        \"terrible\",\n        \"awful\",\n        \"horrible\",\n      ],\n      happy: [\n        //\n        \"joyful\",\n        \"cheerful\",\n        \"glad\",\n        \"pleased\",\n      ],\n      sad: [\n        //\n        \"unhappy\",\n        \"depressed\",\n        \"melancholy\",\n        \"sorrowful\",\n      ],\n    };\n\n    const normalized = this.normalize(word);\n    return synonymMap[normalized] || [];\n  }\n}\n","import { BaseLanguageProcessor } from \"../base/LanguageProcessor.js\";\nimport type { FuzzyFeature } from \"../../core/types.js\";\n\n/**\n * Spanish language processor with specialized features:\n * - Accent normalization (á, é, í, ó, ú, ñ)\n * - Spanish phonetic patterns\n * - Common Spanish word endings\n * - Spanish synonym support\n */\nexport class SpanishProcessor extends BaseLanguageProcessor {\n  readonly language = \"spanish\";\n  readonly displayName = \"Español\";\n  readonly supportedFeatures: FuzzyFeature[] = [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n    \"extra-letters\",\n  ];\n\n  /**\n   * Spanish text normalization with accent handling\n   */\n  normalize(text: string): string {\n    return (\n      text\n        .toLowerCase()\n        .trim()\n        .replace(/\\s+/g, \" \")\n        // Normalize accented characters\n        .replace(/á/g, \"a\")\n        .replace(/é/g, \"e\")\n        .replace(/í/g, \"i\")\n        .replace(/ó/g, \"o\")\n        .replace(/ú/g, \"u\")\n        .replace(/ñ/g, \"n\")\n        .replace(/ü/g, \"u\")\n    );\n  }\n\n  /**\n   * Spanish phonetic matching\n   */\n  getPhoneticCode(word: string): string {\n    const normalized = this.normalize(word);\n    if (normalized.length === 0) return \"\";\n\n    let code = \"\";\n    let prev = \"\";\n\n    for (let i = 0; i < normalized.length; i++) {\n      const char = normalized[i];\n      const next = i < normalized.length - 1 ? normalized[i + 1] : \"\";\n      let digit = \"\";\n\n      switch (char) {\n        case \"a\":\n        case \"e\":\n        case \"i\":\n        case \"o\":\n        case \"u\":\n          digit = \"0\";\n          break;\n        case \"b\":\n        case \"v\": // B and V sound similar in Spanish\n          digit = \"1\";\n          break;\n        case \"c\":\n          if (next === \"h\") {\n            digit = \"2\"; // CH sound\n          } else if (next === \"e\" || next === \"i\") {\n            digit = \"8\"; // CE, CI sounds like S\n          } else {\n            digit = \"4\";\n          }\n          break;\n        case \"d\":\n          digit = \"3\";\n          break;\n        case \"f\":\n          digit = \"5\";\n          break;\n        case \"g\":\n          if (next === \"u\" && i + 2 < normalized.length && (normalized[i + 2] === \"e\" || normalized[i + 2] === \"i\")) {\n            digit = \"4\"; // GUE, GUI\n          } else if (next === \"e\" || next === \"i\") {\n            digit = \"6\"; // GE, GI sound like J\n          } else {\n            digit = \"4\";\n          }\n          break;\n        case \"h\":\n          // H is silent in Spanish\n          continue;\n        case \"j\":\n          digit = \"6\";\n          break;\n        case \"k\":\n          digit = \"4\";\n          break;\n        case \"l\":\n          if (next === \"l\") {\n            digit = \"7\"; // LL sound\n          } else {\n            digit = \"5\";\n          }\n          break;\n        case \"m\":\n          digit = \"6\";\n          break;\n        case \"n\":\n          if (next === \"n\") {\n            digit = \"7\"; // NN sound (rare)\n          } else {\n            digit = \"6\";\n          }\n          break;\n        case \"ñ\":\n          digit = \"7\"; // Ñ sound\n          break;\n        case \"p\":\n          digit = \"1\";\n          break;\n        case \"q\":\n          digit = \"4\";\n          break;\n        case \"r\":\n          if (next === \"r\" || i === 0) {\n            digit = \"8\"; // RR or initial R\n          } else {\n            digit = \"7\";\n          }\n          break;\n        case \"s\":\n          digit = \"8\";\n          break;\n        case \"t\":\n          digit = \"3\";\n          break;\n        case \"w\":\n          digit = \"1\"; // Rare in Spanish\n          break;\n        case \"x\":\n          digit = \"48\";\n          break;\n        case \"y\":\n          digit = \"7\";\n          break;\n        case \"z\":\n          digit = \"8\";\n          break;\n        default:\n          continue;\n      }\n\n      if (digit && digit !== prev) {\n        code += digit;\n      }\n      prev = digit;\n    }\n\n    return code || \"0\";\n  }\n\n  /**\n   * Spanish word endings\n   */\n  protected getCommonEndings(): string[] {\n    return [\n      //\n      \"o\",\n      \"a\",\n      \"os\",\n      \"as\",\n      \"e\",\n      \"es\",\n      \"ar\",\n      \"er\",\n      \"ir\",\n      \"ado\",\n      \"ada\",\n      \"idos\",\n      \"idas\",\n      \"ando\",\n      \"endo\",\n      \"iendo\",\n      \"cion\",\n      \"sion\",\n      \"dad\",\n      \"tad\",\n      \"mente\",\n      \"oso\",\n      \"osa\",\n      \"ito\",\n      \"ita\",\n      \"illo\",\n      \"illa\",\n    ];\n  }\n\n  /**\n   * Spanish synonyms\n   */\n  getSynonyms(word: string): string[] {\n    const synonymMap: Record<string, string[]> = {\n      medico: [\n        //\n        \"doctor\",\n        \"facultativo\",\n      ],\n      hospital: [\n        //\n        \"clinica\",\n        \"sanatorio\",\n      ],\n      escuela: [\n        //\n        \"colegio\",\n        \"instituto\",\n      ],\n      coche: [\n        //\n        \"auto\",\n        \"automovil\",\n        \"vehiculo\",\n      ],\n      casa: [\n        //\n        \"hogar\",\n        \"vivienda\",\n        \"domicilio\",\n      ],\n      calle: [\n        //\n        \"via\",\n        \"avenida\",\n        \"carretera\",\n      ],\n      ciudad: [\n        //\n        \"urbe\",\n        \"poblacion\",\n        \"municipio\",\n      ],\n      trabajo: [\n        //\n        \"empleo\",\n        \"ocupacion\",\n        \"labor\",\n      ],\n      dinero: [\n        //\n        \"plata\",\n        \"efectivo\",\n        \"capital\",\n      ],\n      tiempo: [\n        //\n        \"momento\",\n        \"periodo\",\n        \"duracion\",\n      ],\n      grande: [\n        //\n        \"enorme\",\n        \"gigante\",\n        \"inmenso\",\n      ],\n      pequeno: [\n        //\n        \"chico\",\n        \"diminuto\",\n        \"minusculo\",\n      ],\n      rapido: [\n        //\n        \"veloz\",\n        \"ligero\",\n        \"acelerado\",\n      ],\n      lento: [\n        //\n        \"despacio\",\n        \"pausado\",\n      ],\n      bueno: [\n        //\n        \"excelente\",\n        \"magnifico\",\n        \"estupendo\",\n      ],\n      malo: [\n        //\n        \"pesimo\",\n        \"terrible\",\n        \"horrible\",\n      ],\n    };\n\n    const normalized = this.normalize(word);\n    return synonymMap[normalized] || [];\n  }\n}\n","import { BaseLanguageProcessor } from \"../base/LanguageProcessor.js\";\nimport type { FuzzyFeature } from \"../../core/types.js\";\n\n/**\n * French language processor with specialized features:\n * - Accent normalization (à, é, è, ê, ç, etc.)\n * - French phonetic patterns\n * - Common French word endings\n * - French synonym support\n */\nexport class FrenchProcessor extends BaseLanguageProcessor {\n  readonly language = \"french\";\n  readonly displayName = \"Français\";\n  readonly supportedFeatures: FuzzyFeature[] = [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n    \"extra-letters\",\n  ];\n\n  /**\n   * French text normalization with accent handling\n   */\n  normalize(text: string): string {\n    return (\n      text\n        .toLowerCase()\n        .trim()\n        .replace(/\\s+/g, \" \")\n        // Normalize accented characters\n        .replace(/[àáâãä]/g, \"a\")\n        .replace(/[èéêë]/g, \"e\")\n        .replace(/[ìíîï]/g, \"i\")\n        .replace(/[òóôõö]/g, \"o\")\n        .replace(/[ùúûü]/g, \"u\")\n        .replace(/ç/g, \"c\")\n        .replace(/ñ/g, \"n\")\n        .replace(/ÿ/g, \"y\")\n    );\n  }\n\n  /**\n   * French phonetic matching\n   */\n  getPhoneticCode(word: string): string {\n    const normalized = this.normalize(word);\n    if (normalized.length === 0) return \"\";\n\n    let code = \"\";\n    let prev = \"\";\n\n    for (let i = 0; i < normalized.length; i++) {\n      const char = normalized[i];\n      const next = i < normalized.length - 1 ? normalized[i + 1] : \"\";\n      const next2 = i < normalized.length - 2 ? normalized[i + 2] : \"\";\n      let digit = \"\";\n\n      switch (char) {\n        case \"a\":\n        case \"e\":\n        case \"i\":\n        case \"o\":\n        case \"u\":\n        case \"y\":\n          digit = \"0\";\n          break;\n        case \"b\":\n          digit = \"1\";\n          break;\n        case \"c\":\n          if (next === \"h\") {\n            digit = \"2\"; // CH sound\n          } else if (next === \"e\" || next === \"i\") {\n            digit = \"8\"; // CE, CI sounds like S\n          } else {\n            digit = \"4\";\n          }\n          break;\n        case \"d\":\n          digit = \"3\";\n          break;\n        case \"f\":\n          digit = \"5\";\n          break;\n        case \"g\":\n          if (next === \"n\") {\n            digit = \"6\"; // GN sound\n          } else if (next === \"u\" && (next2 === \"e\" || next2 === \"i\")) {\n            digit = \"4\"; // GUE, GUI\n          } else if (next === \"e\" || next === \"i\") {\n            digit = \"6\"; // GE, GI sound like J\n          } else {\n            digit = \"4\";\n          }\n          break;\n        case \"h\":\n          // H is often silent in French\n          if (i === 0) {\n            digit = \"0\"; // Initial H\n          }\n          break;\n        case \"j\":\n          digit = \"6\";\n          break;\n        case \"k\":\n          digit = \"4\";\n          break;\n        case \"l\":\n          digit = \"5\";\n          break;\n        case \"m\":\n          digit = \"6\";\n          break;\n        case \"n\":\n          digit = \"6\";\n          break;\n        case \"p\":\n          if (next === \"h\") {\n            digit = \"5\"; // PH sounds like F\n          } else {\n            digit = \"1\";\n          }\n          break;\n        case \"q\":\n          digit = \"4\";\n          break;\n        case \"r\":\n          digit = \"7\";\n          break;\n        case \"s\":\n          digit = \"8\";\n          break;\n        case \"t\":\n          if (next === \"h\") {\n            digit = \"3\"; // TH sound\n          } else {\n            digit = \"3\";\n          }\n          break;\n        case \"v\":\n          digit = \"5\";\n          break;\n        case \"w\":\n          digit = \"5\"; // Rare in French\n          break;\n        case \"x\":\n          digit = \"48\";\n          break;\n        case \"z\":\n          digit = \"8\";\n          break;\n        default:\n          continue;\n      }\n\n      if (digit && digit !== prev) {\n        code += digit;\n      }\n      prev = digit;\n    }\n\n    return code || \"0\";\n  }\n\n  /**\n   * French word endings\n   */\n  protected getCommonEndings(): string[] {\n    return [\"e\", \"es\", \"s\", \"x\", \"ent\", \"ant\", \"ment\", \"tion\", \"sion\", \"eur\", \"euse\", \"teur\", \"trice\", \"able\", \"ible\", \"ique\", \"aire\", \"oire\", \"ette\", \"elle\", \"esse\", \"asse\", \"isse\", \"age\", \"isme\", \"iste\", \"ite\", \"ude\", \"ade\"];\n  }\n\n  /**\n   * French synonyms\n   */\n  getSynonyms(word: string): string[] {\n    const synonymMap: Record<string, string[]> = {\n      medecin: [\n        //\n        \"docteur\",\n        \"praticien\",\n      ],\n      hopital: [\n        //\n        \"clinique\",\n        \"centre medical\",\n      ],\n      ecole: [\n        //\n        \"etablissement\",\n        \"institution\",\n      ],\n      voiture: [\n        //\n        \"automobile\",\n        \"vehicule\",\n        \"auto\",\n      ],\n      maison: [\n        //\n        \"domicile\",\n        \"residence\",\n        \"habitation\",\n      ],\n      rue: [\n        //\n        \"avenue\",\n        \"boulevard\",\n        \"voie\",\n      ],\n      ville: [\n        //\n        \"cite\",\n        \"commune\",\n        \"agglomeration\",\n      ],\n      travail: [\n        //\n        \"emploi\",\n        \"occupation\",\n        \"metier\",\n      ],\n      argent: [\n        //\n        \"monnaie\",\n        \"especes\",\n        \"capital\",\n      ],\n      temps: [\n        //\n        \"duree\",\n        \"periode\",\n        \"moment\",\n      ],\n      grand: [\n        //\n        \"enorme\",\n        \"immense\",\n        \"gigantesque\",\n      ],\n      petit: [\n        //\n        \"minuscule\",\n        \"minime\",\n        \"reduit\",\n      ],\n      rapide: [\n        //\n        \"vite\",\n        \"accelere\",\n        \"prompt\",\n      ],\n      lent: [\n        //\n        \"lentement\",\n        \"doucement\",\n      ],\n      bon: [\n        //\n        \"excellent\",\n        \"parfait\",\n        \"formidable\",\n      ],\n      mauvais: [\n        //\n        \"terrible\",\n        \"affreux\",\n        \"horrible\",\n      ],\n      heureux: [\n        //\n        \"joyeux\",\n        \"content\",\n        \"ravi\",\n      ],\n      triste: [\n        //\n        \"malheureux\",\n        \"chagrine\",\n        \"melancolique\",\n      ],\n    };\n\n    const normalized = this.normalize(word);\n    return synonymMap[normalized] || [];\n  }\n\n  /**\n   * French keyboard layout (AZERTY)\n   */\n  protected getKeyboardNeighbors(): Record<string, string[]> {\n    return {\n      a: [\n        //\n        \"z\",\n        \"e\",\n        \"r\",\n        \"q\",\n        \"s\",\n      ],\n      z: [\n        //\n        \"a\",\n        \"e\",\n        \"r\",\n        \"q\",\n        \"s\",\n        \"d\",\n      ],\n      e: [\n        //\n        \"z\",\n        \"r\",\n        \"t\",\n        \"s\",\n        \"d\",\n        \"f\",\n      ],\n      r: [\n        //\n        \"e\",\n        \"t\",\n        \"y\",\n        \"d\",\n        \"f\",\n        \"g\",\n      ],\n      t: [\n        //\n        \"r\",\n        \"y\",\n        \"u\",\n        \"f\",\n        \"g\",\n        \"h\",\n      ],\n      y: [\n        //\n        \"t\",\n        \"u\",\n        \"i\",\n        \"g\",\n        \"h\",\n        \"j\",\n      ],\n      u: [\n        //\n        \"y\",\n        \"i\",\n        \"o\",\n        \"h\",\n        \"j\",\n        \"k\",\n      ],\n      i: [\n        //\n        \"u\",\n        \"o\",\n        \"p\",\n        \"j\",\n        \"k\",\n        \"l\",\n      ],\n      o: [\n        //\n        \"i\",\n        \"p\",\n        \"k\",\n        \"l\",\n        \"m\",\n      ],\n      p: [\n        //\n        \"o\",\n        \"l\",\n        \"m\",\n      ],\n      q: [\n        //\n        \"a\",\n        \"z\",\n        \"s\",\n        \"w\",\n        \"x\",\n      ],\n      s: [\n        //\n        \"a\",\n        \"z\",\n        \"e\",\n        \"q\",\n        \"d\",\n        \"w\",\n        \"x\",\n        \"c\",\n      ],\n      d: [\n        //\n        \"z\",\n        \"e\",\n        \"r\",\n        \"s\",\n        \"f\",\n        \"x\",\n        \"c\",\n        \"v\",\n      ],\n      f: [\n        //\n        \"e\",\n        \"r\",\n        \"t\",\n        \"d\",\n        \"g\",\n        \"c\",\n        \"v\",\n        \"b\",\n      ],\n      g: [\n        //\n        \"r\",\n        \"t\",\n        \"y\",\n        \"f\",\n        \"h\",\n        \"v\",\n        \"b\",\n        \"n\",\n      ],\n      h: [\n        //\n        \"t\",\n        \"y\",\n        \"u\",\n        \"g\",\n        \"j\",\n        \"b\",\n        \"n\",\n      ],\n      j: [\n        //\n        \"y\",\n        \"u\",\n        \"i\",\n        \"h\",\n        \"k\",\n        \"n\",\n      ],\n      k: [\n        //\n        \"u\",\n        \"i\",\n        \"o\",\n        \"j\",\n        \"l\",\n      ],\n      l: [\n        //\n        \"i\",\n        \"o\",\n        \"p\",\n        \"k\",\n        \"m\",\n      ],\n      m: [\n        //\n        \"o\",\n        \"p\",\n        \"l\",\n      ],\n      w: [\n        //\n        \"q\",\n        \"s\",\n        \"x\",\n      ],\n      x: [\n        //\n        \"q\",\n        \"s\",\n        \"d\",\n        \"w\",\n        \"c\",\n      ],\n      c: [\n        //\n        \"s\",\n        \"d\",\n        \"f\",\n        \"x\",\n        \"v\",\n      ],\n      v: [\n        //\n        \"d\",\n        \"f\",\n        \"g\",\n        \"c\",\n        \"b\",\n      ],\n      b: [\n        //\n        \"f\",\n        \"g\",\n        \"h\",\n        \"v\",\n        \"n\",\n      ],\n      n: [\n        //\n        \"g\",\n        \"h\",\n        \"j\",\n        \"b\",\n      ],\n    };\n  }\n}\n","import type { LanguageProcessor } from \"../core/types.js\";\nimport { GermanProcessor } from \"./german/GermanProcessor.js\";\nimport { EnglishProcessor } from \"./english/EnglishProcessor.js\";\nimport { SpanishProcessor } from \"./spanish/SpanishProcessor.js\";\nimport { FrenchProcessor } from \"./french/FrenchProcessor.js\";\n\n/**\n * Registry of all available language processors\n */\nexport class LanguageRegistry {\n  private static processors = new Map<string, LanguageProcessor>([\n    [\"german\", new GermanProcessor()],\n    [\"english\", new EnglishProcessor()],\n    [\"spanish\", new SpanishProcessor()],\n    [\"french\", new FrenchProcessor()],\n  ]);\n\n  /**\n   * Get a language processor by name\n   */\n  static getProcessor(language: string): LanguageProcessor | undefined {\n    return this.processors.get(language.toLowerCase());\n  }\n\n  /**\n   * Get multiple language processors\n   */\n  static getProcessors(languages: string[]): LanguageProcessor[] {\n    return languages.map((lang) => this.getProcessor(lang)).filter((processor): processor is LanguageProcessor => processor !== undefined);\n  }\n\n  /**\n   * Get all available language names\n   */\n  static getAvailableLanguages(): string[] {\n    return Array.from(this.processors.keys());\n  }\n\n  /**\n   * Register a custom language processor\n   */\n  static registerProcessor(processor: LanguageProcessor): void {\n    this.processors.set(processor.language.toLowerCase(), processor);\n  }\n\n  /**\n   * Check if a language is supported\n   */\n  static isSupported(language: string): boolean {\n    return this.processors.has(language.toLowerCase());\n  }\n\n  /**\n   * Get processor info for all languages\n   */\n  static getProcessorInfo(): Array<{\n    language: string;\n    displayName: string;\n    supportedFeatures: string[];\n  }> {\n    return Array.from(this.processors.values()).map((processor) => ({\n      language: processor.language,\n      displayName: processor.displayName,\n      supportedFeatures: processor.supportedFeatures,\n    }));\n  }\n}\n\n// Export individual processors for direct use\nexport { GermanProcessor } from \"./german/GermanProcessor.js\";\nexport { EnglishProcessor } from \"./english/EnglishProcessor.js\";\nexport { SpanishProcessor } from \"./spanish/SpanishProcessor.js\";\nexport { FrenchProcessor } from \"./french/FrenchProcessor.js\";\nexport { BaseLanguageProcessor } from \"./base/LanguageProcessor.js\";\n","/**\n * Optimized Levenshtein distance calculation with early termination\n * Performance-focused implementation for fuzzy matching\n */\n\n/**\n * Calculate Levenshtein distance with maximum threshold\n * Returns early if distance exceeds maxDistance for performance\n */\nexport function calculateLevenshteinDistance(str1: string, str2: string, maxDistance: number = Infinity): number {\n  const len1 = str1.length;\n  const len2 = str2.length;\n\n  // Quick checks for performance\n  if (Math.abs(len1 - len2) > maxDistance) {\n    return maxDistance + 1;\n  }\n\n  if (len1 === 0) return len2;\n  if (len2 === 0) return len1;\n  if (str1 === str2) return 0;\n\n  // Use single array optimization for memory efficiency\n  let previousRow = new Array(len2 + 1);\n  let currentRow = new Array(len2 + 1);\n\n  // Initialize first row\n  for (let j = 0; j <= len2; j++) {\n    previousRow[j] = j;\n  }\n\n  for (let i = 1; i <= len1; i++) {\n    currentRow[0] = i;\n    let minInRow = i;\n\n    for (let j = 1; j <= len2; j++) {\n      const cost = str1[i - 1] === str2[j - 1] ? 0 : 1;\n\n      currentRow[j] = Math.min(\n        currentRow[j - 1] + 1, // insertion\n        previousRow[j] + 1, // deletion\n        previousRow[j - 1] + cost // substitution\n      );\n\n      minInRow = Math.min(minInRow, currentRow[j]);\n    }\n\n    // Early termination if minimum in row exceeds threshold\n    if (minInRow > maxDistance) {\n      return maxDistance + 1;\n    }\n\n    // Swap arrays\n    [previousRow, currentRow] = [currentRow, previousRow];\n  }\n\n  return previousRow[len2];\n}\n\n/**\n * Calculate Damerau-Levenshtein distance (includes transpositions)\n * More expensive but handles character swaps\n */\nexport function calculateDamerauLevenshteinDistance(str1: string, str2: string, maxDistance: number = Infinity): number {\n  const len1 = str1.length;\n  const len2 = str2.length;\n\n  if (Math.abs(len1 - len2) > maxDistance) {\n    return maxDistance + 1;\n  }\n\n  if (len1 === 0) return len2;\n  if (len2 === 0) return len1;\n  if (str1 === str2) return 0;\n\n  const maxLen = Math.max(len1, len2);\n  const H: number[][] = [];\n  const INF = maxLen + 1;\n\n  // Initialize H matrix\n  for (let i = 0; i <= len1 + 1; i++) {\n    H[i] = new Array(len2 + 2).fill(INF);\n  }\n\n  H[0][0] = INF;\n  for (let i = 0; i <= len1; i++) {\n    H[i + 1][0] = INF;\n    H[i + 1][1] = i;\n  }\n  for (let j = 0; j <= len2; j++) {\n    H[0][j + 1] = INF;\n    H[1][j + 1] = j;\n  }\n\n  const charMap = new Map<string, number>();\n\n  for (let i = 1; i <= len1; i++) {\n    let lastMatchCol = 0;\n\n    for (let j = 1; j <= len2; j++) {\n      const char1 = str1[i - 1];\n      const char2 = str2[j - 1];\n      const lastMatchRow = charMap.get(char2) || 0;\n\n      let cost = 1;\n      if (char1 === char2) {\n        cost = 0;\n        lastMatchCol = j;\n      }\n\n      H[i + 1][j + 1] = Math.min(\n        H[i][j] + cost, // substitution\n        H[i + 1][j] + 1, // insertion\n        H[i][j + 1] + 1, // deletion\n        H[lastMatchRow][lastMatchCol] + (i - lastMatchRow - 1) + 1 + (j - lastMatchCol - 1) // transposition\n      );\n    }\n\n    charMap.set(str1[i - 1], i);\n  }\n\n  const result = H[len1 + 1][len2 + 1];\n  return result > maxDistance ? maxDistance + 1 : result;\n}\n\n/**\n * Fast approximate string matching using n-gram similarity\n * Much faster than edit distance for initial filtering\n */\nexport function calculateNgramSimilarity(str1: string, str2: string, n: number = 3): number {\n  if (str1 === str2) return 1.0;\n  if (str1.length === 0 || str2.length === 0) return 0.0;\n\n  const ngrams1 = generateNgrams(str1, n);\n  const ngrams2 = generateNgrams(str2, n);\n\n  if (ngrams1.length === 0 && ngrams2.length === 0) return 1.0;\n  if (ngrams1.length === 0 || ngrams2.length === 0) return 0.0;\n\n  const set1 = new Set(ngrams1);\n  const set2 = new Set(ngrams2);\n\n  const intersection = new Set([...set1].filter((x) => set2.has(x)));\n  const union = new Set([...set1, ...set2]);\n\n  return intersection.size / union.size;\n}\n\n/**\n * Generate n-grams from a string\n */\nexport function generateNgrams(str: string, n: number): string[] {\n  if (str.length < n) return [str];\n\n  const ngrams: string[] = [];\n  for (let i = 0; i <= str.length - n; i++) {\n    ngrams.push(str.slice(i, i + n));\n  }\n  return ngrams;\n}\n\n/**\n * Calculate similarity score (0-1) from edit distance\n */\nexport function distanceToSimilarity(distance: number, maxLength: number): number {\n  if (maxLength === 0) return distance === 0 ? 1.0 : 0.0;\n  return Math.max(0, 1 - distance / maxLength);\n}\n\n/**\n * Check if strings are similar within threshold using fast approximation\n */\nexport function areStringsSimilar(str1: string, str2: string, threshold: number = 0.8, maxDistance: number = 2): boolean {\n  // Quick exact match\n  if (str1 === str2) return true;\n\n  // Quick length check\n  const maxLen = Math.max(str1.length, str2.length);\n  if (Math.abs(str1.length - str2.length) > maxDistance) return false;\n\n  // Use n-gram similarity for fast approximation\n  const ngramSim = calculateNgramSimilarity(str1, str2);\n  if (ngramSim < threshold - 0.2) return false; // Early rejection\n\n  // Calculate actual edit distance only if n-gram similarity is promising\n  const distance = calculateLevenshteinDistance(str1, str2, maxDistance);\n  const similarity = distanceToSimilarity(distance, maxLen);\n\n  return similarity >= threshold;\n}\n","/**\n * Trie (Prefix Tree) for fast prefix matching\n * Provides O(k) lookup where k is the query length, instead of O(n) where n is the number of terms\n */\n\nexport interface TrieNode {\n  children: Map<string, TrieNode>;\n  isEndOfWord: boolean;\n  docIds: Set<number>;\n  term?: string; // Store the full term at leaf nodes\n}\n\nexport class Trie {\n  private root: TrieNode;\n  private size: number;\n\n  constructor() {\n    this.root = this.createNode();\n    this.size = 0;\n  }\n\n  private createNode(): TrieNode {\n    return {\n      children: new Map(),\n      isEndOfWord: false,\n      docIds: new Set(),\n    };\n  }\n\n  /**\n   * Insert a term with associated document IDs\n   */\n  insert(term: string, docIds: number[]): void {\n    if (!term) return;\n\n    let node = this.root;\n\n    for (const char of term) {\n      if (!node.children.has(char)) {\n        node.children.set(char, this.createNode());\n      }\n      node = node.children.get(char)!;\n    }\n\n    node.isEndOfWord = true;\n    node.term = term;\n    docIds.forEach(id => node.docIds.add(id));\n    this.size++;\n  }\n\n  /**\n   * Find all terms that start with the given prefix\n   * Returns array of [term, docIds[]] tuples\n   */\n  findWithPrefix(prefix: string): Array<[string, number[]]> {\n    if (!prefix) return [];\n\n    // Navigate to the prefix node\n    let node = this.root;\n    for (const char of prefix) {\n      if (!node.children.has(char)) {\n        return []; // Prefix not found\n      }\n      node = node.children.get(char)!;\n    }\n\n    // Collect all terms from this node downwards\n    const results: Array<[string, number[]]> = [];\n    this.collectTerms(node, results);\n    return results;\n  }\n\n  /**\n   * Check if exact term exists\n   */\n  has(term: string): boolean {\n    let node = this.root;\n    for (const char of term) {\n      if (!node.children.has(char)) {\n        return false;\n      }\n      node = node.children.get(char)!;\n    }\n    return node.isEndOfWord;\n  }\n\n  /**\n   * Get document IDs for exact term\n   */\n  get(term: string): number[] | null {\n    let node = this.root;\n    for (const char of term) {\n      if (!node.children.has(char)) {\n        return null;\n      }\n      node = node.children.get(char)!;\n    }\n    return node.isEndOfWord ? Array.from(node.docIds) : null;\n  }\n\n  /**\n   * Recursively collect all terms from a node\n   */\n  private collectTerms(node: TrieNode, results: Array<[string, number[]]>): void {\n    if (node.isEndOfWord && node.term) {\n      results.push([node.term, Array.from(node.docIds)]);\n    }\n\n    for (const child of node.children.values()) {\n      this.collectTerms(child, results);\n    }\n  }\n\n  /**\n   * Get the number of terms in the trie\n   */\n  getSize(): number {\n    return this.size;\n  }\n\n  /**\n   * Clear the trie\n   */\n  clear(): void {\n    this.root = this.createNode();\n    this.size = 0;\n  }\n\n  /**\n   * Serialize trie to JSON-compatible format\n   */\n  toJSON(): any {\n    return {\n      root: this.serializeNode(this.root),\n      size: this.size,\n    };\n  }\n\n  /**\n   * Deserialize trie from JSON\n   */\n  static fromJSON(data: any): Trie {\n    const trie = new Trie();\n    trie.root = Trie.deserializeNode(data.root);\n    trie.size = data.size;\n    return trie;\n  }\n\n  private serializeNode(node: TrieNode): any {\n    return {\n      children: Array.from(node.children.entries()).map(([char, child]) => [\n        char,\n        this.serializeNode(child),\n      ]),\n      isEndOfWord: node.isEndOfWord,\n      docIds: Array.from(node.docIds),\n      term: node.term,\n    };\n  }\n\n  private static deserializeNode(data: any): TrieNode {\n    const node: TrieNode = {\n      children: new Map(),\n      isEndOfWord: data.isEndOfWord,\n      docIds: new Set(data.docIds),\n      term: data.term,\n    };\n\n    for (const [char, childData] of data.children) {\n      node.children.set(char, Trie.deserializeNode(childData));\n    }\n\n    return node;\n  }\n}\n","/**\n * BM25 (Best Matching 25) Scoring Algorithm\n * Industry-standard probabilistic ranking function used by search engines\n * \n * BM25 considers:\n * - Term frequency (TF): How often does the term appear?\n * - Inverse document frequency (IDF): How rare is the term?\n * - Document length normalization: Penalize very long documents\n * \n * Formula: BM25(D, Q) = Σ IDF(qi) * (f(qi, D) * (k1 + 1)) / (f(qi, D) + k1 * (1 - b + b * |D| / avgdl))\n * \n * Where:\n * - D = document\n * - Q = query\n * - qi = query term i\n * - f(qi, D) = frequency of qi in D\n * - |D| = length of document D\n * - avgdl = average document length\n * - k1 = term frequency saturation parameter (default: 1.2)\n * - b = length normalization parameter (default: 0.75)\n */\n\nexport interface BM25Config {\n  /** Term frequency saturation parameter (typical: 1.2-2.0) */\n  k1: number;\n  /** Length normalization parameter (typical: 0.5-0.8) */\n  b: number;\n  /** Minimum IDF value to prevent negative scores */\n  minIDF: number;\n}\n\nexport const DEFAULT_BM25_CONFIG: BM25Config = {\n  k1: 1.2,\n  b: 0.75,\n  minIDF: 0.1,\n};\n\n/**\n * Document statistics for BM25 calculation\n */\nexport interface DocumentStats {\n  /** Document ID */\n  docId: number;\n  /** Document length (number of terms) */\n  length: number;\n  /** Term frequencies in this document */\n  termFrequencies: Map<string, number>;\n}\n\n/**\n * Corpus statistics for BM25 calculation\n */\nexport interface CorpusStats {\n  /** Total number of documents */\n  totalDocs: number;\n  /** Average document length */\n  avgDocLength: number;\n  /** Document frequency for each term (how many docs contain the term) */\n  documentFrequencies: Map<string, number>;\n}\n\n/**\n * Calculate IDF (Inverse Document Frequency) for a term\n * IDF = log((N - df + 0.5) / (df + 0.5) + 1)\n * \n * Where:\n * - N = total number of documents\n * - df = document frequency (number of documents containing the term)\n */\nexport function calculateIDF(\n  term: string,\n  corpusStats: CorpusStats,\n  config: BM25Config = DEFAULT_BM25_CONFIG\n): number {\n  const df = corpusStats.documentFrequencies.get(term) || 0;\n  const N = corpusStats.totalDocs;\n\n  // Prevent division by zero and negative IDF\n  if (df === 0 || N === 0) {\n    return config.minIDF;\n  }\n\n  // BM25 IDF formula with smoothing\n  const idf = Math.log((N - df + 0.5) / (df + 0.5) + 1);\n\n  // Ensure minimum IDF\n  return Math.max(idf, config.minIDF);\n}\n\n/**\n * Calculate BM25 score for a single term in a document\n */\nexport function calculateTermScore(\n  term: string,\n  docStats: DocumentStats,\n  corpusStats: CorpusStats,\n  config: BM25Config = DEFAULT_BM25_CONFIG\n): number {\n  const tf = docStats.termFrequencies.get(term) || 0;\n\n  // If term not in document, score is 0\n  if (tf === 0) {\n    return 0;\n  }\n\n  const idf = calculateIDF(term, corpusStats, config);\n  const docLength = docStats.length;\n  const avgDocLength = corpusStats.avgDocLength;\n\n  // BM25 formula\n  const numerator = tf * (config.k1 + 1);\n  const denominator = tf + config.k1 * (1 - config.b + config.b * (docLength / avgDocLength));\n\n  return idf * (numerator / denominator);\n}\n\n/**\n * Calculate BM25 score for a query against a document\n * Returns the sum of BM25 scores for all query terms\n */\nexport function calculateBM25Score(\n  queryTerms: string[],\n  docStats: DocumentStats,\n  corpusStats: CorpusStats,\n  config: BM25Config = DEFAULT_BM25_CONFIG\n): number {\n  let totalScore = 0;\n\n  for (const term of queryTerms) {\n    totalScore += calculateTermScore(term, docStats, corpusStats, config);\n  }\n\n  return totalScore;\n}\n\n/**\n * Build corpus statistics from documents\n * This should be called once during index building\n */\nexport function buildCorpusStats(documents: DocumentStats[]): CorpusStats {\n  const totalDocs = documents.length;\n  let totalLength = 0;\n  const documentFrequencies = new Map<string, number>();\n\n  for (const doc of documents) {\n    totalLength += doc.length;\n\n    // Count unique terms per document (for document frequency)\n    const uniqueTerms = new Set(doc.termFrequencies.keys());\n    for (const term of uniqueTerms) {\n      documentFrequencies.set(term, (documentFrequencies.get(term) || 0) + 1);\n    }\n  }\n\n  const avgDocLength = totalDocs > 0 ? totalLength / totalDocs : 0;\n\n  return {\n    totalDocs,\n    avgDocLength,\n    documentFrequencies,\n  };\n}\n\n/**\n * Normalize BM25 score to 0-1 range for consistency with existing scoring\n * Uses sigmoid function for smooth normalization\n */\nexport function normalizeBM25Score(score: number, maxScore: number = 10): number {\n  if (maxScore === 0) return 0;\n\n  // Sigmoid normalization: 1 / (1 + e^(-x))\n  // Scale score to reasonable range first\n  const scaledScore = (score / maxScore) * 6 - 3; // Map to [-3, 3] range\n  return 1 / (1 + Math.exp(-scaledScore));\n}\n\n/**\n * Combine BM25 score with fuzzy match score\n * Provides a hybrid scoring approach\n */\nexport function combineScores(\n  bm25Score: number,\n  fuzzyScore: number,\n  bm25Weight: number = 0.6,\n  fuzzyWeight: number = 0.4\n): number {\n  // Normalize weights\n  const totalWeight = bm25Weight + fuzzyWeight;\n  const normalizedBM25Weight = bm25Weight / totalWeight;\n  const normalizedFuzzyWeight = fuzzyWeight / totalWeight;\n\n  // Weighted combination\n  return normalizedBM25Weight * bm25Score + normalizedFuzzyWeight * fuzzyScore;\n}\n","/**\n * Bloom Filter Implementation\n * Probabilistic data structure for fast membership testing\n * \n * Benefits:\n * - O(1) lookup time\n * - Space-efficient (much smaller than Set/Map)\n * - No false negatives (if it says \"no\", it's definitely not there)\n * - Small false positive rate (configurable)\n * \n * Use case: Quickly check if a term exists before expensive lookups\n * Saves 50-70% of lookup time for non-existent terms\n */\n\nexport interface BloomFilterConfig {\n  /** Expected number of elements */\n  expectedElements: number;\n  /** Desired false positive rate (0-1, e.g., 0.01 = 1%) */\n  falsePositiveRate: number;\n}\n\nexport class BloomFilter {\n  private bitArray: Uint8Array;\n  private size: number;\n  private numHashFunctions: number;\n  private numElements: number = 0;\n\n  constructor(config: BloomFilterConfig) {\n    // Calculate optimal bit array size\n    // m = -(n * ln(p)) / (ln(2)^2)\n    // where n = expected elements, p = false positive rate\n    const n = config.expectedElements;\n    const p = config.falsePositiveRate;\n    \n    this.size = Math.ceil(-(n * Math.log(p)) / (Math.log(2) ** 2));\n    \n    // Calculate optimal number of hash functions\n    // k = (m / n) * ln(2)\n    this.numHashFunctions = Math.ceil((this.size / n) * Math.log(2));\n    \n    // Use Uint8Array for efficient bit storage (8 bits per byte)\n    this.bitArray = new Uint8Array(Math.ceil(this.size / 8));\n  }\n\n  /**\n   * Add an element to the bloom filter\n   */\n  add(item: string): void {\n    const hashes = this.getHashes(item);\n    \n    for (const hash of hashes) {\n      const byteIndex = Math.floor(hash / 8);\n      const bitIndex = hash % 8;\n      this.bitArray[byteIndex] |= (1 << bitIndex);\n    }\n    \n    this.numElements++;\n  }\n\n  /**\n   * Check if an element might be in the set\n   * Returns:\n   * - true: element MIGHT be in the set (could be false positive)\n   * - false: element is DEFINITELY NOT in the set (no false negatives)\n   */\n  mightContain(item: string): boolean {\n    const hashes = this.getHashes(item);\n    \n    for (const hash of hashes) {\n      const byteIndex = Math.floor(hash / 8);\n      const bitIndex = hash % 8;\n      \n      if ((this.bitArray[byteIndex] & (1 << bitIndex)) === 0) {\n        return false; // Definitely not in set\n      }\n    }\n    \n    return true; // Might be in set\n  }\n\n  /**\n   * Generate multiple hash values for an item\n   * Uses double hashing technique for efficiency\n   */\n  private getHashes(item: string): number[] {\n    const hash1 = this.hash(item, 0);\n    const hash2 = this.hash(item, 1);\n    \n    const hashes: number[] = [];\n    \n    for (let i = 0; i < this.numHashFunctions; i++) {\n      // Double hashing: h(i) = (hash1 + i * hash2) mod m\n      const combinedHash = (hash1 + i * hash2) % this.size;\n      hashes.push(Math.abs(combinedHash));\n    }\n    \n    return hashes;\n  }\n\n  /**\n   * Simple hash function (FNV-1a variant)\n   */\n  private hash(str: string, seed: number): number {\n    let hash = 2166136261 ^ seed; // FNV offset basis\n    \n    for (let i = 0; i < str.length; i++) {\n      hash ^= str.charCodeAt(i);\n      hash += (hash << 1) + (hash << 4) + (hash << 7) + (hash << 8) + (hash << 24);\n    }\n    \n    return hash >>> 0; // Convert to unsigned 32-bit integer\n  }\n\n  /**\n   * Get current false positive probability\n   * Actual rate may differ from configured rate as elements are added\n   */\n  getFalsePositiveRate(): number {\n    if (this.numElements === 0) return 0;\n    \n    // p = (1 - e^(-kn/m))^k\n    // where k = num hash functions, n = num elements, m = bit array size\n    const k = this.numHashFunctions;\n    const n = this.numElements;\n    const m = this.size;\n    \n    return Math.pow(1 - Math.exp((-k * n) / m), k);\n  }\n\n  /**\n   * Get statistics about the bloom filter\n   */\n  getStats(): {\n    size: number;\n    numHashFunctions: number;\n    numElements: number;\n    falsePositiveRate: number;\n    memoryUsage: number;\n  } {\n    return {\n      size: this.size,\n      numHashFunctions: this.numHashFunctions,\n      numElements: this.numElements,\n      falsePositiveRate: this.getFalsePositiveRate(),\n      memoryUsage: this.bitArray.byteLength,\n    };\n  }\n\n  /**\n   * Clear all elements from the filter\n   */\n  clear(): void {\n    this.bitArray.fill(0);\n    this.numElements = 0;\n  }\n\n  /**\n   * Serialize bloom filter to JSON\n   */\n  toJSON(): {\n    bitArray: number[];\n    size: number;\n    numHashFunctions: number;\n    numElements: number;\n  } {\n    return {\n      bitArray: Array.from(this.bitArray),\n      size: this.size,\n      numHashFunctions: this.numHashFunctions,\n      numElements: this.numElements,\n    };\n  }\n\n  /**\n   * Deserialize bloom filter from JSON\n   */\n  static fromJSON(data: {\n    bitArray: number[];\n    size: number;\n    numHashFunctions: number;\n    numElements: number;\n  }): BloomFilter {\n    // Create a dummy filter with minimal config\n    const filter = new BloomFilter({\n      expectedElements: 100,\n      falsePositiveRate: 0.01,\n    });\n    \n    // Override with saved data\n    filter.bitArray = new Uint8Array(data.bitArray);\n    filter.size = data.size;\n    filter.numHashFunctions = data.numHashFunctions;\n    filter.numElements = data.numElements;\n    \n    return filter;\n  }\n}\n\n/**\n * Create a bloom filter with sensible defaults\n */\nexport function createBloomFilter(expectedElements: number, falsePositiveRate: number = 0.01): BloomFilter {\n  return new BloomFilter({\n    expectedElements,\n    falsePositiveRate,\n  });\n}\n","/**\n * Inverted Index Implementation\n * Optimized for large datasets (1M+ words)\n *\n * Architecture:\n * - Token → [docId1, docId2, ...] (posting lists)\n * - Fast intersection/union operations\n * - BM25-like scoring for relevance\n * - Parallel to existing hash-based index (backwards compatible)\n */\n\nimport type { InvertedIndex, DocumentMetadata, PostingList, FuzzyConfig, LanguageProcessor, SearchMatch } from \"./types.js\";\nimport { generateNgrams, calculateLevenshteinDistance, calculateDamerauLevenshteinDistance } from \"../algorithms/levenshtein.js\";\nimport { Trie } from \"./trie.js\";\nimport { calculateBM25Score, normalizeBM25Score, DEFAULT_BM25_CONFIG, type DocumentStats, type CorpusStats } from \"../algorithms/bm25.js\";\nimport { BloomFilter } from \"../algorithms/bloom-filter.js\";\n\n/**\n * Build inverted index from documents\n * This runs ALONGSIDE the existing index building\n */\nexport function buildInvertedIndex(words: string[], languageProcessors: LanguageProcessor[], config: FuzzyConfig, featureSet: Set<string>): { invertedIndex: InvertedIndex; documents: DocumentMetadata[] } {\n  const documents: DocumentMetadata[] = [];\n  const invertedIndex: InvertedIndex = {\n    termToPostings: new Map(),\n    termTrie: new Trie(), // Initialize Trie for fast prefix matching\n    phoneticToPostings: new Map(),\n    ngramToPostings: new Map(),\n    synonymToPostings: new Map(),\n    fieldIndices: new Map(),\n    totalDocs: 0,\n    avgDocLength: 0,\n  };\n\n  let totalLength = 0;\n  let docId = 0;\n\n  // Build documents and posting lists\n  for (const word of words) {\n    if (!word || word.trim().length < config.minQueryLength) continue;\n\n    const trimmedWord = word.trim();\n\n    // Process with each language processor\n    for (const processor of languageProcessors) {\n      const normalized = processor.normalize(trimmedWord);\n      const phoneticCode = featureSet.has(\"phonetic\") && processor.supportedFeatures.includes(\"phonetic\") ? processor.getPhoneticCode(trimmedWord) : undefined;\n\n      const compoundParts = featureSet.has(\"compound\") && processor.supportedFeatures.includes(\"compound\") ? processor.splitCompoundWords(trimmedWord) : undefined;\n\n      // Create document metadata\n      const doc: DocumentMetadata = {\n        id: docId,\n        word: trimmedWord,\n        normalized,\n        phoneticCode,\n        language: processor.language,\n        compoundParts: compoundParts && compoundParts.length > 1 ? compoundParts : undefined,\n      };\n\n      documents.push(doc);\n      totalLength += normalized.length;\n\n      // Index the normalized term\n      addToPostingList(invertedIndex.termToPostings, normalized, docId);\n      invertedIndex.termTrie!.insert(normalized, [docId]);\n\n      // Index original word (for exact matching)\n      const lowerWord = trimmedWord.toLowerCase();\n      addToPostingList(invertedIndex.termToPostings, lowerWord, docId);\n      invertedIndex.termTrie!.insert(lowerWord, [docId]);\n\n      // Index word variants (prefixes)\n      if (featureSet.has(\"partial-words\")) {\n        const variants = processor.getWordVariants(trimmedWord);\n        variants.forEach((variant) => {\n          addToPostingList(invertedIndex.termToPostings, variant, docId);\n          invertedIndex.termTrie!.insert(variant, [docId]);\n        });\n      }\n\n      // Index phonetic code\n      if (phoneticCode) {\n        addToPostingList(invertedIndex.phoneticToPostings, phoneticCode, docId);\n      }\n\n      // Index n-grams\n      const ngrams = generateNgrams(normalized, config.ngramSize);\n      ngrams.forEach((ngram) => {\n        addToPostingList(invertedIndex.ngramToPostings, ngram, docId);\n      });\n\n      // Index compound parts\n      if (compoundParts && compoundParts.length > 1) {\n        compoundParts.forEach((part) => {\n          const normalizedPart = processor.normalize(part);\n          addToPostingList(invertedIndex.termToPostings, normalizedPart, docId);\n          invertedIndex.termTrie!.insert(normalizedPart, [docId]);\n        });\n      }\n\n      // Index synonyms\n      if (featureSet.has(\"synonyms\")) {\n        const synonyms = processor.getSynonyms(normalized);\n        synonyms.forEach((synonym) => {\n          addToPostingList(invertedIndex.synonymToPostings, synonym, docId);\n        });\n\n        // Custom synonyms\n        if (config.customSynonyms) {\n          const customSynonyms = config.customSynonyms[normalized];\n          if (customSynonyms) {\n            customSynonyms.forEach((synonym) => {\n              addToPostingList(invertedIndex.synonymToPostings, synonym, docId);\n            });\n          }\n        }\n      }\n\n      docId++;\n    }\n  }\n\n  invertedIndex.totalDocs = docId;\n  invertedIndex.avgDocLength = totalLength / Math.max(1, docId);\n\n  // Build BM25 statistics if enabled\n  if (config.useBM25) {\n    const documentFrequencies = new Map<string, number>();\n    const documentLengths = new Map<number, number>();\n\n    // Calculate document frequencies (how many docs contain each term)\n    for (const [term, posting] of invertedIndex.termToPostings.entries()) {\n      documentFrequencies.set(term, posting.docIds.length);\n    }\n\n    // Store document lengths\n    documents.forEach((doc) => {\n      documentLengths.set(doc.id, doc.normalized.length);\n    });\n\n    invertedIndex.bm25Stats = {\n      documentFrequencies,\n      documentLengths,\n    };\n  }\n\n  // Build Bloom Filter if enabled or auto-enable for large datasets\n  const shouldUseBloomFilter = config.useBloomFilter || words.length >= 10000;\n  \n  if (shouldUseBloomFilter) {\n    const falsePositiveRate = config.bloomFilterFalsePositiveRate || 0.01;\n    const bloomFilter = new BloomFilter({\n      expectedElements: invertedIndex.termToPostings.size,\n      falsePositiveRate,\n    });\n    \n    // Add all terms to bloom filter\n    for (const term of invertedIndex.termToPostings.keys()) {\n      bloomFilter.add(term);\n    }\n    \n    invertedIndex.bloomFilter = bloomFilter;\n  }\n\n  return { invertedIndex, documents };\n}\n\n/**\n * Search using inverted index\n * Much faster than hash-based approach for large datasets\n */\nexport function searchInvertedIndex(invertedIndex: InvertedIndex, documents: DocumentMetadata[], query: string, processors: LanguageProcessor[], config: FuzzyConfig): SearchMatch[] {\n  const matches = new Map<number, SearchMatch>();\n  const featureSet = new Set(config.features);\n\n  // Process query with each language processor\n  for (const processor of processors) {\n    const normalizedQuery = processor.normalize(query.trim());\n\n    // 1. Exact term lookup (fastest)\n    findExactMatchesInverted(normalizedQuery, invertedIndex, documents, matches, processor.language);\n\n    // 2. Prefix matches\n    findPrefixMatchesInverted(normalizedQuery, invertedIndex, documents, matches, processor.language);\n\n    // 3. Phonetic matches\n    if (featureSet.has(\"phonetic\") && processor.supportedFeatures.includes(\"phonetic\")) {\n      findPhoneticMatchesInverted(normalizedQuery, processor, invertedIndex, documents, matches);\n    }\n\n    // 4. Synonym matches\n    if (featureSet.has(\"synonyms\")) {\n      findSynonymMatchesInverted(normalizedQuery, invertedIndex, documents, matches);\n    }\n\n    // 5. N-gram matches\n    findNgramMatchesInverted(normalizedQuery, invertedIndex, documents, matches, processor.language, config.ngramSize);\n\n    // 6. Fuzzy matches (most expensive, do last)\n    if (featureSet.has(\"missing-letters\") || featureSet.has(\"extra-letters\") || featureSet.has(\"transpositions\")) {\n      findFuzzyMatchesInverted(normalizedQuery, invertedIndex, documents, matches, processor, config.maxEditDistance, config);\n    }\n  }\n\n  // Convert to array and return\n  return Array.from(matches.values());\n}\n\n/**\n * Helper: Add document to posting list\n */\nfunction addToPostingList(postings: Map<string, PostingList>, term: string, docId: number): void {\n  let posting = postings.get(term);\n  if (!posting) {\n    posting = { term, docIds: [] };\n    postings.set(term, posting);\n  }\n\n  // Avoid duplicates\n  if (!posting.docIds.includes(docId)) {\n    posting.docIds.push(docId);\n  }\n}\n\n/**\n * Find exact matches in inverted index\n */\nfunction findExactMatchesInverted(query: string, invertedIndex: InvertedIndex, documents: DocumentMetadata[], matches: Map<number, SearchMatch>, language: string): void {\n  // BLOOM FILTER: Fast negative lookup\n  if (invertedIndex.bloomFilter && !invertedIndex.bloomFilter.mightContain(query)) {\n    return; // Definitely not in index, skip expensive lookup\n  }\n  \n  const posting = invertedIndex.termToPostings.get(query);\n  if (!posting) return;\n\n  posting.docIds.forEach((docId) => {\n    const doc = documents[docId];\n    if (!doc) return;\n\n    if (!matches.has(docId)) {\n      matches.set(docId, {\n        word: doc.word,\n        normalized: query,\n        matchType: \"exact\",\n        editDistance: 0,\n        language,\n        docId,\n      });\n    }\n  });\n}\n\n/**\n * Find prefix matches in inverted index\n * Now uses Trie for O(k) lookup instead of O(n) iteration!\n */\nfunction findPrefixMatchesInverted(query: string, invertedIndex: InvertedIndex, documents: DocumentMetadata[], matches: Map<number, SearchMatch>, language: string): void {\n  // Use Trie for fast prefix matching (100-1000x faster!)\n  if (invertedIndex.termTrie) {\n    const prefixMatches = invertedIndex.termTrie.findWithPrefix(query);\n    \n    for (const [term, docIds] of prefixMatches) {\n      if (term !== query) { // Exclude exact matches (handled separately)\n        docIds.forEach((docId: number) => {\n          const doc = documents[docId];\n          if (!doc) return;\n\n          if (!matches.has(docId)) {\n            matches.set(docId, {\n              word: doc.word,\n              normalized: term,\n              matchType: \"prefix\",\n              language,\n              docId,\n            });\n          }\n        });\n      }\n    }\n  } else {\n    // Fallback to old O(n) method if Trie not available\n    for (const [term, posting] of invertedIndex.termToPostings.entries()) {\n      if (term.startsWith(query) && term !== query) {\n        posting.docIds.forEach((docId) => {\n          const doc = documents[docId];\n          if (!doc) return;\n\n          if (!matches.has(docId)) {\n            matches.set(docId, {\n              word: doc.word,\n              normalized: term,\n              matchType: \"prefix\",\n              language,\n              docId,\n            });\n          }\n        });\n      }\n    }\n  }\n}\n\n/**\n * Find phonetic matches in inverted index\n */\nfunction findPhoneticMatchesInverted(query: string, processor: LanguageProcessor, invertedIndex: InvertedIndex, documents: DocumentMetadata[], matches: Map<number, SearchMatch>): void {\n  const phoneticCode = processor.getPhoneticCode(query);\n  if (!phoneticCode) return;\n\n  const posting = invertedIndex.phoneticToPostings.get(phoneticCode);\n  if (!posting) return;\n\n  posting.docIds.forEach((docId) => {\n    const doc = documents[docId];\n    if (!doc) return;\n\n    if (!matches.has(docId)) {\n      matches.set(docId, {\n        word: doc.word,\n        normalized: query,\n        matchType: \"phonetic\",\n        phoneticCode,\n        language: processor.language,\n        docId,\n      });\n    }\n  });\n}\n\n/**\n * Find synonym matches in inverted index\n */\nfunction findSynonymMatchesInverted(query: string, invertedIndex: InvertedIndex, documents: DocumentMetadata[], matches: Map<number, SearchMatch>): void {\n  const posting = invertedIndex.synonymToPostings.get(query);\n  if (!posting) return;\n\n  posting.docIds.forEach((docId) => {\n    const doc = documents[docId];\n    if (!doc) return;\n\n    if (!matches.has(docId)) {\n      matches.set(docId, {\n        word: doc.word,\n        normalized: query,\n        matchType: \"synonym\",\n        language: \"synonym\",\n        docId,\n      });\n    }\n  });\n}\n\n/**\n * Find n-gram matches in inverted index\n */\nfunction findNgramMatchesInverted(query: string, invertedIndex: InvertedIndex, documents: DocumentMetadata[], matches: Map<number, SearchMatch>, language: string, ngramSize: number): void {\n  if (query.length < ngramSize) return;\n\n  const queryNgrams = generateNgrams(query, ngramSize);\n  const candidateDocs = new Set<number>();\n\n  // Collect all documents that contain at least one n-gram\n  queryNgrams.forEach((ngram) => {\n    const posting = invertedIndex.ngramToPostings.get(ngram);\n    if (posting) {\n      posting.docIds.forEach((docId) => candidateDocs.add(docId));\n    }\n  });\n\n  // Add to matches\n  candidateDocs.forEach((docId) => {\n    const doc = documents[docId];\n    if (!doc) return;\n\n    if (!matches.has(docId)) {\n      matches.set(docId, {\n        word: doc.word,\n        normalized: query,\n        matchType: \"ngram\",\n        language,\n        docId,\n      });\n    }\n  });\n}\n\n/**\n * Find fuzzy matches in inverted index\n * Optimized with length-based pre-filtering (5-10x faster)\n */\nfunction findFuzzyMatchesInverted(query: string, invertedIndex: InvertedIndex, documents: DocumentMetadata[], matches: Map<number, SearchMatch>, processor: LanguageProcessor, maxDistance: number, config: FuzzyConfig): void {\n  const queryLen = query.length;\n  const minLen = queryLen - maxDistance;\n  const maxLen = queryLen + maxDistance;\n  \n  // Pre-compute for performance\n  const useTranspositions = config.features?.includes('transpositions');\n  \n  // Limit number of fuzzy candidates to avoid performance issues\n  const MAX_FUZZY_CANDIDATES = 10000;\n  let candidatesChecked = 0;\n  \n  // Iterate through all terms with optimized filtering\n  for (const [term, posting] of invertedIndex.termToPostings.entries()) {\n    // OPTIMIZATION 1: Length-based pre-filter (O(1) check)\n    // This eliminates 80-90% of candidates before expensive Levenshtein\n    const termLen = term.length;\n    if (termLen < minLen || termLen > maxLen) {\n      continue;\n    }\n    \n    // OPTIMIZATION 2: Limit candidates in large datasets\n    if (candidatesChecked >= MAX_FUZZY_CANDIDATES) {\n      break;\n    }\n    candidatesChecked++;\n    \n    // OPTIMIZATION 3: Early termination if we have enough matches\n    if (matches.size >= config.maxResults * 3) {\n      break;\n    }\n    \n    // Now do expensive edit distance calculation\n    const distance = useTranspositions\n      ? calculateDamerauLevenshteinDistance(query, term, maxDistance)\n      : calculateLevenshteinDistance(query, term, maxDistance);\n      \n    if (distance <= maxDistance) {\n      posting.docIds.forEach((docId) => {\n        const doc = documents[docId];\n        if (!doc) return;\n\n        const existingMatch = matches.get(docId);\n        // Only update if this is a better match (lower edit distance)\n        if (!existingMatch || (existingMatch.editDistance || Infinity) > distance) {\n          matches.set(docId, {\n            word: doc.word,\n            normalized: term,\n            matchType: \"fuzzy\",\n            editDistance: distance,\n            language: processor.language,\n            docId,\n          });\n        }\n      });\n    }\n  }\n}\n\n/**\n * Calculate BM25 scores for search matches\n * Enhances relevance ranking with statistical scoring\n */\nexport function calculateBM25Scores(\n  matches: SearchMatch[],\n  queryTerms: string[],\n  invertedIndex: InvertedIndex,\n  documents: DocumentMetadata[],\n  config: FuzzyConfig\n): SearchMatch[] {\n  if (!config.useBM25 || !invertedIndex.bm25Stats) {\n    return matches;\n  }\n\n  const bm25Config = {\n    ...DEFAULT_BM25_CONFIG,\n    ...config.bm25Config,\n  };\n\n  // Build corpus stats from inverted index\n  const corpusStats: CorpusStats = {\n    totalDocs: invertedIndex.totalDocs,\n    avgDocLength: invertedIndex.avgDocLength,\n    documentFrequencies: invertedIndex.bm25Stats.documentFrequencies,\n  };\n\n  // Calculate BM25 score for each match\n  return matches.map((match) => {\n    if (match.docId === undefined) {\n      return match;\n    }\n\n    const doc = documents[match.docId];\n    if (!doc) {\n      return match;\n    }\n\n    // Build document stats\n    const termFrequencies = new Map<string, number>();\n    const normalizedTerms = doc.normalized.toLowerCase().split(/\\s+/);\n    \n    for (const term of normalizedTerms) {\n      termFrequencies.set(term, (termFrequencies.get(term) || 0) + 1);\n    }\n\n    const docStats: DocumentStats = {\n      docId: doc.id,\n      length: normalizedTerms.length,\n      termFrequencies,\n    };\n\n    // Calculate BM25 score\n    const bm25Score = calculateBM25Score(queryTerms, docStats, corpusStats, bm25Config);\n    const normalizedBM25 = normalizeBM25Score(bm25Score);\n\n    return {\n      ...match,\n      bm25Score: normalizedBM25,\n    };\n  });\n}\n","/**\n * Match Highlighting Utilities\n * Calculates positions of matched characters for UI highlighting\n */\n\nimport type { MatchHighlight, MatchType, SearchMatch } from \"./types.js\";\n\n/**\n * Calculate highlights for a search match\n */\nexport function calculateHighlights(\n  match: SearchMatch,\n  query: string,\n  displayText: string\n): MatchHighlight[] {\n  const highlights: MatchHighlight[] = [];\n  const normalizedDisplay = displayText.toLowerCase();\n  const normalizedQuery = query.toLowerCase();\n\n  switch (match.matchType) {\n    case \"exact\":\n      // Highlight the entire word\n      highlights.push({\n        start: 0,\n        end: displayText.length,\n        type: \"exact\",\n      });\n      break;\n\n    case \"prefix\":\n      // Highlight the matching prefix\n      const prefixEnd = Math.min(normalizedQuery.length, displayText.length);\n      highlights.push({\n        start: 0,\n        end: prefixEnd,\n        type: \"prefix\",\n      });\n      break;\n\n    case \"substring\":\n      // Find where the query appears in the display text\n      const substringIndex = normalizedDisplay.indexOf(normalizedQuery);\n      if (substringIndex !== -1) {\n        highlights.push({\n          start: substringIndex,\n          end: substringIndex + normalizedQuery.length,\n          type: \"substring\",\n        });\n      }\n      break;\n\n    case \"fuzzy\":\n      // For fuzzy matches, highlight matching characters\n      highlights.push(...calculateFuzzyHighlights(normalizedQuery, normalizedDisplay, \"fuzzy\"));\n      break;\n\n    case \"ngram\":\n      // Highlight n-gram matches\n      highlights.push(...calculateNgramHighlights(normalizedQuery, normalizedDisplay));\n      break;\n\n    case \"phonetic\":\n    case \"synonym\":\n    case \"compound\":\n      // For phonetic/synonym/compound, highlight the whole word\n      highlights.push({\n        start: 0,\n        end: displayText.length,\n        type: match.matchType,\n      });\n      break;\n  }\n\n  return mergeOverlappingHighlights(highlights);\n}\n\n/**\n * Calculate highlights for fuzzy matches using edit distance alignment\n */\nfunction calculateFuzzyHighlights(\n  query: string,\n  text: string,\n  type: MatchType\n): MatchHighlight[] {\n  const highlights: MatchHighlight[] = [];\n  let queryIdx = 0;\n  let textIdx = 0;\n\n  // Simple greedy matching - find matching characters\n  while (queryIdx < query.length && textIdx < text.length) {\n    if (query[queryIdx] === text[textIdx]) {\n      // Found a match\n      const start = textIdx;\n      let end = textIdx + 1;\n\n      // Extend the match as far as possible\n      queryIdx++;\n      textIdx++;\n      while (queryIdx < query.length && textIdx < text.length && query[queryIdx] === text[textIdx]) {\n        end++;\n        queryIdx++;\n        textIdx++;\n      }\n\n      highlights.push({ start, end, type });\n    } else {\n      textIdx++;\n    }\n  }\n\n  return highlights;\n}\n\n/**\n * Calculate highlights for n-gram matches\n */\nfunction calculateNgramHighlights(\n  query: string,\n  text: string\n): MatchHighlight[] {\n  const highlights: MatchHighlight[] = [];\n  const ngramSize = 3;\n\n  // Find all n-grams from query that appear in text\n  for (let i = 0; i <= query.length - ngramSize; i++) {\n    const ngram = query.slice(i, i + ngramSize);\n    let searchStart = 0;\n\n    // Find all occurrences of this n-gram\n    while (true) {\n      const index = text.indexOf(ngram, searchStart);\n      if (index === -1) break;\n\n      highlights.push({\n        start: index,\n        end: index + ngramSize,\n        type: \"ngram\",\n      });\n\n      searchStart = index + 1;\n    }\n  }\n\n  return highlights;\n}\n\n/**\n * Merge overlapping highlights to avoid duplicate highlighting\n */\nfunction mergeOverlappingHighlights(highlights: MatchHighlight[]): MatchHighlight[] {\n  if (highlights.length === 0) return [];\n\n  // Sort by start position\n  const sorted = [...highlights].sort((a, b) => a.start - b.start);\n  const merged: MatchHighlight[] = [sorted[0]];\n\n  for (let i = 1; i < sorted.length; i++) {\n    const current = sorted[i];\n    const last = merged[merged.length - 1];\n\n    if (current.start <= last.end) {\n      // Overlapping - merge them\n      last.end = Math.max(last.end, current.end);\n      // Keep the more specific match type\n      if (getMatchTypePriority(current.type) > getMatchTypePriority(last.type)) {\n        last.type = current.type;\n      }\n    } else {\n      // No overlap - add as new highlight\n      merged.push(current);\n    }\n  }\n\n  return merged;\n}\n\n/**\n * Get priority for match types (higher = more specific)\n */\nfunction getMatchTypePriority(type: MatchType): number {\n  const priorities: Record<MatchType, number> = {\n    exact: 10,\n    prefix: 9,\n    substring: 8,\n    fuzzy: 7,\n    ngram: 6,\n    phonetic: 5,\n    compound: 4,\n    synonym: 3,\n  };\n  return priorities[type] || 0;\n}\n\n/**\n * Format highlighted text for HTML rendering\n */\nexport function formatHighlightedHTML(\n  text: string,\n  highlights: MatchHighlight[],\n  className: string = \"highlight\"\n): string {\n  if (!highlights || highlights.length === 0) {\n    return escapeHTML(text);\n  }\n\n  let result = \"\";\n  let lastEnd = 0;\n\n  for (const highlight of highlights) {\n    // Add text before highlight\n    if (highlight.start > lastEnd) {\n      result += escapeHTML(text.slice(lastEnd, highlight.start));\n    }\n\n    // Add highlighted text\n    const highlightedText = text.slice(highlight.start, highlight.end);\n    result += `<mark class=\"${className} ${className}--${highlight.type}\">${escapeHTML(highlightedText)}</mark>`;\n\n    lastEnd = highlight.end;\n  }\n\n  // Add remaining text\n  if (lastEnd < text.length) {\n    result += escapeHTML(text.slice(lastEnd));\n  }\n\n  return result;\n}\n\n/**\n * Escape HTML special characters\n */\nfunction escapeHTML(text: string): string {\n  const div = typeof document !== \"undefined\" ? document.createElement(\"div\") : null;\n  if (div) {\n    div.textContent = text;\n    return div.innerHTML;\n  }\n  // Fallback for Node.js\n  return text\n    .replace(/&/g, \"&amp;\")\n    .replace(/</g, \"&lt;\")\n    .replace(/>/g, \"&gt;\")\n    .replace(/\"/g, \"&quot;\")\n    .replace(/'/g, \"&#039;\");\n}\n","/**\n * LRU Cache for Search Results\n * Provides 10-100x speedup for repeated queries (e.g., autocomplete)\n */\n\nimport type { SuggestionResult } from \"./types.js\";\n\n/**\n * LRU (Least Recently Used) Cache\n * Automatically evicts oldest entries when capacity is reached\n */\nexport class LRUCache<K, V> {\n  private cache: Map<K, V>;\n  private capacity: number;\n\n  constructor(capacity: number = 100) {\n    this.cache = new Map();\n    this.capacity = capacity;\n  }\n\n  /**\n   * Get value from cache\n   * Moves item to end (most recently used)\n   */\n  get(key: K): V | undefined {\n    if (!this.cache.has(key)) {\n      return undefined;\n    }\n\n    // Move to end (most recently used)\n    const value = this.cache.get(key)!;\n    this.cache.delete(key);\n    this.cache.set(key, value);\n\n    return value;\n  }\n\n  /**\n   * Set value in cache\n   * Evicts oldest entry if capacity exceeded\n   */\n  set(key: K, value: V): void {\n    // Remove if exists (to update position)\n    if (this.cache.has(key)) {\n      this.cache.delete(key);\n    }\n\n    // Add to end (most recently used)\n    this.cache.set(key, value);\n\n    // Evict oldest if over capacity\n    if (this.cache.size > this.capacity) {\n      const firstKey = this.cache.keys().next().value as K;\n      if (firstKey !== undefined) {\n        this.cache.delete(firstKey);\n      }\n    }\n  }\n\n  /**\n   * Check if key exists in cache\n   */\n  has(key: K): boolean {\n    return this.cache.has(key);\n  }\n\n  /**\n   * Clear all cached entries\n   */\n  clear(): void {\n    this.cache.clear();\n  }\n\n  /**\n   * Get current cache size\n   */\n  get size(): number {\n    return this.cache.size;\n  }\n\n  /**\n   * Get cache statistics\n   */\n  getStats(): { size: number; capacity: number; utilization: number } {\n    return {\n      size: this.cache.size,\n      capacity: this.capacity,\n      utilization: this.cache.size / this.capacity,\n    };\n  }\n}\n\n/**\n * Search Result Cache\n * Caches search results with automatic invalidation\n */\nexport class SearchCache {\n  private cache: LRUCache<string, SuggestionResult[]>;\n  private hits: number = 0;\n  private misses: number = 0;\n\n  constructor(capacity: number = 100) {\n    this.cache = new LRUCache(capacity);\n  }\n\n  /**\n   * Generate cache key from query and options\n   */\n  private getCacheKey(query: string, maxResults?: number, options?: any): string {\n    const optionsKey = options ? JSON.stringify(options) : \"\";\n    return `${query}|${maxResults || \"default\"}|${optionsKey}`;\n  }\n\n  /**\n   * Get cached results\n   */\n  get(query: string, maxResults?: number, options?: any): SuggestionResult[] | undefined {\n    const key = this.getCacheKey(query, maxResults, options);\n    const result = this.cache.get(key);\n\n    if (result) {\n      this.hits++;\n    } else {\n      this.misses++;\n    }\n\n    return result;\n  }\n\n  /**\n   * Set cached results\n   */\n  set(query: string, results: SuggestionResult[], maxResults?: number, options?: any): void {\n    const key = this.getCacheKey(query, maxResults, options);\n    this.cache.set(key, results);\n  }\n\n  /**\n   * Clear cache\n   */\n  clear(): void {\n    this.cache.clear();\n    this.hits = 0;\n    this.misses = 0;\n  }\n\n  /**\n   * Get cache statistics\n   */\n  getStats(): {\n    size: number;\n    capacity: number;\n    hits: number;\n    misses: number;\n    hitRate: number;\n  } {\n    const cacheStats = this.cache.getStats();\n    const total = this.hits + this.misses;\n    const hitRate = total > 0 ? this.hits / total : 0;\n\n    return {\n      ...cacheStats,\n      hits: this.hits,\n      misses: this.misses,\n      hitRate,\n    };\n  }\n}\n","/**\n * Accent Normalization Utilities\n * Removes diacritics and accents from text for better matching\n */\n\n/**\n * Comprehensive accent/diacritic mapping\n * Maps accented characters to their base forms\n */\nconst ACCENT_MAP: Record<string, string> = {\n  // Latin Extended-A\n  à: \"a\",\n  á: \"a\",\n  â: \"a\",\n  ã: \"a\",\n  ä: \"a\",\n  å: \"a\",\n  ā: \"a\",\n  ă: \"a\",\n  ą: \"a\",\n  À: \"A\",\n  Á: \"A\",\n  Â: \"A\",\n  Ã: \"A\",\n  Ä: \"A\",\n  Å: \"A\",\n  Ā: \"A\",\n  Ă: \"A\",\n  Ą: \"A\",\n\n  è: \"e\",\n  é: \"e\",\n  ê: \"e\",\n  ë: \"e\",\n  ē: \"e\",\n  ĕ: \"e\",\n  ė: \"e\",\n  ę: \"e\",\n  ě: \"e\",\n  È: \"E\",\n  É: \"E\",\n  Ê: \"E\",\n  Ë: \"E\",\n  Ē: \"E\",\n  Ĕ: \"E\",\n  Ė: \"E\",\n  Ę: \"E\",\n  Ě: \"E\",\n\n  ì: \"i\",\n  í: \"i\",\n  î: \"i\",\n  ï: \"i\",\n  ĩ: \"i\",\n  ī: \"i\",\n  ĭ: \"i\",\n  į: \"i\",\n  Ì: \"I\",\n  Í: \"I\",\n  Î: \"I\",\n  Ï: \"I\",\n  Ĩ: \"I\",\n  Ī: \"I\",\n  Ĭ: \"I\",\n  Į: \"I\",\n\n  'ò': 'o', 'ó': 'o', 'ô': 'o', 'õ': 'o', 'ö': 'o', 'ø': 'o', 'ō': 'o', 'ŏ': 'o', 'ő': 'o',\n  'Ò': 'O', 'Ó': 'O', 'Ô': 'O', 'Õ': 'O', 'Ö': 'O', 'Ø': 'O', 'Ō': 'O', 'Ŏ': 'O', 'Ő': 'O',\n\n  'ù': 'u', 'ú': 'u', 'û': 'u', 'ü': 'u', 'ũ': 'u', 'ū': 'u', 'ŭ': 'u', 'ů': 'u', 'ű': 'u', 'ų': 'u',\n  'Ù': 'U', 'Ú': 'U', 'Û': 'U', 'Ü': 'U', 'Ũ': 'U', 'Ū': 'U', 'Ŭ': 'U', 'Ů': 'U', 'Ű': 'U', 'Ų': 'U',\n\n  ý: \"y\",\n  ÿ: \"y\",\n  ŷ: \"y\",\n  Ý: \"Y\",\n  Ÿ: \"Y\",\n  Ŷ: \"Y\",\n\n  ñ: \"n\",\n  ń: \"n\",\n  ņ: \"n\",\n  ň: \"n\",\n  Ñ: \"N\",\n  Ń: \"N\",\n  Ņ: \"N\",\n  Ň: \"N\",\n\n  ç: \"c\",\n  ć: \"c\",\n  ĉ: \"c\",\n  ċ: \"c\",\n  č: \"c\",\n  Ç: \"C\",\n  Ć: \"C\",\n  Ĉ: \"C\",\n  Ċ: \"C\",\n  Č: \"C\",\n\n  ß: \"ss\", // German sharp s\n\n  ð: \"d\",\n  đ: \"d\",\n  Ð: \"D\",\n  Đ: \"D\",\n\n  ĝ: \"g\",\n  ğ: \"g\",\n  ġ: \"g\",\n  ģ: \"g\",\n  Ĝ: \"G\",\n  Ğ: \"G\",\n  Ġ: \"G\",\n  Ģ: \"G\",\n\n  ĥ: \"h\",\n  ħ: \"h\",\n  Ĥ: \"H\",\n  Ħ: \"H\",\n\n  ĵ: \"j\",\n  Ĵ: \"J\",\n\n  ķ: \"k\",\n  Ķ: \"K\",\n\n  ĺ: \"l\",\n  ļ: \"l\",\n  ľ: \"l\",\n  ŀ: \"l\",\n  ł: \"l\",\n  Ĺ: \"L\",\n  Ļ: \"L\",\n  Ľ: \"L\",\n  Ŀ: \"L\",\n  Ł: \"L\",\n\n  ŕ: \"r\",\n  ŗ: \"r\",\n  ř: \"r\",\n  Ŕ: \"R\",\n  Ŗ: \"R\",\n  Ř: \"R\",\n\n  ś: \"s\",\n  ŝ: \"s\",\n  ş: \"s\",\n  š: \"s\",\n  Ś: \"S\",\n  Ŝ: \"S\",\n  Ş: \"S\",\n  Š: \"S\",\n\n  ţ: \"t\",\n  ť: \"t\",\n  ŧ: \"t\",\n  Ţ: \"T\",\n  Ť: \"T\",\n  Ŧ: \"T\",\n\n  ŵ: \"w\",\n  Ŵ: \"W\",\n\n  ź: \"z\",\n  ż: \"z\",\n  ž: \"z\",\n  Ź: \"Z\",\n  Ż: \"Z\",\n  Ž: \"Z\",\n\n  æ: \"ae\",\n  œ: \"oe\",\n  Æ: \"AE\",\n  Œ: \"OE\",\n\n  þ: \"th\",\n  Þ: \"TH\",\n};\n\n/**\n * Remove accents and diacritics from a string\n * Uses both custom mapping and Unicode normalization\n */\nexport function removeAccents(text: string): string {\n  if (!text) return text;\n\n  // First pass: Use custom accent map for known characters\n  let result = \"\";\n  for (let i = 0; i < text.length; i++) {\n    const char = text[i];\n    result += ACCENT_MAP[char] || char;\n  }\n\n  // Second pass: Use Unicode normalization for any remaining accents\n  // NFD = Canonical Decomposition (separates base char from combining marks)\n  // Then remove combining diacritical marks (Unicode range \\u0300-\\u036f)\n  result = result.normalize(\"NFD\").replace(/[\\u0300-\\u036f]/g, \"\");\n\n  return result;\n}\n\n/**\n * Check if a string contains any accented characters\n */\nexport function hasAccents(text: string): boolean {\n  if (!text) return false;\n\n  // Check custom map\n  for (let i = 0; i < text.length; i++) {\n    if (ACCENT_MAP[text[i]]) {\n      return true;\n    }\n  }\n\n  // Check for combining diacritical marks\n  const normalized = text.normalize(\"NFD\");\n  return /[\\u0300-\\u036f]/.test(normalized);\n}\n\n/**\n * Normalize text for accent-insensitive comparison\n * Converts to lowercase and removes accents\n */\nexport function normalizeForComparison(text: string): string {\n  return removeAccents(text.toLowerCase());\n}\n\n/**\n * Create accent-insensitive variants of a word\n * Returns both original and accent-free version\n */\nexport function getAccentVariants(word: string): string[] {\n  const normalized = removeAccents(word);\n\n  // If word has accents, return both versions\n  if (normalized !== word) {\n    return [word, normalized];\n  }\n\n  // Otherwise just return original\n  return [word];\n}\n","/**\n * Field Weighting Utilities\n * Support for multi-field search with weighted scoring\n */\n\n/**\n * Extract field values from an object or string\n */\nexport function extractFieldValues(\n  item: any,\n  fields?: string[]\n): Record<string, string> | null {\n  // If no fields specified, treat item as simple string\n  if (!fields || fields.length === 0) {\n    return null;\n  }\n\n  // If item is a string, can't extract fields\n  if (typeof item === 'string') {\n    return null;\n  }\n\n  // If item is an object, extract field values\n  if (typeof item === 'object' && item !== null) {\n    const fieldValues: Record<string, string> = {};\n    \n    for (const field of fields) {\n      const value = item[field];\n      if (value !== undefined && value !== null) {\n        fieldValues[field] = String(value);\n      }\n    }\n    \n    return Object.keys(fieldValues).length > 0 ? fieldValues : null;\n  }\n\n  return null;\n}\n\n/**\n * Get all searchable text from field values\n */\nexport function getSearchableText(fieldValues: Record<string, string>): string[] {\n  return Object.values(fieldValues).filter(v => v && v.trim().length > 0);\n}\n\n/**\n * Normalize field weights (ensure all fields have a weight)\n */\nexport function normalizeFieldWeights(\n  fields: string[],\n  fieldWeights?: Record<string, number>\n): Record<string, number> {\n  const normalized: Record<string, number> = {};\n  \n  for (const field of fields) {\n    normalized[field] = fieldWeights?.[field] ?? 1.0;\n  }\n  \n  return normalized;\n}\n\n/**\n * Apply field weight to a score\n */\nexport function applyFieldWeight(\n  baseScore: number,\n  fieldWeight: number\n): number {\n  return Math.min(1.0, baseScore * fieldWeight);\n}\n","/**\n * Stop Words Filtering\n * Common words that should be ignored in search queries\n */\n\n/**\n * Default stop words by language\n */\nexport const DEFAULT_STOP_WORDS: Record<string, string[]> = {\n  english: [\n    //\n    \"a\",\n    \"an\",\n    \"and\",\n    \"are\",\n    \"as\",\n    \"at\",\n    \"be\",\n    \"by\",\n    \"for\",\n    \"from\",\n    \"has\",\n    \"he\",\n    \"in\",\n    \"is\",\n    \"it\",\n    \"its\",\n    \"of\",\n    \"on\",\n    \"that\",\n    \"the\",\n    \"to\",\n    \"was\",\n    \"will\",\n    \"with\",\n    \"the\",\n    \"this\",\n    \"but\",\n    \"they\",\n    \"have\",\n    \"had\",\n    \"what\",\n    \"when\",\n    \"where\",\n    \"who\",\n    \"which\",\n    \"why\",\n    \"how\",\n  ],\n  german: [\n    //\n    \"der\",\n    \"die\",\n    \"das\",\n    \"den\",\n    \"dem\",\n    \"des\",\n    \"ein\",\n    \"eine\",\n    \"einer\",\n    \"eines\",\n    \"einem\",\n    \"einen\",\n    \"und\",\n    \"oder\",\n    \"aber\",\n    \"ist\",\n    \"sind\",\n    \"war\",\n    \"waren\",\n    \"hat\",\n    \"haben\",\n    \"wird\",\n    \"werden\",\n    \"von\",\n    \"zu\",\n    \"im\",\n    \"am\",\n    \"um\",\n    \"auf\",\n    \"für\",\n    \"mit\",\n    \"nach\",\n    \"bei\",\n    \"aus\",\n  ],\n  spanish: [\n    //\n    \"el\",\n    \"la\",\n    \"los\",\n    \"las\",\n    \"un\",\n    \"una\",\n    \"unos\",\n    \"unas\",\n    \"de\",\n    \"del\",\n    \"y\",\n    \"o\",\n    \"pero\",\n    \"es\",\n    \"son\",\n    \"era\",\n    \"fueron\",\n    \"ha\",\n    \"han\",\n    \"en\",\n    \"a\",\n    \"al\",\n    \"con\",\n    \"por\",\n    \"para\",\n    \"sin\",\n    \"sobre\",\n    \"entre\",\n  ],\n  french: [\n    //\n    \"le\",\n    \"la\",\n    \"les\",\n    \"un\",\n    \"une\",\n    \"des\",\n    \"du\",\n    \"de\",\n    \"et\",\n    \"ou\",\n    \"mais\",\n    \"est\",\n    \"sont\",\n    \"était\",\n    \"étaient\",\n    \"a\",\n    \"ont\",\n    \"à\",\n    \"au\",\n    \"aux\",\n    \"avec\",\n    \"pour\",\n    \"par\",\n    \"dans\",\n    \"sur\",\n    \"sous\",\n    \"entre\",\n  ],\n};\n\n/**\n * Filter stop words from a query\n */\nexport function filterStopWords(\n  query: string,\n  stopWords: string[] | Set<string>\n): string {\n  const stopWordsSet = stopWords instanceof Set ? stopWords : new Set(stopWords.map(w => w.toLowerCase()));\n  \n  // Split query into words, preserving original case\n  const words = query.split(/\\s+/);\n  const filtered = words.filter(word => !stopWordsSet.has(word.toLowerCase()));\n  \n  // If all words are stop words, return original query to avoid empty search\n  if (filtered.length === 0) {\n    return query;\n  }\n  \n  return filtered.join(' ');\n}\n\n/**\n * Get stop words for specific languages\n */\nexport function getStopWordsForLanguages(languages: string[]): Set<string> {\n  const stopWords = new Set<string>();\n\n  for (const lang of languages) {\n    const langStopWords = DEFAULT_STOP_WORDS[lang.toLowerCase()];\n    if (langStopWords) {\n      langStopWords.forEach((word) => stopWords.add(word));\n    }\n  }\n\n  return stopWords;\n}\n\n/**\n * Check if a word is a stop word\n */\nexport function isStopWord(word: string, stopWords: string[] | Set<string>): boolean {\n  const stopWordsSet = stopWords instanceof Set ? stopWords : new Set(stopWords.map((w) => w.toLowerCase()));\n  return stopWordsSet.has(word.toLowerCase());\n}\n","/**\n * Word Boundary Utilities\n * Check if matches occur at word boundaries for more precise results\n */\n\n/**\n * Check if a match is at a word boundary\n * A word boundary is:\n * - Start of string\n * - After whitespace\n * - After punctuation\n */\nexport function isWordBoundary(text: string, position: number): boolean {\n  // Start of string is always a word boundary\n  if (position === 0) {\n    return true;\n  }\n\n  // Check the character before the position\n  const charBefore = text[position - 1];\n  \n  // Word boundary if previous character is whitespace or punctuation\n  return /[\\s\\-_.,;:!?()[\\]{}'\"\\/\\\\]/.test(charBefore);\n}\n\n/**\n * Check if a match occurs at word boundaries (both start and end)\n */\nexport function matchesAtWordBoundary(\n  text: string,\n  matchStart: number,\n  matchLength: number\n): boolean {\n  const matchEnd = matchStart + matchLength;\n  \n  // Check start boundary\n  const startBoundary = isWordBoundary(text, matchStart);\n  \n  // Check end boundary (either end of string or followed by boundary character)\n  const endBoundary = matchEnd >= text.length || /[\\s\\-_.,;:!?()[\\]{}'\"\\/\\\\]/.test(text[matchEnd]);\n  \n  return startBoundary && endBoundary;\n}\n\n/**\n * Find all word boundary matches of a pattern in text\n */\nexport function findWordBoundaryMatches(\n  text: string,\n  pattern: string,\n  caseSensitive: boolean = false\n): number[] {\n  const positions: number[] = [];\n  const searchText = caseSensitive ? text : text.toLowerCase();\n  const searchPattern = caseSensitive ? pattern : pattern.toLowerCase();\n  \n  let index = 0;\n  while (index < searchText.length) {\n    const found = searchText.indexOf(searchPattern, index);\n    \n    if (found === -1) {\n      break;\n    }\n    \n    // Check if this match is at a word boundary\n    if (matchesAtWordBoundary(text, found, searchPattern.length)) {\n      positions.push(found);\n    }\n    \n    index = found + 1;\n  }\n  \n  return positions;\n}\n\n/**\n * Check if query matches word with word boundaries\n */\nexport function matchesWord(word: string, query: string, wordBoundaries: boolean): boolean {\n  if (!wordBoundaries) {\n    // No word boundary checking - substring match is fine\n    return word.toLowerCase().includes(query.toLowerCase());\n  }\n  \n  // With word boundaries - must match at word boundary\n  const positions = findWordBoundaryMatches(word, query, false);\n  return positions.length > 0;\n}\n\n/**\n * Check if a word starts with query (prefix match with word boundaries)\n */\nexport function startsWithWord(word: string, query: string, wordBoundaries: boolean): boolean {\n  const wordLower = word.toLowerCase();\n  const queryLower = query.toLowerCase();\n  \n  if (!wordBoundaries) {\n    return wordLower.startsWith(queryLower);\n  }\n  \n  // With word boundaries - check if it starts at position 0 (which is always a boundary)\n  return wordLower.startsWith(queryLower);\n}\n\n/**\n * Parse wildcard pattern (supports * for any characters)\n */\nexport function parseWildcard(pattern: string): RegExp {\n  // Escape special regex characters except *\n  const escaped = pattern.replace(/[.+?^${}()|[\\]\\\\]/g, '\\\\$&');\n  \n  // Replace * with .*\n  const regexPattern = escaped.replace(/\\*/g, '.*');\n  \n  // Create regex with word boundaries if no wildcards\n  return new RegExp(`^${regexPattern}$`, 'i');\n}\n\n/**\n * Check if word matches wildcard pattern\n */\nexport function matchesWildcard(word: string, pattern: string): boolean {\n  const regex = parseWildcard(pattern);\n  return regex.test(word);\n}\n","/**\n * Phrase parser for multi-word query support\n * Extracts quoted phrases and regular terms from search queries\n */\n\nexport interface ParsedQuery {\n  /** Quoted phrases to search as units */\n  phrases: string[];\n  /** Individual search terms */\n  terms: string[];\n  /** Original query string */\n  original: string;\n  /** Whether query contains any phrases */\n  hasPhrases: boolean;\n}\n\n/**\n * Parse a search query to extract phrases and terms\n * Supports both double quotes (\") and single quotes (')\n * \n * @example\n * parseQuery('\"new york\" city')\n * // → { phrases: ['new york'], terms: ['city'], hasPhrases: true }\n * \n * parseQuery('hello world')\n * // → { phrases: [], terms: ['hello', 'world'], hasPhrases: false }\n */\nexport function parseQuery(query: string): ParsedQuery {\n  if (!query || typeof query !== 'string') {\n    return {\n      phrases: [],\n      terms: [],\n      original: query || '',\n      hasPhrases: false,\n    };\n  }\n\n  const phrases: string[] = [];\n  let remaining = query;\n\n  // Extract phrases with double quotes\n  const doubleQuoteRegex = /\"([^\"]+)\"/g;\n  let match;\n  \n  while ((match = doubleQuoteRegex.exec(query)) !== null) {\n    const phrase = match[1].trim();\n    if (phrase) {\n      // Validate phrase length (max 10 words)\n      const wordCount = phrase.split(/\\s+/).length;\n      if (wordCount <= 10) {\n        phrases.push(phrase);\n      }\n    }\n  }\n\n  // Remove double-quoted phrases from remaining text (including empty ones)\n  remaining = remaining.replace(/\"[^\"]*\"/g, ' ');\n\n  // Extract phrases with single quotes\n  const singleQuoteRegex = /'([^']+)'/g;\n  \n  while ((match = singleQuoteRegex.exec(query)) !== null) {\n    const phrase = match[1].trim();\n    if (phrase) {\n      // Validate phrase length (max 10 words)\n      const wordCount = phrase.split(/\\s+/).length;\n      if (wordCount <= 10) {\n        phrases.push(phrase);\n      }\n    }\n  }\n\n  // Remove single-quoted phrases from remaining text (including empty ones)\n  remaining = remaining.replace(/'[^']*'/g, ' ');\n\n  // Extract remaining terms (non-phrase words)\n  const terms = remaining\n    .split(/\\s+/)\n    .map(t => t.trim())\n    .filter(t => t.length > 0);\n\n  return {\n    phrases,\n    terms,\n    original: query,\n    hasPhrases: phrases.length > 0,\n  };\n}\n\n/**\n * Check if a query contains phrase syntax (quotes)\n */\nexport function hasPhraseSyntax(query: string): boolean {\n  if (!query) return false;\n  return /\"[^\"]*\"/.test(query) || /'[^']*'/.test(query);\n}\n\n/**\n * Normalize a phrase for matching (lowercase, trim)\n */\nexport function normalizePhrase(phrase: string): string {\n  return phrase.toLowerCase().trim().replace(/\\s+/g, ' ');\n}\n\n/**\n * Split a phrase into words\n */\nexport function splitPhraseWords(phrase: string): string[] {\n  return phrase\n    .toLowerCase()\n    .trim()\n    .split(/\\s+/)\n    .filter(w => w.length > 0);\n}\n","/**\n * Phrase matching algorithms for multi-word query support\n */\n\nimport { calculateLevenshteinDistance, calculateDamerauLevenshteinDistance } from '../algorithms/levenshtein.js';\n\nexport interface PhraseMatchOptions {\n  /** Require exact phrase match (no typos) */\n  exactMatch?: boolean;\n  /** Maximum edit distance per word in phrase */\n  maxEditDistance?: number;\n  /** Score multiplier for phrase matches */\n  proximityBonus?: number;\n  /** Maximum words between phrase words for proximity match */\n  maxProximityDistance?: number;\n  /** Use Damerau-Levenshtein (transpositions) */\n  useTranspositions?: boolean;\n}\n\nexport interface PhraseMatchResult {\n  /** Whether phrase was found */\n  matched: boolean;\n  /** Match score (0-1) */\n  score: number;\n  /** Type of match */\n  matchType: 'exact' | 'fuzzy' | 'proximity' | 'none';\n  /** Start position in text */\n  startPos?: number;\n  /** End position in text */\n  endPos?: number;\n  /** Words that matched */\n  matchedWords?: string[];\n}\n\nconst DEFAULT_OPTIONS: Required<PhraseMatchOptions> = {\n  exactMatch: false,\n  maxEditDistance: 1,\n  proximityBonus: 1.5,\n  maxProximityDistance: 3,\n  useTranspositions: false,\n};\n\n/**\n * Match a phrase in text with various strategies\n */\nexport function matchPhrase(\n  text: string,\n  phrase: string,\n  options: PhraseMatchOptions = {}\n): PhraseMatchResult {\n  const opts = { ...DEFAULT_OPTIONS, ...options };\n  \n  if (!text || !phrase) {\n    return { matched: false, score: 0, matchType: 'none' };\n  }\n\n  const normalizedText = text.toLowerCase();\n  const normalizedPhrase = phrase.toLowerCase();\n\n  // Strategy 1: Exact phrase match (highest score)\n  const exactMatch = findExactPhrase(normalizedText, normalizedPhrase);\n  if (exactMatch.matched) {\n    return { ...exactMatch, score: 1.0, matchType: 'exact' };\n  }\n\n  // If exact match required, stop here\n  if (opts.exactMatch) {\n    return { matched: false, score: 0, matchType: 'none' };\n  }\n\n  // Strategy 2: Fuzzy phrase match (allow typos)\n  const fuzzyMatch = findFuzzyPhrase(\n    normalizedText,\n    normalizedPhrase,\n    opts.maxEditDistance,\n    opts.useTranspositions\n  );\n  if (fuzzyMatch.matched) {\n    return { ...fuzzyMatch, matchType: 'fuzzy' };\n  }\n\n  // Strategy 3: Proximity match (words nearby)\n  const proximityMatch = findProximityMatch(\n    normalizedText,\n    normalizedPhrase,\n    opts.maxProximityDistance\n  );\n  if (proximityMatch.matched) {\n    return { ...proximityMatch, matchType: 'proximity' };\n  }\n\n  return { matched: false, score: 0, matchType: 'none' };\n}\n\n/**\n * Find exact phrase in text\n */\nfunction findExactPhrase(text: string, phrase: string): PhraseMatchResult {\n  const index = text.indexOf(phrase);\n  \n  if (index !== -1) {\n    return {\n      matched: true,\n      score: 1.0,\n      matchType: 'exact',\n      startPos: index,\n      endPos: index + phrase.length,\n    };\n  }\n\n  return { matched: false, score: 0, matchType: 'none' };\n}\n\n/**\n * Find phrase with fuzzy matching (allow typos)\n */\nfunction findFuzzyPhrase(\n  text: string,\n  phrase: string,\n  maxEditDistance: number,\n  useTranspositions: boolean\n): PhraseMatchResult {\n  const phraseWords = phrase.split(/\\s+/);\n  const textWords = text.split(/\\s+/);\n\n  // Try to find consecutive words that match the phrase\n  for (let i = 0; i <= textWords.length - phraseWords.length; i++) {\n    const segment = textWords.slice(i, i + phraseWords.length);\n    \n    // Check if this segment matches the phrase with fuzzy matching\n    let totalDistance = 0;\n    let allMatch = true;\n\n    for (let j = 0; j < phraseWords.length; j++) {\n      const distance = useTranspositions\n        ? calculateDamerauLevenshteinDistance(phraseWords[j], segment[j], maxEditDistance)\n        : calculateLevenshteinDistance(phraseWords[j], segment[j], maxEditDistance);\n\n      if (distance > maxEditDistance) {\n        allMatch = false;\n        break;\n      }\n      totalDistance += distance;\n    }\n\n    if (allMatch) {\n      // Calculate score based on edit distance\n      const maxPossibleDistance = phraseWords.length * maxEditDistance;\n      const score = maxPossibleDistance > 0\n        ? 0.7 + (0.2 * (1 - totalDistance / maxPossibleDistance))\n        : 0.9;\n\n      return {\n        matched: true,\n        score,\n        matchType: 'fuzzy',\n        matchedWords: segment,\n      };\n    }\n  }\n\n  return { matched: false, score: 0, matchType: 'none' };\n}\n\n/**\n * Find words in proximity (nearby but not necessarily consecutive)\n */\nfunction findProximityMatch(\n  text: string,\n  phrase: string,\n  maxDistance: number\n): PhraseMatchResult {\n  const phraseWords = phrase.split(/\\s+/);\n  const textWords = text.split(/\\s+/);\n\n  // Find positions of each phrase word in text\n  const positions: number[][] = phraseWords.map(() => []);\n\n  textWords.forEach((word, index) => {\n    phraseWords.forEach((phraseWord, phraseIndex) => {\n      if (word === phraseWord || word.includes(phraseWord) || phraseWord.includes(word)) {\n        positions[phraseIndex].push(index);\n      }\n    });\n  });\n\n  // Check if all words were found\n  if (positions.some(p => p.length === 0)) {\n    return { matched: false, score: 0, matchType: 'none' };\n  }\n\n  // Find the best combination where words are close together\n  let bestDistance = Infinity;\n  let bestPositions: number[] = [];\n\n  function findBestCombination(wordIndex: number, currentPositions: number[]): void {\n    if (wordIndex === phraseWords.length) {\n      // Calculate total distance\n      const sorted = [...currentPositions].sort((a, b) => a - b);\n      const distance = sorted[sorted.length - 1] - sorted[0];\n      \n      if (distance < bestDistance) {\n        bestDistance = distance;\n        bestPositions = [...currentPositions];\n      }\n      return;\n    }\n\n    for (const pos of positions[wordIndex]) {\n      findBestCombination(wordIndex + 1, [...currentPositions, pos]);\n    }\n  }\n\n  findBestCombination(0, []);\n\n  // Check if words are within max distance\n  if (bestDistance <= maxDistance) {\n    // Score based on proximity (closer = higher score)\n    const score = 0.5 + (0.2 * (1 - bestDistance / maxDistance));\n\n    return {\n      matched: true,\n      score,\n      matchType: 'proximity',\n      matchedWords: bestPositions.map(i => textWords[i]),\n    };\n  }\n\n  return { matched: false, score: 0, matchType: 'none' };\n}\n\n/**\n * Calculate phrase match score for a text\n * Returns 0 if no match, or a boosted score if phrase matches\n */\nexport function calculatePhraseScore(\n  text: string,\n  phrase: string,\n  baseScore: number,\n  options: PhraseMatchOptions = {}\n): number {\n  const match = matchPhrase(text, phrase, options);\n  \n  if (!match.matched) {\n    return 0;\n  }\n\n  // Apply proximity bonus\n  const bonus = options.proximityBonus || 1.5;\n  return Math.min(1.0, baseScore * match.score * bonus);\n}\n","/**\n * Language auto-detection utility\n * Uses character-based heuristics to detect languages in text\n */\n\nexport interface LanguageDetectionResult {\n  /** Detected languages */\n  languages: string[];\n  /** Confidence scores for each language (0-1) */\n  confidence: Record<string, number>;\n  /** Primary language (highest confidence) */\n  primary: string;\n}\n\n/**\n * Detect languages from text using character-based heuristics\n * Detects multiple languages if present in the same text\n * \n * @param text - Text to analyze\n * @returns Array of detected language codes\n * \n * @example\n * detectLanguages('Müller café hello')\n * // → ['english', 'german', 'french']\n */\nexport function detectLanguages(text: string): string[] {\n  if (!text || text.trim().length === 0) {\n    return ['english']; // Default fallback\n  }\n\n  const detected = new Set<string>();\n\n  // Always include English as base language\n  detected.add('english');\n\n  // German indicators: ä, ö, ü, ß\n  if (/[äöüßÄÖÜ]/.test(text)) {\n    detected.add('german');\n  }\n\n  // French indicators: é, è, ê, à, ç, œ, etc.\n  if (/[àâäæçéèêëïîôùûüÿœÀÂÄÆÇÉÈÊËÏÎÔÙÛÜŸŒ]/.test(text)) {\n    detected.add('french');\n  }\n\n  // Spanish indicators: ñ, á, é, í, ó, ú, ¿, ¡\n  if (/[áéíóúñüÁÉÍÓÚÑÜ¿¡]/.test(text)) {\n    detected.add('spanish');\n  }\n\n  return Array.from(detected);\n}\n\n/**\n * Detect languages with confidence scores\n * Provides more detailed information about language detection\n * \n * @param text - Text to analyze\n * @returns Detection result with confidence scores\n */\nexport function detectLanguagesWithConfidence(text: string): LanguageDetectionResult {\n  if (!text || text.trim().length === 0) {\n    return {\n      languages: ['english'],\n      confidence: { english: 1.0 },\n      primary: 'english',\n    };\n  }\n\n  const confidence: Record<string, number> = {\n    english: 0.5, // Base confidence for English\n  };\n\n  const textLength = text.length;\n\n  // Count German characters\n  const germanChars = (text.match(/[äöüßÄÖÜ]/g) || []).length;\n  if (germanChars > 0) {\n    confidence.german = Math.min(1.0, 0.5 + (germanChars / textLength) * 10);\n  }\n\n  // Count French characters\n  const frenchChars = (text.match(/[àâäæçéèêëïîôùûüÿœÀÂÄÆÇÉÈÊËÏÎÔÙÛÜŸŒ]/g) || []).length;\n  if (frenchChars > 0) {\n    confidence.french = Math.min(1.0, 0.5 + (frenchChars / textLength) * 10);\n  }\n\n  // Count Spanish characters\n  const spanishChars = (text.match(/[áéíóúñüÁÉÍÓÚÑÜ¿¡]/g) || []).length;\n  if (spanishChars > 0) {\n    confidence.spanish = Math.min(1.0, 0.5 + (spanishChars / textLength) * 10);\n  }\n\n  // Determine languages (confidence > 0.5)\n  const languages = Object.entries(confidence)\n    .filter(([_, conf]) => conf >= 0.5)\n    .map(([lang]) => lang);\n\n  // Find primary language (highest confidence)\n  const primary = Object.entries(confidence)\n    .sort(([, a], [, b]) => b - a)[0][0];\n\n  return {\n    languages,\n    confidence,\n    primary,\n  };\n}\n\n/**\n * Sample text from a dataset for language detection\n * Takes first N items to avoid processing entire large datasets\n * \n * @param words - Array of words or objects\n * @param sampleSize - Number of items to sample (default: 100)\n * @returns Combined sample text\n */\nexport function sampleTextForDetection(words: (string | any)[], sampleSize: number = 100): string {\n  const sample = words.slice(0, Math.min(sampleSize, words.length));\n  \n  return sample\n    .map(item => {\n      if (typeof item === 'string') {\n        return item;\n      } else if (typeof item === 'object' && item !== null) {\n        // Extract text from object fields\n        return Object.values(item)\n          .filter(v => typeof v === 'string')\n          .join(' ');\n      }\n      return '';\n    })\n    .join(' ');\n}\n\n/**\n * Check if a language code is valid\n */\nexport function isValidLanguage(lang: string): boolean {\n  const validLanguages = ['english', 'german', 'french', 'spanish', 'auto'];\n  return validLanguages.includes(lang.toLowerCase());\n}\n\n/**\n * Normalize language codes\n * Handles common variations and aliases\n */\nexport function normalizeLanguageCode(lang: string): string {\n  const normalized = lang.toLowerCase().trim();\n  \n  // Handle aliases\n  const aliases: Record<string, string> = {\n    'en': 'english',\n    'de': 'german',\n    'fr': 'french',\n    'es': 'spanish',\n    'eng': 'english',\n    'deu': 'german',\n    'fra': 'french',\n    'esp': 'spanish',\n  };\n  \n  return aliases[normalized] || normalized;\n}\n","/**\n * FQL Lexer (Tokenizer)\n * Converts FQL query strings into tokens for parsing\n */\n\nexport const TokenType = {\n  TERM: \"TERM\",\n  QUOTED: \"QUOTED\",\n  AND: \"AND\",\n  OR: \"OR\",\n  NOT: \"NOT\",\n  LPAREN: \"LPAREN\",\n  RPAREN: \"RPAREN\",\n  COLON: \"COLON\",\n  EXACT: \"EXACT\",\n  FUZZY: \"FUZZY\",\n  PHONETIC: \"PHONETIC\",\n  PREFIX: \"PREFIX\",\n  REGEX: \"REGEX\",\n  COMPOUND: \"COMPOUND\",\n  LANG: \"LANG\",\n  SCORE: \"SCORE\",\n  SCORE_OP: \"SCORE_OP\",\n  NUMBER: \"NUMBER\",\n  EOF: \"EOF\",\n} as const;\n\nexport type TokenType = (typeof TokenType)[keyof typeof TokenType];\n\nexport interface Token {\n  type: TokenType;\n  value: string;\n  position: number;\n}\n\nexport class FQLLexer {\n  private input: string = \"\";\n  private position: number = 0;\n  private tokens: Token[] = [];\n\n  /**\n   * Tokenize an FQL query string\n   */\n  tokenize(input: string): Token[] {\n    this.input = input.trim();\n    this.position = 0;\n    this.tokens = [];\n\n    while (this.position < this.input.length) {\n      this.skipWhitespace();\n\n      if (this.position >= this.input.length) break;\n\n      const char = this.input[this.position];\n\n      // Parentheses\n      if (char === \"(\") {\n        this.tokens.push({ type: TokenType.LPAREN, value: \"(\", position: this.position });\n        this.position++;\n        continue;\n      }\n\n      if (char === \")\") {\n        this.tokens.push({ type: TokenType.RPAREN, value: \")\", position: this.position });\n        this.position++;\n        continue;\n      }\n\n      // Colon\n      if (char === \":\") {\n        this.tokens.push({ type: TokenType.COLON, value: \":\", position: this.position });\n        this.position++;\n        continue;\n      }\n\n      // Quoted strings\n      if (char === '\"' || char === \"'\") {\n        this.tokenizeQuotedString(char);\n        continue;\n      }\n\n      // Numbers (for score thresholds)\n      if (this.isDigit(char)) {\n        this.tokenizeNumber();\n        continue;\n      }\n\n      // Keywords and terms\n      if (this.isAlpha(char)) {\n        this.tokenizeKeywordOrTerm();\n        continue;\n      }\n\n      // Score operators (>, <, >=, <=)\n      if (char === \">\" || char === \"<\") {\n        this.tokenizeScoreOperator();\n        continue;\n      }\n\n      // Unknown character - skip it\n      this.position++;\n    }\n\n    // Add EOF token\n    this.tokens.push({ type: TokenType.EOF, value: \"\", position: this.position });\n\n    return this.tokens;\n  }\n\n  private skipWhitespace(): void {\n    while (this.position < this.input.length && /\\s/.test(this.input[this.position])) {\n      this.position++;\n    }\n  }\n\n  private isAlpha(char: string): boolean {\n    return /[a-zA-ZäöüßÄÖÜàâäæçéèêëïîôùûüÿœÀÂÄÆÇÉÈÊËÏÎÔÙÛÜŸŒáéíóúñüÁÉÍÓÚÑÜ_]/.test(char);\n  }\n\n  private isDigit(char: string): boolean {\n    return /[0-9.]/.test(char);\n  }\n\n  private isAlphaNumeric(char: string): boolean {\n    return this.isAlpha(char) || this.isDigit(char);\n  }\n\n  private tokenizeQuotedString(quote: string): void {\n    const start = this.position;\n    this.position++; // Skip opening quote\n\n    let value = \"\";\n    while (this.position < this.input.length && this.input[this.position] !== quote) {\n      value += this.input[this.position];\n      this.position++;\n    }\n\n    if (this.position >= this.input.length) {\n      throw new Error(`Unclosed quote at position ${start}`);\n    }\n\n    this.position++; // Skip closing quote\n\n    this.tokens.push({ type: TokenType.QUOTED, value, position: start });\n  }\n\n  private tokenizeNumber(): void {\n    const start = this.position;\n    let value = \"\";\n\n    while (this.position < this.input.length && this.isDigit(this.input[this.position])) {\n      value += this.input[this.position];\n      this.position++;\n    }\n\n    this.tokens.push({ type: TokenType.NUMBER, value, position: start });\n  }\n\n  private tokenizeKeywordOrTerm(): void {\n    const start = this.position;\n    let value = \"\";\n\n    while (this.position < this.input.length && this.isAlphaNumeric(this.input[this.position])) {\n      value += this.input[this.position];\n      this.position++;\n    }\n\n    const upperValue = value.toUpperCase();\n\n    // Check for keywords\n    switch (upperValue) {\n      case \"AND\":\n        this.tokens.push({ type: TokenType.AND, value: upperValue, position: start });\n        break;\n      case \"OR\":\n        this.tokens.push({ type: TokenType.OR, value: upperValue, position: start });\n        break;\n      case \"NOT\":\n        this.tokens.push({ type: TokenType.NOT, value: upperValue, position: start });\n        break;\n      case \"EXACT\":\n        this.tokens.push({ type: TokenType.EXACT, value: upperValue, position: start });\n        break;\n      case \"FUZZY\":\n        this.tokens.push({ type: TokenType.FUZZY, value: upperValue, position: start });\n        break;\n      case \"PHONETIC\":\n        this.tokens.push({ type: TokenType.PHONETIC, value: upperValue, position: start });\n        break;\n      case \"PREFIX\":\n        this.tokens.push({ type: TokenType.PREFIX, value: upperValue, position: start });\n        break;\n      case \"REGEX\":\n        this.tokens.push({ type: TokenType.REGEX, value: upperValue, position: start });\n        break;\n      case \"COMPOUND\":\n        this.tokens.push({ type: TokenType.COMPOUND, value: upperValue, position: start });\n        break;\n      case \"LANG\":\n        this.tokens.push({ type: TokenType.LANG, value: upperValue, position: start });\n        break;\n      case \"SCORE\":\n        this.tokens.push({ type: TokenType.SCORE, value: upperValue, position: start });\n        break;\n      default:\n        // Regular term (preserve original case)\n        this.tokens.push({ type: TokenType.TERM, value, position: start });\n        break;\n    }\n  }\n\n  private tokenizeScoreOperator(): void {\n    const start = this.position;\n    let value = this.input[this.position];\n    this.position++;\n\n    // Check for >= or <=\n    if (this.position < this.input.length && this.input[this.position] === \"=\") {\n      value += \"=\";\n      this.position++;\n    }\n\n    this.tokens.push({ type: TokenType.SCORE_OP, value, position: start });\n  }\n}\n","/**\n * FQL Parser\n * Converts tokens into an Abstract Syntax Tree (AST)\n */\n\nimport type { Token } from \"./lexer.js\";\nimport { TokenType } from \"./lexer.js\";\nimport type { FQLNode, TermNode, PhraseNode, AndNode, OrNode, NotNode, FilterNode, FieldNode, ScoreNode, LangNode } from \"./ast.js\";\n\nexport class FQLSyntaxError extends Error {\n  public position: number;\n  \n  constructor(message: string, position: number) {\n    super(message);\n    this.name = \"FQLSyntaxError\";\n    this.position = position;\n  }\n}\n\nexport class FQLParser {\n  private tokens: Token[] = [];\n  private current: number = 0;\n\n  /**\n   * Parse tokens into an AST\n   */\n  parse(tokens: Token[]): FQLNode {\n    this.tokens = tokens;\n    this.current = 0;\n\n    if (this.tokens.length === 0 || this.tokens[0].type === TokenType.EOF) {\n      throw new FQLSyntaxError(\"Empty query\", 0);\n    }\n\n    const ast = this.parseExpression();\n\n    // Ensure we consumed all tokens\n    if (!this.isAtEnd()) {\n      throw new FQLSyntaxError(`Unexpected token '${this.peek().value}' at position ${this.peek().position}`, this.peek().position);\n    }\n\n    return ast;\n  }\n\n  /**\n   * expression → or_expr\n   */\n  private parseExpression(): FQLNode {\n    return this.parseOrExpression();\n  }\n\n  /**\n   * or_expr → and_expr ( OR and_expr )*\n   */\n  private parseOrExpression(): FQLNode {\n    let left = this.parseAndExpression();\n\n    while (this.match(TokenType.OR)) {\n      const right = this.parseAndExpression();\n      left = {\n        type: \"or\",\n        left,\n        right,\n      } as OrNode;\n    }\n\n    return left;\n  }\n\n  /**\n   * and_expr → not_expr ( AND not_expr )*\n   */\n  private parseAndExpression(): FQLNode {\n    let left = this.parseNotExpression();\n\n    while (this.match(TokenType.AND)) {\n      const right = this.parseNotExpression();\n      left = {\n        type: \"and\",\n        left,\n        right,\n      } as AndNode;\n    }\n\n    return left;\n  }\n\n  /**\n   * not_expr → NOT? primary\n   */\n  private parseNotExpression(): FQLNode {\n    if (this.match(TokenType.NOT)) {\n      const child = this.parsePrimary();\n      return {\n        type: \"not\",\n        child,\n      } as NotNode;\n    }\n\n    return this.parsePrimary();\n  }\n\n  /**\n   * primary → filter | field | lang | score | term | phrase | grouped\n   */\n  private parsePrimary(): FQLNode {\n    // Grouped expression: ( expression )\n    if (this.match(TokenType.LPAREN)) {\n      const expr = this.parseExpression();\n      if (!this.match(TokenType.RPAREN)) {\n        throw new FQLSyntaxError(`Expected ')' at position ${this.peek().position}`, this.peek().position);\n      }\n      return expr;\n    }\n\n    // Filter: EXACT:value, FUZZY:value, etc.\n    if (this.check(TokenType.EXACT) || this.check(TokenType.FUZZY) || this.check(TokenType.PHONETIC) || this.check(TokenType.PREFIX) || this.check(TokenType.REGEX) || this.check(TokenType.COMPOUND)) {\n      return this.parseFilter();\n    }\n\n    // Language: LANG:german term\n    if (this.check(TokenType.LANG)) {\n      return this.parseLang();\n    }\n\n    // Quoted phrase\n    if (this.check(TokenType.QUOTED)) {\n      const token = this.advance();\n      const phrase: PhraseNode = {\n        type: \"phrase\",\n        value: token.value,\n      };\n\n      // Check for SCORE filter after phrase\n      if (this.check(TokenType.SCORE)) {\n        return this.parseScore(phrase);\n      }\n\n      return phrase;\n    }\n\n    // Term (could be field:value or just term)\n    if (this.check(TokenType.TERM)) {\n      const token = this.advance();\n\n      // Check if it's a field selector: term:expression\n      if (this.match(TokenType.COLON)) {\n        const child = this.parsePrimary();\n        const field: FieldNode = {\n          type: \"field\",\n          field: token.value,\n          child,\n        };\n        return field;\n      }\n\n      // Just a regular term\n      const term: TermNode = {\n        type: \"term\",\n        value: token.value,\n      };\n\n      // Check for SCORE filter after term\n      if (this.check(TokenType.SCORE)) {\n        return this.parseScore(term);\n      }\n\n      return term;\n    }\n\n    throw new FQLSyntaxError(`Unexpected token '${this.peek().value}' at position ${this.peek().position}`, this.peek().position);\n  }\n\n  /**\n   * filter → (EXACT|FUZZY|PHONETIC|PREFIX|REGEX|COMPOUND) COLON value\n   */\n  private parseFilter(): FQLNode {\n    const filterToken = this.advance();\n    const filterType = filterToken.value.toLowerCase() as \"exact\" | \"fuzzy\" | \"phonetic\" | \"prefix\" | \"regex\" | \"compound\";\n\n    if (!this.match(TokenType.COLON)) {\n      throw new FQLSyntaxError(`Expected ':' after ${filterToken.value} at position ${this.peek().position}`, this.peek().position);\n    }\n\n    let value: string;\n\n    if (this.check(TokenType.QUOTED)) {\n      value = this.advance().value;\n    } else if (this.check(TokenType.TERM)) {\n      value = this.advance().value;\n    } else {\n      throw new FQLSyntaxError(`Expected value after ${filterToken.value}: at position ${this.peek().position}`, this.peek().position);\n    }\n\n    const filter: FilterNode = {\n      type: \"filter\",\n      filterType,\n      value,\n    };\n\n    // Check for SCORE filter after filter\n    if (this.check(TokenType.SCORE)) {\n      return this.parseScore(filter);\n    }\n\n    return filter;\n  }\n\n  /**\n   * lang → LANG COLON TERM expression\n   */\n  private parseLang(): LangNode {\n    this.advance(); // Consume LANG\n\n    if (!this.match(TokenType.COLON)) {\n      throw new FQLSyntaxError(`Expected ':' after LANG at position ${this.peek().position}`, this.peek().position);\n    }\n\n    if (!this.check(TokenType.TERM)) {\n      throw new FQLSyntaxError(`Expected language name after LANG: at position ${this.peek().position}`, this.peek().position);\n    }\n\n    const language = this.advance().value;\n    const child = this.parsePrimary();\n\n    return {\n      type: \"lang\",\n      language,\n      child,\n    };\n  }\n\n  /**\n   * score → expression SCORE (>|<|>=|<=) NUMBER\n   */\n  private parseScore(child: FQLNode): ScoreNode {\n    this.advance(); // Consume SCORE\n\n    if (!this.check(TokenType.SCORE_OP)) {\n      throw new FQLSyntaxError(`Expected score operator (>, <, >=, <=) at position ${this.peek().position}`, this.peek().position);\n    }\n\n    const operator = this.advance().value as \">\" | \"<\" | \">=\" | \"<=\";\n\n    if (!this.check(TokenType.NUMBER)) {\n      throw new FQLSyntaxError(`Expected number after ${operator} at position ${this.peek().position}`, this.peek().position);\n    }\n\n    const threshold = parseFloat(this.advance().value);\n\n    if (isNaN(threshold) || threshold < 0 || threshold > 1) {\n      throw new FQLSyntaxError(`Score threshold must be between 0 and 1`, this.previous().position);\n    }\n\n    return {\n      type: \"score\",\n      operator,\n      threshold,\n      child,\n    };\n  }\n\n  // Helper methods\n\n  private match(...types: TokenType[]): boolean {\n    for (const type of types) {\n      if (this.check(type)) {\n        this.advance();\n        return true;\n      }\n    }\n    return false;\n  }\n\n  private check(type: TokenType): boolean {\n    if (this.isAtEnd()) return false;\n    return this.peek().type === type;\n  }\n\n  private advance(): Token {\n    if (!this.isAtEnd()) this.current++;\n    return this.previous();\n  }\n\n  private isAtEnd(): boolean {\n    return this.peek().type === TokenType.EOF;\n  }\n\n  private peek(): Token {\n    return this.tokens[this.current];\n  }\n\n  private previous(): Token {\n    return this.tokens[this.current - 1];\n  }\n}\n","/**\n * FQL Abstract Syntax Tree (AST) Node Types\n */\n\nexport type FQLNode = TermNode | PhraseNode | AndNode | OrNode | NotNode | FilterNode | FieldNode | ScoreNode | LangNode;\n\n/**\n * Simple term node\n */\nexport interface TermNode {\n  type: \"term\";\n  value: string;\n}\n\n/**\n * Quoted phrase node\n */\nexport interface PhraseNode {\n  type: \"phrase\";\n  value: string;\n}\n\n/**\n * AND operator node (intersection)\n */\nexport interface AndNode {\n  type: \"and\";\n  left: FQLNode;\n  right: FQLNode;\n}\n\n/**\n * OR operator node (union)\n */\nexport interface OrNode {\n  type: \"or\";\n  left: FQLNode;\n  right: FQLNode;\n}\n\n/**\n * NOT operator node (exclusion)\n */\nexport interface NotNode {\n  type: \"not\";\n  child: FQLNode;\n}\n\n/**\n * Match type filter node\n */\nexport interface FilterNode {\n  type: \"filter\";\n  filterType: \"exact\" | \"fuzzy\" | \"phonetic\" | \"prefix\" | \"regex\" | \"compound\";\n  value: string;\n}\n\n/**\n * Field selector node\n */\nexport interface FieldNode {\n  type: \"field\";\n  field: string;\n  child: FQLNode;\n}\n\n/**\n * Score filter node\n */\nexport interface ScoreNode {\n  type: \"score\";\n  operator: \">\" | \"<\" | \">=\" | \"<=\";\n  threshold: number;\n  child: FQLNode;\n}\n\n/**\n * Language filter node\n */\nexport interface LangNode {\n  type: \"lang\";\n  language: string;\n  child: FQLNode;\n}\n\n/**\n * Helper to check node type\n */\nexport function isTermNode(node: FQLNode): node is TermNode {\n  return node.type === \"term\";\n}\n\nexport function isPhraseNode(node: FQLNode): node is PhraseNode {\n  return node.type === \"phrase\";\n}\n\nexport function isAndNode(node: FQLNode): node is AndNode {\n  return node.type === \"and\";\n}\n\nexport function isOrNode(node: FQLNode): node is OrNode {\n  return node.type === \"or\";\n}\n\nexport function isNotNode(node: FQLNode): node is NotNode {\n  return node.type === \"not\";\n}\n\nexport function isFilterNode(node: FQLNode): node is FilterNode {\n  return node.type === \"filter\";\n}\n\nexport function isFieldNode(node: FQLNode): node is FieldNode {\n  return node.type === \"field\";\n}\n\nexport function isScoreNode(node: FQLNode): node is ScoreNode {\n  return node.type === \"score\";\n}\n\nexport function isLangNode(node: FQLNode): node is LangNode {\n  return node.type === \"lang\";\n}\n","/**\n * FQL Executor\n * Executes FQL AST against a fuzzy index\n */\n\nimport type { FuzzyIndex, SuggestionResult, SearchOptions } from \"../core/types.js\";\nimport type { FQLNode } from \"./ast.js\";\nimport { isAndNode, isOrNode, isNotNode, isTermNode, isPhraseNode, isFilterNode, isFieldNode, isScoreNode, isLangNode } from \"./ast.js\";\nimport { getSuggestions } from \"../core/index.js\";\n\nexport class FQLTimeoutError extends Error {\n  constructor(message: string) {\n    super(message);\n    this.name = \"FQLTimeoutError\";\n  }\n}\n\nexport class FQLExecutor {\n  private index: FuzzyIndex;\n  private options: SearchOptions;\n  private startTime: number = 0;\n  private timeout: number = 5000; // Default 5 seconds\n\n  constructor(index: FuzzyIndex, options: SearchOptions = {}) {\n    this.index = index;\n    this.options = options;\n    this.timeout = options.fqlOptions?.timeout || 5000;\n  }\n\n  /**\n   * Execute an FQL AST and return results\n   */\n  execute(ast: FQLNode): SuggestionResult[] {\n    this.startTime = Date.now();\n    return this.executeNode(ast);\n  }\n\n  private checkTimeout(): void {\n    if (Date.now() - this.startTime > this.timeout) {\n      throw new FQLTimeoutError(`Query execution timeout after ${this.timeout}ms`);\n    }\n  }\n\n  private executeNode(node: FQLNode): SuggestionResult[] {\n    this.checkTimeout();\n\n    if (isAndNode(node)) {\n      return this.executeAnd(node);\n    }\n\n    if (isOrNode(node)) {\n      return this.executeOr(node);\n    }\n\n    if (isNotNode(node)) {\n      return this.executeNot(node);\n    }\n\n    if (isTermNode(node)) {\n      return this.executeTerm(node.value);\n    }\n\n    if (isPhraseNode(node)) {\n      return this.executePhrase(node.value);\n    }\n\n    if (isFilterNode(node)) {\n      return this.executeFilter(node);\n    }\n\n    if (isFieldNode(node)) {\n      return this.executeField(node);\n    }\n\n    if (isScoreNode(node)) {\n      return this.executeScore(node);\n    }\n\n    if (isLangNode(node)) {\n      return this.executeLang(node);\n    }\n\n    return [];\n  }\n\n  /**\n   * Execute AND - intersection of results\n   */\n  private executeAnd(node: { left: FQLNode; right: FQLNode }): SuggestionResult[] {\n    const leftResults = this.executeNode(node.left);\n    const rightResults = this.executeNode(node.right);\n\n    // Intersection: items that appear in both\n    const rightDisplays = new Set(rightResults.map((r) => r.display));\n    const intersection = leftResults.filter((r) => rightDisplays.has(r.display));\n\n    // Sort by score\n    return intersection.sort((a, b) => b.score - a.score);\n  }\n\n  /**\n   * Execute OR - union of results\n   */\n  private executeOr(node: { left: FQLNode; right: FQLNode }): SuggestionResult[] {\n    const leftResults = this.executeNode(node.left);\n    const rightResults = this.executeNode(node.right);\n\n    // Union: combine and deduplicate\n    const resultMap = new Map<string, SuggestionResult>();\n\n    for (const result of leftResults) {\n      resultMap.set(result.display, result);\n    }\n\n    for (const result of rightResults) {\n      const existing = resultMap.get(result.display);\n      // Keep higher score\n      if (!existing || result.score > existing.score) {\n        resultMap.set(result.display, result);\n      }\n    }\n\n    // Sort by score\n    return Array.from(resultMap.values()).sort((a, b) => b.score - a.score);\n  }\n\n  /**\n   * Execute NOT - exclusion of results\n   */\n  private executeNot(node: { child: FQLNode }): SuggestionResult[] {\n    const childResults = this.executeNode(node.child);\n    const excludeDisplays = new Set(childResults.map((r) => r.display));\n\n    // Get all results and exclude\n    const allResults = getSuggestions(this.index, \"\", this.index.base.length, this.options);\n    return allResults.filter((r) => !excludeDisplays.has(r.display)).sort((a, b) => b.score - a.score);\n  }\n\n  /**\n   * Execute simple term search\n   */\n  private executeTerm(term: string): SuggestionResult[] {\n    return getSuggestions(this.index, term, this.index.base.length, this.options);\n  }\n\n  /**\n   * Execute phrase search\n   */\n  private executePhrase(phrase: string): SuggestionResult[] {\n    // Use existing phrase search with quotes\n    return getSuggestions(this.index, `\"${phrase}\"`, this.index.base.length, this.options);\n  }\n\n  /**\n   * Execute filter (EXACT, FUZZY, PHONETIC, etc.)\n   */\n  private executeFilter(node: { filterType: string; value: string }): SuggestionResult[] {\n    const { filterType, value } = node;\n\n    // Get all results for the value\n    const results = getSuggestions(this.index, value, this.index.base.length, this.options);\n\n    // Filter by match type\n    switch (filterType) {\n      case \"exact\":\n        return results.filter((r) => (r as any)._debug_matchType === \"exact\");\n\n      case \"fuzzy\":\n        return results.filter((r) => (r as any)._debug_matchType === \"fuzzy\");\n\n      case \"phonetic\":\n        return results.filter((r) => (r as any)._debug_matchType === \"phonetic\");\n\n      case \"prefix\":\n        return results.filter((r) => (r as any)._debug_matchType === \"prefix\");\n\n      case \"compound\":\n        return results.filter((r) => (r as any)._debug_matchType === \"compound\");\n\n      case \"regex\":\n        return this.executeRegex(value);\n\n      default:\n        return results;\n    }\n  }\n\n  /**\n   * Execute regex pattern\n   */\n  private executeRegex(pattern: string): SuggestionResult[] {\n    // Check if regex is allowed\n    if (!this.options.fqlOptions?.allowRegex) {\n      throw new Error(\"Regex not enabled. Set fqlOptions.allowRegex = true\");\n    }\n\n    try {\n      const regex = new RegExp(pattern);\n      const results: SuggestionResult[] = [];\n\n      for (const word of this.index.base) {\n        if (regex.test(word)) {\n          results.push({\n            display: word,\n            baseWord: word,\n            score: 1.0,\n            isSynonym: false,\n            language: \"unknown\",\n            _debug_matchType: \"regex\",\n          } as any);\n        }\n      }\n\n      return results;\n    } catch (error) {\n      throw new Error(`Invalid regex pattern: ${pattern}`);\n    }\n  }\n\n  /**\n   * Execute field selector\n   */\n  private executeField(node: { field: string; child: FQLNode }): SuggestionResult[] {\n    // Execute child query\n    const childResults = this.executeNode(node.child);\n\n    // Filter by field if multi-field index\n    if (!this.index.fieldData) {\n      // No field data, return all results\n      return childResults;\n    }\n\n    // Filter results that match the field\n    return childResults.filter((result) => {\n      if (result.field === node.field) {\n        return true;\n      }\n      return false;\n    });\n  }\n\n  /**\n   * Execute score filter\n   */\n  private executeScore(node: { operator: string; threshold: number; child: FQLNode }): SuggestionResult[] {\n    const childResults = this.executeNode(node.child);\n    const { operator, threshold } = node;\n\n    return childResults.filter((result) => {\n      switch (operator) {\n        case \">\":\n          return result.score > threshold;\n        case \"<\":\n          return result.score < threshold;\n        case \">=\":\n          return result.score >= threshold;\n        case \"<=\":\n          return result.score <= threshold;\n        default:\n          return true;\n      }\n    });\n  }\n\n  /**\n   * Execute language filter\n   */\n  private executeLang(node: { language: string; child: FQLNode }): SuggestionResult[] {\n    const childResults = this.executeNode(node.child);\n    const targetLang = node.language.toLowerCase();\n\n    return childResults.filter((result) => {\n      return result.language?.toLowerCase() === targetLang;\n    });\n  }\n}\n","/**\n * FQL (Fuzzy Query Language) - Main entry point\n */\n\nimport type { FuzzyIndex, SuggestionResult, SearchOptions } from \"../core/types.js\";\nimport { FQLLexer } from \"./lexer.js\";\nimport { FQLParser, FQLSyntaxError } from \"./parser.js\";\nimport { FQLExecutor, FQLTimeoutError } from \"./executor.js\";\n\n/**\n * Check if a query is an FQL query\n */\nexport function isFQLQuery(query: string): boolean {\n  const trimmed = query.trim();\n  return trimmed.startsWith(\"fql(\") && trimmed.endsWith(\")\");\n}\n\n/**\n * Extract FQL query from fql(...) wrapper\n */\nexport function extractFQLQuery(query: string): string {\n  const trimmed = query.trim();\n  if (!isFQLQuery(trimmed)) {\n    throw new Error(\"Not a valid FQL query. Must be wrapped in fql(...)\");\n  }\n  \n  // Remove fql( and )\n  return trimmed.slice(4, -1).trim();\n}\n\n/**\n * Execute an FQL query\n */\nexport function executeFQLQuery(\n  index: FuzzyIndex,\n  query: string,\n  maxResults?: number,\n  options: SearchOptions = {}\n): SuggestionResult[] {\n  try {\n    // Extract query from fql(...)\n    const fqlQuery = extractFQLQuery(query);\n    \n    // Lexer: tokenize\n    const lexer = new FQLLexer();\n    const tokens = lexer.tokenize(fqlQuery);\n    \n    // Parser: build AST\n    const parser = new FQLParser();\n    const ast = parser.parse(tokens);\n    \n    // Executor: run query\n    const executor = new FQLExecutor(index, options);\n    const results = executor.execute(ast);\n    \n    // Apply maxResults limit\n    const limit = maxResults || options.maxResults || 10;\n    return results.slice(0, limit);\n  } catch (error) {\n    // Re-throw FQL-specific errors\n    if (error instanceof FQLSyntaxError || error instanceof FQLTimeoutError) {\n      throw error;\n    }\n    \n    // Wrap other errors\n    throw new Error(`FQL execution error: ${(error as Error).message}`);\n  }\n}\n\n// Export all FQL components\nexport { FQLLexer } from \"./lexer.js\";\nexport { FQLParser, FQLSyntaxError } from \"./parser.js\";\nexport { FQLExecutor, FQLTimeoutError } from \"./executor.js\";\nexport type { FQLNode } from \"./ast.js\";\nexport { TokenType } from \"./lexer.js\";\n","import type {\n  //\n  FuzzyIndex,\n  FuzzyConfig,\n  SuggestionResult,\n  SearchMatch,\n  BuildIndexOptions,\n  SearchOptions,\n  LanguageProcessor,\n} from \"./types.js\";\nimport {\n  //\n  mergeConfig,\n  validateConfig,\n} from \"./config.js\";\nimport {\n  //\n  LanguageRegistry,\n} from \"../languages/index.js\";\nimport {\n  //\n  calculateLevenshteinDistance,\n  calculateDamerauLevenshteinDistance,\n  calculateNgramSimilarity,\n} from \"../algorithms/levenshtein.js\";\nimport {\n  //\n  buildInvertedIndex,\n  searchInvertedIndex,\n  calculateBM25Scores,\n} from \"./inverted-index.js\";\nimport {\n  //\n  calculateHighlights,\n} from \"./highlighting.js\";\nimport {\n  //\n  SearchCache,\n} from \"./cache.js\";\nimport { removeAccents } from \"../utils/accent-normalization.js\";\nimport { extractFieldValues, normalizeFieldWeights } from \"./field-weighting.js\";\nimport { filterStopWords } from \"../utils/stop-words.js\";\nimport { matchesWord, matchesWildcard } from \"../utils/word-boundaries.js\";\nimport { parseQuery } from \"../utils/phrase-parser.js\";\nimport { matchPhrase } from \"./phrase-matching.js\";\nimport { detectLanguages, sampleTextForDetection } from \"../utils/language-detection.js\";\nimport { isFQLQuery, executeFQLQuery } from \"../fql/index.js\";\n\n/**\n * Build a fuzzy search index from a dictionary of words or objects\n */\nexport function buildFuzzyIndex(words: (string | any)[] = [], options: BuildIndexOptions = {}): FuzzyIndex {\n  // AUTO-DETECTION: Detect languages if not explicitly specified\n  const userSpecifiedLanguages = options.config?.languages;\n  const shouldAutoDetect = !userSpecifiedLanguages || userSpecifiedLanguages.includes('auto');\n  \n  const config = mergeConfig(options.config);\n  \n  if (shouldAutoDetect) {\n    const sampleText = sampleTextForDetection(words, 100);\n    const detectedLanguages = detectLanguages(sampleText);\n    config.languages = detectedLanguages;\n  }\n  \n  validateConfig(config);\n\n  // Convert features array to Set for O(1) lookup performance\n  const featureSet = new Set(config.features);\n\n  const languageProcessors = options.languageProcessors || LanguageRegistry.getProcessors(config.languages);\n\n  if (languageProcessors.length === 0) {\n    throw new Error(`No language processors found for: ${config.languages.join(\", \")}`);\n  }\n\n  // Check if we're doing multi-field search\n  const hasFields = options.fields && options.fields.length > 0;\n  const isObjectArray = words.length > 0 && typeof words[0] === \"object\" && words[0] !== null;\n\n  // Validate: if objects are provided, fields must be specified\n  if (isObjectArray && !hasFields) {\n    throw new Error(\"When indexing objects, you must specify which fields to index via options.fields\");\n  }\n\n  const index: FuzzyIndex = {\n    base: [],\n    variantToBase: new Map(),\n    phoneticToBase: new Map(),\n    ngramIndex: new Map(),\n    synonymMap: new Map(),\n    languageProcessors: new Map(),\n    config,\n  };\n\n  // Store field configuration if provided\n  if (hasFields) {\n    index.fields = options.fields;\n    index.fieldWeights = normalizeFieldWeights(options.fields!, options.fieldWeights);\n    index.fieldData = new Map();\n  }\n\n  // Store language processors\n  languageProcessors.forEach((processor) => {\n    index.languageProcessors.set(processor.language, processor);\n  });\n\n  const processedWords = new Set<string>();\n  let processed = 0;\n\n  for (const item of words) {\n    if (!item) continue;\n\n    // Handle multi-field objects\n    if (hasFields && isObjectArray) {\n      const fieldValues = extractFieldValues(item, options.fields);\n      if (!fieldValues) continue;\n\n      // Generate a unique ID for this object (use first field value as base)\n      const baseId = Object.values(fieldValues)[0] || `item_${processed}`;\n\n      // Store field data\n      index.fieldData!.set(baseId, fieldValues);\n\n      // Index each field separately\n      for (const [fieldName, fieldValue] of Object.entries(fieldValues)) {\n        if (!fieldValue || fieldValue.trim().length < config.minQueryLength) continue;\n\n        const trimmedValue = fieldValue.trim();\n\n        // Add to base if not already there\n        if (!processedWords.has(baseId.toLowerCase())) {\n          processedWords.add(baseId.toLowerCase());\n          index.base.push(baseId);\n        }\n\n        // Process this field value with each language processor\n        for (const processor of languageProcessors) {\n          processWordWithProcessorAndField(trimmedValue, baseId, fieldName, processor, index, config, featureSet);\n        }\n      }\n    } else {\n      // Handle simple string array (backwards compatible)\n      const word = typeof item === \"string\" ? item : String(item);\n      if (word.trim().length < config.minQueryLength) continue;\n\n      const trimmedWord = word.trim();\n      if (processedWords.has(trimmedWord.toLowerCase())) continue;\n\n      processedWords.add(trimmedWord.toLowerCase());\n      index.base.push(trimmedWord);\n\n      // Process with each language processor\n      for (const processor of languageProcessors) {\n        processWordWithProcessor(trimmedWord, processor, index, config, featureSet);\n      }\n    }\n\n    processed++;\n    if (options.onProgress) {\n      options.onProgress(processed, words.length);\n    }\n  }\n\n  // INVERTED INDEX: Build if enabled or auto-enable for large datasets\n  // Also force inverted index if BM25 or Bloom Filter is enabled\n  const shouldUseInvertedIndex = options.useInvertedIndex || config.useInvertedIndex || config.useBM25 || config.useBloomFilter || words.length >= 10000;\n\n  if (shouldUseInvertedIndex) {\n    const { invertedIndex, documents } = buildInvertedIndex(words, languageProcessors, config, featureSet);\n    index.invertedIndex = invertedIndex;\n    index.documents = documents;\n  }\n\n  // CACHE: Initialize search result cache if enabled (default: true)\n  const enableCache = config.enableCache !== false; // Default to true\n  if (enableCache) {\n    const cacheSize = config.cacheSize || 100;\n    index._cache = new SearchCache(cacheSize);\n  }\n\n  return index;\n}\n\n/**\n * Process a word with a specific language processor\n */\nfunction processWordWithProcessor(word: string, processor: LanguageProcessor, index: FuzzyIndex, config: FuzzyConfig, featureSet: Set<string>): void {\n  const normalized = processor.normalize(word);\n\n  // Add base word mapping\n  addToVariantMap(index.variantToBase, normalized, word);\n  addToVariantMap(index.variantToBase, word.toLowerCase(), word);\n  // Also add the original word as-is for exact matching\n  addToVariantMap(index.variantToBase, word, word);\n\n  // Add accent-insensitive variants\n  const accentFreeWord = removeAccents(word);\n  if (accentFreeWord !== word) {\n    // Add the accent-free version in multiple forms\n    addToVariantMap(index.variantToBase, accentFreeWord, word); // Original case\n    addToVariantMap(index.variantToBase, accentFreeWord.toLowerCase(), word); // Lowercase\n    const normalizedAccentFree = processor.normalize(accentFreeWord);\n    if (normalizedAccentFree !== accentFreeWord.toLowerCase()) {\n      addToVariantMap(index.variantToBase, normalizedAccentFree, word); // Processor normalized\n    }\n  }\n\n  // Generate and index variants\n  if (featureSet.has(\"partial-words\")) {\n    const variants = processor.getWordVariants(word);\n    variants.forEach((variant) => {\n      addToVariantMap(index.variantToBase, variant, word);\n    });\n  }\n\n  // Generate phonetic codes\n  if (featureSet.has(\"phonetic\") && processor.supportedFeatures.includes(\"phonetic\")) {\n    const phoneticCode = processor.getPhoneticCode(word);\n    if (phoneticCode) {\n      addToVariantMap(index.phoneticToBase, phoneticCode, word);\n    }\n  }\n\n  // Generate n-grams for partial matching\n  const ngrams = generateNgrams(normalized, config.ngramSize);\n  ngrams.forEach((ngram: string) => {\n    addToVariantMap(index.ngramIndex, ngram, word);\n  });\n\n  // Handle compound words\n  if (featureSet.has(\"compound\") && processor.supportedFeatures.includes(\"compound\")) {\n    const compoundParts = processor.splitCompoundWords(word);\n    compoundParts.forEach((part) => {\n      if (part !== word) {\n        addToVariantMap(index.variantToBase, processor.normalize(part), word);\n      }\n    });\n  }\n\n  // Add synonyms\n  if (featureSet.has(\"synonyms\")) {\n    const synonyms = processor.getSynonyms(normalized);\n    synonyms.forEach((synonym) => {\n      addToVariantMap(index.synonymMap, synonym, word);\n    });\n\n    // Add custom synonyms\n    if (config.customSynonyms) {\n      const customSynonyms = config.customSynonyms[normalized];\n      if (customSynonyms) {\n        customSynonyms.forEach((synonym) => {\n          addToVariantMap(index.synonymMap, synonym, word);\n        });\n      }\n    }\n  }\n}\n\n/**\n * Process a word with field information for multi-field search\n */\nfunction processWordWithProcessorAndField(fieldValue: string, baseId: string, fieldName: string, processor: LanguageProcessor, index: FuzzyIndex, config: FuzzyConfig, featureSet: Set<string>): void {\n  const normalized = processor.normalize(fieldValue);\n\n  // Add base word mapping with field metadata\n  addToVariantMapWithField(index.variantToBase, normalized, baseId, fieldName);\n  addToVariantMapWithField(index.variantToBase, fieldValue.toLowerCase(), baseId, fieldName);\n  addToVariantMapWithField(index.variantToBase, fieldValue, baseId, fieldName);\n\n  // Add accent-insensitive variants\n  const accentFreeWord = removeAccents(fieldValue);\n  if (accentFreeWord !== fieldValue) {\n    addToVariantMapWithField(index.variantToBase, accentFreeWord, baseId, fieldName);\n    addToVariantMapWithField(index.variantToBase, accentFreeWord.toLowerCase(), baseId, fieldName);\n    const normalizedAccentFree = processor.normalize(accentFreeWord);\n    if (normalizedAccentFree !== accentFreeWord.toLowerCase()) {\n      addToVariantMapWithField(index.variantToBase, normalizedAccentFree, baseId, fieldName);\n    }\n  }\n\n  // Generate and index variants\n  if (featureSet.has(\"partial-words\")) {\n    const variants = processor.getWordVariants(fieldValue);\n    variants.forEach((variant) => {\n      addToVariantMapWithField(index.variantToBase, variant, baseId, fieldName);\n    });\n  }\n\n  // Generate phonetic codes\n  if (featureSet.has(\"phonetic\") && processor.supportedFeatures.includes(\"phonetic\")) {\n    const phoneticCode = processor.getPhoneticCode(fieldValue);\n    if (phoneticCode) {\n      addToVariantMapWithField(index.phoneticToBase, phoneticCode, baseId, fieldName);\n    }\n  }\n\n  // Generate n-grams for partial matching\n  const ngrams = generateNgrams(normalized, config.ngramSize);\n  ngrams.forEach((ngram: string) => {\n    addToVariantMapWithField(index.ngramIndex, ngram, baseId, fieldName);\n  });\n\n  // Handle compound words\n  if (featureSet.has(\"compound\") && processor.supportedFeatures.includes(\"compound\")) {\n    const parts = processor.splitCompoundWords(fieldValue);\n    parts.forEach((part) => {\n      if (part.length >= config.minQueryLength) {\n        addToVariantMapWithField(index.variantToBase, part, baseId, fieldName);\n        addToVariantMapWithField(index.variantToBase, processor.normalize(part), baseId, fieldName);\n      }\n    });\n  }\n\n  // Add synonyms\n  if (featureSet.has(\"synonyms\")) {\n    const synonyms = processor.getSynonyms(normalized);\n    synonyms.forEach((synonym) => {\n      addToVariantMapWithField(index.synonymMap, synonym, baseId, fieldName);\n    });\n\n    // Add custom synonyms\n    if (config.customSynonyms) {\n      const customSynonyms = config.customSynonyms[normalized];\n      if (customSynonyms) {\n        customSynonyms.forEach((synonym) => {\n          addToVariantMapWithField(index.synonymMap, synonym, baseId, fieldName);\n        });\n      }\n    }\n  }\n}\n\n/**\n * Helper function to add mappings to variant maps with field information\n */\nfunction addToVariantMapWithField(map: Map<string, Set<string>>, key: string, value: string, _fieldName: string): void {\n  // For now, we'll use a simple approach: store the value with field metadata\n  // The field information will be tracked separately in the index\n  // _fieldName is prefixed with _ to indicate it's reserved for future use\n  if (!map.has(key)) {\n    map.set(key, new Set());\n  }\n  map.get(key)!.add(value);\n}\n\n/**\n * Helper function to add mappings to variant maps\n */\nfunction addToVariantMap(map: Map<string, Set<string>>, key: string, value: string): void {\n  if (!map.has(key)) {\n    map.set(key, new Set());\n  }\n  map.get(key)!.add(value);\n}\n\n/**\n * Batch search multiple queries at once\n * Deduplicates identical queries and returns results for all\n */\nexport function batchSearch(index: FuzzyIndex, queries: string[], maxResults?: number, options: SearchOptions = {}): Record<string, SuggestionResult[]> {\n  const results: Record<string, SuggestionResult[]> = {};\n  const uniqueQueries = [...new Set(queries)]; // Deduplicate\n\n  for (const query of uniqueQueries) {\n    results[query] = getSuggestions(index, query, maxResults, options);\n  }\n\n  return results;\n}\n\n/**\n * Get fuzzy search suggestions from an index\n * Auto-detects whether to use inverted index or classic hash-based approach\n */\nexport function getSuggestions(index: FuzzyIndex, query: string, maxResults?: number, options: SearchOptions = {}): SuggestionResult[] {\n  const config = index.config;\n  const limit = maxResults || options.maxResults || config.maxResults;\n  const threshold = options.fuzzyThreshold || config.fuzzyThreshold;\n\n  if (!query || query.trim().length < config.minQueryLength) {\n    return [];\n  }\n\n  // FQL: Check if FQL is enabled and query is FQL\n  if (options.enableFQL && isFQLQuery(query)) {\n    return executeFQLQuery(index, query, limit, options);\n  }\n\n  // PHRASE SEARCH: Check if query contains phrases\n  const parsedQuery = parseQuery(query);\n  \n  // If query has phrases, use phrase search\n  if (parsedQuery.hasPhrases) {\n    return searchWithPhrases(index, parsedQuery, limit, threshold, options);\n  }\n\n  // STOP WORDS: Filter stop words from query if enabled\n  let processedQuery = query;\n  if (config.enableStopWords && config.stopWords && config.stopWords.length > 0) {\n    processedQuery = filterStopWords(query, config.stopWords);\n  }\n\n  // CACHE: Check cache first (use processed query for cache key)\n  if (index._cache) {\n    const cached = index._cache.get(processedQuery, limit, options);\n    if (cached) {\n      return cached; // Cache hit - return immediately!\n    }\n  }\n\n  // Get active language processors\n  const activeLanguages = options.languages || config.languages;\n  const processors = activeLanguages.map((lang) => index.languageProcessors.get(lang)).filter((p): p is LanguageProcessor => p !== undefined);\n\n  if (processors.length === 0) {\n    return [];\n  }\n\n  // AUTO-DETECTION: Use inverted index if available\n  if (index.invertedIndex && index.documents) {\n    const results = getSuggestionsInverted(index, processedQuery, limit, threshold, processors, options);\n    // Cache the results\n    if (index._cache) {\n      index._cache.set(processedQuery, results, limit, options);\n    }\n    return results;\n  }\n\n  // CLASSIC: Use hash-based approach (existing implementation)\n  const matches = new Map<string, SearchMatch>();\n\n  // Process query with each language processor\n  for (const processor of processors) {\n    const normalizedQuery = processor.normalize(processedQuery.trim());\n\n    // Find matches using different strategies\n    findExactMatches(normalizedQuery, index, matches, processor.language);\n    findPrefixMatches(normalizedQuery, index, matches, processor.language);\n    findPhoneticMatches(normalizedQuery, processor, index, matches);\n    findSynonymMatches(normalizedQuery, index, matches);\n    findNgramMatches(normalizedQuery, index, matches, processor.language, config.ngramSize);\n\n    if (config.features.includes(\"missing-letters\") || config.features.includes(\"extra-letters\") || config.features.includes(\"transpositions\")) {\n      findFuzzyMatches(normalizedQuery, index, matches, processor, config);\n    }\n  }\n\n  // Convert matches to results and rank them\n  const results = Array.from(matches.values())\n    .map((match) => createSuggestionResult(match, processedQuery, threshold, index, options))\n    .filter((result): result is SuggestionResult => result !== null)\n    .sort((a, b) => b.score - a.score)\n    .slice(0, limit);\n\n  // Cache the results\n  if (index._cache) {\n    index._cache.set(processedQuery, results, limit, options);\n  }\n\n  return results;\n}\n\n/**\n * Find exact matches\n */\nfunction findExactMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>, language: string): void {\n  const wordBoundaries = index.config.wordBoundaries || false;\n\n  // Check for wildcard pattern\n  if (query.includes(\"*\")) {\n    // Wildcard search\n    for (const baseWord of index.base) {\n      if (matchesWildcard(baseWord, query)) {\n        if (!matches.has(baseWord)) {\n          matches.set(baseWord, {\n            word: baseWord,\n            normalized: query,\n            matchType: \"exact\",\n            editDistance: 0,\n            language,\n          });\n        }\n      }\n    }\n    return;\n  }\n\n  // Check for exact matches in the variant map\n  const exactMatches = index.variantToBase.get(query);\n  if (exactMatches) {\n    exactMatches.forEach((word) => {\n      // With word boundaries, verify the match\n      if (wordBoundaries && !matchesWord(word, query, wordBoundaries)) {\n        return;\n      }\n\n      // Always add exact matches, even if already found with lower score\n      const existing = matches.get(word);\n      if (!existing || existing.matchType !== \"exact\") {\n        matches.set(word, {\n          word,\n          normalized: query,\n          matchType: \"exact\",\n          editDistance: 0,\n          language,\n        });\n      }\n    });\n  }\n\n  // Also check if the query exactly matches any base word (case-insensitive)\n  const queryLower = query.toLowerCase();\n  for (const baseWord of index.base) {\n    if (baseWord.toLowerCase() === queryLower) {\n      if (!matches.has(baseWord)) {\n        matches.set(baseWord, {\n          word: baseWord,\n          normalized: query,\n          matchType: \"exact\",\n          editDistance: 0,\n          language,\n        });\n      }\n    }\n  }\n}\n\n/**\n * Find prefix matches\n */\nfunction findPrefixMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>, language: string): void {\n  const wordBoundaries = index.config.wordBoundaries || false;\n\n  for (const [variant, words] of index.variantToBase.entries()) {\n    if (variant.startsWith(query) && variant !== query) {\n      words.forEach((word) => {\n        // With word boundaries, verify the match\n        if (wordBoundaries && !matchesWord(word, query, wordBoundaries)) {\n          return;\n        }\n\n        if (!matches.has(word)) {\n          matches.set(word, {\n            word,\n            normalized: variant,\n            matchType: \"prefix\",\n            language,\n          });\n        }\n      });\n    }\n  }\n}\n\n/**\n * Find phonetic matches\n */\nfunction findPhoneticMatches(query: string, processor: LanguageProcessor, index: FuzzyIndex, matches: Map<string, SearchMatch>): void {\n  if (!processor.supportedFeatures.includes(\"phonetic\")) return;\n\n  const phoneticCode = processor.getPhoneticCode(query);\n  if (phoneticCode) {\n    const phoneticMatches = index.phoneticToBase.get(phoneticCode);\n    if (phoneticMatches) {\n      phoneticMatches.forEach((word) => {\n        if (!matches.has(word)) {\n          matches.set(word, {\n            word,\n            normalized: query,\n            matchType: \"phonetic\",\n            phoneticCode,\n            language: processor.language,\n          });\n        }\n      });\n    }\n  }\n}\n\n/**\n * Find synonym matches\n */\nfunction findSynonymMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>): void {\n  const synonymMatches = index.synonymMap.get(query);\n  if (synonymMatches) {\n    synonymMatches.forEach((word) => {\n      if (!matches.has(word)) {\n        matches.set(word, {\n          word,\n          normalized: query,\n          matchType: \"synonym\",\n          language: \"synonym\",\n        });\n      }\n    });\n  }\n}\n\n/**\n * Find n-gram matches\n */\nfunction findNgramMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>, language: string, ngramSize: number): void {\n  if (query.length < ngramSize) return;\n\n  const queryNgrams = generateNgrams(query, ngramSize);\n  const candidateWords = new Set<string>();\n\n  queryNgrams.forEach((ngram) => {\n    const ngramMatches = index.ngramIndex.get(ngram);\n    if (ngramMatches) {\n      ngramMatches.forEach((word) => candidateWords.add(word));\n    }\n  });\n\n  candidateWords.forEach((word) => {\n    if (!matches.has(word)) {\n      matches.set(word, {\n        word,\n        normalized: query,\n        matchType: \"ngram\",\n        language,\n      });\n    }\n  });\n}\n\n/**\n * Find fuzzy matches using edit distance\n */\nfunction findFuzzyMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>, processor: LanguageProcessor, config: FuzzyConfig): void {\n  const maxDistance = config.maxEditDistance;\n\n  for (const [variant, words] of index.variantToBase.entries()) {\n    if (Math.abs(variant.length - query.length) <= maxDistance) {\n      // Use Damerau-Levenshtein if transpositions feature is enabled\n      const useTranspositions = index.config.features?.includes(\"transpositions\");\n      const distance = useTranspositions ? calculateDamerauLevenshteinDistance(query, variant, maxDistance) : calculateLevenshteinDistance(query, variant, maxDistance);\n\n      if (distance <= maxDistance) {\n        words.forEach((word) => {\n          const existingMatch = matches.get(word);\n          // Don't replace exact or prefix matches with fuzzy matches\n          if (!existingMatch || (existingMatch.matchType !== \"exact\" && existingMatch.matchType !== \"prefix\" && (existingMatch.editDistance || Infinity) > distance)) {\n            matches.set(word, {\n              word,\n              normalized: variant,\n              matchType: \"fuzzy\",\n              editDistance: distance,\n              language: processor.language,\n            });\n          }\n        });\n      }\n    }\n  }\n}\n\n/**\n * Create a suggestion result from a search match\n */\nfunction createSuggestionResult(match: SearchMatch, originalQuery: string, threshold: number, index: FuzzyIndex, options?: SearchOptions): SuggestionResult | null {\n  let score = calculateMatchScore(match, originalQuery);\n\n  // Combine with BM25 score if available\n  if (match.bm25Score !== undefined && index.config.useBM25) {\n    const bm25Weight = index.config.bm25Weight || 0.6;\n    const fuzzyWeight = 1 - bm25Weight;\n    score = bm25Weight * match.bm25Score + fuzzyWeight * score;\n  }\n\n  // Apply field weight if present\n  if (match.fieldWeight) {\n    score = Math.min(1.0, score * match.fieldWeight);\n  }\n\n  if (score < threshold) {\n    return null;\n  }\n\n  const result: SuggestionResult = {\n    display: match.word,\n    baseWord: match.word,\n    isSynonym: match.matchType === \"synonym\",\n    score,\n    language: match.language,\n    // @ts-ignore - temporary debug property\n    _debug_matchType: match.matchType,\n  };\n\n  // Add field information if this is a multi-field search\n  if (index.fieldData && index.fieldData.has(match.word)) {\n    result.fields = index.fieldData.get(match.word);\n    result.field = match.field;\n  }\n\n  // Add highlights if requested\n  if (options?.includeHighlights) {\n    result.highlights = calculateHighlights(match, originalQuery, match.word);\n  }\n\n  return result;\n}\n\n/**\n * Calculate match score (0-1, higher is better)\n */\nfunction calculateMatchScore(\n  //\n  match: SearchMatch,\n  query: string\n): number {\n  const queryLen = query.length;\n  const wordLen = match.word.length;\n  const maxLen = Math.max(queryLen, wordLen);\n\n  let score = 0.5; // Base score\n\n  switch (match.matchType) {\n    case \"exact\":\n      score = 1.0;\n      break;\n    case \"prefix\":\n      score = 0.9 - (wordLen - queryLen) / (maxLen * 2);\n      break;\n    case \"substring\":\n      score = 0.8;\n      break;\n    case \"phonetic\":\n      score = 0.7;\n      break;\n    case \"fuzzy\":\n      if (match.editDistance !== undefined) {\n        score = Math.max(0.3, 1.0 - match.editDistance / maxLen);\n      }\n      break;\n    case \"synonym\":\n      score = 0.6;\n      break;\n    case \"compound\":\n      score = 0.75;\n      break;\n    case \"ngram\":\n      score = calculateNgramSimilarity(query.toLowerCase(), match.normalized, 3) * 0.8;\n      break;\n  }\n\n  // Boost score for shorter words (more likely to be what user wants)\n  // But don't boost exact matches - they should stay at 1.0\n  if (wordLen <= queryLen + 2 && match.matchType !== \"exact\") {\n    score += 0.1;\n  }\n\n  return Math.min(1.0, Math.max(0.0, score));\n}\n\n/**\n * Generate n-grams from a string\n */\nfunction generateNgrams(\n  //\n  str: string,\n  n: number\n): string[] {\n  if (str.length < n) return [str];\n\n  const ngrams: string[] = [];\n  for (let i = 0; i <= str.length - n; i++) {\n    ngrams.push(str.slice(i, i + n));\n  }\n  return ngrams;\n}\n\n/**\n * Get suggestions using inverted index (for large datasets)\n * This is a wrapper that converts inverted index results to the same format\n */\nfunction getSuggestionsInverted(\n  //\n  index: FuzzyIndex,\n  query: string,\n  limit: number,\n  threshold: number,\n  processors: LanguageProcessor[],\n  options?: SearchOptions\n): SuggestionResult[] {\n  if (!index.invertedIndex || !index.documents) {\n    throw new Error(\"Inverted index not available\");\n  }\n\n  // Use inverted index search\n  let matches = searchInvertedIndex(index.invertedIndex, index.documents, query, processors, index.config);\n\n  // Calculate BM25 scores if enabled\n  if (index.config.useBM25) {\n    const queryTerms = query.toLowerCase().split(/\\s+/).filter(t => t.length > 0);\n    matches = calculateBM25Scores(matches, queryTerms, index.invertedIndex, index.documents, index.config);\n  }\n\n  // Convert to suggestion results (same as classic approach)\n  const results = matches\n    .map((match) => createSuggestionResult(match, query, threshold, index, options))\n    .filter((result): result is SuggestionResult => result !== null)\n    .sort((a, b) => b.score - a.score)\n    .slice(0, limit);\n\n  return results;\n}\n\n/**\n * Search with phrase support\n * Handles queries containing quoted phrases\n */\nfunction searchWithPhrases(\n  index: FuzzyIndex,\n  parsedQuery: ReturnType<typeof parseQuery>,\n  limit: number,\n  threshold: number,\n  options: SearchOptions\n): SuggestionResult[] {\n  const config = index.config;\n  const useTranspositions = config.features.includes('transpositions');\n  \n  // Get phrase match options\n  const phraseOptions = {\n    exactMatch: false,\n    maxEditDistance: 1,\n    proximityBonus: 1.5,\n    maxProximityDistance: 3,\n    useTranspositions,\n  };\n\n  // Search all base words for phrase matches\n  const phraseMatches = new Map<string, { score: number; phraseCount: number }>();\n\n  // For each phrase, find matching words\n  for (const phrase of parsedQuery.phrases) {\n    for (const word of index.base) {\n      const match = matchPhrase(word, phrase, phraseOptions);\n      \n      if (match.matched) {\n        const existing = phraseMatches.get(word);\n        const newScore = match.score * phraseOptions.proximityBonus;\n        \n        if (existing) {\n          // Multiple phrases matched - boost even more\n          phraseMatches.set(word, {\n            score: Math.max(existing.score, newScore),\n            phraseCount: existing.phraseCount + 1,\n          });\n        } else {\n          phraseMatches.set(word, { score: newScore, phraseCount: 1 });\n        }\n      }\n    }\n  }\n\n  // If we have regular terms too, search for them\n  let termMatches = new Map<string, SearchMatch>();\n  \n  if (parsedQuery.terms.length > 0) {\n    const termQuery = parsedQuery.terms.join(' ');\n    const processors = config.languages\n      .map((lang) => index.languageProcessors.get(lang))\n      .filter((p): p is LanguageProcessor => p !== undefined);\n\n    for (const processor of processors) {\n      const normalizedQuery = processor.normalize(termQuery);\n      \n      // Use existing search strategies for terms\n      findExactMatches(normalizedQuery, index, termMatches, processor.language);\n      findPrefixMatches(normalizedQuery, index, termMatches, processor.language);\n      findPhoneticMatches(normalizedQuery, processor, index, termMatches);\n      findNgramMatches(normalizedQuery, index, termMatches, processor.language, config.ngramSize);\n      \n      if (config.features.includes(\"missing-letters\") || config.features.includes(\"extra-letters\") || config.features.includes(\"transpositions\")) {\n        findFuzzyMatches(normalizedQuery, index, termMatches, processor, config);\n      }\n    }\n  }\n\n  // Combine phrase and term matches\n  const combinedResults = new Map<string, SuggestionResult>();\n\n  // Add phrase matches\n  for (const [word, phraseData] of phraseMatches.entries()) {\n    const result: SuggestionResult = {\n      display: word,\n      baseWord: word,\n      isSynonym: false,\n      score: phraseData.score,\n    };\n    \n    // If word also matched terms, boost score even more\n    const termMatch = termMatches.get(word);\n    if (termMatch) {\n      result.score = Math.min(1.0, result.score * 1.2);\n    }\n    \n    combinedResults.set(word, result);\n  }\n\n  // Add term matches that didn't match phrases (with lower priority)\n  for (const [word, match] of termMatches.entries()) {\n    if (!combinedResults.has(word)) {\n      const result = createSuggestionResult(match, parsedQuery.terms.join(' '), threshold, index, options);\n      if (result) {\n        // Reduce score slightly since it didn't match the phrase\n        result.score *= 0.8;\n        combinedResults.set(word, result);\n      }\n    }\n  }\n\n  // Sort and limit results\n  const results = Array.from(combinedResults.values())\n    .filter(r => r.score >= threshold)\n    .sort((a, b) => b.score - a.score)\n    .slice(0, limit);\n\n  // Cache the results\n  if (index._cache) {\n    index._cache.set(parsedQuery.original, results, limit, options);\n  }\n\n  return results;\n}\n","/**\n * Index Serialization\n * Save and load fuzzy search indices for 100x faster startup\n */\n\nimport type { FuzzyIndex } from \"./types.js\";\nimport { SearchCache } from \"./cache.js\";\n\n/**\n * Serializable index format (JSON-compatible)\n */\ninterface SerializedIndex {\n  version: string;\n  base: string[];\n  variantToBase: [string, string[]][];\n  phoneticToBase: [string, string[]][];\n  ngramIndex: [string, string[]][];\n  synonymMap: [string, string[]][];\n  config: any;\n  languageProcessorNames: string[];\n  invertedIndex?: any;\n  documents?: any[];\n}\n\n/**\n * Serialize a FuzzyIndex to JSON string\n */\nexport function serializeIndex(index: FuzzyIndex): string {\n  const serialized: SerializedIndex = {\n    version: \"1.0\",\n    base: index.base,\n    variantToBase: Array.from(index.variantToBase.entries()).map(([k, v]) => [k, Array.from(v)]),\n    phoneticToBase: Array.from(index.phoneticToBase.entries()).map(([k, v]) => [k, Array.from(v)]),\n    ngramIndex: Array.from(index.ngramIndex.entries()).map(([k, v]) => [k, Array.from(v)]),\n    synonymMap: Array.from(index.synonymMap.entries()).map(([k, v]) => [k, Array.from(v)]),\n    config: index.config,\n    languageProcessorNames: Array.from(index.languageProcessors.keys()),\n  };\n\n  // Serialize inverted index if present\n  if (index.invertedIndex) {\n    serialized.invertedIndex = {\n      termToPostings: Array.from(index.invertedIndex.termToPostings.entries()),\n      phoneticToPostings: Array.from(index.invertedIndex.phoneticToPostings.entries()),\n      ngramToPostings: Array.from(index.invertedIndex.ngramToPostings.entries()),\n      synonymToPostings: Array.from(index.invertedIndex.synonymToPostings.entries()),\n      totalDocs: index.invertedIndex.totalDocs,\n      avgDocLength: index.invertedIndex.avgDocLength,\n    };\n  }\n\n  // Serialize documents if present\n  if (index.documents) {\n    serialized.documents = index.documents;\n  }\n\n  return JSON.stringify(serialized);\n}\n\n/**\n * Deserialize a FuzzyIndex from JSON string\n */\nexport async function deserializeIndex(json: string): Promise<FuzzyIndex> {\n  const data: SerializedIndex = JSON.parse(json);\n\n  // Reconstruct Maps from arrays\n  const variantToBase = new Map(data.variantToBase.map(([k, v]) => [k, new Set(v)]));\n  const phoneticToBase = new Map(data.phoneticToBase.map(([k, v]) => [k, new Set(v)]));\n  const ngramIndex = new Map(data.ngramIndex.map(([k, v]) => [k, new Set(v)]));\n  const synonymMap = new Map(data.synonymMap.map(([k, v]) => [k, new Set(v)]));\n\n  // Reconstruct language processors (need to import them)\n  const { LanguageRegistry } = await import(\"../languages/index.js\");\n  const languageProcessors = new Map();\n  for (const langName of data.languageProcessorNames) {\n    const processor = LanguageRegistry.getProcessor(langName);\n    if (processor) {\n      languageProcessors.set(langName, processor);\n    }\n  }\n\n  const index: FuzzyIndex = {\n    base: data.base,\n    variantToBase,\n    phoneticToBase,\n    ngramIndex,\n    synonymMap,\n    languageProcessors,\n    config: data.config,\n  };\n\n  // Reconstruct inverted index if present\n  if (data.invertedIndex) {\n    index.invertedIndex = {\n      termToPostings: new Map(data.invertedIndex.termToPostings),\n      phoneticToPostings: new Map(data.invertedIndex.phoneticToPostings),\n      ngramToPostings: new Map(data.invertedIndex.ngramToPostings),\n      synonymToPostings: new Map(data.invertedIndex.synonymToPostings),\n      totalDocs: data.invertedIndex.totalDocs,\n      avgDocLength: data.invertedIndex.avgDocLength,\n    };\n  }\n\n  // Reconstruct documents if present\n  if (data.documents) {\n    index.documents = data.documents;\n  }\n\n  // Reconstruct cache if enabled in config\n  if (data.config.enableCache !== false) {\n    const cacheSize = data.config.cacheSize || 100;\n    index._cache = new SearchCache(cacheSize);\n  }\n\n  return index;\n}\n\n/**\n * Save index to localStorage (browser)\n */\nexport function saveIndexToLocalStorage(index: FuzzyIndex, key: string = \"fuzzy-search-index\"): void {\n  if (typeof localStorage === \"undefined\") {\n    throw new Error(\"localStorage is not available\");\n  }\n  const serialized = serializeIndex(index);\n  localStorage.setItem(key, serialized);\n}\n\n/**\n * Load index from localStorage (browser)\n */\nexport async function loadIndexFromLocalStorage(key: string = \"fuzzy-search-index\"): Promise<FuzzyIndex | null> {\n  if (typeof localStorage === \"undefined\") {\n    throw new Error(\"localStorage is not available\");\n  }\n  const serialized = localStorage.getItem(key);\n  if (!serialized) {\n    return null;\n  }\n  return await deserializeIndex(serialized);\n}\n\n/**\n * Get serialized index size in bytes\n */\nexport function getSerializedSize(index: FuzzyIndex): number {\n  const serialized = serializeIndex(index);\n  return new Blob([serialized]).size;\n}\n","/**\n * Data Indexer Utility\n * Extract unique words from various data formats for fuzzy search indexing\n */\n\nexport interface DataToIndexOptions {\n  /** Minimum word length to include (default: 2) */\n  minLength?: number;\n  /** Split text into words (default: true) */\n  splitWords?: boolean;\n  /** Remove stop words (default: false) */\n  stopWords?: string[] | false;\n  /** Overlap between chunks in characters (default: 0) */\n  overlap?: number;\n  /** Size of each chunk in characters (default: 0 = no chunking) */\n  chunkSize?: number;\n  /** Split strategy for chunking (default: 'word') */\n  splitOn?: \"word\" | \"sentence\" | \"paragraph\";\n  /** Data format (default: 'string') */\n  format?: \"string\" | \"html\" | \"json\" | \"base64\" | \"url\";\n  /** Remove numbers (default: false) */\n  removeNumbers?: boolean;\n  /** Case sensitive (default: false) */\n  caseSensitive?: boolean;\n}\n\n/**\n * Extract unique words from various data formats\n * Returns an array of unique words that can be used as a dictionary for fuzzy search\n *\n * @param content - The content to extract words from\n * @param options - Configuration options\n * @returns Array of unique words (no duplicates)\n *\n * @example\n * // Simple text\n * const words = dataToIndex(\"Hello world! Hello again.\");\n * // → ['hello', 'world', 'again']\n *\n * @example\n * // HTML content\n * const words = dataToIndex(\"<h1>Title</h1><p>Content here</p>\", { format: 'html' });\n * // → ['title', 'content', 'here']\n *\n * @example\n * // JSON data\n * const data = [{ name: \"John\", city: \"NYC\" }, { name: \"Jane\", city: \"LA\" }];\n * const words = dataToIndex(JSON.stringify(data), { format: 'json' });\n * // → ['john', 'nyc', 'jane', 'la']\n */\nexport function dataToIndex(\n  //\n  content: string,\n  options: DataToIndexOptions = {}\n): string[] {\n  const {\n    //\n    minLength = 2,\n    splitWords = true,\n    stopWords = false,\n    overlap = 0,\n    chunkSize = 0,\n    splitOn = \"word\",\n    format = \"string\",\n    removeNumbers = false,\n    caseSensitive = false,\n  } = options;\n\n  let text = content;\n\n  // Step 1: Handle different formats\n  switch (format) {\n    case \"base64\":\n      try {\n        text = atob(content);\n      } catch (e) {\n        console.error(\"Failed to decode base64:\", e);\n        return [];\n      }\n      break;\n\n    case \"html\":\n      text = stripHTML(content);\n      break;\n\n    case \"json\":\n      text = extractFromJSON(content);\n      break;\n\n    case \"url\":\n      // URL format requires async, so we'll throw an error\n      throw new Error(\"URL format requires async. Use dataToIndexAsync() instead.\");\n\n    case \"string\":\n    default:\n      // Already a string, no conversion needed\n      break;\n  }\n\n  // Step 2: Apply chunking if specified\n  if (chunkSize > 0) {\n    const chunks = chunkText(text, chunkSize, overlap, splitOn);\n    text = chunks.join(\" \");\n  }\n\n  // Step 3: Extract words\n  let words: string[] = [];\n\n  if (splitWords) {\n    // Split on whitespace and punctuation\n    words = text.split(/[\\s\\-_.,;:!?()[\\]{}'\"\\/\\\\]+/).filter((word) => word.length > 0);\n  } else {\n    words = [text];\n  }\n\n  // Step 4: Clean and filter words\n  words = words\n    .map((word) => {\n      // Remove leading/trailing punctuation (but preserve unicode letters)\n      word = word.replace(/^[^\\p{L}\\p{N}]+|[^\\p{L}\\p{N}]+$/gu, \"\");\n\n      // Convert case\n      if (!caseSensitive) {\n        word = word.toLowerCase();\n      }\n\n      return word;\n    })\n    .filter((word) => {\n      // Filter by minimum length\n      if (word.length < minLength) return false;\n\n      // Filter numbers if requested\n      if (removeNumbers && /^\\d+$/.test(word)) return false;\n\n      return true;\n    });\n\n  // Step 5: Remove stop words if specified\n  if (stopWords && Array.isArray(stopWords)) {\n    const stopWordsSet = new Set(stopWords.map((w) => w.toLowerCase()));\n    words = words.filter((word) => !stopWordsSet.has(word.toLowerCase()));\n  }\n\n  // Step 6: Remove duplicates and return\n  return Array.from(new Set(words));\n}\n\n/**\n * Strip HTML tags and extract text content\n */\nfunction stripHTML(html: string): string {\n  // Remove script and style tags with their content\n  let text = html.replace(/<script\\b[^<]*(?:(?!<\\/script>)<[^<]*)*<\\/script>/gi, \" \");\n  text = text.replace(/<style\\b[^<]*(?:(?!<\\/style>)<[^<]*)*<\\/style>/gi, \" \");\n\n  // Remove HTML comments\n  text = text.replace(/<!--[\\s\\S]*?-->/g, \" \");\n\n  // Remove all HTML tags\n  text = text.replace(/<[^>]+>/g, \" \");\n\n  // Decode common HTML entities\n  text = text\n    .replace(/&nbsp;/g, \" \")\n    .replace(/&amp;/g, \"&\")\n    .replace(/&lt;/g, \"<\")\n    .replace(/&gt;/g, \">\")\n    .replace(/&quot;/g, '\"')\n    .replace(/&#39;/g, \"'\")\n    .replace(/&apos;/g, \"'\");\n\n  // Normalize whitespace\n  text = text.replace(/\\s+/g, \" \").trim();\n\n  return text;\n}\n\n/**\n * Extract string values from JSON\n */\nfunction extractFromJSON(jsonString: string): string {\n  try {\n    const data = JSON.parse(jsonString);\n    const values: string[] = [];\n\n    function extractValues(obj: any, depth: number = 0): void {\n      // Limit recursion depth to prevent stack overflow\n      if (depth > 10) return;\n\n      if (typeof obj === \"string\") {\n        values.push(obj);\n      } else if (Array.isArray(obj)) {\n        obj.forEach((item) => extractValues(item, depth + 1));\n      } else if (typeof obj === \"object\" && obj !== null) {\n        Object.values(obj).forEach((value) => extractValues(value, depth + 1));\n      }\n    }\n\n    extractValues(data);\n    return values.join(\" \");\n  } catch (e) {\n    console.error(\"Failed to parse JSON:\", e);\n    return \"\";\n  }\n}\n\n/**\n * Chunk text into smaller pieces\n */\nfunction chunkText(text: string, chunkSize: number, overlap: number, splitOn: \"word\" | \"sentence\" | \"paragraph\"): string[] {\n  const chunks: string[] = [];\n\n  if (splitOn === \"paragraph\") {\n    // Split on double newlines\n    const paragraphs = text.split(/\\n\\n+/);\n    let currentChunk = \"\";\n\n    for (const para of paragraphs) {\n      if ((currentChunk + para).length <= chunkSize) {\n        currentChunk += (currentChunk ? \"\\n\\n\" : \"\") + para;\n      } else {\n        if (currentChunk) chunks.push(currentChunk);\n        currentChunk = para;\n      }\n    }\n    if (currentChunk) chunks.push(currentChunk);\n  } else if (splitOn === \"sentence\") {\n    // Split on sentence boundaries\n    const sentences = text.split(/[.!?]+\\s+/);\n    let currentChunk = \"\";\n\n    for (const sentence of sentences) {\n      if ((currentChunk + sentence).length <= chunkSize) {\n        currentChunk += (currentChunk ? \" \" : \"\") + sentence;\n      } else {\n        if (currentChunk) chunks.push(currentChunk);\n        currentChunk = sentence;\n      }\n    }\n    if (currentChunk) chunks.push(currentChunk);\n  } else {\n    // Split on words (default)\n    const words = text.split(/\\s+/);\n    let currentChunk = \"\";\n\n    for (const word of words) {\n      if ((currentChunk + \" \" + word).length <= chunkSize) {\n        currentChunk += (currentChunk ? \" \" : \"\") + word;\n      } else {\n        if (currentChunk) chunks.push(currentChunk);\n\n        // Add overlap\n        if (overlap > 0 && currentChunk) {\n          const overlapWords = currentChunk.split(/\\s+/).slice(-Math.ceil(overlap / 10));\n          currentChunk = overlapWords.join(\" \") + \" \" + word;\n        } else {\n          currentChunk = word;\n        }\n      }\n    }\n    if (currentChunk) chunks.push(currentChunk);\n  }\n\n  return chunks;\n}\n\n/**\n * Async version for URL fetching\n * @param content - URL or content string\n * @param options - Configuration options\n * @returns Promise<string[]> Array of unique words\n */\nexport async function dataToIndexAsync(content: string, options: DataToIndexOptions = {}): Promise<string[]> {\n  const { format = \"string\" } = options;\n\n  if (format === \"url\") {\n    try {\n      const response = await fetch(content);\n      const html = await response.text();\n      return dataToIndex(html, { ...options, format: \"html\" });\n    } catch (e) {\n      console.error(\"Failed to fetch URL:\", e);\n      return [];\n    }\n  }\n\n  return dataToIndex(content, options);\n}\n","/**\n * FuzzyFindJS - A powerful, multi-language optimized fuzzy search library\n *\n * @example\n * ```typescript\n * import { buildFuzzyIndex, getSuggestions } from 'fuzzyfindjs';\n *\n * const dictionary = ['Krankenhaus', 'Schule', 'Kindergarten'];\n * const index = buildFuzzyIndex(dictionary);\n * const results = getSuggestions(index, 'krankenh', 5);\n * ```\n */\n\n// Core functionality\nexport { buildFuzzyIndex, getSuggestions, batchSearch } from \"./core/index.js\";\nimport { buildFuzzyIndex, getSuggestions } from \"./core/index.js\";\n\n// Highlighting utilities (for UI rendering)\nexport { calculateHighlights, formatHighlightedHTML } from \"./core/highlighting.js\";\n\n// Cache utilities (for advanced users)\nexport { SearchCache, LRUCache } from \"./core/cache.js\";\n\n// Serialization utilities (save/load indices)\nexport { serializeIndex, deserializeIndex, saveIndexToLocalStorage, loadIndexFromLocalStorage, getSerializedSize } from \"./core/serialization.js\";\n\n// Accent normalization utilities\nexport { removeAccents, hasAccents, normalizeForComparison, getAccentVariants } from \"./utils/accent-normalization.js\";\n\n// Stop words utilities\nexport { filterStopWords, getStopWordsForLanguages, isStopWord, DEFAULT_STOP_WORDS } from \"./utils/stop-words.js\";\n\n// Word boundary utilities\nexport { isWordBoundary, matchesAtWordBoundary, findWordBoundaryMatches, matchesWord, matchesWildcard } from \"./utils/word-boundaries.js\";\n\n// Data indexing utilities\nexport { dataToIndex, dataToIndexAsync } from \"./utils/data-indexer.js\";\nexport type { DataToIndexOptions } from \"./utils/data-indexer.js\";\n\n// Configuration\nexport { DEFAULT_CONFIG, PERFORMANCE_CONFIGS, mergeConfig } from \"./core/config.js\";\n\n// Types\nexport type { FuzzyIndex, FuzzyConfig, SuggestionResult, SearchMatch, MatchType, FuzzyFeature, LanguageProcessor, BuildIndexOptions, SearchOptions, DebugInfo, SuggestionResultWithDebug } from \"./core/types.js\";\n\n// Language processors\nexport { LanguageRegistry, GermanProcessor, EnglishProcessor, SpanishProcessor, FrenchProcessor, BaseLanguageProcessor } from \"./languages/index.js\";\n\n// Algorithms (for advanced users)\nexport { calculateLevenshteinDistance, calculateDamerauLevenshteinDistance, calculateNgramSimilarity, distanceToSimilarity, areStringsSimilar } from \"./algorithms/levenshtein.js\";\nexport { calculateBM25Score, calculateIDF, normalizeBM25Score, combineScores, buildCorpusStats, DEFAULT_BM25_CONFIG } from \"./algorithms/bm25.js\";\nexport type { BM25Config, DocumentStats, CorpusStats } from \"./algorithms/bm25.js\";\nexport { BloomFilter, createBloomFilter } from \"./algorithms/bloom-filter.js\";\nexport type { BloomFilterConfig } from \"./algorithms/bloom-filter.js\";\n\n/**\n * Quick start function with sensible defaults\n * Perfect for getting started quickly\n */\nexport function createFuzzySearch(\n  dictionary: string[],\n  options: {\n    languages?: string[];\n    performance?: \"fast\" | \"balanced\" | \"comprehensive\";\n    maxResults?: number;\n  } = {}\n) {\n  const index = buildFuzzyIndex(dictionary, {\n    config: {\n      languages: options.languages || [\"german\"],\n      performance: options.performance || \"balanced\",\n      maxResults: options.maxResults || 5,\n    },\n  });\n\n  return {\n    search: (query: string, maxResults?: number) => getSuggestions(index, query, maxResults),\n    index,\n  };\n}\n\n/**\n * Version information\n */\nexport const VERSION = \"1.0.2\";\n"],"names":["DEFAULT_CONFIG","PERFORMANCE_CONFIGS","LANGUAGE_FEATURES","mergeConfig","userConfig","baseConfig","performanceConfig","mergedConfig","recommendedFeatures","lang","feature","validateConfig","config","BaseLanguageProcessor","text","word","normalized","code","consonantMap","i","char","digit","variants","commonEndings","ending","_word","char1","char2","neighbors","n","ngrams","str1","str2","matrix","len1","len2","j","cost","GermanProcessor","prev","next","parts","commonPrefixes","commonSuffixes","commonWords","prefix","remainder","suffix","leftPart","rightPart","part","germanEndings","synonymMap","EnglishProcessor","metaphone","current","length","englishEndings","base","SpanishProcessor","FrenchProcessor","next2","LanguageRegistry","language","languages","processor","calculateLevenshteinDistance","maxDistance","previousRow","currentRow","minInRow","calculateDamerauLevenshteinDistance","maxLen","H","INF","charMap","lastMatchCol","lastMatchRow","result","calculateNgramSimilarity","ngrams1","generateNgrams","ngrams2","set1","set2","intersection","x","union","str","distanceToSimilarity","distance","maxLength","areStringsSimilar","threshold","Trie","term","docIds","node","id","results","child","data","trie","childData","DEFAULT_BM25_CONFIG","calculateIDF","corpusStats","df","N","idf","calculateTermScore","docStats","tf","docLength","avgDocLength","numerator","denominator","calculateBM25Score","queryTerms","totalScore","buildCorpusStats","documents","totalDocs","totalLength","documentFrequencies","doc","uniqueTerms","normalizeBM25Score","score","maxScore","scaledScore","combineScores","bm25Score","fuzzyScore","bm25Weight","fuzzyWeight","totalWeight","normalizedBM25Weight","normalizedFuzzyWeight","BloomFilter","p","item","hashes","hash","byteIndex","bitIndex","hash1","hash2","combinedHash","seed","k","m","filter","createBloomFilter","expectedElements","falsePositiveRate","buildInvertedIndex","words","languageProcessors","featureSet","invertedIndex","docId","trimmedWord","phoneticCode","compoundParts","addToPostingList","lowerWord","variant","ngram","normalizedPart","synonym","customSynonyms","documentLengths","posting","bloomFilter","searchInvertedIndex","query","processors","matches","normalizedQuery","findExactMatchesInverted","findPrefixMatchesInverted","findPhoneticMatchesInverted","findSynonymMatchesInverted","findNgramMatchesInverted","findFuzzyMatchesInverted","postings","prefixMatches","ngramSize","queryNgrams","candidateDocs","queryLen","minLen","useTranspositions","MAX_FUZZY_CANDIDATES","candidatesChecked","termLen","existingMatch","calculateBM25Scores","bm25Config","match","termFrequencies","normalizedTerms","normalizedBM25","calculateHighlights","displayText","highlights","normalizedDisplay","prefixEnd","substringIndex","calculateFuzzyHighlights","calculateNgramHighlights","mergeOverlappingHighlights","type","queryIdx","textIdx","start","end","searchStart","index","sorted","a","b","merged","last","getMatchTypePriority","formatHighlightedHTML","className","escapeHTML","lastEnd","highlight","highlightedText","div","LRUCache","capacity","key","value","firstKey","SearchCache","maxResults","options","optionsKey","cacheStats","total","hitRate","ACCENT_MAP","removeAccents","hasAccents","normalizeForComparison","getAccentVariants","extractFieldValues","fields","fieldValues","field","normalizeFieldWeights","fieldWeights","DEFAULT_STOP_WORDS","filterStopWords","stopWords","stopWordsSet","w","filtered","getStopWordsForLanguages","langStopWords","isStopWord","isWordBoundary","position","charBefore","matchesAtWordBoundary","matchStart","matchLength","matchEnd","startBoundary","endBoundary","findWordBoundaryMatches","pattern","caseSensitive","positions","searchText","searchPattern","found","matchesWord","wordBoundaries","parseWildcard","regexPattern","matchesWildcard","parseQuery","phrases","remaining","doubleQuoteRegex","phrase","singleQuoteRegex","terms","t","DEFAULT_OPTIONS","matchPhrase","opts","normalizedText","normalizedPhrase","exactMatch","findExactPhrase","fuzzyMatch","findFuzzyPhrase","proximityMatch","findProximityMatch","maxEditDistance","phraseWords","textWords","segment","totalDistance","allMatch","maxPossibleDistance","phraseWord","phraseIndex","bestDistance","bestPositions","findBestCombination","wordIndex","currentPositions","pos","detectLanguages","detected","sampleTextForDetection","sampleSize","v","TokenType","FQLLexer","input","quote","upperValue","FQLSyntaxError","message","FQLParser","tokens","ast","left","right","expr","token","filterToken","filterType","operator","types","isTermNode","isPhraseNode","isAndNode","isOrNode","isNotNode","isFilterNode","isFieldNode","isScoreNode","isLangNode","FQLTimeoutError","FQLExecutor","leftResults","rightResults","rightDisplays","r","resultMap","existing","childResults","excludeDisplays","getSuggestions","regex","targetLang","isFQLQuery","trimmed","extractFQLQuery","executeFQLQuery","fqlQuery","limit","error","buildFuzzyIndex","userSpecifiedLanguages","shouldAutoDetect","sampleText","detectedLanguages","hasFields","isObjectArray","processedWords","processed","baseId","fieldName","fieldValue","trimmedValue","processWordWithProcessorAndField","processWordWithProcessor","cacheSize","addToVariantMap","accentFreeWord","normalizedAccentFree","addToVariantMapWithField","map","_fieldName","batchSearch","queries","uniqueQueries","parsedQuery","searchWithPhrases","processedQuery","cached","getSuggestionsInverted","findExactMatches","findPrefixMatches","findPhoneticMatches","findSynonymMatches","findNgramMatches","findFuzzyMatches","createSuggestionResult","baseWord","exactMatches","queryLower","phoneticMatches","synonymMatches","candidateWords","ngramMatches","originalQuery","calculateMatchScore","wordLen","phraseOptions","phraseMatches","newScore","termMatches","termQuery","combinedResults","phraseData","serializeIndex","serialized","deserializeIndex","json","variantToBase","phoneticToBase","ngramIndex","langName","saveIndexToLocalStorage","loadIndexFromLocalStorage","getSerializedSize","dataToIndex","content","minLength","splitWords","overlap","chunkSize","splitOn","format","removeNumbers","e","stripHTML","extractFromJSON","chunkText","html","jsonString","extractValues","obj","depth","values","chunks","paragraphs","currentChunk","para","sentences","sentence","dataToIndexAsync","createFuzzySearch","dictionary","VERSION"],"mappings":"oOAUO,MAAMA,EAA8B,CACzC,UAAW,CAAC,SAAS,EACrB,SAAU,CAAC,WAAY,WAAY,WAAY,qBAAsB,gBAAiB,kBAAmB,gBAAiB,gBAAgB,EAC1I,YAAa,WACb,WAAY,GACZ,eAAgB,EAChB,eAAgB,IAChB,gBAAiB,EACjB,UAAW,CACb,EAKaC,EAA4D,CACvE,KAAM,CACJ,YAAa,OACb,SAAU,CAAC,gBAAiB,iBAAiB,EAC7C,gBAAiB,EACjB,eAAgB,GAChB,WAAY,CAAA,EAEd,SAAU,CACR,YAAa,WACb,SAAU,CAAC,WAAY,gBAAiB,kBAAmB,oBAAoB,EAC/E,gBAAiB,EACjB,eAAgB,IAChB,WAAY,CAAA,EAEd,cAAe,CACb,YAAa,gBACb,SAAU,CAAC,WAAY,WAAY,WAAY,qBAAsB,gBAAiB,kBAAmB,gBAAiB,gBAAgB,EAC1I,gBAAiB,EACjB,eAAgB,GAChB,WAAY,EAAA,CAEhB,EAKaC,EAAoD,CAC/D,OAAQ,CAEN,WACA,WACA,WACA,qBACA,gBACA,kBACA,eAAA,EAEF,QAAS,CAEP,WACA,WACA,qBACA,gBACA,kBACA,gBAAA,EAEF,QAAS,CAEP,WACA,WACA,qBACA,gBACA,iBAAA,EAEF,OAAQ,CAEN,WACA,WACA,qBACA,gBACA,iBAAA,CAEJ,EAKO,SAASC,EAAYC,EAAmC,GAAiB,CAC9E,MAAMC,EAAa,CAAE,GAAGL,CAAA,EAGxB,GAAII,EAAW,aAAeA,EAAW,cAAgB,WAAY,CACnE,MAAME,EAAoBL,EAAoBG,EAAW,WAAW,EACpE,OAAO,OAAOC,EAAYC,CAAiB,CAC7C,CAGA,MAAMC,EAAe,CAAE,GAAGF,EAAY,GAAGD,CAAA,EAGzC,GAAI,CAACA,EAAW,UAAYA,EAAW,UAAW,CAChD,MAAMI,MAA0B,IAEhC,UAAWC,KAAQL,EAAW,WACPF,EAAkBO,CAAI,GAAKP,EAAkB,SACrD,QAASQ,GAAYF,EAAoB,IAAIE,CAAO,CAAC,EAGpEH,EAAa,SAAW,MAAM,KAAKC,CAAmB,CACxD,CAEA,OAAOD,CACT,CAKO,SAASI,GAAeC,EAA2B,CACxD,GAAIA,EAAO,WAAa,EACtB,MAAM,IAAI,MAAM,+BAA+B,EAGjD,GAAIA,EAAO,eAAiB,EAC1B,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIA,EAAO,eAAiB,GAAKA,EAAO,eAAiB,EACvD,MAAM,IAAI,MAAM,wCAAwC,EAG1D,GAAIA,EAAO,gBAAkB,EAC3B,MAAM,IAAI,MAAM,sCAAsC,EAGxD,GAAIA,EAAO,UAAY,EACrB,MAAM,IAAI,MAAM,8BAA8B,EAGhD,GAAIA,EAAO,UAAU,SAAW,EAC9B,MAAM,IAAI,MAAM,yCAAyC,CAE7D,CC5IO,MAAeC,CAAmD,CAQvE,UAAUC,EAAsB,CAC9B,OAAOA,EAAK,cAAc,OAAO,QAAQ,OAAQ,GAAG,CACtD,CAKA,gBAAgBC,EAAsB,CAEpC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,SAAW,EAAG,MAAO,GAEpC,IAAIC,EAAOD,EAAW,CAAC,EAAE,YAAA,EACzB,MAAME,EAAuC,CAC3C,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,GAAA,EAGL,QAASC,EAAI,EAAGA,EAAIH,EAAW,QAAUC,EAAK,OAAS,EAAGE,IAAK,CAC7D,MAAMC,EAAOJ,EAAWG,CAAC,EACnBE,EAAQH,EAAaE,CAAI,EAC3BC,GAASA,IAAUJ,EAAKA,EAAK,OAAS,CAAC,IACzCA,GAAQI,EAEZ,CAEA,OAAOJ,EAAK,OAAO,EAAG,GAAG,CAC3B,CAKA,mBAAmBF,EAAwB,CACzC,MAAO,CAACA,CAAI,CACd,CAKA,gBAAgBA,EAAwB,CACtC,MAAMO,MAAe,IACfN,EAAa,KAAK,UAAUD,CAAI,EAEtCO,EAAS,IAAIN,CAAU,EACvBM,EAAS,IAAIP,CAAI,EAGjB,MAAMQ,EAAgB,KAAK,iBAAA,EAC3B,UAAWC,KAAUD,EACfP,EAAW,SAASQ,CAAM,GAAKR,EAAW,OAASQ,EAAO,OAAS,GACrEF,EAAS,IAAIN,EAAW,MAAM,EAAG,CAACQ,EAAO,MAAM,CAAC,EAKpD,GAAIR,EAAW,OAAS,EACtB,QAASG,EAAI,EAAGA,EAAIH,EAAW,OAAQG,IACrCG,EAAS,IAAIN,EAAW,MAAM,EAAGG,CAAC,CAAC,EAIvC,OAAO,MAAM,KAAKG,CAAQ,CAC5B,CAKU,kBAA6B,CACrC,MAAO,CAEL,IACA,KACA,KACA,MACA,KACA,KAAA,CAEJ,CAKA,YAAYG,EAAyB,CACnC,MAAO,CAAA,CACT,CAKA,oBAAoBC,EAAeC,EAAwB,CAEzD,MAAMC,EADoB,KAAK,qBAAA,EACKF,EAAM,YAAA,CAAa,EACvD,OAAOE,EAAYA,EAAU,SAASD,EAAM,YAAA,CAAa,EAAI,EAC/D,CAKU,sBAAiD,CACzD,MAAO,CACL,EAAG,CAAC,IAAK,IAAK,GAAG,EACjB,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,GAAG,EACtB,EAAG,CAAC,IAAK,GAAG,EACZ,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAC1C,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAC1C,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAC1C,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAC1C,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAC1C,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EACrC,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAChC,EAAG,CAAC,IAAK,IAAK,IAAK,GAAG,EACtB,EAAG,CAAC,IAAK,IAAK,GAAG,EACjB,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,GAAG,CAAA,CAE1B,CAKA,eAAeZ,EAAcc,EAAY,EAAa,CACpD,MAAMb,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,OAASa,EAAG,MAAO,CAACb,CAAU,EAE7C,MAAMc,EAAmB,CAAA,EACzB,QAASX,EAAI,EAAGA,GAAKH,EAAW,OAASa,EAAGV,IAC1CW,EAAO,KAAKd,EAAW,MAAMG,EAAGA,EAAIU,CAAC,CAAC,EAExC,OAAOC,CACT,CAKA,sBAAsBC,EAAcC,EAAsB,CACxD,MAAMC,EAAqB,CAAA,EACrBC,EAAOH,EAAK,OACZI,EAAOH,EAAK,OAGlB,QAASb,EAAI,EAAGA,GAAKe,EAAMf,IACzBc,EAAOd,CAAC,EAAI,CAACA,CAAC,EAEhB,QAASiB,EAAI,EAAGA,GAAKD,EAAMC,IACzBH,EAAO,CAAC,EAAEG,CAAC,EAAIA,EAIjB,QAASjB,EAAI,EAAGA,GAAKe,EAAMf,IACzB,QAASiB,EAAI,EAAGA,GAAKD,EAAMC,IAAK,CAC9B,MAAMC,EAAON,EAAKZ,EAAI,CAAC,IAAMa,EAAKI,EAAI,CAAC,EAAI,EAAI,EAC/CH,EAAOd,CAAC,EAAEiB,CAAC,EAAI,KAAK,IAClBH,EAAOd,EAAI,CAAC,EAAEiB,CAAC,EAAI,EACnBH,EAAOd,CAAC,EAAEiB,EAAI,CAAC,EAAI,EACnBH,EAAOd,EAAI,CAAC,EAAEiB,EAAI,CAAC,EAAIC,CAAA,CAE3B,CAGF,OAAOJ,EAAOC,CAAI,EAAEC,CAAI,CAC1B,CACF,CCjMO,MAAMG,UAAwBzB,CAAsB,CAChD,SAAW,SACX,YAAc,UACd,kBAAoC,CAAC,WAAY,WAAY,WAAY,qBAAsB,gBAAiB,kBAAmB,eAAe,EAK3J,UAAUC,EAAsB,CAC9B,OACEA,EACG,cACA,KAAA,EACA,QAAQ,OAAQ,GAAG,EAEnB,QAAQ,KAAM,IAAI,EAClB,QAAQ,KAAM,IAAI,EAClB,QAAQ,KAAM,IAAI,EAClB,QAAQ,KAAM,IAAI,CAEzB,CAKA,gBAAgBC,EAAsB,CACpC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,SAAW,EAAG,MAAO,GAEpC,IAAIC,EAAO,GACPsB,EAAO,GAEX,QAASpB,EAAI,EAAGA,EAAIH,EAAW,OAAQG,IAAK,CAC1C,MAAMC,EAAOJ,EAAWG,CAAC,EACnBqB,EAAOrB,EAAIH,EAAW,OAAS,EAAIA,EAAWG,EAAI,CAAC,EAAI,GAC7D,IAAIE,EAAQ,GAEZ,OAAQD,EAAA,CACN,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACHC,EAAQ,IACR,MACF,IAAK,IAEH,SACF,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACL,IAAK,IACCmB,IAAS,KAAOA,IAAS,KAAOA,IAAS,IAC3CnB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACL,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACL,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCF,IAAM,EACJqB,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,IAC3InB,EAAQ,IAERA,EAAQ,IAGNkB,IAAS,KAAOA,IAAS,IAC3BlB,EAAQ,IACCmB,IAAS,KAETA,IAAS,KAAOA,IAAS,IADlCnB,EAAQ,IAIRA,EAAQ,IAGZ,MACF,IAAK,IACCkB,IAAS,KAAOA,IAAS,KAAOA,IAAS,IAC3ClB,EAAQ,IAERA,EAAQ,KAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,QACE,QAAA,CAIAA,GAASA,IAAUkB,IACrBtB,GAAQI,GAEVkB,EAAOlB,CACT,CAEA,OAAOJ,GAAQ,GACjB,CAMA,mBAAmBF,EAAwB,CACzC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,OAAS,EAAG,MAAO,CAACD,CAAI,EAEvC,MAAM0B,EAAkB,CAAA,EAClBC,EAAiB,KAAK,kBAAA,EACtBC,EAAiB,KAAK,kBAAA,EACtBC,EAAc,KAAK,eAAA,EAGzB,UAAWC,KAAUH,EACnB,GAAI1B,EAAW,WAAW6B,CAAM,GAAK7B,EAAW,OAAS6B,EAAO,OAAS,EAAG,CAC1E,MAAMC,EAAY9B,EAAW,MAAM6B,EAAO,MAAM,EAChDJ,EAAM,KAAKI,CAAM,EACjBJ,EAAM,KAAK,GAAG,KAAK,mBAAmBK,CAAS,CAAC,EAChD,KACF,CAGF,GAAIL,EAAM,SAAW,GAEnB,UAAWM,KAAUJ,EACnB,GAAI3B,EAAW,SAAS+B,CAAM,GAAK/B,EAAW,OAAS+B,EAAO,OAAS,EAAG,CACxE,MAAMD,EAAY9B,EAAW,MAAM,EAAG,CAAC+B,EAAO,MAAM,EACpDN,EAAM,KAAK,GAAG,KAAK,mBAAmBK,CAAS,CAAC,EAChDL,EAAM,KAAKM,CAAM,EACjB,KACF,EAIJ,GAAIN,EAAM,SAAW,EAEnB,QAAStB,EAAI,EAAGA,GAAKH,EAAW,OAAS,EAAGG,IAAK,CAC/C,MAAM6B,EAAWhC,EAAW,MAAM,EAAGG,CAAC,EAChC8B,EAAYjC,EAAW,MAAMG,CAAC,EAEpC,GAAIyB,EAAY,IAAII,CAAQ,GAAKC,EAAU,QAAU,EAAG,CACtDR,EAAM,KAAKO,CAAQ,EACnBP,EAAM,KAAK,GAAG,KAAK,mBAAmBQ,CAAS,CAAC,EAChD,KACF,CACF,CAGF,OAAOR,EAAM,OAAS,EAAIA,EAAQ,CAAC1B,CAAI,CACzC,CAKA,gBAAgBA,EAAwB,CACtC,MAAMO,MAAe,IACfN,EAAa,KAAK,UAAUD,CAAI,EAEtCO,EAAS,IAAIN,CAAU,EACvBM,EAAS,IAAIP,CAAI,EAGK,KAAK,mBAAmBA,CAAI,EACpC,QAASmC,GAAS5B,EAAS,IAAI,KAAK,UAAU4B,CAAI,CAAC,CAAC,EAGlE,MAAMC,EAAgB,KAAK,iBAAA,EAC3B,UAAW3B,KAAU2B,EACfnC,EAAW,SAASQ,CAAM,GAAKR,EAAW,OAASQ,EAAO,OAAS,GACrEF,EAAS,IAAIN,EAAW,MAAM,EAAG,CAACQ,EAAO,MAAM,CAAC,EAKpD,GAAIR,EAAW,OAAS,EACtB,QAASG,EAAI,EAAGA,EAAIH,EAAW,OAAQG,IACrCG,EAAS,IAAIN,EAAW,MAAM,EAAGG,CAAC,CAAC,EAIvC,OAAO,MAAM,KAAKG,CAAQ,CAC5B,CAKU,kBAA6B,CACrC,MAAO,CAEL,KACA,IACA,KACA,IACA,IACA,IACA,KACA,IACA,MACA,OACA,OACA,SACA,OACA,OACA,OACA,KACA,OACA,MACA,MACA,MAAA,CAEJ,CAKA,YAAYP,EAAwB,CAClC,MAAMqC,EAAuC,CAC3C,KAAM,CAEJ,SACA,YACA,KAAA,EAEF,YAAa,CAEX,SACA,SACA,UAAA,EAEF,OAAQ,CAEN,sBACA,aAAA,EAEF,KAAM,CAEJ,QACA,WACA,KAAA,EAEF,KAAM,CAEJ,WACA,OACA,UAAA,EAEF,QAAS,CAEP,MACA,QACA,OAAA,EAEF,MAAO,CAEL,MACA,WACA,WAAA,EAEF,OAAQ,CAEN,MACA,QACA,YAAA,EAEF,KAAM,CAEJ,WACA,UACA,UAAA,EAEF,KAAM,CAEJ,QACA,UACA,UAAA,CACF,EAGIpC,EAAa,KAAK,UAAUD,CAAI,EACtC,OAAOqC,EAAWpC,CAAU,GAAK,CAAA,CACnC,CAKU,sBAAiD,CACzD,MAAO,CACL,EAAG,CAED,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IAAA,EAEF,EAAG,CAED,IACA,KACA,IACA,IAAA,EAEF,GAAI,CAEF,IACA,IAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IAAA,EAEF,GAAI,CAEF,IACA,IACA,KACA,IACA,IAAA,EAEF,GAAI,CAEF,KACA,IAAA,EAEF,EAAG,CAED,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,GAAA,CACF,CAEJ,CAKQ,mBAA8B,CACpC,MAAO,CAAC,KAAM,MAAO,OAAQ,MAAO,MAAO,KAAM,KAAM,MAAO,MAAO,MAAO,QAAS,SAAU,QAAS,QAAS,QAAS,WAAY,QAAQ,CAChJ,CAKQ,mBAA8B,CACpC,MAAO,CAAC,OAAQ,QAAS,UAAW,MAAO,MAAO,OAAQ,MAAO,OAAQ,QAAS,OAAQ,OAAQ,OAAQ,MAAO,SAAU,SAAS,CACtI,CAKQ,gBAA8B,CACpC,OAAO,IAAI,IAAI,CAAC,UAAW,SAAU,SAAU,UAAW,MAAO,MAAO,QAAS,QAAS,OAAQ,OAAQ,OAAQ,OAAQ,QAAS,SAAU,OAAQ,QAAS,QAAS,UAAW,UAAW,UAAW,QAAS,OAAQ,OAAQ,OAAQ,OAAQ,MAAO,MAAO,OAAQ,SAAU,MAAO,QAAS,SAAU,QAAS,OAAQ,OAAQ,QAAS,WAAY,QAAS,OAAQ,MAAO,QAAS,SAAU,QAAS,SAAU,OAAQ,OAAQ,OAAO,CAAC,CACjb,CACF,CC/jBO,MAAMqC,UAAyBxC,CAAsB,CACjD,SAAW,UACX,YAAc,UACd,kBAAoC,CAE3C,WACA,WACA,qBACA,gBACA,kBACA,gBACA,gBAAA,EAMF,UAAUC,EAAsB,CAC9B,OACEA,EACG,YAAA,EACA,OACA,QAAQ,OAAQ,GAAG,EAEnB,QAAQ,SAAU,UAAU,EAC5B,QAAQ,SAAU,QAAQ,EAC1B,QAAQ,OAAQ,MAAM,EACtB,QAAQ,OAAQ,MAAM,EACtB,QAAQ,OAAQ,OAAO,EACvB,QAAQ,OAAQ,OAAO,EACvB,QAAQ,MAAO,QAAQ,EACvB,QAAQ,MAAO,KAAK,EACpB,QAAQ,KAAM,EAAE,CAEvB,CAKA,gBAAgBC,EAAsB,CACpC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EAAE,QAAQ,UAAW,EAAE,EAC7D,GAAIC,EAAW,SAAW,EAAG,MAAO,GAEpC,IAAIsC,EAAY,GACZC,EAAU,EACd,MAAMC,EAASxC,EAAW,OAO1B,KAJIA,EAAW,WAAW,IAAI,GAAKA,EAAW,WAAW,IAAI,GAAKA,EAAW,WAAW,IAAI,GAAKA,EAAW,WAAW,IAAI,KACzHuC,EAAU,GAGLA,EAAUC,GAAUF,EAAU,OAAS,GAAG,CAC/C,MAAMlC,EAAOJ,EAAWuC,CAAO,EACzBf,EAAOe,EAAU,EAAIC,EAASxC,EAAWuC,EAAU,CAAC,EAAI,GACxDhB,EAAOgB,EAAU,EAAIvC,EAAWuC,EAAU,CAAC,EAAI,GAErD,OAAQnC,EAAA,CACN,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACCmC,IAAY,IAAGD,GAAalC,EAAK,YAAA,GACrC,MACF,IAAK,IACCmC,IAAYC,EAAS,GAAKjB,IAAS,MAGrCe,GAAa,KAEf,MACF,IAAK,IACCd,IAAS,KACXc,GAAa,IACbC,KACSf,IAAS,KAAOA,IAAS,KAAOA,IAAS,IAClDc,GAAa,IAEbA,GAAa,IAEf,MACF,IAAK,IACCd,IAAS,KACXc,GAAa,IACbC,KAEAD,GAAa,IAEf,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACCd,IAAS,KAAOe,IAAY,IAErBf,IAAS,KAClBc,GAAa,IACbC,KACSf,IAAS,KAAOA,IAAS,KAAOA,IAAS,IAClDc,GAAa,IAEbA,GAAa,KAEf,MACF,IAAK,KACCC,IAAY,GAAK,QAAQ,SAAShB,CAAI,GAAK,QAAQ,SAASC,CAAI,KAClEc,GAAa,KAEf,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACCf,IAAS,MACXe,GAAa,KAEf,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACCd,IAAS,KACXc,GAAa,IACbC,KAEAD,GAAa,IAEf,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACCd,IAAS,KACXc,GAAa,IACbC,KAEAD,GAAa,IAEf,MACF,IAAK,IACCd,IAAS,KACXc,GAAa,IACbC,KACSf,IAAS,KAAOe,EAAU,EAAIC,IAAWxC,EAAWuC,EAAU,CAAC,IAAM,KAAOvC,EAAWuC,EAAU,CAAC,IAAM,KACjHD,GAAa,IAEbA,GAAa,IAEf,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACC,QAAQ,SAASd,CAAI,IACvBc,GAAa,KAEf,MACF,IAAK,IACHA,GAAa,KACb,MACF,IAAK,IACC,QAAQ,SAASd,CAAI,IACvBc,GAAa,KAEf,MACF,IAAK,IACHA,GAAa,IACb,KAAA,CAEJC,GACF,CAEA,OAAOD,GAAa,GACtB,CAKA,gBAAgBvC,EAAwB,CACtC,MAAMO,MAAe,IACfN,EAAa,KAAK,UAAUD,CAAI,EAEtCO,EAAS,IAAIN,CAAU,EACvBM,EAAS,IAAIP,CAAI,EAGjB,MAAM0C,EAAiB,KAAK,iBAAA,EAC5B,UAAWjC,KAAUiC,EACfzC,EAAW,SAASQ,CAAM,GAAKR,EAAW,OAASQ,EAAO,OAAS,GACrEF,EAAS,IAAIN,EAAW,MAAM,EAAG,CAACQ,EAAO,MAAM,CAAC,EAapD,GARIR,EAAW,SAAS,GAAG,GAAKA,EAAW,OAAS,GAClDM,EAAS,IAAIN,EAAW,MAAM,EAAG,EAAE,CAAC,EAEjCA,EAAW,SAAS,GAAG,GAC1BM,EAAS,IAAIN,EAAa,GAAG,EAI3BA,EAAW,SAAS,KAAK,GAAKA,EAAW,OAAS,EAAG,CACvD,MAAM0C,EAAO1C,EAAW,MAAM,EAAG,EAAE,EACnCM,EAAS,IAAIoC,CAAI,EACjBpC,EAAS,IAAIoC,EAAO,GAAG,CACzB,CACA,GAAI1C,EAAW,SAAS,IAAI,GAAKA,EAAW,OAAS,EAAG,CACtD,MAAM0C,EAAO1C,EAAW,MAAM,EAAG,EAAE,EACnCM,EAAS,IAAIoC,CAAI,EACjBpC,EAAS,IAAIoC,EAAO,GAAG,CACzB,CAGA,GAAI1C,EAAW,OAAS,EACtB,QAASG,EAAI,EAAGA,EAAIH,EAAW,OAAQG,IACrCG,EAAS,IAAIN,EAAW,MAAM,EAAGG,CAAC,CAAC,EAIvC,OAAO,MAAM,KAAKG,CAAQ,CAC5B,CAKU,kBAA6B,CACrC,MAAO,CAEL,IACA,KACA,KACA,MACA,KACA,MACA,KACA,OACA,OACA,OACA,OACA,OACA,OACA,MACA,OACA,MACA,OACA,KACA,MACA,KACA,MACA,MACA,MACA,KAAA,CAEJ,CAKA,YAAYP,EAAwB,CAClC,MAAMqC,EAAuC,CAC3C,OAAQ,CAEN,YACA,QACA,MACA,IAAA,EAEF,SAAU,CAER,SACA,iBACA,WAAA,EAEF,OAAQ,CAEN,UACA,cACA,UACA,YAAA,EAEF,IAAK,CAEH,UACA,aACA,MAAA,EAEF,MAAO,CAEL,OACA,YACA,WACA,UAAA,EAEF,OAAQ,CAEN,OACA,SACA,OACA,WAAA,EAEF,KAAM,CAEJ,OACA,eACA,YAAA,EAEF,KAAM,CAEJ,MACA,aACA,aACA,QAAA,EAEF,MAAO,CAEL,OACA,WACA,QACA,SAAA,EAEF,KAAM,CAEJ,WACA,SACA,SACA,MAAA,EAEF,IAAK,CAEH,QACA,OACA,WACA,UACA,OAAA,EAEF,MAAO,CAEL,SACA,OACA,YACA,QAAA,EAEF,KAAM,CAEJ,QACA,QACA,SACA,OAAA,EAEF,KAAM,CAEJ,WACA,UACA,WAAA,EAEF,KAAM,CAEJ,YACA,QACA,YACA,MAAA,EAEF,IAAK,CAEH,OACA,WACA,QACA,UAAA,EAEF,MAAO,CAEL,SACA,WACA,OACA,SAAA,EAEF,IAAK,CAEH,UACA,YACA,aACA,WAAA,CACF,EAGIpC,EAAa,KAAK,UAAUD,CAAI,EACtC,OAAOqC,EAAWpC,CAAU,GAAK,CAAA,CACnC,CACF,CC/YO,MAAM2C,UAAyB9C,CAAsB,CACjD,SAAW,UACX,YAAc,UACd,kBAAoC,CAE3C,WACA,WACA,qBACA,gBACA,kBACA,eAAA,EAMF,UAAUC,EAAsB,CAC9B,OACEA,EACG,YAAA,EACA,KAAA,EACA,QAAQ,OAAQ,GAAG,EAEnB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,CAExB,CAKA,gBAAgBC,EAAsB,CACpC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,SAAW,EAAG,MAAO,GAEpC,IAAIC,EAAO,GACPsB,EAAO,GAEX,QAASpB,EAAI,EAAGA,EAAIH,EAAW,OAAQG,IAAK,CAC1C,MAAMC,EAAOJ,EAAWG,CAAC,EACnBqB,EAAOrB,EAAIH,EAAW,OAAS,EAAIA,EAAWG,EAAI,CAAC,EAAI,GAC7D,IAAIE,EAAQ,GAEZ,OAAQD,EAAA,CACN,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACHC,EAAQ,IACR,MACF,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCmB,IAAS,IACXnB,EAAQ,IACCmB,IAAS,KAAOA,IAAS,IAClCnB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCmB,IAAS,KAAOrB,EAAI,EAAIH,EAAW,SAAWA,EAAWG,EAAI,CAAC,IAAM,KAAOH,EAAWG,EAAI,CAAC,IAAM,KACnGE,EAAQ,IACCmB,IAAS,KAAOA,IAAS,IAClCnB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IAEH,SACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCmB,IAAS,IACXnB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCmB,IAAS,IACXnB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCmB,IAAS,KAAOrB,IAAM,EACxBE,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,KACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,QACE,QAAA,CAGAA,GAASA,IAAUkB,IACrBtB,GAAQI,GAEVkB,EAAOlB,CACT,CAEA,OAAOJ,GAAQ,GACjB,CAKU,kBAA6B,CACrC,MAAO,CAEL,IACA,IACA,KACA,KACA,IACA,KACA,KACA,KACA,KACA,MACA,MACA,OACA,OACA,OACA,OACA,QACA,OACA,OACA,MACA,MACA,QACA,MACA,MACA,MACA,MACA,OACA,MAAA,CAEJ,CAKA,YAAYF,EAAwB,CAClC,MAAMqC,EAAuC,CAC3C,OAAQ,CAEN,SACA,aAAA,EAEF,SAAU,CAER,UACA,WAAA,EAEF,QAAS,CAEP,UACA,WAAA,EAEF,MAAO,CAEL,OACA,YACA,UAAA,EAEF,KAAM,CAEJ,QACA,WACA,WAAA,EAEF,MAAO,CAEL,MACA,UACA,WAAA,EAEF,OAAQ,CAEN,OACA,YACA,WAAA,EAEF,QAAS,CAEP,SACA,YACA,OAAA,EAEF,OAAQ,CAEN,QACA,WACA,SAAA,EAEF,OAAQ,CAEN,UACA,UACA,UAAA,EAEF,OAAQ,CAEN,SACA,UACA,SAAA,EAEF,QAAS,CAEP,QACA,WACA,WAAA,EAEF,OAAQ,CAEN,QACA,SACA,WAAA,EAEF,MAAO,CAEL,WACA,SAAA,EAEF,MAAO,CAEL,YACA,YACA,WAAA,EAEF,KAAM,CAEJ,SACA,WACA,UAAA,CACF,EAGIpC,EAAa,KAAK,UAAUD,CAAI,EACtC,OAAOqC,EAAWpC,CAAU,GAAK,CAAA,CACnC,CACF,CCvSO,MAAM4C,UAAwB/C,CAAsB,CAChD,SAAW,SACX,YAAc,WACd,kBAAoC,CAE3C,WACA,WACA,qBACA,gBACA,kBACA,eAAA,EAMF,UAAUC,EAAsB,CAC9B,OACEA,EACG,cACA,KAAA,EACA,QAAQ,OAAQ,GAAG,EAEnB,QAAQ,WAAY,GAAG,EACvB,QAAQ,UAAW,GAAG,EACtB,QAAQ,UAAW,GAAG,EACtB,QAAQ,WAAY,GAAG,EACvB,QAAQ,UAAW,GAAG,EACtB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,CAExB,CAKA,gBAAgBC,EAAsB,CACpC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,SAAW,EAAG,MAAO,GAEpC,IAAIC,EAAO,GACPsB,EAAO,GAEX,QAASpB,EAAI,EAAGA,EAAIH,EAAW,OAAQG,IAAK,CAC1C,MAAMC,EAAOJ,EAAWG,CAAC,EACnBqB,EAAOrB,EAAIH,EAAW,OAAS,EAAIA,EAAWG,EAAI,CAAC,EAAI,GACvD0C,EAAQ1C,EAAIH,EAAW,OAAS,EAAIA,EAAWG,EAAI,CAAC,EAAI,GAC9D,IAAIE,EAAQ,GAEZ,OAAQD,EAAA,CACN,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACHC,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCmB,IAAS,IACXnB,EAAQ,IACCmB,IAAS,KAAOA,IAAS,IAClCnB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCmB,IAAS,IACXnB,EAAQ,IACCmB,IAAS,MAAQqB,IAAU,KAAOA,IAAU,KACrDxC,EAAQ,IACCmB,IAAS,KAAOA,IAAS,IAClCnB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IAECF,IAAM,IACRE,EAAQ,KAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCmB,IAAS,IACXnB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IAEDA,EAAQ,IAIV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,KACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,QACE,QAAA,CAGAA,GAASA,IAAUkB,IACrBtB,GAAQI,GAEVkB,EAAOlB,CACT,CAEA,OAAOJ,GAAQ,GACjB,CAKU,kBAA6B,CACrC,MAAO,CAAC,IAAK,KAAM,IAAK,IAAK,MAAO,MAAO,OAAQ,OAAQ,OAAQ,MAAO,OAAQ,OAAQ,QAAS,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,MAAO,OAAQ,OAAQ,MAAO,MAAO,KAAK,CAC/N,CAKA,YAAYF,EAAwB,CAClC,MAAMqC,EAAuC,CAC3C,QAAS,CAEP,UACA,WAAA,EAEF,QAAS,CAEP,WACA,gBAAA,EAEF,MAAO,CAEL,gBACA,aAAA,EAEF,QAAS,CAEP,aACA,WACA,MAAA,EAEF,OAAQ,CAEN,WACA,YACA,YAAA,EAEF,IAAK,CAEH,SACA,YACA,MAAA,EAEF,MAAO,CAEL,OACA,UACA,eAAA,EAEF,QAAS,CAEP,SACA,aACA,QAAA,EAEF,OAAQ,CAEN,UACA,UACA,SAAA,EAEF,MAAO,CAEL,QACA,UACA,QAAA,EAEF,MAAO,CAEL,SACA,UACA,aAAA,EAEF,MAAO,CAEL,YACA,SACA,QAAA,EAEF,OAAQ,CAEN,OACA,WACA,QAAA,EAEF,KAAM,CAEJ,YACA,WAAA,EAEF,IAAK,CAEH,YACA,UACA,YAAA,EAEF,QAAS,CAEP,WACA,UACA,UAAA,EAEF,QAAS,CAEP,SACA,UACA,MAAA,EAEF,OAAQ,CAEN,aACA,WACA,cAAA,CACF,EAGIpC,EAAa,KAAK,UAAUD,CAAI,EACtC,OAAOqC,EAAWpC,CAAU,GAAK,CAAA,CACnC,CAKU,sBAAiD,CACzD,MAAO,CACL,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,GAAA,CACF,CAEJ,CACF,CC9fO,MAAM8C,CAAiB,CAC5B,OAAe,WAAa,IAAI,IAA+B,CAC7D,CAAC,SAAU,IAAIxB,CAAiB,EAChC,CAAC,UAAW,IAAIe,CAAkB,EAClC,CAAC,UAAW,IAAIM,CAAkB,EAClC,CAAC,SAAU,IAAIC,CAAiB,CAAA,CACjC,EAKD,OAAO,aAAaG,EAAiD,CACnE,OAAO,KAAK,WAAW,IAAIA,EAAS,aAAa,CACnD,CAKA,OAAO,cAAcC,EAA0C,CAC7D,OAAOA,EAAU,IAAKvD,GAAS,KAAK,aAAaA,CAAI,CAAC,EAAE,OAAQwD,GAA8CA,IAAc,MAAS,CACvI,CAKA,OAAO,uBAAkC,CACvC,OAAO,MAAM,KAAK,KAAK,WAAW,MAAM,CAC1C,CAKA,OAAO,kBAAkBA,EAAoC,CAC3D,KAAK,WAAW,IAAIA,EAAU,SAAS,YAAA,EAAeA,CAAS,CACjE,CAKA,OAAO,YAAYF,EAA2B,CAC5C,OAAO,KAAK,WAAW,IAAIA,EAAS,aAAa,CACnD,CAKA,OAAO,kBAIJ,CACD,OAAO,MAAM,KAAK,KAAK,WAAW,QAAQ,EAAE,IAAKE,IAAe,CAC9D,SAAUA,EAAU,SACpB,YAAaA,EAAU,YACvB,kBAAmBA,EAAU,iBAAA,EAC7B,CACJ,CACF,0NCzDO,SAASC,EAA6BnC,EAAcC,EAAcmC,EAAsB,IAAkB,CAC/G,MAAMjC,EAAOH,EAAK,OACZI,EAAOH,EAAK,OAGlB,GAAI,KAAK,IAAIE,EAAOC,CAAI,EAAIgC,EAC1B,OAAOA,EAAc,EAGvB,GAAIjC,IAAS,EAAG,OAAOC,EACvB,GAAIA,IAAS,EAAG,OAAOD,EACvB,GAAIH,IAASC,EAAM,MAAO,GAG1B,IAAIoC,EAAc,IAAI,MAAMjC,EAAO,CAAC,EAChCkC,EAAa,IAAI,MAAMlC,EAAO,CAAC,EAGnC,QAASC,EAAI,EAAGA,GAAKD,EAAMC,IACzBgC,EAAYhC,CAAC,EAAIA,EAGnB,QAASjB,EAAI,EAAGA,GAAKe,EAAMf,IAAK,CAC9BkD,EAAW,CAAC,EAAIlD,EAChB,IAAImD,EAAWnD,EAEf,QAASiB,EAAI,EAAGA,GAAKD,EAAMC,IAAK,CAC9B,MAAMC,EAAON,EAAKZ,EAAI,CAAC,IAAMa,EAAKI,EAAI,CAAC,EAAI,EAAI,EAE/CiC,EAAWjC,CAAC,EAAI,KAAK,IACnBiC,EAAWjC,EAAI,CAAC,EAAI,EACpBgC,EAAYhC,CAAC,EAAI,EACjBgC,EAAYhC,EAAI,CAAC,EAAIC,CAAA,EAGvBiC,EAAW,KAAK,IAAIA,EAAUD,EAAWjC,CAAC,CAAC,CAC7C,CAGA,GAAIkC,EAAWH,EACb,OAAOA,EAAc,EAIvB,CAACC,EAAaC,CAAU,EAAI,CAACA,EAAYD,CAAW,CACtD,CAEA,OAAOA,EAAYjC,CAAI,CACzB,CAMO,SAASoC,EAAoCxC,EAAcC,EAAcmC,EAAsB,IAAkB,CACtH,MAAMjC,EAAOH,EAAK,OACZI,EAAOH,EAAK,OAElB,GAAI,KAAK,IAAIE,EAAOC,CAAI,EAAIgC,EAC1B,OAAOA,EAAc,EAGvB,GAAIjC,IAAS,EAAG,OAAOC,EACvB,GAAIA,IAAS,EAAG,OAAOD,EACvB,GAAIH,IAASC,EAAM,MAAO,GAE1B,MAAMwC,EAAS,KAAK,IAAItC,EAAMC,CAAI,EAC5BsC,EAAgB,CAAA,EAChBC,EAAMF,EAAS,EAGrB,QAASrD,EAAI,EAAGA,GAAKe,EAAO,EAAGf,IAC7BsD,EAAEtD,CAAC,EAAI,IAAI,MAAMgB,EAAO,CAAC,EAAE,KAAKuC,CAAG,EAGrCD,EAAE,CAAC,EAAE,CAAC,EAAIC,EACV,QAASvD,EAAI,EAAGA,GAAKe,EAAMf,IACzBsD,EAAEtD,EAAI,CAAC,EAAE,CAAC,EAAIuD,EACdD,EAAEtD,EAAI,CAAC,EAAE,CAAC,EAAIA,EAEhB,QAASiB,EAAI,EAAGA,GAAKD,EAAMC,IACzBqC,EAAE,CAAC,EAAErC,EAAI,CAAC,EAAIsC,EACdD,EAAE,CAAC,EAAErC,EAAI,CAAC,EAAIA,EAGhB,MAAMuC,MAAc,IAEpB,QAASxD,EAAI,EAAGA,GAAKe,EAAMf,IAAK,CAC9B,IAAIyD,EAAe,EAEnB,QAASxC,EAAI,EAAGA,GAAKD,EAAMC,IAAK,CAC9B,MAAMV,EAAQK,EAAKZ,EAAI,CAAC,EAClBQ,EAAQK,EAAKI,EAAI,CAAC,EAClByC,EAAeF,EAAQ,IAAIhD,CAAK,GAAK,EAE3C,IAAIU,EAAO,EACPX,IAAUC,IACZU,EAAO,EACPuC,EAAexC,GAGjBqC,EAAEtD,EAAI,CAAC,EAAEiB,EAAI,CAAC,EAAI,KAAK,IACrBqC,EAAEtD,CAAC,EAAEiB,CAAC,EAAIC,EACVoC,EAAEtD,EAAI,CAAC,EAAEiB,CAAC,EAAI,EACdqC,EAAEtD,CAAC,EAAEiB,EAAI,CAAC,EAAI,EACdqC,EAAEI,CAAY,EAAED,CAAY,GAAKzD,EAAI0D,EAAe,GAAK,GAAKzC,EAAIwC,EAAe,EAAA,CAErF,CAEAD,EAAQ,IAAI5C,EAAKZ,EAAI,CAAC,EAAGA,CAAC,CAC5B,CAEA,MAAM2D,EAASL,EAAEvC,EAAO,CAAC,EAAEC,EAAO,CAAC,EACnC,OAAO2C,EAASX,EAAcA,EAAc,EAAIW,CAClD,CAMO,SAASC,EAAyBhD,EAAcC,EAAcH,EAAY,EAAW,CAC1F,GAAIE,IAASC,EAAM,MAAO,GAC1B,GAAID,EAAK,SAAW,GAAKC,EAAK,SAAW,EAAG,MAAO,GAEnD,MAAMgD,EAAUC,EAAelD,EAAMF,CAAC,EAChCqD,EAAUD,EAAejD,EAAMH,CAAC,EAEtC,GAAImD,EAAQ,SAAW,GAAKE,EAAQ,SAAW,EAAG,MAAO,GACzD,GAAIF,EAAQ,SAAW,GAAKE,EAAQ,SAAW,EAAG,MAAO,GAEzD,MAAMC,EAAO,IAAI,IAAIH,CAAO,EACtBI,EAAO,IAAI,IAAIF,CAAO,EAEtBG,EAAe,IAAI,IAAI,CAAC,GAAGF,CAAI,EAAE,OAAQG,GAAMF,EAAK,IAAIE,CAAC,CAAC,CAAC,EAC3DC,MAAY,IAAI,CAAC,GAAGJ,EAAM,GAAGC,CAAI,CAAC,EAExC,OAAOC,EAAa,KAAOE,EAAM,IACnC,CAKO,SAASN,EAAeO,EAAa3D,EAAqB,CAC/D,GAAI2D,EAAI,OAAS3D,EAAG,MAAO,CAAC2D,CAAG,EAE/B,MAAM1D,EAAmB,CAAA,EACzB,QAASX,EAAI,EAAGA,GAAKqE,EAAI,OAAS3D,EAAGV,IACnCW,EAAO,KAAK0D,EAAI,MAAMrE,EAAGA,EAAIU,CAAC,CAAC,EAEjC,OAAOC,CACT,CAKO,SAAS2D,EAAqBC,EAAkBC,EAA2B,CAChF,OAAIA,IAAc,EAAUD,IAAa,EAAI,EAAM,EAC5C,KAAK,IAAI,EAAG,EAAIA,EAAWC,CAAS,CAC7C,CAKO,SAASC,GAAkB7D,EAAcC,EAAc6D,EAAoB,GAAK1B,EAAsB,EAAY,CAEvH,GAAIpC,IAASC,EAAM,MAAO,GAG1B,MAAMwC,EAAS,KAAK,IAAIzC,EAAK,OAAQC,EAAK,MAAM,EAKhD,GAJI,KAAK,IAAID,EAAK,OAASC,EAAK,MAAM,EAAImC,GAGzBY,EAAyBhD,EAAMC,CAAI,EACrC6D,EAAY,GAAK,MAAO,GAGvC,MAAMH,EAAWxB,EAA6BnC,EAAMC,EAAMmC,CAAW,EAGrE,OAFmBsB,EAAqBC,EAAUlB,CAAM,GAEnCqB,CACvB,CCjLO,MAAMC,CAAK,CACR,KACA,KAER,aAAc,CACZ,KAAK,KAAO,KAAK,WAAA,EACjB,KAAK,KAAO,CACd,CAEQ,YAAuB,CAC7B,MAAO,CACL,aAAc,IACd,YAAa,GACb,WAAY,GAAI,CAEpB,CAKA,OAAOC,EAAcC,EAAwB,CAC3C,GAAI,CAACD,EAAM,OAEX,IAAIE,EAAO,KAAK,KAEhB,UAAW7E,KAAQ2E,EACZE,EAAK,SAAS,IAAI7E,CAAI,GACzB6E,EAAK,SAAS,IAAI7E,EAAM,KAAK,YAAY,EAE3C6E,EAAOA,EAAK,SAAS,IAAI7E,CAAI,EAG/B6E,EAAK,YAAc,GACnBA,EAAK,KAAOF,EACZC,EAAO,QAAQE,GAAMD,EAAK,OAAO,IAAIC,CAAE,CAAC,EACxC,KAAK,MACP,CAMA,eAAerD,EAA2C,CACxD,GAAI,CAACA,EAAQ,MAAO,CAAA,EAGpB,IAAIoD,EAAO,KAAK,KAChB,UAAW7E,KAAQyB,EAAQ,CACzB,GAAI,CAACoD,EAAK,SAAS,IAAI7E,CAAI,EACzB,MAAO,CAAA,EAET6E,EAAOA,EAAK,SAAS,IAAI7E,CAAI,CAC/B,CAGA,MAAM+E,EAAqC,CAAA,EAC3C,YAAK,aAAaF,EAAME,CAAO,EACxBA,CACT,CAKA,IAAIJ,EAAuB,CACzB,IAAIE,EAAO,KAAK,KAChB,UAAW7E,KAAQ2E,EAAM,CACvB,GAAI,CAACE,EAAK,SAAS,IAAI7E,CAAI,EACzB,MAAO,GAET6E,EAAOA,EAAK,SAAS,IAAI7E,CAAI,CAC/B,CACA,OAAO6E,EAAK,WACd,CAKA,IAAIF,EAA+B,CACjC,IAAIE,EAAO,KAAK,KAChB,UAAW7E,KAAQ2E,EAAM,CACvB,GAAI,CAACE,EAAK,SAAS,IAAI7E,CAAI,EACzB,OAAO,KAET6E,EAAOA,EAAK,SAAS,IAAI7E,CAAI,CAC/B,CACA,OAAO6E,EAAK,YAAc,MAAM,KAAKA,EAAK,MAAM,EAAI,IACtD,CAKQ,aAAaA,EAAgBE,EAA0C,CACzEF,EAAK,aAAeA,EAAK,MAC3BE,EAAQ,KAAK,CAACF,EAAK,KAAM,MAAM,KAAKA,EAAK,MAAM,CAAC,CAAC,EAGnD,UAAWG,KAASH,EAAK,SAAS,OAAA,EAChC,KAAK,aAAaG,EAAOD,CAAO,CAEpC,CAKA,SAAkB,CAChB,OAAO,KAAK,IACd,CAKA,OAAc,CACZ,KAAK,KAAO,KAAK,WAAA,EACjB,KAAK,KAAO,CACd,CAKA,QAAc,CACZ,MAAO,CACL,KAAM,KAAK,cAAc,KAAK,IAAI,EAClC,KAAM,KAAK,IAAA,CAEf,CAKA,OAAO,SAASE,EAAiB,CAC/B,MAAMC,EAAO,IAAIR,EACjB,OAAAQ,EAAK,KAAOR,EAAK,gBAAgBO,EAAK,IAAI,EAC1CC,EAAK,KAAOD,EAAK,KACVC,CACT,CAEQ,cAAcL,EAAqB,CACzC,MAAO,CACL,SAAU,MAAM,KAAKA,EAAK,SAAS,SAAS,EAAE,IAAI,CAAC,CAAC7E,EAAMgF,CAAK,IAAM,CACnEhF,EACA,KAAK,cAAcgF,CAAK,CAAA,CACzB,EACD,YAAaH,EAAK,YAClB,OAAQ,MAAM,KAAKA,EAAK,MAAM,EAC9B,KAAMA,EAAK,IAAA,CAEf,CAEA,OAAe,gBAAgBI,EAAqB,CAClD,MAAMJ,EAAiB,CACrB,aAAc,IACd,YAAaI,EAAK,YAClB,OAAQ,IAAI,IAAIA,EAAK,MAAM,EAC3B,KAAMA,EAAK,IAAA,EAGb,SAAW,CAACjF,EAAMmF,CAAS,IAAKF,EAAK,SACnCJ,EAAK,SAAS,IAAI7E,EAAM0E,EAAK,gBAAgBS,CAAS,CAAC,EAGzD,OAAON,CACT,CACF,CC/IO,MAAMO,EAAkC,CAC7C,GAAI,IACJ,EAAG,IACH,OAAQ,EACV,EAkCO,SAASC,GACdV,EACAW,EACA9F,EAAqB4F,EACb,CACR,MAAMG,EAAKD,EAAY,oBAAoB,IAAIX,CAAI,GAAK,EAClDa,EAAIF,EAAY,UAGtB,GAAIC,IAAO,GAAKC,IAAM,EACpB,OAAOhG,EAAO,OAIhB,MAAMiG,EAAM,KAAK,KAAKD,EAAID,EAAK,KAAQA,EAAK,IAAO,CAAC,EAGpD,OAAO,KAAK,IAAIE,EAAKjG,EAAO,MAAM,CACpC,CAKO,SAASkG,GACdf,EACAgB,EACAL,EACA9F,EAAqB4F,EACb,CACR,MAAMQ,EAAKD,EAAS,gBAAgB,IAAIhB,CAAI,GAAK,EAGjD,GAAIiB,IAAO,EACT,MAAO,GAGT,MAAMH,EAAMJ,GAAaV,EAAMW,EAAa9F,CAAM,EAC5CqG,EAAYF,EAAS,OACrBG,EAAeR,EAAY,aAG3BS,EAAYH,GAAMpG,EAAO,GAAK,GAC9BwG,EAAcJ,EAAKpG,EAAO,IAAM,EAAIA,EAAO,EAAIA,EAAO,GAAKqG,EAAYC,IAE7E,OAAOL,GAAOM,EAAYC,EAC5B,CAMO,SAASC,GACdC,EACAP,EACAL,EACA9F,EAAqB4F,EACb,CACR,IAAIe,EAAa,EAEjB,UAAWxB,KAAQuB,EACjBC,GAAcT,GAAmBf,EAAMgB,EAAUL,EAAa9F,CAAM,EAGtE,OAAO2G,CACT,CAMO,SAASC,GAAiBC,EAAyC,CACxE,MAAMC,EAAYD,EAAU,OAC5B,IAAIE,EAAc,EAClB,MAAMC,MAA0B,IAEhC,UAAWC,KAAOJ,EAAW,CAC3BE,GAAeE,EAAI,OAGnB,MAAMC,EAAc,IAAI,IAAID,EAAI,gBAAgB,MAAM,EACtD,UAAW9B,KAAQ+B,EACjBF,EAAoB,IAAI7B,GAAO6B,EAAoB,IAAI7B,CAAI,GAAK,GAAK,CAAC,CAE1E,CAEA,MAAMmB,EAAeQ,EAAY,EAAIC,EAAcD,EAAY,EAE/D,MAAO,CACL,UAAAA,EACA,aAAAR,EACA,oBAAAU,CAAA,CAEJ,CAMO,SAASG,GAAmBC,EAAeC,EAAmB,GAAY,CAC/E,GAAIA,IAAa,EAAG,MAAO,GAI3B,MAAMC,EAAeF,EAAQC,EAAY,EAAI,EAC7C,MAAO,IAAK,EAAI,KAAK,IAAI,CAACC,CAAW,EACvC,CAMO,SAASC,GACdC,EACAC,EACAC,EAAqB,GACrBC,EAAsB,GACd,CAER,MAAMC,EAAcF,EAAaC,EAC3BE,EAAuBH,EAAaE,EACpCE,EAAwBH,EAAcC,EAG5C,OAAOC,EAAuBL,EAAYM,EAAwBL,CACpE,CC5KO,MAAMM,CAAY,CACf,SACA,KACA,iBACA,YAAsB,EAE9B,YAAY/H,EAA2B,CAIrC,MAAMiB,EAAIjB,EAAO,iBACXgI,EAAIhI,EAAO,kBAEjB,KAAK,KAAO,KAAK,KAAK,EAAEiB,EAAI,KAAK,IAAI+G,CAAC,GAAM,KAAK,IAAI,CAAC,GAAK,CAAE,EAI7D,KAAK,iBAAmB,KAAK,KAAM,KAAK,KAAO/G,EAAK,KAAK,IAAI,CAAC,CAAC,EAG/D,KAAK,SAAW,IAAI,WAAW,KAAK,KAAK,KAAK,KAAO,CAAC,CAAC,CACzD,CAKA,IAAIgH,EAAoB,CACtB,MAAMC,EAAS,KAAK,UAAUD,CAAI,EAElC,UAAWE,KAAQD,EAAQ,CACzB,MAAME,EAAY,KAAK,MAAMD,EAAO,CAAC,EAC/BE,EAAWF,EAAO,EACxB,KAAK,SAASC,CAAS,GAAM,GAAKC,CACpC,CAEA,KAAK,aACP,CAQA,aAAaJ,EAAuB,CAClC,MAAMC,EAAS,KAAK,UAAUD,CAAI,EAElC,UAAWE,KAAQD,EAAQ,CACzB,MAAME,EAAY,KAAK,MAAMD,EAAO,CAAC,EAC/BE,EAAWF,EAAO,EAExB,IAAK,KAAK,SAASC,CAAS,EAAK,GAAKC,KAAe,EACnD,MAAO,EAEX,CAEA,MAAO,EACT,CAMQ,UAAUJ,EAAwB,CACxC,MAAMK,EAAQ,KAAK,KAAKL,EAAM,CAAC,EACzBM,EAAQ,KAAK,KAAKN,EAAM,CAAC,EAEzBC,EAAmB,CAAA,EAEzB,QAAS3H,EAAI,EAAGA,EAAI,KAAK,iBAAkBA,IAAK,CAE9C,MAAMiI,GAAgBF,EAAQ/H,EAAIgI,GAAS,KAAK,KAChDL,EAAO,KAAK,KAAK,IAAIM,CAAY,CAAC,CACpC,CAEA,OAAON,CACT,CAKQ,KAAKtD,EAAa6D,EAAsB,CAC9C,IAAIN,EAAO,WAAaM,EAExB,QAAS,EAAI,EAAG,EAAI7D,EAAI,OAAQ,IAC9BuD,GAAQvD,EAAI,WAAW,CAAC,EACxBuD,IAASA,GAAQ,IAAMA,GAAQ,IAAMA,GAAQ,IAAMA,GAAQ,IAAMA,GAAQ,IAG3E,OAAOA,IAAS,CAClB,CAMA,sBAA+B,CAC7B,GAAI,KAAK,cAAgB,EAAG,MAAO,GAInC,MAAMO,EAAI,KAAK,iBACTzH,EAAI,KAAK,YACT0H,EAAI,KAAK,KAEf,OAAO,KAAK,IAAI,EAAI,KAAK,IAAK,CAACD,EAAIzH,EAAK0H,CAAC,EAAGD,CAAC,CAC/C,CAKA,UAME,CACA,MAAO,CACL,KAAM,KAAK,KACX,iBAAkB,KAAK,iBACvB,YAAa,KAAK,YAClB,kBAAmB,KAAK,qBAAA,EACxB,YAAa,KAAK,SAAS,UAAA,CAE/B,CAKA,OAAc,CACZ,KAAK,SAAS,KAAK,CAAC,EACpB,KAAK,YAAc,CACrB,CAKA,QAKE,CACA,MAAO,CACL,SAAU,MAAM,KAAK,KAAK,QAAQ,EAClC,KAAM,KAAK,KACX,iBAAkB,KAAK,iBACvB,YAAa,KAAK,WAAA,CAEtB,CAKA,OAAO,SAASjD,EAKA,CAEd,MAAMmD,EAAS,IAAIb,EAAY,CAC7B,iBAAkB,IAClB,kBAAmB,GAAA,CACpB,EAGD,OAAAa,EAAO,SAAW,IAAI,WAAWnD,EAAK,QAAQ,EAC9CmD,EAAO,KAAOnD,EAAK,KACnBmD,EAAO,iBAAmBnD,EAAK,iBAC/BmD,EAAO,YAAcnD,EAAK,YAEnBmD,CACT,CACF,CAKO,SAASC,GAAkBC,EAA0BC,EAA4B,IAAmB,CACzG,OAAO,IAAIhB,EAAY,CACrB,iBAAAe,EACA,kBAAAC,CAAA,CACD,CACH,CCzLO,SAASC,GAAmBC,EAAiBC,EAAyClJ,EAAqBmJ,EAA0F,CAC1M,MAAMtC,EAAgC,CAAA,EAChCuC,EAA+B,CACnC,mBAAoB,IACpB,SAAU,IAAIlE,EACd,uBAAwB,IACxB,oBAAqB,IACrB,sBAAuB,IACvB,iBAAkB,IAClB,UAAW,EACX,aAAc,CAAA,EAGhB,IAAI6B,EAAc,EACdsC,EAAQ,EAGZ,UAAWlJ,KAAQ8I,EAAO,CACxB,GAAI,CAAC9I,GAAQA,EAAK,OAAO,OAASH,EAAO,eAAgB,SAEzD,MAAMsJ,EAAcnJ,EAAK,KAAA,EAGzB,UAAWkD,KAAa6F,EAAoB,CAC1C,MAAM9I,EAAaiD,EAAU,UAAUiG,CAAW,EAC5CC,EAAeJ,EAAW,IAAI,UAAU,GAAK9F,EAAU,kBAAkB,SAAS,UAAU,EAAIA,EAAU,gBAAgBiG,CAAW,EAAI,OAEzIE,EAAgBL,EAAW,IAAI,UAAU,GAAK9F,EAAU,kBAAkB,SAAS,UAAU,EAAIA,EAAU,mBAAmBiG,CAAW,EAAI,OAG7IrC,EAAwB,CAC5B,GAAIoC,EACJ,KAAMC,EACN,WAAAlJ,EACA,aAAAmJ,EACA,SAAUlG,EAAU,SACpB,cAAemG,GAAiBA,EAAc,OAAS,EAAIA,EAAgB,MAAA,EAG7E3C,EAAU,KAAKI,CAAG,EAClBF,GAAe3G,EAAW,OAG1BqJ,EAAiBL,EAAc,eAAgBhJ,EAAYiJ,CAAK,EAChED,EAAc,SAAU,OAAOhJ,EAAY,CAACiJ,CAAK,CAAC,EAGlD,MAAMK,EAAYJ,EAAY,YAAA,EAkC9B,GAjCAG,EAAiBL,EAAc,eAAgBM,EAAWL,CAAK,EAC/DD,EAAc,SAAU,OAAOM,EAAW,CAACL,CAAK,CAAC,EAG7CF,EAAW,IAAI,eAAe,GACf9F,EAAU,gBAAgBiG,CAAW,EAC7C,QAASK,GAAY,CAC5BF,EAAiBL,EAAc,eAAgBO,EAASN,CAAK,EAC7DD,EAAc,SAAU,OAAOO,EAAS,CAACN,CAAK,CAAC,CACjD,CAAC,EAICE,GACFE,EAAiBL,EAAc,mBAAoBG,EAAcF,CAAK,EAIzDhF,EAAejE,EAAYJ,EAAO,SAAS,EACnD,QAAS4J,GAAU,CACxBH,EAAiBL,EAAc,gBAAiBQ,EAAOP,CAAK,CAC9D,CAAC,EAGGG,GAAiBA,EAAc,OAAS,GAC1CA,EAAc,QAASlH,GAAS,CAC9B,MAAMuH,EAAiBxG,EAAU,UAAUf,CAAI,EAC/CmH,EAAiBL,EAAc,eAAgBS,EAAgBR,CAAK,EACpED,EAAc,SAAU,OAAOS,EAAgB,CAACR,CAAK,CAAC,CACxD,CAAC,EAICF,EAAW,IAAI,UAAU,IACV9F,EAAU,YAAYjD,CAAU,EACxC,QAAS0J,GAAY,CAC5BL,EAAiBL,EAAc,kBAAmBU,EAAST,CAAK,CAClE,CAAC,EAGGrJ,EAAO,gBAAgB,CACzB,MAAM+J,EAAiB/J,EAAO,eAAeI,CAAU,EACnD2J,GACFA,EAAe,QAASD,GAAY,CAClCL,EAAiBL,EAAc,kBAAmBU,EAAST,CAAK,CAClE,CAAC,CAEL,CAGFA,GACF,CACF,CAMA,GAJAD,EAAc,UAAYC,EAC1BD,EAAc,aAAerC,EAAc,KAAK,IAAI,EAAGsC,CAAK,EAGxDrJ,EAAO,QAAS,CAClB,MAAMgH,MAA0B,IAC1BgD,MAAsB,IAG5B,SAAW,CAAC7E,EAAM8E,CAAO,IAAKb,EAAc,eAAe,UACzDpC,EAAoB,IAAI7B,EAAM8E,EAAQ,OAAO,MAAM,EAIrDpD,EAAU,QAASI,GAAQ,CACzB+C,EAAgB,IAAI/C,EAAI,GAAIA,EAAI,WAAW,MAAM,CACnD,CAAC,EAEDmC,EAAc,UAAY,CACxB,oBAAApC,EACA,gBAAAgD,CAAA,CAEJ,CAKA,GAF6BhK,EAAO,gBAAkBiJ,EAAM,QAAU,IAE5C,CACxB,MAAMF,EAAoB/I,EAAO,8BAAgC,IAC3DkK,EAAc,IAAInC,EAAY,CAClC,iBAAkBqB,EAAc,eAAe,KAC/C,kBAAAL,CAAA,CACD,EAGD,UAAW5D,KAAQiE,EAAc,eAAe,KAAA,EAC9Cc,EAAY,IAAI/E,CAAI,EAGtBiE,EAAc,YAAcc,CAC9B,CAEA,MAAO,CAAE,cAAAd,EAAe,UAAAvC,CAAA,CAC1B,CAMO,SAASsD,GAAoBf,EAA8BvC,EAA+BuD,EAAeC,EAAiCrK,EAAoC,CACnL,MAAMsK,MAAc,IACdnB,EAAa,IAAI,IAAInJ,EAAO,QAAQ,EAG1C,UAAWqD,KAAagH,EAAY,CAClC,MAAME,EAAkBlH,EAAU,UAAU+G,EAAM,MAAM,EAGxDI,GAAyBD,EAAiBnB,EAAevC,EAAWyD,EAASjH,EAAU,QAAQ,EAG/FoH,GAA0BF,EAAiBnB,EAAevC,EAAWyD,EAASjH,EAAU,QAAQ,EAG5F8F,EAAW,IAAI,UAAU,GAAK9F,EAAU,kBAAkB,SAAS,UAAU,GAC/EqH,GAA4BH,EAAiBlH,EAAW+F,EAAevC,EAAWyD,CAAO,EAIvFnB,EAAW,IAAI,UAAU,GAC3BwB,GAA2BJ,EAAiBnB,EAAevC,EAAWyD,CAAO,EAI/EM,GAAyBL,EAAiBnB,EAAevC,EAAWyD,EAASjH,EAAU,SAAUrD,EAAO,SAAS,GAG7GmJ,EAAW,IAAI,iBAAiB,GAAKA,EAAW,IAAI,eAAe,GAAKA,EAAW,IAAI,gBAAgB,IACzG0B,GAAyBN,EAAiBnB,EAAevC,EAAWyD,EAASjH,EAAWrD,EAAO,gBAAiBA,CAAM,CAE1H,CAGA,OAAO,MAAM,KAAKsK,EAAQ,OAAA,CAAQ,CACpC,CAKA,SAASb,EAAiBqB,EAAoC3F,EAAckE,EAAqB,CAC/F,IAAIY,EAAUa,EAAS,IAAI3F,CAAI,EAC1B8E,IACHA,EAAU,CAAE,KAAA9E,EAAM,OAAQ,EAAC,EAC3B2F,EAAS,IAAI3F,EAAM8E,CAAO,GAIvBA,EAAQ,OAAO,SAASZ,CAAK,GAChCY,EAAQ,OAAO,KAAKZ,CAAK,CAE7B,CAKA,SAASmB,GAAyBJ,EAAehB,EAA8BvC,EAA+ByD,EAAmCnH,EAAwB,CAEvK,GAAIiG,EAAc,aAAe,CAACA,EAAc,YAAY,aAAagB,CAAK,EAC5E,OAGF,MAAMH,EAAUb,EAAc,eAAe,IAAIgB,CAAK,EACjDH,GAELA,EAAQ,OAAO,QAASZ,GAAU,CAChC,MAAMpC,EAAMJ,EAAUwC,CAAK,EACtBpC,IAEAqD,EAAQ,IAAIjB,CAAK,GACpBiB,EAAQ,IAAIjB,EAAO,CACjB,KAAMpC,EAAI,KACV,WAAYmD,EACZ,UAAW,QACX,aAAc,EACd,SAAAjH,EACA,MAAAkG,CAAA,CACD,EAEL,CAAC,CACH,CAMA,SAASoB,GAA0BL,EAAehB,EAA8BvC,EAA+ByD,EAAmCnH,EAAwB,CAExK,GAAIiG,EAAc,SAAU,CAC1B,MAAM2B,EAAgB3B,EAAc,SAAS,eAAegB,CAAK,EAEjE,SAAW,CAACjF,EAAMC,CAAM,IAAK2F,EACvB5F,IAASiF,GACXhF,EAAO,QAASiE,GAAkB,CAChC,MAAMpC,EAAMJ,EAAUwC,CAAK,EACtBpC,IAEAqD,EAAQ,IAAIjB,CAAK,GACpBiB,EAAQ,IAAIjB,EAAO,CACjB,KAAMpC,EAAI,KACV,WAAY9B,EACZ,UAAW,SACX,SAAAhC,EACA,MAAAkG,CAAA,CACD,EAEL,CAAC,CAGP,KAEE,UAAW,CAAClE,EAAM8E,CAAO,IAAKb,EAAc,eAAe,UACrDjE,EAAK,WAAWiF,CAAK,GAAKjF,IAASiF,GACrCH,EAAQ,OAAO,QAASZ,GAAU,CAChC,MAAMpC,EAAMJ,EAAUwC,CAAK,EACtBpC,IAEAqD,EAAQ,IAAIjB,CAAK,GACpBiB,EAAQ,IAAIjB,EAAO,CACjB,KAAMpC,EAAI,KACV,WAAY9B,EACZ,UAAW,SACX,SAAAhC,EACA,MAAAkG,CAAA,CACD,EAEL,CAAC,CAIT,CAKA,SAASqB,GAA4BN,EAAe/G,EAA8B+F,EAA8BvC,EAA+ByD,EAAyC,CACtL,MAAMf,EAAelG,EAAU,gBAAgB+G,CAAK,EACpD,GAAI,CAACb,EAAc,OAEnB,MAAMU,EAAUb,EAAc,mBAAmB,IAAIG,CAAY,EAC5DU,GAELA,EAAQ,OAAO,QAASZ,GAAU,CAChC,MAAMpC,EAAMJ,EAAUwC,CAAK,EACtBpC,IAEAqD,EAAQ,IAAIjB,CAAK,GACpBiB,EAAQ,IAAIjB,EAAO,CACjB,KAAMpC,EAAI,KACV,WAAYmD,EACZ,UAAW,WACX,aAAAb,EACA,SAAUlG,EAAU,SACpB,MAAAgG,CAAA,CACD,EAEL,CAAC,CACH,CAKA,SAASsB,GAA2BP,EAAehB,EAA8BvC,EAA+ByD,EAAyC,CACvJ,MAAML,EAAUb,EAAc,kBAAkB,IAAIgB,CAAK,EACpDH,GAELA,EAAQ,OAAO,QAASZ,GAAU,CAChC,MAAMpC,EAAMJ,EAAUwC,CAAK,EACtBpC,IAEAqD,EAAQ,IAAIjB,CAAK,GACpBiB,EAAQ,IAAIjB,EAAO,CACjB,KAAMpC,EAAI,KACV,WAAYmD,EACZ,UAAW,UACX,SAAU,UACV,MAAAf,CAAA,CACD,EAEL,CAAC,CACH,CAKA,SAASuB,GAAyBR,EAAehB,EAA8BvC,EAA+ByD,EAAmCnH,EAAkB6H,EAAyB,CAC1L,GAAIZ,EAAM,OAASY,EAAW,OAE9B,MAAMC,EAAc5G,EAAe+F,EAAOY,CAAS,EAC7CE,MAAoB,IAG1BD,EAAY,QAASrB,GAAU,CAC7B,MAAMK,EAAUb,EAAc,gBAAgB,IAAIQ,CAAK,EACnDK,GACFA,EAAQ,OAAO,QAASZ,GAAU6B,EAAc,IAAI7B,CAAK,CAAC,CAE9D,CAAC,EAGD6B,EAAc,QAAS7B,GAAU,CAC/B,MAAMpC,EAAMJ,EAAUwC,CAAK,EACtBpC,IAEAqD,EAAQ,IAAIjB,CAAK,GACpBiB,EAAQ,IAAIjB,EAAO,CACjB,KAAMpC,EAAI,KACV,WAAYmD,EACZ,UAAW,QACX,SAAAjH,EACA,MAAAkG,CAAA,CACD,EAEL,CAAC,CACH,CAMA,SAASwB,GAAyBT,EAAehB,EAA8BvC,EAA+ByD,EAAmCjH,EAA8BE,EAAqBvD,EAA2B,CAC7N,MAAMmL,EAAWf,EAAM,OACjBgB,EAASD,EAAW5H,EACpBK,EAASuH,EAAW5H,EAGpB8H,EAAoBrL,EAAO,UAAU,SAAS,gBAAgB,EAG9DsL,EAAuB,IAC7B,IAAIC,EAAoB,EAGxB,SAAW,CAACpG,EAAM8E,CAAO,IAAKb,EAAc,eAAe,UAAW,CAGpE,MAAMoC,EAAUrG,EAAK,OACrB,GAAIqG,EAAUJ,GAAUI,EAAU5H,EAChC,SAUF,GANI2H,GAAqBD,IAGzBC,IAGIjB,EAAQ,MAAQtK,EAAO,WAAa,GACtC,MAIF,MAAM8E,EAAWuG,EACb1H,EAAoCyG,EAAOjF,EAAM5B,CAAW,EAC5DD,EAA6B8G,EAAOjF,EAAM5B,CAAW,EAErDuB,GAAYvB,GACd0G,EAAQ,OAAO,QAASZ,GAAU,CAChC,MAAMpC,EAAMJ,EAAUwC,CAAK,EAC3B,GAAI,CAACpC,EAAK,OAEV,MAAMwE,EAAgBnB,EAAQ,IAAIjB,CAAK,GAEnC,CAACoC,IAAkBA,EAAc,cAAgB,KAAY3G,IAC/DwF,EAAQ,IAAIjB,EAAO,CACjB,KAAMpC,EAAI,KACV,WAAY9B,EACZ,UAAW,QACX,aAAcL,EACd,SAAUzB,EAAU,SACpB,MAAAgG,CAAA,CACD,CAEL,CAAC,CAEL,CACF,CAMO,SAASqC,GACdpB,EACA5D,EACA0C,EACAvC,EACA7G,EACe,CACf,GAAI,CAACA,EAAO,SAAW,CAACoJ,EAAc,UACpC,OAAOkB,EAGT,MAAMqB,EAAa,CACjB,GAAG/F,EACH,GAAG5F,EAAO,UAAA,EAIN8F,EAA2B,CAC/B,UAAWsD,EAAc,UACzB,aAAcA,EAAc,aAC5B,oBAAqBA,EAAc,UAAU,mBAAA,EAI/C,OAAOkB,EAAQ,IAAKsB,GAAU,CAC5B,GAAIA,EAAM,QAAU,OAClB,OAAOA,EAGT,MAAM3E,EAAMJ,EAAU+E,EAAM,KAAK,EACjC,GAAI,CAAC3E,EACH,OAAO2E,EAIT,MAAMC,MAAsB,IACtBC,EAAkB7E,EAAI,WAAW,YAAA,EAAc,MAAM,KAAK,EAEhE,UAAW9B,KAAQ2G,EACjBD,EAAgB,IAAI1G,GAAO0G,EAAgB,IAAI1G,CAAI,GAAK,GAAK,CAAC,EAGhE,MAAMgB,EAA0B,CAC9B,MAAOc,EAAI,GACX,OAAQ6E,EAAgB,OACxB,gBAAAD,CAAA,EAIIrE,EAAYf,GAAmBC,EAAYP,EAAUL,EAAa6F,CAAU,EAC5EI,EAAiB5E,GAAmBK,CAAS,EAEnD,MAAO,CACL,GAAGoE,EACH,UAAWG,CAAA,CAEf,CAAC,CACH,CCtfO,SAASC,GACdJ,EACAxB,EACA6B,EACkB,CAClB,MAAMC,EAA+B,CAAA,EAC/BC,EAAoBF,EAAY,YAAA,EAChC1B,EAAkBH,EAAM,YAAA,EAE9B,OAAQwB,EAAM,UAAA,CACZ,IAAK,QAEHM,EAAW,KAAK,CACd,MAAO,EACP,IAAKD,EAAY,OACjB,KAAM,OAAA,CACP,EACD,MAEF,IAAK,SAEH,MAAMG,EAAY,KAAK,IAAI7B,EAAgB,OAAQ0B,EAAY,MAAM,EACrEC,EAAW,KAAK,CACd,MAAO,EACP,IAAKE,EACL,KAAM,QAAA,CACP,EACD,MAEF,IAAK,YAEH,MAAMC,EAAiBF,EAAkB,QAAQ5B,CAAe,EAC5D8B,IAAmB,IACrBH,EAAW,KAAK,CACd,MAAOG,EACP,IAAKA,EAAiB9B,EAAgB,OACtC,KAAM,WAAA,CACP,EAEH,MAEF,IAAK,QAEH2B,EAAW,KAAK,GAAGI,GAAyB/B,EAAiB4B,EAAmB,OAAO,CAAC,EACxF,MAEF,IAAK,QAEHD,EAAW,KAAK,GAAGK,GAAyBhC,EAAiB4B,CAAiB,CAAC,EAC/E,MAEF,IAAK,WACL,IAAK,UACL,IAAK,WAEHD,EAAW,KAAK,CACd,MAAO,EACP,IAAKD,EAAY,OACjB,KAAML,EAAM,SAAA,CACb,EACD,KAAA,CAGJ,OAAOY,GAA2BN,CAAU,CAC9C,CAKA,SAASI,GACPlC,EACAlK,EACAuM,EACkB,CAClB,MAAMP,EAA+B,CAAA,EACrC,IAAIQ,EAAW,EACXC,EAAU,EAGd,KAAOD,EAAWtC,EAAM,QAAUuC,EAAUzM,EAAK,QAC/C,GAAIkK,EAAMsC,CAAQ,IAAMxM,EAAKyM,CAAO,EAAG,CAErC,MAAMC,EAAQD,EACd,IAAIE,EAAMF,EAAU,EAKpB,IAFAD,IACAC,IACOD,EAAWtC,EAAM,QAAUuC,EAAUzM,EAAK,QAAUkK,EAAMsC,CAAQ,IAAMxM,EAAKyM,CAAO,GACzFE,IACAH,IACAC,IAGFT,EAAW,KAAK,CAAE,MAAAU,EAAO,IAAAC,EAAK,KAAAJ,EAAM,CACtC,MACEE,IAIJ,OAAOT,CACT,CAKA,SAASK,GACPnC,EACAlK,EACkB,CAClB,MAAMgM,EAA+B,CAAA,EAIrC,QAAS,EAAI,EAAG,GAAK9B,EAAM,OAAS,EAAW,IAAK,CAClD,MAAMR,EAAQQ,EAAM,MAAM,EAAG,EAAI,CAAS,EAC1C,IAAI0C,EAAc,EAGlB,OAAa,CACX,MAAMC,EAAQ7M,EAAK,QAAQ0J,EAAOkD,CAAW,EAC7C,GAAIC,IAAU,GAAI,MAElBb,EAAW,KAAK,CACd,MAAOa,EACP,IAAKA,EAAQ,EACb,KAAM,OAAA,CACP,EAEDD,EAAcC,EAAQ,CACxB,CACF,CAEA,OAAOb,CACT,CAKA,SAASM,GAA2BN,EAAgD,CAClF,GAAIA,EAAW,SAAW,EAAG,MAAO,CAAA,EAGpC,MAAMc,EAAS,CAAC,GAAGd,CAAU,EAAE,KAAK,CAACe,EAAGC,IAAMD,EAAE,MAAQC,EAAE,KAAK,EACzDC,EAA2B,CAACH,EAAO,CAAC,CAAC,EAE3C,QAASzM,EAAI,EAAGA,EAAIyM,EAAO,OAAQzM,IAAK,CACtC,MAAMoC,EAAUqK,EAAOzM,CAAC,EAClB6M,EAAOD,EAAOA,EAAO,OAAS,CAAC,EAEjCxK,EAAQ,OAASyK,EAAK,KAExBA,EAAK,IAAM,KAAK,IAAIA,EAAK,IAAKzK,EAAQ,GAAG,EAErC0K,GAAqB1K,EAAQ,IAAI,EAAI0K,GAAqBD,EAAK,IAAI,IACrEA,EAAK,KAAOzK,EAAQ,OAItBwK,EAAO,KAAKxK,CAAO,CAEvB,CAEA,OAAOwK,CACT,CAKA,SAASE,GAAqBZ,EAAyB,CAWrD,MAV8C,CAC5C,MAAO,GACP,OAAQ,EACR,UAAW,EACX,MAAO,EACP,MAAO,EACP,SAAU,EACV,SAAU,EACV,QAAS,CAAA,EAEOA,CAAI,GAAK,CAC7B,CAKO,SAASa,GACdpN,EACAgM,EACAqB,EAAoB,YACZ,CACR,GAAI,CAACrB,GAAcA,EAAW,SAAW,EACvC,OAAOsB,EAAWtN,CAAI,EAGxB,IAAIgE,EAAS,GACTuJ,EAAU,EAEd,UAAWC,KAAaxB,EAAY,CAE9BwB,EAAU,MAAQD,IACpBvJ,GAAUsJ,EAAWtN,EAAK,MAAMuN,EAASC,EAAU,KAAK,CAAC,GAI3D,MAAMC,EAAkBzN,EAAK,MAAMwN,EAAU,MAAOA,EAAU,GAAG,EACjExJ,GAAU,gBAAgBqJ,CAAS,IAAIA,CAAS,KAAKG,EAAU,IAAI,KAAKF,EAAWG,CAAe,CAAC,UAEnGF,EAAUC,EAAU,GACtB,CAGA,OAAID,EAAUvN,EAAK,SACjBgE,GAAUsJ,EAAWtN,EAAK,MAAMuN,CAAO,CAAC,GAGnCvJ,CACT,CAKA,SAASsJ,EAAWtN,EAAsB,CACxC,MAAM0N,EAAM,OAAO,SAAa,IAAc,SAAS,cAAc,KAAK,EAAI,KAC9E,OAAIA,GACFA,EAAI,YAAc1N,EACX0N,EAAI,WAGN1N,EACJ,QAAQ,KAAM,OAAO,EACrB,QAAQ,KAAM,MAAM,EACpB,QAAQ,KAAM,MAAM,EACpB,QAAQ,KAAM,QAAQ,EACtB,QAAQ,KAAM,QAAQ,CAC3B,CC1OO,MAAM2N,EAAe,CAClB,MACA,SAER,YAAYC,EAAmB,IAAK,CAClC,KAAK,UAAY,IACjB,KAAK,SAAWA,CAClB,CAMA,IAAIC,EAAuB,CACzB,GAAI,CAAC,KAAK,MAAM,IAAIA,CAAG,EACrB,OAIF,MAAMC,EAAQ,KAAK,MAAM,IAAID,CAAG,EAChC,YAAK,MAAM,OAAOA,CAAG,EACrB,KAAK,MAAM,IAAIA,EAAKC,CAAK,EAElBA,CACT,CAMA,IAAID,EAAQC,EAAgB,CAU1B,GARI,KAAK,MAAM,IAAID,CAAG,GACpB,KAAK,MAAM,OAAOA,CAAG,EAIvB,KAAK,MAAM,IAAIA,EAAKC,CAAK,EAGrB,KAAK,MAAM,KAAO,KAAK,SAAU,CACnC,MAAMC,EAAW,KAAK,MAAM,KAAA,EAAO,OAAO,MACtCA,IAAa,QACf,KAAK,MAAM,OAAOA,CAAQ,CAE9B,CACF,CAKA,IAAIF,EAAiB,CACnB,OAAO,KAAK,MAAM,IAAIA,CAAG,CAC3B,CAKA,OAAc,CACZ,KAAK,MAAM,MAAA,CACb,CAKA,IAAI,MAAe,CACjB,OAAO,KAAK,MAAM,IACpB,CAKA,UAAoE,CAClE,MAAO,CACL,KAAM,KAAK,MAAM,KACjB,SAAU,KAAK,SACf,YAAa,KAAK,MAAM,KAAO,KAAK,QAAA,CAExC,CACF,CAMO,MAAMG,CAAY,CACf,MACA,KAAe,EACf,OAAiB,EAEzB,YAAYJ,EAAmB,IAAK,CAClC,KAAK,MAAQ,IAAID,GAASC,CAAQ,CACpC,CAKQ,YAAY1D,EAAe+D,EAAqBC,EAAuB,CAC7E,MAAMC,EAAaD,EAAU,KAAK,UAAUA,CAAO,EAAI,GACvD,MAAO,GAAGhE,CAAK,IAAI+D,GAAc,SAAS,IAAIE,CAAU,EAC1D,CAKA,IAAIjE,EAAe+D,EAAqBC,EAA+C,CACrF,MAAML,EAAM,KAAK,YAAY3D,EAAO+D,EAAYC,CAAO,EACjDlK,EAAS,KAAK,MAAM,IAAI6J,CAAG,EAEjC,OAAI7J,EACF,KAAK,OAEL,KAAK,SAGAA,CACT,CAKA,IAAIkG,EAAe7E,EAA6B4I,EAAqBC,EAAqB,CACxF,MAAML,EAAM,KAAK,YAAY3D,EAAO+D,EAAYC,CAAO,EACvD,KAAK,MAAM,IAAIL,EAAKxI,CAAO,CAC7B,CAKA,OAAc,CACZ,KAAK,MAAM,MAAA,EACX,KAAK,KAAO,EACZ,KAAK,OAAS,CAChB,CAKA,UAME,CACA,MAAM+I,EAAa,KAAK,MAAM,SAAA,EACxBC,EAAQ,KAAK,KAAO,KAAK,OACzBC,EAAUD,EAAQ,EAAI,KAAK,KAAOA,EAAQ,EAEhD,MAAO,CACL,GAAGD,EACH,KAAM,KAAK,KACX,OAAQ,KAAK,OACb,QAAAE,CAAA,CAEJ,CACF,CC9JA,MAAMC,GAAqC,CAEzC,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IACrF,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAErF,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAC/F,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAE/F,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,KAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,KACH,EAAG,KACH,EAAG,KACH,EAAG,KAEH,EAAG,KACH,EAAG,IACL,EAMO,SAASC,EAAcxO,EAAsB,CAClD,GAAI,CAACA,EAAM,OAAOA,EAGlB,IAAIgE,EAAS,GACb,QAAS3D,EAAI,EAAGA,EAAIL,EAAK,OAAQK,IAAK,CACpC,MAAMC,EAAON,EAAKK,CAAC,EACnB2D,GAAUuK,GAAWjO,CAAI,GAAKA,CAChC,CAKA,OAAA0D,EAASA,EAAO,UAAU,KAAK,EAAE,QAAQ,mBAAoB,EAAE,EAExDA,CACT,CAKO,SAASyK,GAAWzO,EAAuB,CAChD,GAAI,CAACA,EAAM,MAAO,GAGlB,QAASK,EAAI,EAAGA,EAAIL,EAAK,OAAQK,IAC/B,GAAIkO,GAAWvO,EAAKK,CAAC,CAAC,EACpB,MAAO,GAKX,MAAMH,EAAaF,EAAK,UAAU,KAAK,EACvC,MAAO,kBAAkB,KAAKE,CAAU,CAC1C,CAMO,SAASwO,GAAuB1O,EAAsB,CAC3D,OAAOwO,EAAcxO,EAAK,aAAa,CACzC,CAMO,SAAS2O,GAAkB1O,EAAwB,CACxD,MAAMC,EAAasO,EAAcvO,CAAI,EAGrC,OAAIC,IAAeD,EACV,CAACA,EAAMC,CAAU,EAInB,CAACD,CAAI,CACd,CCzOO,SAAS2O,GACd7G,EACA8G,EAC+B,CAO/B,GALI,CAACA,GAAUA,EAAO,SAAW,GAK7B,OAAO9G,GAAS,SAClB,OAAO,KAIT,GAAI,OAAOA,GAAS,UAAYA,IAAS,KAAM,CAC7C,MAAM+G,EAAsC,CAAA,EAE5C,UAAWC,KAASF,EAAQ,CAC1B,MAAMf,EAAQ/F,EAAKgH,CAAK,EACGjB,GAAU,OACnCgB,EAAYC,CAAK,EAAI,OAAOjB,CAAK,EAErC,CAEA,OAAO,OAAO,KAAKgB,CAAW,EAAE,OAAS,EAAIA,EAAc,IAC7D,CAEA,OAAO,IACT,CAYO,SAASE,GACdH,EACAI,EACwB,CACxB,MAAM/O,EAAqC,CAAA,EAE3C,UAAW6O,KAASF,EAClB3O,EAAW6O,CAAK,EAAIE,IAAeF,CAAK,GAAK,EAG/C,OAAO7O,CACT,CCpDO,MAAMgP,GAA+C,CAC1D,QAAS,CAEP,IACA,KACA,MACA,MACA,KACA,KACA,KACA,KACA,MACA,OACA,MACA,KACA,KACA,KACA,KACA,MACA,KACA,KACA,OACA,MACA,KACA,MACA,OACA,OACA,MACA,OACA,MACA,OACA,OACA,MACA,OACA,OACA,QACA,MACA,QACA,MACA,KAAA,EAEF,OAAQ,CAEN,MACA,MACA,MACA,MACA,MACA,MACA,MACA,OACA,QACA,QACA,QACA,QACA,MACA,OACA,OACA,MACA,OACA,MACA,QACA,MACA,QACA,OACA,SACA,MACA,KACA,KACA,KACA,KACA,MACA,MACA,MACA,OACA,MACA,KAAA,EAEF,QAAS,CAEP,KACA,KACA,MACA,MACA,KACA,MACA,OACA,OACA,KACA,MACA,IACA,IACA,OACA,KACA,MACA,MACA,SACA,KACA,MACA,KACA,IACA,KACA,MACA,MACA,OACA,MACA,QACA,OAAA,EAEF,OAAQ,CAEN,KACA,KACA,MACA,KACA,MACA,MACA,KACA,KACA,KACA,KACA,OACA,MACA,OACA,QACA,UACA,IACA,MACA,IACA,KACA,MACA,OACA,OACA,MACA,OACA,MACA,OACA,OAAA,CAEJ,EAKO,SAASC,GACdjF,EACAkF,EACQ,CACR,MAAMC,EAAeD,aAAqB,IAAMA,EAAY,IAAI,IAAIA,EAAU,IAAIE,GAAKA,EAAE,YAAA,CAAa,CAAC,EAIjGC,EADQrF,EAAM,MAAM,KAAK,EACR,OAAOjK,GAAQ,CAACoP,EAAa,IAAIpP,EAAK,YAAA,CAAa,CAAC,EAG3E,OAAIsP,EAAS,SAAW,EACfrF,EAGFqF,EAAS,KAAK,GAAG,CAC1B,CAKO,SAASC,GAAyBtM,EAAkC,CACzE,MAAMkM,MAAgB,IAEtB,UAAWzP,KAAQuD,EAAW,CAC5B,MAAMuM,EAAgBP,GAAmBvP,EAAK,YAAA,CAAa,EACvD8P,GACFA,EAAc,QAASxP,GAASmP,EAAU,IAAInP,CAAI,CAAC,CAEvD,CAEA,OAAOmP,CACT,CAKO,SAASM,GAAWzP,EAAcmP,EAA4C,CAEnF,OADqBA,aAAqB,IAAMA,EAAY,IAAI,IAAIA,EAAU,IAAKE,GAAMA,EAAE,YAAA,CAAa,CAAC,GACrF,IAAIrP,EAAK,YAAA,CAAa,CAC5C,CCpLO,SAAS0P,GAAe3P,EAAc4P,EAA2B,CAEtE,GAAIA,IAAa,EACf,MAAO,GAIT,MAAMC,EAAa7P,EAAK4P,EAAW,CAAC,EAGpC,MAAO,6BAA6B,KAAKC,CAAU,CACrD,CAKO,SAASC,GACd9P,EACA+P,EACAC,EACS,CACT,MAAMC,EAAWF,EAAaC,EAGxBE,EAAgBP,GAAe3P,EAAM+P,CAAU,EAG/CI,EAAcF,GAAYjQ,EAAK,QAAU,6BAA6B,KAAKA,EAAKiQ,CAAQ,CAAC,EAE/F,OAAOC,GAAiBC,CAC1B,CAKO,SAASC,GACdpQ,EACAqQ,EACAC,EAAyB,GACf,CACV,MAAMC,EAAsB,CAAA,EACtBC,EAAaF,EAAgBtQ,EAAOA,EAAK,YAAA,EACzCyQ,EAAgBH,EAAgBD,EAAUA,EAAQ,YAAA,EAExD,IAAIxD,EAAQ,EACZ,KAAOA,EAAQ2D,EAAW,QAAQ,CAChC,MAAME,EAAQF,EAAW,QAAQC,EAAe5D,CAAK,EAErD,GAAI6D,IAAU,GACZ,MAIEZ,GAAsB9P,EAAM0Q,EAAOD,EAAc,MAAM,GACzDF,EAAU,KAAKG,CAAK,EAGtB7D,EAAQ6D,EAAQ,CAClB,CAEA,OAAOH,CACT,CAKO,SAASI,EAAY1Q,EAAciK,EAAe0G,EAAkC,CACzF,OAAKA,EAMaR,GAAwBnQ,EAAMiK,EAAO,EAAK,EAC3C,OAAS,EALjBjK,EAAK,YAAA,EAAc,SAASiK,EAAM,aAAa,CAM1D,CAoBO,SAAS2G,GAAcR,EAAyB,CAKrD,MAAMS,EAHUT,EAAQ,QAAQ,qBAAsB,MAAM,EAG/B,QAAQ,MAAO,IAAI,EAGhD,OAAO,IAAI,OAAO,IAAIS,CAAY,IAAK,GAAG,CAC5C,CAKO,SAASC,GAAgB9Q,EAAcoQ,EAA0B,CAEtE,OADcQ,GAAcR,CAAO,EACtB,KAAKpQ,CAAI,CACxB,CCjGO,SAAS+Q,GAAW9G,EAA4B,CACrD,GAAI,CAACA,GAAS,OAAOA,GAAU,SAC7B,MAAO,CACL,QAAS,CAAA,EACT,MAAO,CAAA,EACP,SAAUA,GAAS,GACnB,WAAY,EAAA,EAIhB,MAAM+G,EAAoB,CAAA,EAC1B,IAAIC,EAAYhH,EAGhB,MAAMiH,EAAmB,aACzB,IAAIzF,EAEJ,MAAQA,EAAQyF,EAAiB,KAAKjH,CAAK,KAAO,MAAM,CACtD,MAAMkH,EAAS1F,EAAM,CAAC,EAAE,KAAA,EACpB0F,GAEgBA,EAAO,MAAM,KAAK,EAAE,QACrB,IACfH,EAAQ,KAAKG,CAAM,CAGzB,CAGAF,EAAYA,EAAU,QAAQ,WAAY,GAAG,EAG7C,MAAMG,EAAmB,aAEzB,MAAQ3F,EAAQ2F,EAAiB,KAAKnH,CAAK,KAAO,MAAM,CACtD,MAAMkH,EAAS1F,EAAM,CAAC,EAAE,KAAA,EACpB0F,GAEgBA,EAAO,MAAM,KAAK,EAAE,QACrB,IACfH,EAAQ,KAAKG,CAAM,CAGzB,CAGAF,EAAYA,EAAU,QAAQ,WAAY,GAAG,EAG7C,MAAMI,EAAQJ,EACX,MAAM,KAAK,EACX,IAAIK,GAAKA,EAAE,KAAA,CAAM,EACjB,OAAOA,GAAKA,EAAE,OAAS,CAAC,EAE3B,MAAO,CACL,QAAAN,EACA,MAAAK,EACA,SAAUpH,EACV,WAAY+G,EAAQ,OAAS,CAAA,CAEjC,CCrDA,MAAMO,GAAgD,CACpD,WAAY,GACZ,gBAAiB,EACjB,eAAgB,IAChB,qBAAsB,EACtB,kBAAmB,EACrB,EAKO,SAASC,GACdzR,EACAoR,EACAlD,EAA8B,CAAA,EACX,CACnB,MAAMwD,EAAO,CAAE,GAAGF,GAAiB,GAAGtD,CAAA,EAEtC,GAAI,CAAClO,GAAQ,CAACoR,EACZ,MAAO,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,EAGhD,MAAMO,EAAiB3R,EAAK,YAAA,EACtB4R,EAAmBR,EAAO,YAAA,EAG1BS,EAAaC,GAAgBH,EAAgBC,CAAgB,EACnE,GAAIC,EAAW,QACb,MAAO,CAAE,GAAGA,EAAY,MAAO,EAAK,UAAW,OAAA,EAIjD,GAAIH,EAAK,WACP,MAAO,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,EAIhD,MAAMK,EAAaC,GACjBL,EACAC,EACAF,EAAK,gBACLA,EAAK,iBAAA,EAEP,GAAIK,EAAW,QACb,MAAO,CAAE,GAAGA,EAAY,UAAW,OAAA,EAIrC,MAAME,EAAiBC,GACrBP,EACAC,EACAF,EAAK,oBAAA,EAEP,OAAIO,EAAe,QACV,CAAE,GAAGA,EAAgB,UAAW,WAAA,EAGlC,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,CAChD,CAKA,SAASH,GAAgB9R,EAAcoR,EAAmC,CACxE,MAAMvE,EAAQ7M,EAAK,QAAQoR,CAAM,EAEjC,OAAIvE,IAAU,GACL,CACL,QAAS,GACT,MAAO,EACP,UAAW,QACX,SAAUA,EACV,OAAQA,EAAQuE,EAAO,MAAA,EAIpB,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,CAChD,CAKA,SAASY,GACPhS,EACAoR,EACAe,EACAhH,EACmB,CACnB,MAAMiH,EAAchB,EAAO,MAAM,KAAK,EAChCiB,EAAYrS,EAAK,MAAM,KAAK,EAGlC,QAASK,EAAI,EAAGA,GAAKgS,EAAU,OAASD,EAAY,OAAQ/R,IAAK,CAC/D,MAAMiS,EAAUD,EAAU,MAAMhS,EAAGA,EAAI+R,EAAY,MAAM,EAGzD,IAAIG,EAAgB,EAChBC,EAAW,GAEf,QAASlR,EAAI,EAAGA,EAAI8Q,EAAY,OAAQ9Q,IAAK,CAC3C,MAAMsD,EAAWuG,EACb1H,EAAoC2O,EAAY9Q,CAAC,EAAGgR,EAAQhR,CAAC,EAAG6Q,CAAe,EAC/E/O,EAA6BgP,EAAY9Q,CAAC,EAAGgR,EAAQhR,CAAC,EAAG6Q,CAAe,EAE5E,GAAIvN,EAAWuN,EAAiB,CAC9BK,EAAW,GACX,KACF,CACAD,GAAiB3N,CACnB,CAEA,GAAI4N,EAAU,CAEZ,MAAMC,EAAsBL,EAAY,OAASD,EAKjD,MAAO,CACL,QAAS,GACT,MANYM,EAAsB,EAChC,GAAO,IAAO,EAAIF,EAAgBE,GAClC,GAKF,UAAW,QACX,aAAcH,CAAA,CAElB,CACF,CAEA,MAAO,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,CAChD,CAKA,SAASJ,GACPlS,EACAoR,EACA/N,EACmB,CACnB,MAAM+O,EAAchB,EAAO,MAAM,KAAK,EAChCiB,EAAYrS,EAAK,MAAM,KAAK,EAG5BuQ,EAAwB6B,EAAY,IAAI,IAAM,CAAA,CAAE,EAWtD,GATAC,EAAU,QAAQ,CAACpS,EAAM4M,IAAU,CACjCuF,EAAY,QAAQ,CAACM,EAAYC,IAAgB,EAC3C1S,IAASyS,GAAczS,EAAK,SAASyS,CAAU,GAAKA,EAAW,SAASzS,CAAI,IAC9EsQ,EAAUoC,CAAW,EAAE,KAAK9F,CAAK,CAErC,CAAC,CACH,CAAC,EAGG0D,EAAU,KAAKzI,GAAKA,EAAE,SAAW,CAAC,EACpC,MAAO,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,EAIhD,IAAI8K,EAAe,IACfC,EAA0B,CAAA,EAE9B,SAASC,EAAoBC,EAAmBC,EAAkC,CAChF,GAAID,IAAcX,EAAY,OAAQ,CAEpC,MAAMtF,EAAS,CAAC,GAAGkG,CAAgB,EAAE,KAAK,CAACjG,EAAGC,IAAMD,EAAIC,CAAC,EACnDpI,EAAWkI,EAAOA,EAAO,OAAS,CAAC,EAAIA,EAAO,CAAC,EAEjDlI,EAAWgO,IACbA,EAAehO,EACfiO,EAAgB,CAAC,GAAGG,CAAgB,GAEtC,MACF,CAEA,UAAWC,KAAO1C,EAAUwC,CAAS,EACnCD,EAAoBC,EAAY,EAAG,CAAC,GAAGC,EAAkBC,CAAG,CAAC,CAEjE,CAKA,OAHAH,EAAoB,EAAG,EAAE,EAGrBF,GAAgBvP,EAIX,CACL,QAAS,GACT,MAJY,GAAO,IAAO,EAAIuP,EAAevP,GAK7C,UAAW,YACX,aAAcwP,EAAc,IAAIxS,GAAKgS,EAAUhS,CAAC,CAAC,CAAA,EAI9C,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,CAChD,CC5MO,SAAS6S,GAAgBlT,EAAwB,CACtD,GAAI,CAACA,GAAQA,EAAK,KAAA,EAAO,SAAW,EAClC,MAAO,CAAC,SAAS,EAGnB,MAAMmT,MAAe,IAGrB,OAAAA,EAAS,IAAI,SAAS,EAGlB,YAAY,KAAKnT,CAAI,GACvBmT,EAAS,IAAI,QAAQ,EAInB,uCAAuC,KAAKnT,CAAI,GAClDmT,EAAS,IAAI,QAAQ,EAInB,qBAAqB,KAAKnT,CAAI,GAChCmT,EAAS,IAAI,SAAS,EAGjB,MAAM,KAAKA,CAAQ,CAC5B,CAkEO,SAASC,GAAuBrK,EAAyBsK,EAAqB,IAAa,CAGhG,OAFetK,EAAM,MAAM,EAAG,KAAK,IAAIsK,EAAYtK,EAAM,MAAM,CAAC,EAG7D,IAAIhB,GACC,OAAOA,GAAS,SACXA,EACE,OAAOA,GAAS,UAAYA,IAAS,KAEvC,OAAO,OAAOA,CAAI,EACtB,OAAOuL,GAAK,OAAOA,GAAM,QAAQ,EACjC,KAAK,GAAG,EAEN,EACR,EACA,KAAK,GAAG,CACb,CChIO,MAAMC,EAAY,CACvB,KAAM,OACN,OAAQ,SACR,IAAK,MACL,GAAI,KACJ,IAAK,MACL,OAAQ,SACR,OAAQ,SACR,MAAO,QACP,MAAO,QACP,MAAO,QACP,SAAU,WACV,OAAQ,SACR,MAAO,QACP,SAAU,WACV,KAAM,OACN,MAAO,QACP,SAAU,WACV,OAAQ,SACR,IAAK,KACP,EAUO,MAAMC,EAAS,CACZ,MAAgB,GAChB,SAAmB,EACnB,OAAkB,CAAA,EAK1B,SAASC,EAAwB,CAK/B,IAJA,KAAK,MAAQA,EAAM,KAAA,EACnB,KAAK,SAAW,EAChB,KAAK,OAAS,CAAA,EAEP,KAAK,SAAW,KAAK,MAAM,SAChC,KAAK,eAAA,EAED,OAAK,UAAY,KAAK,MAAM,UAHQ,CAKxC,MAAMnT,EAAO,KAAK,MAAM,KAAK,QAAQ,EAGrC,GAAIA,IAAS,IAAK,CAChB,KAAK,OAAO,KAAK,CAAE,KAAMiT,EAAU,OAAQ,MAAO,IAAK,SAAU,KAAK,QAAA,CAAU,EAChF,KAAK,WACL,QACF,CAEA,GAAIjT,IAAS,IAAK,CAChB,KAAK,OAAO,KAAK,CAAE,KAAMiT,EAAU,OAAQ,MAAO,IAAK,SAAU,KAAK,QAAA,CAAU,EAChF,KAAK,WACL,QACF,CAGA,GAAIjT,IAAS,IAAK,CAChB,KAAK,OAAO,KAAK,CAAE,KAAMiT,EAAU,MAAO,MAAO,IAAK,SAAU,KAAK,QAAA,CAAU,EAC/E,KAAK,WACL,QACF,CAGA,GAAIjT,IAAS,KAAOA,IAAS,IAAK,CAChC,KAAK,qBAAqBA,CAAI,EAC9B,QACF,CAGA,GAAI,KAAK,QAAQA,CAAI,EAAG,CACtB,KAAK,eAAA,EACL,QACF,CAGA,GAAI,KAAK,QAAQA,CAAI,EAAG,CACtB,KAAK,sBAAA,EACL,QACF,CAGA,GAAIA,IAAS,KAAOA,IAAS,IAAK,CAChC,KAAK,sBAAA,EACL,QACF,CAGA,KAAK,UACP,CAGA,YAAK,OAAO,KAAK,CAAE,KAAMiT,EAAU,IAAK,MAAO,GAAI,SAAU,KAAK,QAAA,CAAU,EAErE,KAAK,MACd,CAEQ,gBAAuB,CAC7B,KAAO,KAAK,SAAW,KAAK,MAAM,QAAU,KAAK,KAAK,KAAK,MAAM,KAAK,QAAQ,CAAC,GAC7E,KAAK,UAET,CAEQ,QAAQjT,EAAuB,CACrC,MAAO,mEAAmE,KAAKA,CAAI,CACrF,CAEQ,QAAQA,EAAuB,CACrC,MAAO,SAAS,KAAKA,CAAI,CAC3B,CAEQ,eAAeA,EAAuB,CAC5C,OAAO,KAAK,QAAQA,CAAI,GAAK,KAAK,QAAQA,CAAI,CAChD,CAEQ,qBAAqBoT,EAAqB,CAChD,MAAMhH,EAAQ,KAAK,SACnB,KAAK,WAEL,IAAIoB,EAAQ,GACZ,KAAO,KAAK,SAAW,KAAK,MAAM,QAAU,KAAK,MAAM,KAAK,QAAQ,IAAM4F,GACxE5F,GAAS,KAAK,MAAM,KAAK,QAAQ,EACjC,KAAK,WAGP,GAAI,KAAK,UAAY,KAAK,MAAM,OAC9B,MAAM,IAAI,MAAM,8BAA8BpB,CAAK,EAAE,EAGvD,KAAK,WAEL,KAAK,OAAO,KAAK,CAAE,KAAM6G,EAAU,OAAQ,MAAAzF,EAAO,SAAUpB,EAAO,CACrE,CAEQ,gBAAuB,CAC7B,MAAMA,EAAQ,KAAK,SACnB,IAAIoB,EAAQ,GAEZ,KAAO,KAAK,SAAW,KAAK,MAAM,QAAU,KAAK,QAAQ,KAAK,MAAM,KAAK,QAAQ,CAAC,GAChFA,GAAS,KAAK,MAAM,KAAK,QAAQ,EACjC,KAAK,WAGP,KAAK,OAAO,KAAK,CAAE,KAAMyF,EAAU,OAAQ,MAAAzF,EAAO,SAAUpB,EAAO,CACrE,CAEQ,uBAA8B,CACpC,MAAMA,EAAQ,KAAK,SACnB,IAAIoB,EAAQ,GAEZ,KAAO,KAAK,SAAW,KAAK,MAAM,QAAU,KAAK,eAAe,KAAK,MAAM,KAAK,QAAQ,CAAC,GACvFA,GAAS,KAAK,MAAM,KAAK,QAAQ,EACjC,KAAK,WAGP,MAAM6F,EAAa7F,EAAM,YAAA,EAGzB,OAAQ6F,EAAA,CACN,IAAK,MACH,KAAK,OAAO,KAAK,CAAE,KAAMJ,EAAU,IAAK,MAAOI,EAAY,SAAUjH,CAAA,CAAO,EAC5E,MACF,IAAK,KACH,KAAK,OAAO,KAAK,CAAE,KAAM6G,EAAU,GAAI,MAAOI,EAAY,SAAUjH,CAAA,CAAO,EAC3E,MACF,IAAK,MACH,KAAK,OAAO,KAAK,CAAE,KAAM6G,EAAU,IAAK,MAAOI,EAAY,SAAUjH,CAAA,CAAO,EAC5E,MACF,IAAK,QACH,KAAK,OAAO,KAAK,CAAE,KAAM6G,EAAU,MAAO,MAAOI,EAAY,SAAUjH,CAAA,CAAO,EAC9E,MACF,IAAK,QACH,KAAK,OAAO,KAAK,CAAE,KAAM6G,EAAU,MAAO,MAAOI,EAAY,SAAUjH,CAAA,CAAO,EAC9E,MACF,IAAK,WACH,KAAK,OAAO,KAAK,CAAE,KAAM6G,EAAU,SAAU,MAAOI,EAAY,SAAUjH,CAAA,CAAO,EACjF,MACF,IAAK,SACH,KAAK,OAAO,KAAK,CAAE,KAAM6G,EAAU,OAAQ,MAAOI,EAAY,SAAUjH,CAAA,CAAO,EAC/E,MACF,IAAK,QACH,KAAK,OAAO,KAAK,CAAE,KAAM6G,EAAU,MAAO,MAAOI,EAAY,SAAUjH,CAAA,CAAO,EAC9E,MACF,IAAK,WACH,KAAK,OAAO,KAAK,CAAE,KAAM6G,EAAU,SAAU,MAAOI,EAAY,SAAUjH,CAAA,CAAO,EACjF,MACF,IAAK,OACH,KAAK,OAAO,KAAK,CAAE,KAAM6G,EAAU,KAAM,MAAOI,EAAY,SAAUjH,CAAA,CAAO,EAC7E,MACF,IAAK,QACH,KAAK,OAAO,KAAK,CAAE,KAAM6G,EAAU,MAAO,MAAOI,EAAY,SAAUjH,CAAA,CAAO,EAC9E,MACF,QAEE,KAAK,OAAO,KAAK,CAAE,KAAM6G,EAAU,KAAM,MAAAzF,EAAO,SAAUpB,EAAO,EACjE,KAAA,CAEN,CAEQ,uBAA8B,CACpC,MAAMA,EAAQ,KAAK,SACnB,IAAIoB,EAAQ,KAAK,MAAM,KAAK,QAAQ,EACpC,KAAK,WAGD,KAAK,SAAW,KAAK,MAAM,QAAU,KAAK,MAAM,KAAK,QAAQ,IAAM,MACrEA,GAAS,IACT,KAAK,YAGP,KAAK,OAAO,KAAK,CAAE,KAAMyF,EAAU,SAAU,MAAAzF,EAAO,SAAUpB,EAAO,CACvE,CACF,CCvNO,MAAMkH,UAAuB,KAAM,CACjC,SAEP,YAAYC,EAAiBjE,EAAkB,CAC7C,MAAMiE,CAAO,EACb,KAAK,KAAO,iBACZ,KAAK,SAAWjE,CAClB,CACF,CAEO,MAAMkE,EAAU,CACb,OAAkB,CAAA,EAClB,QAAkB,EAK1B,MAAMC,EAA0B,CAI9B,GAHA,KAAK,OAASA,EACd,KAAK,QAAU,EAEX,KAAK,OAAO,SAAW,GAAK,KAAK,OAAO,CAAC,EAAE,OAASR,EAAU,IAChE,MAAM,IAAIK,EAAe,cAAe,CAAC,EAG3C,MAAMI,EAAM,KAAK,gBAAA,EAGjB,GAAI,CAAC,KAAK,UACR,MAAM,IAAIJ,EAAe,qBAAqB,KAAK,KAAA,EAAO,KAAK,iBAAiB,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAG9H,OAAOI,CACT,CAKQ,iBAA2B,CACjC,OAAO,KAAK,kBAAA,CACd,CAKQ,mBAA6B,CACnC,IAAIC,EAAO,KAAK,mBAAA,EAEhB,KAAO,KAAK,MAAMV,EAAU,EAAE,GAAG,CAC/B,MAAMW,EAAQ,KAAK,mBAAA,EACnBD,EAAO,CACL,KAAM,KACN,KAAAA,EACA,MAAAC,CAAA,CAEJ,CAEA,OAAOD,CACT,CAKQ,oBAA8B,CACpC,IAAIA,EAAO,KAAK,mBAAA,EAEhB,KAAO,KAAK,MAAMV,EAAU,GAAG,GAAG,CAChC,MAAMW,EAAQ,KAAK,mBAAA,EACnBD,EAAO,CACL,KAAM,MACN,KAAAA,EACA,MAAAC,CAAA,CAEJ,CAEA,OAAOD,CACT,CAKQ,oBAA8B,CACpC,OAAI,KAAK,MAAMV,EAAU,GAAG,EAEnB,CACL,KAAM,MACN,MAHY,KAAK,aAAA,CAGjB,EAIG,KAAK,aAAA,CACd,CAKQ,cAAwB,CAE9B,GAAI,KAAK,MAAMA,EAAU,MAAM,EAAG,CAChC,MAAMY,EAAO,KAAK,gBAAA,EAClB,GAAI,CAAC,KAAK,MAAMZ,EAAU,MAAM,EAC9B,MAAM,IAAIK,EAAe,4BAA4B,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAEnG,OAAOO,CACT,CAGA,GAAI,KAAK,MAAMZ,EAAU,KAAK,GAAK,KAAK,MAAMA,EAAU,KAAK,GAAK,KAAK,MAAMA,EAAU,QAAQ,GAAK,KAAK,MAAMA,EAAU,MAAM,GAAK,KAAK,MAAMA,EAAU,KAAK,GAAK,KAAK,MAAMA,EAAU,QAAQ,EAC9L,OAAO,KAAK,YAAA,EAId,GAAI,KAAK,MAAMA,EAAU,IAAI,EAC3B,OAAO,KAAK,UAAA,EAId,GAAI,KAAK,MAAMA,EAAU,MAAM,EAAG,CAEhC,MAAMnC,EAAqB,CACzB,KAAM,SACN,MAHY,KAAK,QAAA,EAGJ,KAAA,EAIf,OAAI,KAAK,MAAMmC,EAAU,KAAK,EACrB,KAAK,WAAWnC,CAAM,EAGxBA,CACT,CAGA,GAAI,KAAK,MAAMmC,EAAU,IAAI,EAAG,CAC9B,MAAMa,EAAQ,KAAK,QAAA,EAGnB,GAAI,KAAK,MAAMb,EAAU,KAAK,EAAG,CAC/B,MAAMjO,EAAQ,KAAK,aAAA,EAMnB,MALyB,CACvB,KAAM,QACN,MAAO8O,EAAM,MACb,MAAA9O,CAAA,CAGJ,CAGA,MAAML,EAAiB,CACrB,KAAM,OACN,MAAOmP,EAAM,KAAA,EAIf,OAAI,KAAK,MAAMb,EAAU,KAAK,EACrB,KAAK,WAAWtO,CAAI,EAGtBA,CACT,CAEA,MAAM,IAAI2O,EAAe,qBAAqB,KAAK,KAAA,EAAO,KAAK,iBAAiB,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,CAC9H,CAKQ,aAAuB,CAC7B,MAAMS,EAAc,KAAK,QAAA,EACnBC,EAAaD,EAAY,MAAM,YAAA,EAErC,GAAI,CAAC,KAAK,MAAMd,EAAU,KAAK,EAC7B,MAAM,IAAIK,EAAe,sBAAsBS,EAAY,KAAK,gBAAgB,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAG9H,IAAIvG,EAEJ,GAAI,KAAK,MAAMyF,EAAU,MAAM,EAC7BzF,EAAQ,KAAK,UAAU,cACd,KAAK,MAAMyF,EAAU,IAAI,EAClCzF,EAAQ,KAAK,UAAU,UAEvB,OAAM,IAAI8F,EAAe,wBAAwBS,EAAY,KAAK,iBAAiB,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAGjI,MAAM3L,EAAqB,CACzB,KAAM,SACN,WAAA4L,EACA,MAAAxG,CAAA,EAIF,OAAI,KAAK,MAAMyF,EAAU,KAAK,EACrB,KAAK,WAAW7K,CAAM,EAGxBA,CACT,CAKQ,WAAsB,CAG5B,GAFA,KAAK,QAAA,EAED,CAAC,KAAK,MAAM6K,EAAU,KAAK,EAC7B,MAAM,IAAIK,EAAe,uCAAuC,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAG9G,GAAI,CAAC,KAAK,MAAML,EAAU,IAAI,EAC5B,MAAM,IAAIK,EAAe,kDAAkD,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAGzH,MAAM3Q,EAAW,KAAK,QAAA,EAAU,MAC1BqC,EAAQ,KAAK,aAAA,EAEnB,MAAO,CACL,KAAM,OACN,SAAArC,EACA,MAAAqC,CAAA,CAEJ,CAKQ,WAAWA,EAA2B,CAG5C,GAFA,KAAK,QAAA,EAED,CAAC,KAAK,MAAMiO,EAAU,QAAQ,EAChC,MAAM,IAAIK,EAAe,sDAAsD,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAG7H,MAAMW,EAAW,KAAK,QAAA,EAAU,MAEhC,GAAI,CAAC,KAAK,MAAMhB,EAAU,MAAM,EAC9B,MAAM,IAAIK,EAAe,yBAAyBW,CAAQ,gBAAgB,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAGxH,MAAMxP,EAAY,WAAW,KAAK,QAAA,EAAU,KAAK,EAEjD,GAAI,MAAMA,CAAS,GAAKA,EAAY,GAAKA,EAAY,EACnD,MAAM,IAAI6O,EAAe,0CAA2C,KAAK,SAAA,EAAW,QAAQ,EAG9F,MAAO,CACL,KAAM,QACN,SAAAW,EACA,UAAAxP,EACA,MAAAO,CAAA,CAEJ,CAIQ,SAASkP,EAA6B,CAC5C,UAAWjI,KAAQiI,EACjB,GAAI,KAAK,MAAMjI,CAAI,EACjB,YAAK,QAAA,EACE,GAGX,MAAO,EACT,CAEQ,MAAMA,EAA0B,CACtC,OAAI,KAAK,QAAA,EAAkB,GACpB,KAAK,OAAO,OAASA,CAC9B,CAEQ,SAAiB,CACvB,OAAK,KAAK,WAAW,KAAK,UACnB,KAAK,SAAA,CACd,CAEQ,SAAmB,CACzB,OAAO,KAAK,KAAA,EAAO,OAASgH,EAAU,GACxC,CAEQ,MAAc,CACpB,OAAO,KAAK,OAAO,KAAK,OAAO,CACjC,CAEQ,UAAkB,CACxB,OAAO,KAAK,OAAO,KAAK,QAAU,CAAC,CACrC,CACF,CC/MO,SAASkB,GAAWtP,EAAiC,CAC1D,OAAOA,EAAK,OAAS,MACvB,CAEO,SAASuP,GAAavP,EAAmC,CAC9D,OAAOA,EAAK,OAAS,QACvB,CAEO,SAASwP,GAAUxP,EAAgC,CACxD,OAAOA,EAAK,OAAS,KACvB,CAEO,SAASyP,GAASzP,EAA+B,CACtD,OAAOA,EAAK,OAAS,IACvB,CAEO,SAAS0P,GAAU1P,EAAgC,CACxD,OAAOA,EAAK,OAAS,KACvB,CAEO,SAAS2P,GAAa3P,EAAmC,CAC9D,OAAOA,EAAK,OAAS,QACvB,CAEO,SAAS4P,GAAY5P,EAAkC,CAC5D,OAAOA,EAAK,OAAS,OACvB,CAEO,SAAS6P,GAAY7P,EAAkC,CAC5D,OAAOA,EAAK,OAAS,OACvB,CAEO,SAAS8P,GAAW9P,EAAiC,CAC1D,OAAOA,EAAK,OAAS,MACvB,CChHO,MAAM+P,WAAwB,KAAM,CACzC,YAAYrB,EAAiB,CAC3B,MAAMA,CAAO,EACb,KAAK,KAAO,iBACd,CACF,CAEO,MAAMsB,EAAY,CACf,MACA,QACA,UAAoB,EACpB,QAAkB,IAE1B,YAAYtI,EAAmBqB,EAAyB,GAAI,CAC1D,KAAK,MAAQrB,EACb,KAAK,QAAUqB,EACf,KAAK,QAAUA,EAAQ,YAAY,SAAW,GAChD,CAKA,QAAQ8F,EAAkC,CACxC,YAAK,UAAY,KAAK,IAAA,EACf,KAAK,YAAYA,CAAG,CAC7B,CAEQ,cAAqB,CAC3B,GAAI,KAAK,IAAA,EAAQ,KAAK,UAAY,KAAK,QACrC,MAAM,IAAIkB,GAAgB,iCAAiC,KAAK,OAAO,IAAI,CAE/E,CAEQ,YAAY/P,EAAmC,CAGrD,OAFA,KAAK,aAAA,EAEDwP,GAAUxP,CAAI,EACT,KAAK,WAAWA,CAAI,EAGzByP,GAASzP,CAAI,EACR,KAAK,UAAUA,CAAI,EAGxB0P,GAAU1P,CAAI,EACT,KAAK,WAAWA,CAAI,EAGzBsP,GAAWtP,CAAI,EACV,KAAK,YAAYA,EAAK,KAAK,EAGhCuP,GAAavP,CAAI,EACZ,KAAK,cAAcA,EAAK,KAAK,EAGlC2P,GAAa3P,CAAI,EACZ,KAAK,cAAcA,CAAI,EAG5B4P,GAAY5P,CAAI,EACX,KAAK,aAAaA,CAAI,EAG3B6P,GAAY7P,CAAI,EACX,KAAK,aAAaA,CAAI,EAG3B8P,GAAW9P,CAAI,EACV,KAAK,YAAYA,CAAI,EAGvB,CAAA,CACT,CAKQ,WAAWA,EAA6D,CAC9E,MAAMiQ,EAAc,KAAK,YAAYjQ,EAAK,IAAI,EACxCkQ,EAAe,KAAK,YAAYlQ,EAAK,KAAK,EAG1CmQ,EAAgB,IAAI,IAAID,EAAa,IAAKE,GAAMA,EAAE,OAAO,CAAC,EAIhE,OAHqBH,EAAY,OAAQG,GAAMD,EAAc,IAAIC,EAAE,OAAO,CAAC,EAGvD,KAAK,CAAC,EAAGvI,IAAMA,EAAE,MAAQ,EAAE,KAAK,CACtD,CAKQ,UAAU7H,EAA6D,CAC7E,MAAMiQ,EAAc,KAAK,YAAYjQ,EAAK,IAAI,EACxCkQ,EAAe,KAAK,YAAYlQ,EAAK,KAAK,EAG1CqQ,MAAgB,IAEtB,UAAWxR,KAAUoR,EACnBI,EAAU,IAAIxR,EAAO,QAASA,CAAM,EAGtC,UAAWA,KAAUqR,EAAc,CACjC,MAAMI,EAAWD,EAAU,IAAIxR,EAAO,OAAO,GAEzC,CAACyR,GAAYzR,EAAO,MAAQyR,EAAS,QACvCD,EAAU,IAAIxR,EAAO,QAASA,CAAM,CAExC,CAGA,OAAO,MAAM,KAAKwR,EAAU,OAAA,CAAQ,EAAE,KAAK,CAACzI,EAAGC,IAAMA,EAAE,MAAQD,EAAE,KAAK,CACxE,CAKQ,WAAW5H,EAA8C,CAC/D,MAAMuQ,EAAe,KAAK,YAAYvQ,EAAK,KAAK,EAC1CwQ,EAAkB,IAAI,IAAID,EAAa,IAAK,GAAM,EAAE,OAAO,CAAC,EAIlE,OADmBE,EAAe,KAAK,MAAO,GAAI,KAAK,MAAM,KAAK,OAAQ,KAAK,OAAO,EACpE,OAAQ,GAAM,CAACD,EAAgB,IAAI,EAAE,OAAO,CAAC,EAAE,KAAK,CAAC5I,EAAGC,IAAMA,EAAE,MAAQD,EAAE,KAAK,CACnG,CAKQ,YAAY9H,EAAkC,CACpD,OAAO2Q,EAAe,KAAK,MAAO3Q,EAAM,KAAK,MAAM,KAAK,OAAQ,KAAK,OAAO,CAC9E,CAKQ,cAAcmM,EAAoC,CAExD,OAAOwE,EAAe,KAAK,MAAO,IAAIxE,CAAM,IAAK,KAAK,MAAM,KAAK,OAAQ,KAAK,OAAO,CACvF,CAKQ,cAAcjM,EAAiE,CACrF,KAAM,CAAE,WAAAmP,EAAY,MAAAxG,CAAA,EAAU3I,EAGxBE,EAAUuQ,EAAe,KAAK,MAAO9H,EAAO,KAAK,MAAM,KAAK,OAAQ,KAAK,OAAO,EAGtF,OAAQwG,EAAA,CACN,IAAK,QACH,OAAOjP,EAAQ,OAAQ,GAAO,EAAU,mBAAqB,OAAO,EAEtE,IAAK,QACH,OAAOA,EAAQ,OAAQ,GAAO,EAAU,mBAAqB,OAAO,EAEtE,IAAK,WACH,OAAOA,EAAQ,OAAQ,GAAO,EAAU,mBAAqB,UAAU,EAEzE,IAAK,SACH,OAAOA,EAAQ,OAAQ,GAAO,EAAU,mBAAqB,QAAQ,EAEvE,IAAK,WACH,OAAOA,EAAQ,OAAQ,GAAO,EAAU,mBAAqB,UAAU,EAEzE,IAAK,QACH,OAAO,KAAK,aAAayI,CAAK,EAEhC,QACE,OAAOzI,CAAA,CAEb,CAKQ,aAAagL,EAAqC,CAExD,GAAI,CAAC,KAAK,QAAQ,YAAY,WAC5B,MAAM,IAAI,MAAM,qDAAqD,EAGvE,GAAI,CACF,MAAMwF,EAAQ,IAAI,OAAOxF,CAAO,EAC1BhL,EAA8B,CAAA,EAEpC,UAAWpF,KAAQ,KAAK,MAAM,KACxB4V,EAAM,KAAK5V,CAAI,GACjBoF,EAAQ,KAAK,CACX,QAASpF,EACT,SAAUA,EACV,MAAO,EACP,UAAW,GACX,SAAU,UACV,iBAAkB,OAAA,CACZ,EAIZ,OAAOoF,CACT,MAAgB,CACd,MAAM,IAAI,MAAM,0BAA0BgL,CAAO,EAAE,CACrD,CACF,CAKQ,aAAalL,EAA6D,CAEhF,MAAMuQ,EAAe,KAAK,YAAYvQ,EAAK,KAAK,EAGhD,OAAK,KAAK,MAAM,UAMTuQ,EAAa,OAAQ1R,GACtBA,EAAO,QAAUmB,EAAK,KAI3B,EATQuQ,CAUX,CAKQ,aAAavQ,EAAmF,CACtG,MAAMuQ,EAAe,KAAK,YAAYvQ,EAAK,KAAK,EAC1C,CAAE,SAAAoP,EAAU,UAAAxP,CAAA,EAAcI,EAEhC,OAAOuQ,EAAa,OAAQ1R,GAAW,CACrC,OAAQuQ,EAAA,CACN,IAAK,IACH,OAAOvQ,EAAO,MAAQe,EACxB,IAAK,IACH,OAAOf,EAAO,MAAQe,EACxB,IAAK,KACH,OAAOf,EAAO,OAASe,EACzB,IAAK,KACH,OAAOf,EAAO,OAASe,EACzB,QACE,MAAO,EAAA,CAEb,CAAC,CACH,CAKQ,YAAYI,EAAgE,CAClF,MAAMuQ,EAAe,KAAK,YAAYvQ,EAAK,KAAK,EAC1C2Q,EAAa3Q,EAAK,SAAS,YAAA,EAEjC,OAAOuQ,EAAa,OAAQ1R,GACnBA,EAAO,UAAU,YAAA,IAAkB8R,CAC3C,CACH,CACF,CCvQO,SAASC,GAAW7L,EAAwB,CACjD,MAAM8L,EAAU9L,EAAM,KAAA,EACtB,OAAO8L,EAAQ,WAAW,MAAM,GAAKA,EAAQ,SAAS,GAAG,CAC3D,CAKO,SAASC,GAAgB/L,EAAuB,CACrD,MAAM8L,EAAU9L,EAAM,KAAA,EACtB,GAAI,CAAC6L,GAAWC,CAAO,EACrB,MAAM,IAAI,MAAM,oDAAoD,EAItE,OAAOA,EAAQ,MAAM,EAAG,EAAE,EAAE,KAAA,CAC9B,CAKO,SAASE,GACdrJ,EACA3C,EACA+D,EACAC,EAAyB,CAAA,EACL,CACpB,GAAI,CAEF,MAAMiI,EAAWF,GAAgB/L,CAAK,EAIhC6J,EADQ,IAAIP,GAAA,EACG,SAAS2C,CAAQ,EAIhCnC,EADS,IAAIF,GAAA,EACA,MAAMC,CAAM,EAIzB1O,EADW,IAAI8P,GAAYtI,EAAOqB,CAAO,EACtB,QAAQ8F,CAAG,EAG9BoC,EAAQnI,GAAcC,EAAQ,YAAc,GAClD,OAAO7I,EAAQ,MAAM,EAAG+Q,CAAK,CAC/B,OAASC,EAAO,CAEd,MAAIA,aAAiBzC,GAAkByC,aAAiBnB,GAChDmB,EAIF,IAAI,MAAM,wBAAyBA,EAAgB,OAAO,EAAE,CACpE,CACF,CChBO,SAASC,GAAgBvN,EAA0B,GAAImF,EAA6B,CAAA,EAAgB,CAEzG,MAAMqI,EAAyBrI,EAAQ,QAAQ,UACzCsI,EAAmB,CAACD,GAA0BA,EAAuB,SAAS,MAAM,EAEpFzW,EAAST,EAAY6O,EAAQ,MAAM,EAEzC,GAAIsI,EAAkB,CACpB,MAAMC,EAAarD,GAAuBrK,EAAO,GAAG,EAC9C2N,EAAoBxD,GAAgBuD,CAAU,EACpD3W,EAAO,UAAY4W,CACrB,CAEA7W,GAAeC,CAAM,EAGrB,MAAMmJ,EAAa,IAAI,IAAInJ,EAAO,QAAQ,EAEpCkJ,EAAqBkF,EAAQ,oBAAsBlL,EAAiB,cAAclD,EAAO,SAAS,EAExG,GAAIkJ,EAAmB,SAAW,EAChC,MAAM,IAAI,MAAM,qCAAqClJ,EAAO,UAAU,KAAK,IAAI,CAAC,EAAE,EAIpF,MAAM6W,EAAYzI,EAAQ,QAAUA,EAAQ,OAAO,OAAS,EACtD0I,EAAgB7N,EAAM,OAAS,GAAK,OAAOA,EAAM,CAAC,GAAM,UAAYA,EAAM,CAAC,IAAM,KAGvF,GAAI6N,GAAiB,CAACD,EACpB,MAAM,IAAI,MAAM,kFAAkF,EAGpG,MAAM9J,EAAoB,CACxB,KAAM,CAAA,EACN,kBAAmB,IACnB,mBAAoB,IACpB,eAAgB,IAChB,eAAgB,IAChB,uBAAwB,IACxB,OAAA/M,CAAA,EAIE6W,IACF9J,EAAM,OAASqB,EAAQ,OACvBrB,EAAM,aAAemC,GAAsBd,EAAQ,OAASA,EAAQ,YAAY,EAChFrB,EAAM,cAAgB,KAIxB7D,EAAmB,QAAS7F,GAAc,CACxC0J,EAAM,mBAAmB,IAAI1J,EAAU,SAAUA,CAAS,CAC5D,CAAC,EAED,MAAM0T,MAAqB,IAC3B,IAAIC,EAAY,EAEhB,UAAW/O,KAAQgB,EACjB,GAAKhB,EAGL,IAAI4O,GAAaC,EAAe,CAC9B,MAAM9H,EAAcF,GAAmB7G,EAAMmG,EAAQ,MAAM,EAC3D,GAAI,CAACY,EAAa,SAGlB,MAAMiI,EAAS,OAAO,OAAOjI,CAAW,EAAE,CAAC,GAAK,QAAQgI,CAAS,GAGjEjK,EAAM,UAAW,IAAIkK,EAAQjI,CAAW,EAGxC,SAAW,CAACkI,EAAWC,CAAU,IAAK,OAAO,QAAQnI,CAAW,EAAG,CACjE,GAAI,CAACmI,GAAcA,EAAW,OAAO,OAASnX,EAAO,eAAgB,SAErE,MAAMoX,EAAeD,EAAW,KAAA,EAG3BJ,EAAe,IAAIE,EAAO,YAAA,CAAa,IAC1CF,EAAe,IAAIE,EAAO,aAAa,EACvClK,EAAM,KAAK,KAAKkK,CAAM,GAIxB,UAAW5T,KAAa6F,EACtBmO,GAAiCD,EAAcH,EAAQC,EAAW7T,EAAW0J,EAAO/M,EAAQmJ,CAAU,CAE1G,CACF,KAAO,CAEL,MAAMhJ,EAAO,OAAO8H,GAAS,SAAWA,EAAO,OAAOA,CAAI,EAC1D,GAAI9H,EAAK,KAAA,EAAO,OAASH,EAAO,eAAgB,SAEhD,MAAMsJ,EAAcnJ,EAAK,KAAA,EACzB,GAAI4W,EAAe,IAAIzN,EAAY,YAAA,CAAa,EAAG,SAEnDyN,EAAe,IAAIzN,EAAY,aAAa,EAC5CyD,EAAM,KAAK,KAAKzD,CAAW,EAG3B,UAAWjG,KAAa6F,EACtBoO,GAAyBhO,EAAajG,EAAW0J,EAAO/M,EAAQmJ,CAAU,CAE9E,CAEA6N,IACI5I,EAAQ,YACVA,EAAQ,WAAW4I,EAAW/N,EAAM,MAAM,EAQ9C,GAF+BmF,EAAQ,kBAAoBpO,EAAO,kBAAoBA,EAAO,SAAWA,EAAO,gBAAkBiJ,EAAM,QAAU,IAErH,CAC1B,KAAM,CAAE,cAAAG,EAAe,UAAAvC,GAAcmC,GAAmBC,EAAOC,EAAoBlJ,EAAQmJ,CAAU,EACrG4D,EAAM,cAAgB3D,EACtB2D,EAAM,UAAYlG,CACpB,CAIA,GADoB7G,EAAO,cAAgB,GAC1B,CACf,MAAMuX,EAAYvX,EAAO,WAAa,IACtC+M,EAAM,OAAS,IAAImB,EAAYqJ,CAAS,CAC1C,CAEA,OAAOxK,CACT,CAKA,SAASuK,GAAyBnX,EAAckD,EAA8B0J,EAAmB/M,EAAqBmJ,EAA+B,CACnJ,MAAM/I,EAAaiD,EAAU,UAAUlD,CAAI,EAG3CqX,EAAgBzK,EAAM,cAAe3M,EAAYD,CAAI,EACrDqX,EAAgBzK,EAAM,cAAe5M,EAAK,YAAA,EAAeA,CAAI,EAE7DqX,EAAgBzK,EAAM,cAAe5M,EAAMA,CAAI,EAG/C,MAAMsX,EAAiB/I,EAAcvO,CAAI,EACzC,GAAIsX,IAAmBtX,EAAM,CAE3BqX,EAAgBzK,EAAM,cAAe0K,EAAgBtX,CAAI,EACzDqX,EAAgBzK,EAAM,cAAe0K,EAAe,YAAA,EAAetX,CAAI,EACvE,MAAMuX,EAAuBrU,EAAU,UAAUoU,CAAc,EAC3DC,IAAyBD,EAAe,eAC1CD,EAAgBzK,EAAM,cAAe2K,EAAsBvX,CAAI,CAEnE,CAWA,GARIgJ,EAAW,IAAI,eAAe,GACf9F,EAAU,gBAAgBlD,CAAI,EACtC,QAASwJ,GAAY,CAC5B6N,EAAgBzK,EAAM,cAAepD,EAASxJ,CAAI,CACpD,CAAC,EAICgJ,EAAW,IAAI,UAAU,GAAK9F,EAAU,kBAAkB,SAAS,UAAU,EAAG,CAClF,MAAMkG,EAAelG,EAAU,gBAAgBlD,CAAI,EAC/CoJ,GACFiO,EAAgBzK,EAAM,eAAgBxD,EAAcpJ,CAAI,CAE5D,CAmBA,GAhBekE,EAAejE,EAAYJ,EAAO,SAAS,EACnD,QAAS4J,GAAkB,CAChC4N,EAAgBzK,EAAM,WAAYnD,EAAOzJ,CAAI,CAC/C,CAAC,EAGGgJ,EAAW,IAAI,UAAU,GAAK9F,EAAU,kBAAkB,SAAS,UAAU,GACzDA,EAAU,mBAAmBlD,CAAI,EACzC,QAASmC,GAAS,CAC1BA,IAASnC,GACXqX,EAAgBzK,EAAM,cAAe1J,EAAU,UAAUf,CAAI,EAAGnC,CAAI,CAExE,CAAC,EAICgJ,EAAW,IAAI,UAAU,IACV9F,EAAU,YAAYjD,CAAU,EACxC,QAAS0J,GAAY,CAC5B0N,EAAgBzK,EAAM,WAAYjD,EAAS3J,CAAI,CACjD,CAAC,EAGGH,EAAO,gBAAgB,CACzB,MAAM+J,EAAiB/J,EAAO,eAAeI,CAAU,EACnD2J,GACFA,EAAe,QAASD,GAAY,CAClC0N,EAAgBzK,EAAM,WAAYjD,EAAS3J,CAAI,CACjD,CAAC,CAEL,CAEJ,CAKA,SAASkX,GAAiCF,EAAoBF,EAAgBC,EAAmB7T,EAA8B0J,EAAmB/M,EAAqBmJ,EAA+B,CACpM,MAAM/I,EAAaiD,EAAU,UAAU8T,CAAU,EAGjDQ,EAAyB5K,EAAM,cAAe3M,EAAY6W,CAAiB,EAC3EU,EAAyB5K,EAAM,cAAeoK,EAAW,YAAA,EAAeF,CAAiB,EACzFU,EAAyB5K,EAAM,cAAeoK,EAAYF,CAAiB,EAG3E,MAAMQ,EAAiB/I,EAAcyI,CAAU,EAC/C,GAAIM,IAAmBN,EAAY,CACjCQ,EAAyB5K,EAAM,cAAe0K,EAAgBR,CAAiB,EAC/EU,EAAyB5K,EAAM,cAAe0K,EAAe,YAAA,EAAeR,CAAiB,EAC7F,MAAMS,EAAuBrU,EAAU,UAAUoU,CAAc,EAC3DC,IAAyBD,EAAe,eAC1CE,EAAyB5K,EAAM,cAAe2K,EAAsBT,CAAiB,CAEzF,CAWA,GARI9N,EAAW,IAAI,eAAe,GACf9F,EAAU,gBAAgB8T,CAAU,EAC5C,QAASxN,GAAY,CAC5BgO,EAAyB5K,EAAM,cAAepD,EAASsN,CAAiB,CAC1E,CAAC,EAIC9N,EAAW,IAAI,UAAU,GAAK9F,EAAU,kBAAkB,SAAS,UAAU,EAAG,CAClF,MAAMkG,EAAelG,EAAU,gBAAgB8T,CAAU,EACrD5N,GACFoO,EAAyB5K,EAAM,eAAgBxD,EAAc0N,CAAiB,CAElF,CAoBA,GAjBe5S,EAAejE,EAAYJ,EAAO,SAAS,EACnD,QAAS4J,GAAkB,CAChC+N,EAAyB5K,EAAM,WAAYnD,EAAOqN,CAAiB,CACrE,CAAC,EAGG9N,EAAW,IAAI,UAAU,GAAK9F,EAAU,kBAAkB,SAAS,UAAU,GACjEA,EAAU,mBAAmB8T,CAAU,EAC/C,QAAS7U,GAAS,CAClBA,EAAK,QAAUtC,EAAO,iBACxB2X,EAAyB5K,EAAM,cAAezK,EAAM2U,CAAiB,EACrEU,EAAyB5K,EAAM,cAAe1J,EAAU,UAAUf,CAAI,EAAG2U,CAAiB,EAE9F,CAAC,EAIC9N,EAAW,IAAI,UAAU,IACV9F,EAAU,YAAYjD,CAAU,EACxC,QAAS0J,GAAY,CAC5B6N,EAAyB5K,EAAM,WAAYjD,EAASmN,CAAiB,CACvE,CAAC,EAGGjX,EAAO,gBAAgB,CACzB,MAAM+J,EAAiB/J,EAAO,eAAeI,CAAU,EACnD2J,GACFA,EAAe,QAASD,GAAY,CAClC6N,EAAyB5K,EAAM,WAAYjD,EAASmN,CAAiB,CACvE,CAAC,CAEL,CAEJ,CAKA,SAASU,EAAyBC,EAA+B7J,EAAaC,EAAe6J,EAA0B,CAIhHD,EAAI,IAAI7J,CAAG,GACd6J,EAAI,IAAI7J,EAAK,IAAI,GAAK,EAExB6J,EAAI,IAAI7J,CAAG,EAAG,IAAIC,CAAK,CACzB,CAKA,SAASwJ,EAAgBI,EAA+B7J,EAAaC,EAAqB,CACnF4J,EAAI,IAAI7J,CAAG,GACd6J,EAAI,IAAI7J,EAAK,IAAI,GAAK,EAExB6J,EAAI,IAAI7J,CAAG,EAAG,IAAIC,CAAK,CACzB,CAMO,SAAS8J,GAAY/K,EAAmBgL,EAAmB5J,EAAqBC,EAAyB,CAAA,EAAwC,CACtJ,MAAM7I,EAA8C,CAAA,EAC9CyS,EAAgB,CAAC,GAAG,IAAI,IAAID,CAAO,CAAC,EAE1C,UAAW3N,KAAS4N,EAClBzS,EAAQ6E,CAAK,EAAI0L,EAAe/I,EAAO3C,EAAO+D,EAAYC,CAAO,EAGnE,OAAO7I,CACT,CAMO,SAASuQ,EAAe/I,EAAmB3C,EAAe+D,EAAqBC,EAAyB,CAAA,EAAwB,CACrI,MAAMpO,EAAS+M,EAAM,OACfuJ,EAAQnI,GAAcC,EAAQ,YAAcpO,EAAO,WACnDiF,EAAYmJ,EAAQ,gBAAkBpO,EAAO,eAEnD,GAAI,CAACoK,GAASA,EAAM,OAAO,OAASpK,EAAO,eACzC,MAAO,CAAA,EAIT,GAAIoO,EAAQ,WAAa6H,GAAW7L,CAAK,EACvC,OAAOgM,GAAgBrJ,EAAO3C,EAAOkM,EAAOlI,CAAO,EAIrD,MAAM6J,EAAc/G,GAAW9G,CAAK,EAGpC,GAAI6N,EAAY,WACd,OAAOC,GAAkBnL,EAAOkL,EAAa3B,EAAOrR,EAAWmJ,CAAO,EAIxE,IAAI+J,EAAiB/N,EAMrB,GALIpK,EAAO,iBAAmBA,EAAO,WAAaA,EAAO,UAAU,OAAS,IAC1EmY,EAAiB9I,GAAgBjF,EAAOpK,EAAO,SAAS,GAItD+M,EAAM,OAAQ,CAChB,MAAMqL,EAASrL,EAAM,OAAO,IAAIoL,EAAgB7B,EAAOlI,CAAO,EAC9D,GAAIgK,EACF,OAAOA,CAEX,CAIA,MAAM/N,GADkB+D,EAAQ,WAAapO,EAAO,WACjB,IAAKH,GAASkN,EAAM,mBAAmB,IAAIlN,CAAI,CAAC,EAAE,OAAQmI,GAA8BA,IAAM,MAAS,EAE1I,GAAIqC,EAAW,SAAW,EACxB,MAAO,CAAA,EAIT,GAAI0C,EAAM,eAAiBA,EAAM,UAAW,CAC1C,MAAMxH,EAAU8S,GAAuBtL,EAAOoL,EAAgB7B,EAAOrR,EAAWoF,EAAY+D,CAAO,EAEnG,OAAIrB,EAAM,QACRA,EAAM,OAAO,IAAIoL,EAAgB5S,EAAS+Q,EAAOlI,CAAO,EAEnD7I,CACT,CAGA,MAAM+E,MAAc,IAGpB,UAAWjH,KAAagH,EAAY,CAClC,MAAME,EAAkBlH,EAAU,UAAU8U,EAAe,MAAM,EAGjEG,GAAiB/N,EAAiBwC,EAAOzC,EAASjH,EAAU,QAAQ,EACpEkV,GAAkBhO,EAAiBwC,EAAOzC,EAASjH,EAAU,QAAQ,EACrEmV,GAAoBjO,EAAiBlH,EAAW0J,EAAOzC,CAAO,EAC9DmO,GAAmBlO,EAAiBwC,EAAOzC,CAAO,EAClDoO,GAAiBnO,EAAiBwC,EAAOzC,EAASjH,EAAU,SAAUrD,EAAO,SAAS,GAElFA,EAAO,SAAS,SAAS,iBAAiB,GAAKA,EAAO,SAAS,SAAS,eAAe,GAAKA,EAAO,SAAS,SAAS,gBAAgB,IACvI2Y,GAAiBpO,EAAiBwC,EAAOzC,EAASjH,EAAWrD,CAAM,CAEvE,CAGA,MAAMuF,EAAU,MAAM,KAAK+E,EAAQ,QAAQ,EACxC,IAAKsB,GAAUgN,EAAuBhN,EAAOuM,EAAgBlT,EAAW8H,EAAOqB,CAAO,CAAC,EACvF,OAAQlK,GAAuCA,IAAW,IAAI,EAC9D,KAAK,CAAC+I,EAAGC,IAAMA,EAAE,MAAQD,EAAE,KAAK,EAChC,MAAM,EAAGqJ,CAAK,EAGjB,OAAIvJ,EAAM,QACRA,EAAM,OAAO,IAAIoL,EAAgB5S,EAAS+Q,EAAOlI,CAAO,EAGnD7I,CACT,CAKA,SAAS+S,GAAiBlO,EAAe2C,EAAmBzC,EAAmCnH,EAAwB,CACrH,MAAM2N,EAAiB/D,EAAM,OAAO,gBAAkB,GAGtD,GAAI3C,EAAM,SAAS,GAAG,EAAG,CAEvB,UAAWyO,KAAY9L,EAAM,KACvBkE,GAAgB4H,EAAUzO,CAAK,IAC5BE,EAAQ,IAAIuO,CAAQ,GACvBvO,EAAQ,IAAIuO,EAAU,CACpB,KAAMA,EACN,WAAYzO,EACZ,UAAW,QACX,aAAc,EACd,SAAAjH,CAAA,CACD,GAIP,MACF,CAGA,MAAM2V,EAAe/L,EAAM,cAAc,IAAI3C,CAAK,EAC9C0O,GACFA,EAAa,QAAS3Y,GAAS,CAE7B,GAAI2Q,GAAkB,CAACD,EAAY1Q,EAAMiK,EAAO0G,CAAc,EAC5D,OAIF,MAAM6E,EAAWrL,EAAQ,IAAInK,CAAI,GAC7B,CAACwV,GAAYA,EAAS,YAAc,UACtCrL,EAAQ,IAAInK,EAAM,CAChB,KAAAA,EACA,WAAYiK,EACZ,UAAW,QACX,aAAc,EACd,SAAAjH,CAAA,CACD,CAEL,CAAC,EAIH,MAAM4V,EAAa3O,EAAM,YAAA,EACzB,UAAWyO,KAAY9L,EAAM,KACvB8L,EAAS,YAAA,IAAkBE,IACxBzO,EAAQ,IAAIuO,CAAQ,GACvBvO,EAAQ,IAAIuO,EAAU,CACpB,KAAMA,EACN,WAAYzO,EACZ,UAAW,QACX,aAAc,EACd,SAAAjH,CAAA,CACD,EAIT,CAKA,SAASoV,GAAkBnO,EAAe2C,EAAmBzC,EAAmCnH,EAAwB,CACtH,MAAM2N,EAAiB/D,EAAM,OAAO,gBAAkB,GAEtD,SAAW,CAACpD,EAASV,CAAK,IAAK8D,EAAM,cAAc,UAC7CpD,EAAQ,WAAWS,CAAK,GAAKT,IAAYS,GAC3CnB,EAAM,QAAS9I,GAAS,CAElB2Q,GAAkB,CAACD,EAAY1Q,EAAMiK,EAAO0G,CAAc,GAIzDxG,EAAQ,IAAInK,CAAI,GACnBmK,EAAQ,IAAInK,EAAM,CAChB,KAAAA,EACA,WAAYwJ,EACZ,UAAW,SACX,SAAAxG,CAAA,CACD,CAEL,CAAC,CAGP,CAKA,SAASqV,GAAoBpO,EAAe/G,EAA8B0J,EAAmBzC,EAAyC,CACpI,GAAI,CAACjH,EAAU,kBAAkB,SAAS,UAAU,EAAG,OAEvD,MAAMkG,EAAelG,EAAU,gBAAgB+G,CAAK,EACpD,GAAIb,EAAc,CAChB,MAAMyP,EAAkBjM,EAAM,eAAe,IAAIxD,CAAY,EACzDyP,GACFA,EAAgB,QAAS7Y,GAAS,CAC3BmK,EAAQ,IAAInK,CAAI,GACnBmK,EAAQ,IAAInK,EAAM,CAChB,KAAAA,EACA,WAAYiK,EACZ,UAAW,WACX,aAAAb,EACA,SAAUlG,EAAU,QAAA,CACrB,CAEL,CAAC,CAEL,CACF,CAKA,SAASoV,GAAmBrO,EAAe2C,EAAmBzC,EAAyC,CACrG,MAAM2O,EAAiBlM,EAAM,WAAW,IAAI3C,CAAK,EAC7C6O,GACFA,EAAe,QAAS9Y,GAAS,CAC1BmK,EAAQ,IAAInK,CAAI,GACnBmK,EAAQ,IAAInK,EAAM,CAChB,KAAAA,EACA,WAAYiK,EACZ,UAAW,UACX,SAAU,SAAA,CACX,CAEL,CAAC,CAEL,CAKA,SAASsO,GAAiBtO,EAAe2C,EAAmBzC,EAAmCnH,EAAkB6H,EAAyB,CACxI,GAAIZ,EAAM,OAASY,EAAW,OAE9B,MAAMC,EAAc5G,EAAe+F,EAAOY,CAAS,EAC7CkO,MAAqB,IAE3BjO,EAAY,QAASrB,GAAU,CAC7B,MAAMuP,EAAepM,EAAM,WAAW,IAAInD,CAAK,EAC3CuP,GACFA,EAAa,QAAShZ,GAAS+Y,EAAe,IAAI/Y,CAAI,CAAC,CAE3D,CAAC,EAED+Y,EAAe,QAAS/Y,GAAS,CAC1BmK,EAAQ,IAAInK,CAAI,GACnBmK,EAAQ,IAAInK,EAAM,CAChB,KAAAA,EACA,WAAYiK,EACZ,UAAW,QACX,SAAAjH,CAAA,CACD,CAEL,CAAC,CACH,CAKA,SAASwV,GAAiBvO,EAAe2C,EAAmBzC,EAAmCjH,EAA8BrD,EAA2B,CACtJ,MAAMuD,EAAcvD,EAAO,gBAE3B,SAAW,CAAC2J,EAASV,CAAK,IAAK8D,EAAM,cAAc,UACjD,GAAI,KAAK,IAAIpD,EAAQ,OAASS,EAAM,MAAM,GAAK7G,EAAa,CAG1D,MAAMuB,EADoBiI,EAAM,OAAO,UAAU,SAAS,gBAAgB,EACrCpJ,EAAoCyG,EAAOT,EAASpG,CAAW,EAAID,EAA6B8G,EAAOT,EAASpG,CAAW,EAE5JuB,GAAYvB,GACd0F,EAAM,QAAS9I,GAAS,CACtB,MAAMsL,EAAgBnB,EAAQ,IAAInK,CAAI,GAElC,CAACsL,GAAkBA,EAAc,YAAc,SAAWA,EAAc,YAAc,WAAaA,EAAc,cAAgB,KAAY3G,IAC/IwF,EAAQ,IAAInK,EAAM,CAChB,KAAAA,EACA,WAAYwJ,EACZ,UAAW,QACX,aAAc7E,EACd,SAAUzB,EAAU,QAAA,CACrB,CAEL,CAAC,CAEL,CAEJ,CAKA,SAASuV,EAAuBhN,EAAoBwN,EAAuBnU,EAAmB8H,EAAmBqB,EAAkD,CACjK,IAAIhH,EAAQiS,GAAoBzN,EAAOwN,CAAa,EAGpD,GAAIxN,EAAM,YAAc,QAAamB,EAAM,OAAO,QAAS,CACzD,MAAMrF,EAAaqF,EAAM,OAAO,YAAc,GACxCpF,EAAc,EAAID,EACxBN,EAAQM,EAAakE,EAAM,UAAYjE,EAAcP,CACvD,CAOA,GAJIwE,EAAM,cACRxE,EAAQ,KAAK,IAAI,EAAKA,EAAQwE,EAAM,WAAW,GAG7CxE,EAAQnC,EACV,OAAO,KAGT,MAAMf,EAA2B,CAC/B,QAAS0H,EAAM,KACf,SAAUA,EAAM,KAChB,UAAWA,EAAM,YAAc,UAC/B,MAAAxE,EACA,SAAUwE,EAAM,SAEhB,iBAAkBA,EAAM,SAAA,EAI1B,OAAImB,EAAM,WAAaA,EAAM,UAAU,IAAInB,EAAM,IAAI,IACnD1H,EAAO,OAAS6I,EAAM,UAAU,IAAInB,EAAM,IAAI,EAC9C1H,EAAO,MAAQ0H,EAAM,OAInBwC,GAAS,oBACXlK,EAAO,WAAa8H,GAAoBJ,EAAOwN,EAAexN,EAAM,IAAI,GAGnE1H,CACT,CAKA,SAASmV,GAEPzN,EACAxB,EACQ,CACR,MAAMe,EAAWf,EAAM,OACjBkP,EAAU1N,EAAM,KAAK,OACrBhI,EAAS,KAAK,IAAIuH,EAAUmO,CAAO,EAEzC,IAAIlS,EAAQ,GAEZ,OAAQwE,EAAM,UAAA,CACZ,IAAK,QACHxE,EAAQ,EACR,MACF,IAAK,SACHA,EAAQ,IAAOkS,EAAUnO,IAAavH,EAAS,GAC/C,MACF,IAAK,YACHwD,EAAQ,GACR,MACF,IAAK,WACHA,EAAQ,GACR,MACF,IAAK,QACCwE,EAAM,eAAiB,SACzBxE,EAAQ,KAAK,IAAI,GAAK,EAAMwE,EAAM,aAAehI,CAAM,GAEzD,MACF,IAAK,UACHwD,EAAQ,GACR,MACF,IAAK,WACHA,EAAQ,IACR,MACF,IAAK,QACHA,EAAQjD,EAAyBiG,EAAM,YAAA,EAAewB,EAAM,WAAY,CAAC,EAAI,GAC7E,KAAA,CAKJ,OAAI0N,GAAWnO,EAAW,GAAKS,EAAM,YAAc,UACjDxE,GAAS,IAGJ,KAAK,IAAI,EAAK,KAAK,IAAI,EAAKA,CAAK,CAAC,CAC3C,CAKA,SAAS/C,EAEPO,EACA3D,EACU,CACV,GAAI2D,EAAI,OAAS3D,EAAG,MAAO,CAAC2D,CAAG,EAE/B,MAAM1D,EAAmB,CAAA,EACzB,QAASX,EAAI,EAAGA,GAAKqE,EAAI,OAAS3D,EAAGV,IACnCW,EAAO,KAAK0D,EAAI,MAAMrE,EAAGA,EAAIU,CAAC,CAAC,EAEjC,OAAOC,CACT,CAMA,SAASmX,GAEPtL,EACA3C,EACAkM,EACArR,EACAoF,EACA+D,EACoB,CACpB,GAAI,CAACrB,EAAM,eAAiB,CAACA,EAAM,UACjC,MAAM,IAAI,MAAM,8BAA8B,EAIhD,IAAIzC,EAAUH,GAAoB4C,EAAM,cAAeA,EAAM,UAAW3C,EAAOC,EAAY0C,EAAM,MAAM,EAGvG,GAAIA,EAAM,OAAO,QAAS,CACxB,MAAMrG,EAAa0D,EAAM,YAAA,EAAc,MAAM,KAAK,EAAE,OAAOqH,GAAKA,EAAE,OAAS,CAAC,EAC5EnH,EAAUoB,GAAoBpB,EAAS5D,EAAYqG,EAAM,cAAeA,EAAM,UAAWA,EAAM,MAAM,CACvG,CASA,OANgBzC,EACb,IAAKsB,GAAUgN,EAAuBhN,EAAOxB,EAAOnF,EAAW8H,EAAOqB,CAAO,CAAC,EAC9E,OAAQlK,GAAuCA,IAAW,IAAI,EAC9D,KAAK,CAAC+I,EAAGC,IAAMA,EAAE,MAAQD,EAAE,KAAK,EAChC,MAAM,EAAGqJ,CAAK,CAGnB,CAMA,SAAS4B,GACPnL,EACAkL,EACA3B,EACArR,EACAmJ,EACoB,CACpB,MAAMpO,EAAS+M,EAAM,OAIfwM,EAAgB,CACpB,WAAY,GACZ,gBAAiB,EACjB,eAAgB,IAChB,qBAAsB,EACtB,kBARwBvZ,EAAO,SAAS,SAAS,gBAAgB,CAQjE,EAIIwZ,MAAoB,IAG1B,UAAWlI,KAAU2G,EAAY,QAC/B,UAAW9X,KAAQ4M,EAAM,KAAM,CAC7B,MAAMnB,EAAQ+F,GAAYxR,EAAMmR,EAAQiI,CAAa,EAErD,GAAI3N,EAAM,QAAS,CACjB,MAAM+J,EAAW6D,EAAc,IAAIrZ,CAAI,EACjCsZ,EAAW7N,EAAM,MAAQ2N,EAAc,eAEzC5D,EAEF6D,EAAc,IAAIrZ,EAAM,CACtB,MAAO,KAAK,IAAIwV,EAAS,MAAO8D,CAAQ,EACxC,YAAa9D,EAAS,YAAc,CAAA,CACrC,EAED6D,EAAc,IAAIrZ,EAAM,CAAE,MAAOsZ,EAAU,YAAa,EAAG,CAE/D,CACF,CAIF,IAAIC,MAAkB,IAEtB,GAAIzB,EAAY,MAAM,OAAS,EAAG,CAChC,MAAM0B,EAAY1B,EAAY,MAAM,KAAK,GAAG,EACtC5N,EAAarK,EAAO,UACvB,IAAKH,GAASkN,EAAM,mBAAmB,IAAIlN,CAAI,CAAC,EAChD,OAAQmI,GAA8BA,IAAM,MAAS,EAExD,UAAW3E,KAAagH,EAAY,CAClC,MAAME,EAAkBlH,EAAU,UAAUsW,CAAS,EAGrDrB,GAAiB/N,EAAiBwC,EAAO2M,EAAarW,EAAU,QAAQ,EACxEkV,GAAkBhO,EAAiBwC,EAAO2M,EAAarW,EAAU,QAAQ,EACzEmV,GAAoBjO,EAAiBlH,EAAW0J,EAAO2M,CAAW,EAClEhB,GAAiBnO,EAAiBwC,EAAO2M,EAAarW,EAAU,SAAUrD,EAAO,SAAS,GAEtFA,EAAO,SAAS,SAAS,iBAAiB,GAAKA,EAAO,SAAS,SAAS,eAAe,GAAKA,EAAO,SAAS,SAAS,gBAAgB,IACvI2Y,GAAiBpO,EAAiBwC,EAAO2M,EAAarW,EAAWrD,CAAM,CAE3E,CACF,CAGA,MAAM4Z,MAAsB,IAG5B,SAAW,CAACzZ,EAAM0Z,CAAU,IAAKL,EAAc,UAAW,CACxD,MAAMtV,EAA2B,CAC/B,QAAS/D,EACT,SAAUA,EACV,UAAW,GACX,MAAO0Z,EAAW,KAAA,EAIFH,EAAY,IAAIvZ,CAAI,IAEpC+D,EAAO,MAAQ,KAAK,IAAI,EAAKA,EAAO,MAAQ,GAAG,GAGjD0V,EAAgB,IAAIzZ,EAAM+D,CAAM,CAClC,CAGA,SAAW,CAAC/D,EAAMyL,CAAK,IAAK8N,EAAY,UACtC,GAAI,CAACE,EAAgB,IAAIzZ,CAAI,EAAG,CAC9B,MAAM+D,EAAS0U,EAAuBhN,EAAOqM,EAAY,MAAM,KAAK,GAAG,EAAGhT,EAAW8H,EAAOqB,CAAO,EAC/FlK,IAEFA,EAAO,OAAS,GAChB0V,EAAgB,IAAIzZ,EAAM+D,CAAM,EAEpC,CAIF,MAAMqB,EAAU,MAAM,KAAKqU,EAAgB,QAAQ,EAChD,OAAOnE,GAAKA,EAAE,OAASxQ,CAAS,EAChC,KAAK,CAACgI,EAAGC,IAAMA,EAAE,MAAQD,EAAE,KAAK,EAChC,MAAM,EAAGqJ,CAAK,EAGjB,OAAIvJ,EAAM,QACRA,EAAM,OAAO,IAAIkL,EAAY,SAAU1S,EAAS+Q,EAAOlI,CAAO,EAGzD7I,CACT,CCl4BO,SAASuU,EAAe/M,EAA2B,CACxD,MAAMgN,EAA8B,CAClC,QAAS,MACT,KAAMhN,EAAM,KACZ,cAAe,MAAM,KAAKA,EAAM,cAAc,QAAA,CAAS,EAAE,IAAI,CAAC,CAACrE,EAAG8K,CAAC,IAAM,CAAC9K,EAAG,MAAM,KAAK8K,CAAC,CAAC,CAAC,EAC3F,eAAgB,MAAM,KAAKzG,EAAM,eAAe,QAAA,CAAS,EAAE,IAAI,CAAC,CAACrE,EAAG8K,CAAC,IAAM,CAAC9K,EAAG,MAAM,KAAK8K,CAAC,CAAC,CAAC,EAC7F,WAAY,MAAM,KAAKzG,EAAM,WAAW,QAAA,CAAS,EAAE,IAAI,CAAC,CAACrE,EAAG8K,CAAC,IAAM,CAAC9K,EAAG,MAAM,KAAK8K,CAAC,CAAC,CAAC,EACrF,WAAY,MAAM,KAAKzG,EAAM,WAAW,QAAA,CAAS,EAAE,IAAI,CAAC,CAACrE,EAAG8K,CAAC,IAAM,CAAC9K,EAAG,MAAM,KAAK8K,CAAC,CAAC,CAAC,EACrF,OAAQzG,EAAM,OACd,uBAAwB,MAAM,KAAKA,EAAM,mBAAmB,MAAM,CAAA,EAIpE,OAAIA,EAAM,gBACRgN,EAAW,cAAgB,CACzB,eAAgB,MAAM,KAAKhN,EAAM,cAAc,eAAe,SAAS,EACvE,mBAAoB,MAAM,KAAKA,EAAM,cAAc,mBAAmB,SAAS,EAC/E,gBAAiB,MAAM,KAAKA,EAAM,cAAc,gBAAgB,SAAS,EACzE,kBAAmB,MAAM,KAAKA,EAAM,cAAc,kBAAkB,SAAS,EAC7E,UAAWA,EAAM,cAAc,UAC/B,aAAcA,EAAM,cAAc,YAAA,GAKlCA,EAAM,YACRgN,EAAW,UAAYhN,EAAM,WAGxB,KAAK,UAAUgN,CAAU,CAClC,CAKA,eAAsBC,GAAiBC,EAAmC,CACxE,MAAMxU,EAAwB,KAAK,MAAMwU,CAAI,EAGvCC,EAAgB,IAAI,IAAIzU,EAAK,cAAc,IAAI,CAAC,CAACiD,EAAG8K,CAAC,IAAM,CAAC9K,EAAG,IAAI,IAAI8K,CAAC,CAAC,CAAC,CAAC,EAC3E2G,EAAiB,IAAI,IAAI1U,EAAK,eAAe,IAAI,CAAC,CAACiD,EAAG8K,CAAC,IAAM,CAAC9K,EAAG,IAAI,IAAI8K,CAAC,CAAC,CAAC,CAAC,EAC7E4G,EAAa,IAAI,IAAI3U,EAAK,WAAW,IAAI,CAAC,CAACiD,EAAG8K,CAAC,IAAM,CAAC9K,EAAG,IAAI,IAAI8K,CAAC,CAAC,CAAC,CAAC,EACrEhR,EAAa,IAAI,IAAIiD,EAAK,WAAW,IAAI,CAAC,CAACiD,EAAG8K,CAAC,IAAM,CAAC9K,EAAG,IAAI,IAAI8K,CAAC,CAAC,CAAC,CAAC,EAGrE,CAAE,iBAAAtQ,CAAA,EAAqB,MAAM,QAAA,QAAA,EAAA,KAAA,IAAA6J,EAAA,EAC7B7D,MAAyB,IAC/B,UAAWmR,KAAY5U,EAAK,uBAAwB,CAClD,MAAMpC,EAAYH,EAAiB,aAAamX,CAAQ,EACpDhX,GACF6F,EAAmB,IAAImR,EAAUhX,CAAS,CAE9C,CAEA,MAAM0J,EAAoB,CACxB,KAAMtH,EAAK,KACX,cAAAyU,EACA,eAAAC,EACA,WAAAC,EACA,WAAA5X,EACA,mBAAA0G,EACA,OAAQzD,EAAK,MAAA,EAqBf,GAjBIA,EAAK,gBACPsH,EAAM,cAAgB,CACpB,eAAgB,IAAI,IAAItH,EAAK,cAAc,cAAc,EACzD,mBAAoB,IAAI,IAAIA,EAAK,cAAc,kBAAkB,EACjE,gBAAiB,IAAI,IAAIA,EAAK,cAAc,eAAe,EAC3D,kBAAmB,IAAI,IAAIA,EAAK,cAAc,iBAAiB,EAC/D,UAAWA,EAAK,cAAc,UAC9B,aAAcA,EAAK,cAAc,YAAA,GAKjCA,EAAK,YACPsH,EAAM,UAAYtH,EAAK,WAIrBA,EAAK,OAAO,cAAgB,GAAO,CACrC,MAAM8R,EAAY9R,EAAK,OAAO,WAAa,IAC3CsH,EAAM,OAAS,IAAImB,EAAYqJ,CAAS,CAC1C,CAEA,OAAOxK,CACT,CAKO,SAASuN,GAAwBvN,EAAmBgB,EAAc,qBAA4B,CACnG,GAAI,OAAO,aAAiB,IAC1B,MAAM,IAAI,MAAM,+BAA+B,EAEjD,MAAMgM,EAAaD,EAAe/M,CAAK,EACvC,aAAa,QAAQgB,EAAKgM,CAAU,CACtC,CAKA,eAAsBQ,GAA0BxM,EAAc,qBAAkD,CAC9G,GAAI,OAAO,aAAiB,IAC1B,MAAM,IAAI,MAAM,+BAA+B,EAEjD,MAAMgM,EAAa,aAAa,QAAQhM,CAAG,EAC3C,OAAKgM,EAGE,MAAMC,GAAiBD,CAAU,EAF/B,IAGX,CAKO,SAASS,GAAkBzN,EAA2B,CAC3D,MAAMgN,EAAaD,EAAe/M,CAAK,EACvC,OAAO,IAAI,KAAK,CAACgN,CAAU,CAAC,EAAE,IAChC,CClGO,SAASU,EAEdC,EACAtM,EAA8B,GACpB,CACV,KAAM,CAEJ,UAAAuM,EAAY,EACZ,WAAAC,EAAa,GACb,UAAAtL,EAAY,GACZ,QAAAuL,EAAU,EACV,UAAAC,EAAY,EACZ,QAAAC,EAAU,OACV,OAAAC,EAAS,SACT,cAAAC,EAAgB,GAChB,cAAAzK,EAAgB,EAAA,EACdpC,EAEJ,IAAIlO,EAAOwa,EAGX,OAAQM,EAAA,CACN,IAAK,SACH,GAAI,CACF9a,EAAO,KAAKwa,CAAO,CACrB,OAASQ,EAAG,CACV,eAAQ,MAAM,2BAA4BA,CAAC,EACpC,CAAA,CACT,CACA,MAEF,IAAK,OACHhb,EAAOib,GAAUT,CAAO,EACxB,MAEF,IAAK,OACHxa,EAAOkb,GAAgBV,CAAO,EAC9B,MAEF,IAAK,MAEH,MAAM,IAAI,MAAM,4DAA4D,CAK5E,CAIAI,EAAY,IAEd5a,EADemb,GAAUnb,EAAM4a,EAAWD,EAASE,CAAO,EAC5C,KAAK,GAAG,GAIxB,IAAI9R,EAAkB,CAAA,EAiCtB,GA/BI2R,EAEF3R,EAAQ/I,EAAK,MAAM,6BAA6B,EAAE,OAAQC,GAASA,EAAK,OAAS,CAAC,EAElF8I,EAAQ,CAAC/I,CAAI,EAIf+I,EAAQA,EACL,IAAK9I,IAEJA,EAAOA,EAAK,QAAQ,oCAAqC,EAAE,EAGtDqQ,IACHrQ,EAAOA,EAAK,YAAA,GAGPA,EACR,EACA,OAAQA,GAEH,EAAAA,EAAK,OAASwa,GAGdM,GAAiB,QAAQ,KAAK9a,CAAI,EAGvC,EAGCmP,GAAa,MAAM,QAAQA,CAAS,EAAG,CACzC,MAAMC,EAAe,IAAI,IAAID,EAAU,IAAKE,GAAMA,EAAE,YAAA,CAAa,CAAC,EAClEvG,EAAQA,EAAM,OAAQ9I,GAAS,CAACoP,EAAa,IAAIpP,EAAK,YAAA,CAAa,CAAC,CACtE,CAGA,OAAO,MAAM,KAAK,IAAI,IAAI8I,CAAK,CAAC,CAClC,CAKA,SAASkS,GAAUG,EAAsB,CAEvC,IAAIpb,EAAOob,EAAK,QAAQ,sDAAuD,GAAG,EAClF,OAAApb,EAAOA,EAAK,QAAQ,mDAAoD,GAAG,EAG3EA,EAAOA,EAAK,QAAQ,mBAAoB,GAAG,EAG3CA,EAAOA,EAAK,QAAQ,WAAY,GAAG,EAGnCA,EAAOA,EACJ,QAAQ,UAAW,GAAG,EACtB,QAAQ,SAAU,GAAG,EACrB,QAAQ,QAAS,GAAG,EACpB,QAAQ,QAAS,GAAG,EACpB,QAAQ,UAAW,GAAG,EACtB,QAAQ,SAAU,GAAG,EACrB,QAAQ,UAAW,GAAG,EAGzBA,EAAOA,EAAK,QAAQ,OAAQ,GAAG,EAAE,KAAA,EAE1BA,CACT,CAKA,SAASkb,GAAgBG,EAA4B,CACnD,GAAI,CAIF,IAASC,EAAT,SAAuBC,EAAUC,EAAgB,EAAS,CAEpDA,EAAQ,KAER,OAAOD,GAAQ,SACjBE,EAAO,KAAKF,CAAG,EACN,MAAM,QAAQA,CAAG,EAC1BA,EAAI,QAASxT,GAASuT,EAAcvT,EAAMyT,EAAQ,CAAC,CAAC,EAC3C,OAAOD,GAAQ,UAAYA,IAAQ,MAC5C,OAAO,OAAOA,CAAG,EAAE,QAASzN,GAAUwN,EAAcxN,EAAO0N,EAAQ,CAAC,CAAC,EAEzE,EAdA,MAAMjW,EAAO,KAAK,MAAM8V,CAAU,EAC5BI,EAAmB,CAAA,EAezB,OAAAH,EAAc/V,CAAI,EACXkW,EAAO,KAAK,GAAG,CACxB,OAAS,EAAG,CACV,eAAQ,MAAM,wBAAyB,CAAC,EACjC,EACT,CACF,CAKA,SAASN,GAAUnb,EAAc4a,EAAmBD,EAAiBE,EAAsD,CACzH,MAAMa,EAAmB,CAAA,EAEzB,GAAIb,IAAY,YAAa,CAE3B,MAAMc,EAAa3b,EAAK,MAAM,OAAO,EACrC,IAAI4b,EAAe,GAEnB,UAAWC,KAAQF,GACZC,EAAeC,GAAM,QAAUjB,EAClCgB,IAAiBA,EAAe;AAAA;AAAA,EAAS,IAAMC,GAE3CD,GAAcF,EAAO,KAAKE,CAAY,EAC1CA,EAAeC,GAGfD,GAAcF,EAAO,KAAKE,CAAY,CAC5C,SAAWf,IAAY,WAAY,CAEjC,MAAMiB,EAAY9b,EAAK,MAAM,WAAW,EACxC,IAAI4b,EAAe,GAEnB,UAAWG,KAAYD,GAChBF,EAAeG,GAAU,QAAUnB,EACtCgB,IAAiBA,EAAe,IAAM,IAAMG,GAExCH,GAAcF,EAAO,KAAKE,CAAY,EAC1CA,EAAeG,GAGfH,GAAcF,EAAO,KAAKE,CAAY,CAC5C,KAAO,CAEL,MAAM7S,EAAQ/I,EAAK,MAAM,KAAK,EAC9B,IAAI4b,EAAe,GAEnB,UAAW3b,KAAQ8I,GACZ6S,EAAe,IAAM3b,GAAM,QAAU2a,EACxCgB,IAAiBA,EAAe,IAAM,IAAM3b,GAExC2b,GAAcF,EAAO,KAAKE,CAAY,EAGtCjB,EAAU,GAAKiB,EAEjBA,EADqBA,EAAa,MAAM,KAAK,EAAE,MAAM,CAAC,KAAK,KAAKjB,EAAU,EAAE,CAAC,EACjD,KAAK,GAAG,EAAI,IAAM1a,EAE9C2b,EAAe3b,GAIjB2b,GAAcF,EAAO,KAAKE,CAAY,CAC5C,CAEA,OAAOF,CACT,CAQA,eAAsBM,GAAiBxB,EAAiBtM,EAA8B,GAAuB,CAC3G,KAAM,CAAE,OAAA4M,EAAS,QAAA,EAAa5M,EAE9B,GAAI4M,IAAW,MACb,GAAI,CAEF,MAAMM,EAAO,MADI,MAAM,MAAMZ,CAAO,GACR,KAAA,EAC5B,OAAOD,EAAYa,EAAM,CAAE,GAAGlN,EAAS,OAAQ,OAAQ,CACzD,OAAS8M,EAAG,CACV,eAAQ,MAAM,uBAAwBA,CAAC,EAChC,CAAA,CACT,CAGF,OAAOT,EAAYC,EAAStM,CAAO,CACrC,CCrOO,SAAS+N,GACdC,EACAhO,EAII,GACJ,CACA,MAAMrB,EAAQyJ,GAAgB4F,EAAY,CACxC,OAAQ,CACN,UAAWhO,EAAQ,WAAa,CAAC,QAAQ,EACzC,YAAaA,EAAQ,aAAe,WACpC,WAAYA,EAAQ,YAAc,CAAA,CACpC,CACD,EAED,MAAO,CACL,OAAQ,CAAChE,EAAe+D,IAAwB2H,EAAe/I,EAAO3C,EAAO+D,CAAU,EACvF,MAAApB,CAAA,CAEJ,CAKO,MAAMsP,GAAU"}