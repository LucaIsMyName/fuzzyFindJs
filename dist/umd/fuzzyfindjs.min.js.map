{"version":3,"file":"fuzzyfindjs.min.js","sources":["../../src/core/config.ts","../../src/languages/base/LanguageProcessor.ts","../../src/languages/german/GermanProcessor.ts","../../src/languages/english/EnglishProcessor.ts","../../src/languages/spanish/SpanishProcessor.ts","../../src/languages/french/FrenchProcessor.ts","../../src/languages/index.ts","../../src/utils/memory-pool.ts","../../src/algorithms/levenshtein.ts","../../src/core/trie.ts","../../src/algorithms/bm25.ts","../../src/algorithms/bloom-filter.ts","../../src/core/inverted-index.ts","../../src/core/highlighting.ts","../../src/core/cache.ts","../../src/utils/accent-normalization.ts","../../src/core/field-weighting.ts","../../src/utils/stop-words.ts","../../src/utils/word-boundaries.ts","../../src/utils/phrase-parser.ts","../../src/core/phrase-matching.ts","../../src/utils/language-detection.ts","../../src/fql/lexer.ts","../../src/fql/parser.ts","../../src/fql/ast.ts","../../src/fql/executor.ts","../../src/fql/index.ts","../../src/core/index.ts","../../src/core/serialization.ts","../../src/utils/data-indexer.ts","../../src/index.ts"],"sourcesContent":["import type {\n  //\n  FuzzyConfig,\n  FuzzyFeature,\n} from \"./types.js\";\n\n/**\n * Default configuration for FuzzyFindJS\n * Provides sensible defaults that work out of the box\n */\nexport const DEFAULT_CONFIG: FuzzyConfig = {\n  languages: [\"english\"],\n  features: [\"phonetic\", \"compound\", \"synonyms\", \"keyboard-neighbors\", \"partial-words\", \"missing-letters\", \"extra-letters\", \"transpositions\"],\n  performance: \"balanced\",\n  maxResults: 10,\n  minQueryLength: 2,\n  fuzzyThreshold: 0.75,\n  maxEditDistance: 2,\n  ngramSize: 3,\n};\n\n/**\n * Performance-optimized configurations\n */\nexport const PERFORMANCE_CONFIGS: Record<string, Partial<FuzzyConfig>> = {\n  fast: {\n    performance: \"fast\",\n    features: [\"partial-words\", \"missing-letters\"],\n    maxEditDistance: 1,\n    fuzzyThreshold: 0.9,\n    maxResults: 3,\n  },\n  balanced: {\n    performance: \"balanced\",\n    features: [\"phonetic\", \"partial-words\", \"missing-letters\", \"keyboard-neighbors\"],\n    maxEditDistance: 2,\n    fuzzyThreshold: 0.75,\n    maxResults: 5,\n  },\n  comprehensive: {\n    performance: \"comprehensive\",\n    features: [\"phonetic\", \"compound\", \"synonyms\", \"keyboard-neighbors\", \"partial-words\", \"missing-letters\", \"extra-letters\", \"transpositions\"],\n    maxEditDistance: 3,\n    fuzzyThreshold: 0.7,\n    maxResults: 10,\n  },\n};\n\n/**\n * Language-specific feature recommendations\n */\nexport const LANGUAGE_FEATURES: Record<string, FuzzyFeature[]> = {\n  german: [\n    //\n    \"phonetic\",\n    \"compound\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n    \"extra-letters\",\n  ],\n  english: [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n    \"transpositions\",\n  ],\n  spanish: [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n  ],\n  french: [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n  ],\n};\n\n/**\n * Merge user configuration with defaults\n */\nexport function mergeConfig(userConfig: Partial<FuzzyConfig> = {}): FuzzyConfig {\n  const baseConfig = { ...DEFAULT_CONFIG };\n\n  // Apply performance preset if specified\n  if (userConfig.performance && userConfig.performance !== \"balanced\") {\n    const performanceConfig = PERFORMANCE_CONFIGS[userConfig.performance];\n    Object.assign(baseConfig, performanceConfig);\n  }\n\n  // Apply user overrides\n  const mergedConfig = { ...baseConfig, ...userConfig };\n\n  // Auto-adjust features based on languages if not explicitly set\n  if (!userConfig.features && userConfig.languages) {\n    const recommendedFeatures = new Set<FuzzyFeature>();\n\n    for (const lang of userConfig.languages) {\n      const langFeatures = LANGUAGE_FEATURES[lang] || LANGUAGE_FEATURES.english;\n      langFeatures.forEach((feature) => recommendedFeatures.add(feature));\n    }\n\n    mergedConfig.features = Array.from(recommendedFeatures);\n  }\n\n  return mergedConfig;\n}\n\n/**\n * Validate configuration\n */\nexport function validateConfig(config: FuzzyConfig): void {\n  if (config.maxResults < 1) {\n    throw new Error(\"maxResults must be at least 1\");\n  }\n\n  if (config.minQueryLength < 1) {\n    throw new Error(\"minQueryLength must be at least 1\");\n  }\n\n  if (config.fuzzyThreshold < 0 || config.fuzzyThreshold > 1) {\n    throw new Error(\"fuzzyThreshold must be between 0 and 1\");\n  }\n\n  if (config.maxEditDistance < 0) {\n    throw new Error(\"maxEditDistance must be non-negative\");\n  }\n\n  if (config.ngramSize < 2) {\n    throw new Error(\"ngramSize must be at least 2\");\n  }\n\n  if (config.languages.length === 0) {\n    throw new Error(\"At least one language must be specified\");\n  }\n}\n","import type { LanguageProcessor, FuzzyFeature } from \"../../core/types.js\";\n\n/**\n * Abstract base class for language processors\n * Provides common functionality and enforces interface\n */\nexport abstract class BaseLanguageProcessor implements LanguageProcessor {\n  abstract readonly language: string;\n  abstract readonly displayName: string;\n  abstract readonly supportedFeatures: FuzzyFeature[];\n\n  /**\n   * Basic text normalization (override for language-specific behavior)\n   */\n  normalize(text: string): string {\n    return text.toLowerCase().trim().replace(/\\s+/g, \" \");\n  }\n\n  /**\n   * Default phonetic implementation (override for language-specific algorithms)\n   */\n  getPhoneticCode(word: string): string {\n    // Simple soundex-like algorithm as fallback\n    const normalized = this.normalize(word);\n    if (normalized.length === 0) return \"\";\n\n    let code = normalized[0].toUpperCase();\n    const consonantMap: Record<string, string> = {\n      b: \"1\",\n      f: \"1\",\n      p: \"1\",\n      v: \"1\",\n      c: \"2\",\n      g: \"2\",\n      j: \"2\",\n      k: \"2\",\n      q: \"2\",\n      s: \"2\",\n      x: \"2\",\n      z: \"2\",\n      d: \"3\",\n      t: \"3\",\n      l: \"4\",\n      m: \"5\",\n      n: \"5\",\n      r: \"6\",\n    };\n\n    for (let i = 1; i < normalized.length && code.length < 4; i++) {\n      const char = normalized[i];\n      const digit = consonantMap[char];\n      if (digit && digit !== code[code.length - 1]) {\n        code += digit;\n      }\n    }\n\n    return code.padEnd(4, \"0\");\n  }\n\n  /**\n   * Default compound word splitting (override for languages that support it)\n   */\n  splitCompoundWords(word: string): string[] {\n    return [word]; // No splitting by default\n  }\n\n  /**\n   * Generate common word variants\n   */\n  getWordVariants(word: string): string[] {\n    const variants = new Set<string>();\n    const normalized = this.normalize(word);\n\n    variants.add(normalized);\n    variants.add(word); // Original form\n\n    // Add variants without common endings\n    const commonEndings = this.getCommonEndings();\n    for (const ending of commonEndings) {\n      if (normalized.endsWith(ending) && normalized.length > ending.length + 2) {\n        variants.add(normalized.slice(0, -ending.length));\n      }\n    }\n\n    // Add partial variants for longer words\n    if (normalized.length > 4) {\n      for (let i = 3; i < normalized.length; i++) {\n        variants.add(normalized.slice(0, i));\n      }\n    }\n\n    return Array.from(variants);\n  }\n\n  /**\n   * Get common word endings for this language (override for language-specific endings)\n   */\n  protected getCommonEndings(): string[] {\n    return [\n      //\n      \"s\",\n      \"es\",\n      \"ed\",\n      \"ing\",\n      \"er\",\n      \"est\",\n    ];\n  }\n\n  /**\n   * Default synonym lookup (override to provide language-specific synonyms)\n   */\n  getSynonyms(_word: string): string[] {\n    return []; // No built-in synonyms by default\n  }\n\n  /**\n   * Check if two characters are keyboard neighbors\n   */\n  isValidSubstitution(char1: string, char2: string): boolean {\n    const keyboardNeighbors = this.getKeyboardNeighbors();\n    const neighbors = keyboardNeighbors[char1.toLowerCase()];\n    return neighbors ? neighbors.includes(char2.toLowerCase()) : false;\n  }\n\n  /**\n   * Get keyboard neighbor mappings (QWERTY layout by default)\n   */\n  protected getKeyboardNeighbors(): Record<string, string[]> {\n    return {\n      q: [\"w\", \"a\", \"s\"],\n      w: [\"q\", \"e\", \"a\", \"s\", \"d\"],\n      e: [\"w\", \"r\", \"s\", \"d\", \"f\"],\n      r: [\"e\", \"t\", \"d\", \"f\", \"g\"],\n      t: [\"r\", \"y\", \"f\", \"g\", \"h\"],\n      y: [\"t\", \"u\", \"g\", \"h\", \"j\"],\n      u: [\"y\", \"i\", \"h\", \"j\", \"k\"],\n      i: [\"u\", \"o\", \"j\", \"k\", \"l\"],\n      o: [\"i\", \"p\", \"k\", \"l\"],\n      p: [\"o\", \"l\"],\n      a: [\"q\", \"w\", \"s\", \"z\", \"x\"],\n      s: [\"q\", \"w\", \"e\", \"a\", \"d\", \"z\", \"x\", \"c\"],\n      d: [\"w\", \"e\", \"r\", \"s\", \"f\", \"x\", \"c\", \"v\"],\n      f: [\"e\", \"r\", \"t\", \"d\", \"g\", \"c\", \"v\", \"b\"],\n      g: [\"r\", \"t\", \"y\", \"f\", \"h\", \"v\", \"b\", \"n\"],\n      h: [\"t\", \"y\", \"u\", \"g\", \"j\", \"b\", \"n\", \"m\"],\n      j: [\"y\", \"u\", \"i\", \"h\", \"k\", \"n\", \"m\"],\n      k: [\"u\", \"i\", \"o\", \"j\", \"l\", \"m\"],\n      l: [\"i\", \"o\", \"p\", \"k\"],\n      z: [\"a\", \"s\", \"x\"],\n      x: [\"a\", \"s\", \"d\", \"z\", \"c\"],\n      c: [\"s\", \"d\", \"f\", \"x\", \"v\"],\n      v: [\"d\", \"f\", \"g\", \"c\", \"b\"],\n      b: [\"f\", \"g\", \"h\", \"v\", \"n\"],\n      n: [\"g\", \"h\", \"j\", \"b\", \"m\"],\n      m: [\"h\", \"j\", \"k\", \"n\"],\n    };\n  }\n\n  /**\n   * Generate n-grams for partial matching\n   */\n  generateNgrams(word: string, n: number = 3): string[] {\n    const normalized = this.normalize(word);\n    if (normalized.length < n) return [normalized];\n\n    const ngrams: string[] = [];\n    for (let i = 0; i <= normalized.length - n; i++) {\n      ngrams.push(normalized.slice(i, i + n));\n    }\n    return ngrams;\n  }\n\n  /**\n   * Calculate basic edit distance (Levenshtein)\n   */\n  calculateEditDistance(str1: string, str2: string): number {\n    const matrix: number[][] = [];\n    const len1 = str1.length;\n    const len2 = str2.length;\n\n    // Initialize matrix\n    for (let i = 0; i <= len1; i++) {\n      matrix[i] = [i];\n    }\n    for (let j = 0; j <= len2; j++) {\n      matrix[0][j] = j;\n    }\n\n    // Fill matrix\n    for (let i = 1; i <= len1; i++) {\n      for (let j = 1; j <= len2; j++) {\n        const cost = str1[i - 1] === str2[j - 1] ? 0 : 1;\n        matrix[i][j] = Math.min(\n          matrix[i - 1][j] + 1, // deletion\n          matrix[i][j - 1] + 1, // insertion\n          matrix[i - 1][j - 1] + cost // substitution\n        );\n      }\n    }\n\n    return matrix[len1][len2];\n  }\n}\n","import { BaseLanguageProcessor } from \"../base/LanguageProcessor.js\";\nimport type { FuzzyFeature } from \"../../core/types.js\";\n\n/**\n * German language processor with specialized features:\n * - Umlaut normalization (ä, ö, ü, ß)\n * - Compound word splitting\n * - German-specific phonetic matching (Kölner Phonetik)\n * - Common German word endings\n */\nexport class GermanProcessor extends BaseLanguageProcessor {\n  readonly language = \"german\";\n  readonly displayName = \"Deutsch\";\n  readonly supportedFeatures: FuzzyFeature[] = [\"phonetic\", \"compound\", \"synonyms\", \"keyboard-neighbors\", \"partial-words\", \"missing-letters\", \"extra-letters\"];\n\n  /**\n   * German text normalization with umlaut handling\n   */\n  normalize(text: string): string {\n    return (\n      text\n        .toLowerCase()\n        .trim()\n        .replace(/\\s+/g, \" \")\n        // Normalize umlauts\n        .replace(/ä/g, \"ae\")\n        .replace(/ö/g, \"oe\")\n        .replace(/ü/g, \"ue\")\n        .replace(/ß/g, \"ss\")\n    );\n  }\n\n  /**\n   * Kölner Phonetik algorithm for German phonetic matching\n   */\n  getPhoneticCode(word: string): string {\n    const normalized = this.normalize(word);\n    if (normalized.length === 0) return \"\";\n\n    let code = \"\";\n    let prev = \"\";\n\n    for (let i = 0; i < normalized.length; i++) {\n      const char = normalized[i];\n      const next = i < normalized.length - 1 ? normalized[i + 1] : \"\";\n      let digit = \"\";\n\n      switch (char) {\n        case \"a\":\n        case \"e\":\n        case \"i\":\n        case \"j\":\n        case \"o\":\n        case \"u\":\n        case \"y\":\n          digit = \"0\";\n          break;\n        case \"h\":\n          // H is ignored\n          continue;\n        case \"b\":\n        case \"p\":\n          digit = \"1\";\n          break;\n        case \"d\":\n        case \"t\":\n          if (next === \"c\" || next === \"s\" || next === \"z\") {\n            digit = \"8\";\n          } else {\n            digit = \"2\";\n          }\n          break;\n        case \"f\":\n        case \"v\":\n        case \"w\":\n          digit = \"3\";\n          break;\n        case \"g\":\n        case \"k\":\n        case \"q\":\n          digit = \"4\";\n          break;\n        case \"c\":\n          if (i === 0) {\n            if (next === \"a\" || next === \"h\" || next === \"k\" || next === \"l\" || next === \"o\" || next === \"q\" || next === \"r\" || next === \"u\" || next === \"x\") {\n              digit = \"4\";\n            } else {\n              digit = \"8\";\n            }\n          } else {\n            if (prev === \"s\" || prev === \"z\") {\n              digit = \"8\";\n            } else if (next === \"h\") {\n              digit = \"4\";\n            } else if (next === \"k\" || next === \"q\") {\n              digit = \"4\";\n            } else {\n              digit = \"8\";\n            }\n          }\n          break;\n        case \"x\":\n          if (prev === \"c\" || prev === \"k\" || prev === \"q\") {\n            digit = \"8\";\n          } else {\n            digit = \"48\";\n          }\n          break;\n        case \"l\":\n          digit = \"5\";\n          break;\n        case \"m\":\n        case \"n\":\n          digit = \"6\";\n          break;\n        case \"r\":\n          digit = \"7\";\n          break;\n        case \"s\":\n        case \"z\":\n          digit = \"8\";\n          break;\n        default:\n          continue;\n      }\n\n      // Don't add consecutive identical digits\n      if (digit && digit !== prev) {\n        code += digit;\n      }\n      prev = digit;\n    }\n\n    return code || \"0\";\n  }\n\n  /**\n   * German compound word splitting\n   * Uses common German compound patterns and a dictionary approach\n   */\n  splitCompoundWords(word: string): string[] {\n    const normalized = this.normalize(word);\n    if (normalized.length < 6) return [word]; // Too short to be compound\n\n    const parts: string[] = [];\n    const commonPrefixes = this.getCommonPrefixes();\n    const commonSuffixes = this.getCommonSuffixes();\n    const commonWords = this.getCommonWords();\n\n    // Try to find known prefixes\n    for (const prefix of commonPrefixes) {\n      if (normalized.startsWith(prefix) && normalized.length > prefix.length + 3) {\n        const remainder = normalized.slice(prefix.length);\n        parts.push(prefix);\n        parts.push(...this.splitCompoundWords(remainder));\n        break;\n      }\n    }\n\n    if (parts.length === 0) {\n      // Try to find known suffixes\n      for (const suffix of commonSuffixes) {\n        if (normalized.endsWith(suffix) && normalized.length > suffix.length + 3) {\n          const remainder = normalized.slice(0, -suffix.length);\n          parts.push(...this.splitCompoundWords(remainder));\n          parts.push(suffix);\n          break;\n        }\n      }\n    }\n\n    if (parts.length === 0) {\n      // Try to find known words within the compound\n      for (let i = 3; i <= normalized.length - 3; i++) {\n        const leftPart = normalized.slice(0, i);\n        const rightPart = normalized.slice(i);\n\n        if (commonWords.has(leftPart) && rightPart.length >= 3) {\n          parts.push(leftPart);\n          parts.push(...this.splitCompoundWords(rightPart));\n          break;\n        }\n      }\n    }\n\n    return parts.length > 0 ? parts : [word];\n  }\n\n  /**\n   * German word variants including common endings\n   */\n  getWordVariants(word: string): string[] {\n    const variants = new Set<string>();\n    const normalized = this.normalize(word);\n\n    variants.add(normalized);\n    variants.add(word);\n\n    // Add compound word parts\n    const compoundParts = this.splitCompoundWords(word);\n    compoundParts.forEach((part) => variants.add(this.normalize(part)));\n\n    // Add variants without German endings\n    const germanEndings = this.getCommonEndings();\n    for (const ending of germanEndings) {\n      if (normalized.endsWith(ending) && normalized.length > ending.length + 2) {\n        variants.add(normalized.slice(0, -ending.length));\n      }\n    }\n\n    // Add partial variants\n    if (normalized.length > 4) {\n      for (let i = 3; i < normalized.length; i++) {\n        variants.add(normalized.slice(0, i));\n      }\n    }\n\n    return Array.from(variants);\n  }\n\n  /**\n   * German word endings\n   */\n  protected getCommonEndings(): string[] {\n    return [\n      //\n      \"en\",\n      \"e\",\n      \"er\",\n      \"n\",\n      \"r\",\n      \"s\",\n      \"es\",\n      \"t\",\n      \"ung\",\n      \"heit\",\n      \"keit\",\n      \"schaft\",\n      \"chen\",\n      \"lein\",\n      \"lich\",\n      \"ig\",\n      \"isch\",\n      \"bar\",\n      \"los\",\n      \"voll\",\n    ];\n  }\n\n  /**\n   * German synonyms for common words\n   */\n  getSynonyms(word: string): string[] {\n    const synonymMap: Record<string, string[]> = {\n      arzt: [\n        //\n        \"doktor\",\n        \"mediziner\",\n        \"doc\",\n      ],\n      krankenhaus: [\n        //\n        \"spital\",\n        \"klinik\",\n        \"hospital\",\n      ],\n      schule: [\n        //\n        \"bildungseinrichtung\",\n        \"lehranstalt\",\n      ],\n      auto: [\n        //\n        \"wagen\",\n        \"fahrzeug\",\n        \"pkw\",\n      ],\n      haus: [\n        //\n        \"gebaeude\",\n        \"heim\",\n        \"wohnhaus\",\n      ],\n      strasse: [\n        //\n        \"weg\",\n        \"gasse\",\n        \"allee\",\n      ],\n      stadt: [\n        //\n        \"ort\",\n        \"gemeinde\",\n        \"ortschaft\",\n      ],\n      arbeit: [\n        //\n        \"job\",\n        \"beruf\",\n        \"taetigkeit\",\n      ],\n      geld: [\n        //\n        \"waehrung\",\n        \"kapital\",\n        \"finanzen\",\n      ],\n      zeit: [\n        //\n        \"dauer\",\n        \"periode\",\n        \"zeitraum\",\n      ],\n    };\n\n    const normalized = this.normalize(word);\n    return synonymMap[normalized] || [];\n  }\n\n  /**\n   * German keyboard layout (QWERTZ)\n   */\n  protected getKeyboardNeighbors(): Record<string, string[]> {\n    return {\n      q: [\n        //\n        \"w\",\n        \"a\",\n        \"s\",\n      ],\n      w: [\n        //\n        \"q\",\n        \"e\",\n        \"a\",\n        \"s\",\n        \"d\",\n      ],\n      e: [\n        //\n        \"w\",\n        \"r\",\n        \"s\",\n        \"d\",\n        \"f\",\n      ],\n      r: [\n        //\n        \"e\",\n        \"t\",\n        \"d\",\n        \"f\",\n        \"g\",\n      ],\n      t: [\n        //\n        \"r\",\n        \"z\",\n        \"f\",\n        \"g\",\n        \"h\",\n      ],\n      z: [\n        //\n        \"t\",\n        \"u\",\n        \"g\",\n        \"h\",\n        \"j\",\n      ], // QWERTZ difference\n      u: [\n        //\n        \"z\",\n        \"i\",\n        \"h\",\n        \"j\",\n        \"k\",\n      ],\n      i: [\n        //\n        \"u\",\n        \"o\",\n        \"j\",\n        \"k\",\n        \"l\",\n      ],\n      o: [\n        //\n        \"i\",\n        \"p\",\n        \"k\",\n        \"l\",\n        \"oe\",\n      ],\n      p: [\n        //\n        \"o\",\n        \"ue\",\n        \"l\",\n        \"oe\",\n      ],\n      ue: [\n        //\n        \"p\",\n        \"ae\",\n      ], // German umlaut\n      a: [\n        //\n        \"q\",\n        \"w\",\n        \"s\",\n        \"y\",\n        \"x\",\n      ],\n      s: [\n        //\n        \"q\",\n        \"w\",\n        \"e\",\n        \"a\",\n        \"d\",\n        \"y\",\n        \"x\",\n        \"c\",\n      ],\n      d: [\n        //\n        \"w\",\n        \"e\",\n        \"r\",\n        \"s\",\n        \"f\",\n        \"x\",\n        \"c\",\n        \"v\",\n      ],\n      f: [\n        //\n        \"e\",\n        \"r\",\n        \"t\",\n        \"d\",\n        \"g\",\n        \"c\",\n        \"v\",\n        \"b\",\n      ],\n      g: [\n        //\n        \"r\",\n        \"t\",\n        \"z\",\n        \"f\",\n        \"h\",\n        \"v\",\n        \"b\",\n        \"n\",\n      ],\n      h: [\n        //\n        \"t\",\n        \"z\",\n        \"u\",\n        \"g\",\n        \"j\",\n        \"b\",\n        \"n\",\n        \"m\",\n      ],\n      j: [\n        //\n        \"z\",\n        \"u\",\n        \"i\",\n        \"h\",\n        \"k\",\n        \"n\",\n        \"m\",\n      ],\n      k: [\n        //\n        \"u\",\n        \"i\",\n        \"o\",\n        \"j\",\n        \"l\",\n        \"m\",\n      ],\n      l: [\n        //\n        \"i\",\n        \"o\",\n        \"p\",\n        \"k\",\n        \"oe\",\n      ],\n      oe: [\n        //\n        \"o\",\n        \"p\",\n        \"ue\",\n        \"l\",\n        \"ae\",\n      ], // German umlaut\n      ae: [\n        //\n        \"ue\",\n        \"oe\",\n      ], // German umlaut\n      y: [\n        //\n        \"a\",\n        \"s\",\n        \"x\",\n      ], // QWERTZ difference\n      x: [\n        //\n        \"a\",\n        \"s\",\n        \"d\",\n        \"y\",\n        \"c\",\n      ],\n      c: [\n        //\n        \"s\",\n        \"d\",\n        \"f\",\n        \"x\",\n        \"v\",\n      ],\n      v: [\n        //\n        \"d\",\n        \"f\",\n        \"g\",\n        \"c\",\n        \"b\",\n      ],\n      b: [\n        //\n        \"f\",\n        \"g\",\n        \"h\",\n        \"v\",\n        \"n\",\n      ],\n      n: [\n        //\n        \"g\",\n        \"h\",\n        \"j\",\n        \"b\",\n        \"m\",\n      ],\n      m: [\n        //\n        \"h\",\n        \"j\",\n        \"k\",\n        \"n\",\n      ],\n    };\n  }\n\n  /**\n   * Common German prefixes for compound word splitting\n   */\n  private getCommonPrefixes(): string[] {\n    return [\"un\", \"vor\", \"nach\", \"bei\", \"mit\", \"ab\", \"an\", \"auf\", \"aus\", \"ein\", \"gegen\", \"hinter\", \"neben\", \"ueber\", \"unter\", \"zwischen\", \"selbst\"];\n  }\n\n  /**\n   * Common German suffixes for compound word splitting\n   */\n  private getCommonSuffixes(): string[] {\n    return [\"haus\", \"platz\", \"strasse\", \"weg\", \"hof\", \"berg\", \"tal\", \"feld\", \"stadt\", \"dorf\", \"heim\", \"werk\", \"bau\", \"anlage\", \"zentrum\"];\n  }\n\n  /**\n   * Common German words for compound splitting\n   */\n  private getCommonWords(): Set<string> {\n    return new Set([\"kranken\", \"kinder\", \"frauen\", \"maenner\", \"alt\", \"neu\", \"gross\", \"klein\", \"hoch\", \"tief\", \"lang\", \"kurz\", \"breit\", \"schmal\", \"dick\", \"duenn\", \"stark\", \"schwach\", \"schnell\", \"langsam\", \"heiss\", \"kalt\", \"warm\", \"auto\", \"bahn\", \"bus\", \"zug\", \"flug\", \"schiff\", \"rad\", \"motor\", \"wasser\", \"feuer\", \"erde\", \"luft\", \"licht\", \"schatten\", \"sonne\", \"mond\", \"tag\", \"nacht\", \"morgen\", \"abend\", \"mittag\", \"zeit\", \"jahr\", \"monat\"]);\n  }\n}\n","import { BaseLanguageProcessor } from \"../base/LanguageProcessor.js\";\nimport type { FuzzyFeature } from \"../../core/types.js\";\n\n/**\n * English language processor with specialized features:\n * - Metaphone phonetic algorithm\n * - Common English contractions\n * - English-specific word endings\n * - Comprehensive synonym support\n */\nexport class EnglishProcessor extends BaseLanguageProcessor {\n  readonly language = \"english\";\n  readonly displayName = \"English\";\n  readonly supportedFeatures: FuzzyFeature[] = [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n    \"extra-letters\",\n    \"transpositions\",\n  ];\n\n  /**\n   * English text normalization with contraction handling\n   */\n  normalize(text: string): string {\n    return (\n      text\n        .toLowerCase()\n        .trim()\n        .replace(/\\s+/g, \" \")\n        // Handle common contractions\n        .replace(/won't/g, \"will not\")\n        .replace(/can't/g, \"cannot\")\n        .replace(/n't/g, \" not\")\n        .replace(/'re/g, \" are\")\n        .replace(/'ve/g, \" have\")\n        .replace(/'ll/g, \" will\")\n        .replace(/'d/g, \" would\")\n        .replace(/'m/g, \" am\")\n        .replace(/'/g, \"\")\n    ); // Remove remaining apostrophes\n  }\n\n  /**\n   * Simplified Metaphone algorithm for English phonetic matching\n   */\n  getPhoneticCode(word: string): string {\n    const normalized = this.normalize(word).replace(/[^a-z]/g, \"\");\n    if (normalized.length === 0) return \"\";\n\n    let metaphone = \"\";\n    let current = 0;\n    const length = normalized.length;\n\n    // Handle initial letters\n    if (normalized.startsWith(\"gn\") || normalized.startsWith(\"kn\") || normalized.startsWith(\"pn\") || normalized.startsWith(\"wr\")) {\n      current = 1;\n    }\n\n    while (current < length && metaphone.length < 4) {\n      const char = normalized[current];\n      const next = current + 1 < length ? normalized[current + 1] : \"\";\n      const prev = current > 0 ? normalized[current - 1] : \"\";\n\n      switch (char) {\n        case \"a\":\n        case \"e\":\n        case \"i\":\n        case \"o\":\n        case \"u\":\n          if (current === 0) metaphone += char.toUpperCase();\n          break;\n        case \"b\":\n          if (current === length - 1 && prev === \"m\") {\n            // Silent B at end after M\n          } else {\n            metaphone += \"B\";\n          }\n          break;\n        case \"c\":\n          if (next === \"h\") {\n            metaphone += \"X\";\n            current++;\n          } else if (next === \"i\" || next === \"e\" || next === \"y\") {\n            metaphone += \"S\";\n          } else {\n            metaphone += \"K\";\n          }\n          break;\n        case \"d\":\n          if (next === \"g\") {\n            metaphone += \"J\";\n            current++;\n          } else {\n            metaphone += \"T\";\n          }\n          break;\n        case \"f\":\n          metaphone += \"F\";\n          break;\n        case \"g\":\n          if (next === \"h\" && current !== 0) {\n            // Silent GH\n          } else if (next === \"n\") {\n            metaphone += \"N\";\n            current++;\n          } else if (next === \"i\" || next === \"e\" || next === \"y\") {\n            metaphone += \"J\";\n          } else {\n            metaphone += \"K\";\n          }\n          break;\n        case \"h\":\n          if (current === 0 || \"aeiou\".includes(prev) || \"aeiou\".includes(next)) {\n            metaphone += \"H\";\n          }\n          break;\n        case \"j\":\n          metaphone += \"J\";\n          break;\n        case \"k\":\n          if (prev !== \"c\") {\n            metaphone += \"K\";\n          }\n          break;\n        case \"l\":\n          metaphone += \"L\";\n          break;\n        case \"m\":\n          metaphone += \"M\";\n          break;\n        case \"n\":\n          metaphone += \"N\";\n          break;\n        case \"p\":\n          if (next === \"h\") {\n            metaphone += \"F\";\n            current++;\n          } else {\n            metaphone += \"P\";\n          }\n          break;\n        case \"q\":\n          metaphone += \"K\";\n          break;\n        case \"r\":\n          metaphone += \"R\";\n          break;\n        case \"s\":\n          if (next === \"h\") {\n            metaphone += \"X\";\n            current++;\n          } else {\n            metaphone += \"S\";\n          }\n          break;\n        case \"t\":\n          if (next === \"h\") {\n            metaphone += \"0\";\n            current++;\n          } else if (next === \"i\" && current + 2 < length && (normalized[current + 2] === \"a\" || normalized[current + 2] === \"o\")) {\n            metaphone += \"X\";\n          } else {\n            metaphone += \"T\";\n          }\n          break;\n        case \"v\":\n          metaphone += \"F\";\n          break;\n        case \"w\":\n          if (\"aeiou\".includes(next)) {\n            metaphone += \"W\";\n          }\n          break;\n        case \"x\":\n          metaphone += \"KS\";\n          break;\n        case \"y\":\n          if (\"aeiou\".includes(next)) {\n            metaphone += \"Y\";\n          }\n          break;\n        case \"z\":\n          metaphone += \"S\";\n          break;\n      }\n      current++;\n    }\n\n    return metaphone || \"A\";\n  }\n\n  /**\n   * English word variants\n   */\n  getWordVariants(word: string): string[] {\n    const variants = new Set<string>();\n    const normalized = this.normalize(word);\n\n    variants.add(normalized);\n    variants.add(word);\n\n    // Add variants without English endings\n    const englishEndings = this.getCommonEndings();\n    for (const ending of englishEndings) {\n      if (normalized.endsWith(ending) && normalized.length > ending.length + 2) {\n        variants.add(normalized.slice(0, -ending.length));\n      }\n    }\n\n    // Add plural/singular variants\n    if (normalized.endsWith(\"s\") && normalized.length > 3) {\n      variants.add(normalized.slice(0, -1));\n    }\n    if (!normalized.endsWith(\"s\")) {\n      variants.add(normalized + \"s\");\n    }\n\n    // Add -ing/-ed variants\n    if (normalized.endsWith(\"ing\") && normalized.length > 5) {\n      const base = normalized.slice(0, -3);\n      variants.add(base);\n      variants.add(base + \"e\"); // handle dropped 'e'\n    }\n    if (normalized.endsWith(\"ed\") && normalized.length > 4) {\n      const base = normalized.slice(0, -2);\n      variants.add(base);\n      variants.add(base + \"e\"); // handle dropped 'e'\n    }\n\n    // Add partial variants\n    if (normalized.length > 4) {\n      for (let i = 3; i < normalized.length; i++) {\n        variants.add(normalized.slice(0, i));\n      }\n    }\n\n    return Array.from(variants);\n  }\n\n  /**\n   * English word endings\n   */\n  protected getCommonEndings(): string[] {\n    return [\n      //\n      \"s\",\n      \"es\",\n      \"ed\",\n      \"ing\",\n      \"er\",\n      \"est\",\n      \"ly\",\n      \"tion\",\n      \"sion\",\n      \"ness\",\n      \"ment\",\n      \"able\",\n      \"ible\",\n      \"ful\",\n      \"less\",\n      \"ous\",\n      \"ious\",\n      \"al\",\n      \"ial\",\n      \"ic\",\n      \"ive\",\n      \"ary\",\n      \"ery\",\n      \"ory\",\n    ];\n  }\n\n  /**\n   * English synonyms for common words\n   */\n  getSynonyms(word: string): string[] {\n    const synonymMap: Record<string, string[]> = {\n      doctor: [\n        //\n        \"physician\",\n        \"medic\",\n        \"doc\",\n        \"md\",\n      ],\n      hospital: [\n        //\n        \"clinic\",\n        \"medical center\",\n        \"infirmary\",\n      ],\n      school: [\n        //\n        \"academy\",\n        \"institution\",\n        \"college\",\n        \"university\",\n      ],\n      car: [\n        //\n        \"vehicle\",\n        \"automobile\",\n        \"auto\",\n      ],\n      house: [\n        //\n        \"home\",\n        \"residence\",\n        \"dwelling\",\n        \"building\",\n      ],\n      street: [\n        //\n        \"road\",\n        \"avenue\",\n        \"lane\",\n        \"boulevard\",\n      ],\n      city: [\n        //\n        \"town\",\n        \"municipality\",\n        \"urban area\",\n      ],\n      work: [\n        //\n        \"job\",\n        \"employment\",\n        \"occupation\",\n        \"career\",\n      ],\n      money: [\n        //\n        \"cash\",\n        \"currency\",\n        \"funds\",\n        \"capital\",\n      ],\n      time: [\n        //\n        \"duration\",\n        \"period\",\n        \"moment\",\n        \"hour\",\n      ],\n      big: [\n        //\n        \"large\",\n        \"huge\",\n        \"enormous\",\n        \"massive\",\n        \"giant\",\n      ],\n      small: [\n        //\n        \"little\",\n        \"tiny\",\n        \"miniature\",\n        \"petite\",\n      ],\n      fast: [\n        //\n        \"quick\",\n        \"rapid\",\n        \"speedy\",\n        \"swift\",\n      ],\n      slow: [\n        //\n        \"sluggish\",\n        \"gradual\",\n        \"leisurely\",\n      ],\n      good: [\n        //\n        \"excellent\",\n        \"great\",\n        \"wonderful\",\n        \"fine\",\n      ],\n      bad: [\n        //\n        \"poor\",\n        \"terrible\",\n        \"awful\",\n        \"horrible\",\n      ],\n      happy: [\n        //\n        \"joyful\",\n        \"cheerful\",\n        \"glad\",\n        \"pleased\",\n      ],\n      sad: [\n        //\n        \"unhappy\",\n        \"depressed\",\n        \"melancholy\",\n        \"sorrowful\",\n      ],\n    };\n\n    const normalized = this.normalize(word);\n    return synonymMap[normalized] || [];\n  }\n}\n","import { BaseLanguageProcessor } from \"../base/LanguageProcessor.js\";\nimport type { FuzzyFeature } from \"../../core/types.js\";\n\n/**\n * Spanish language processor with specialized features:\n * - Accent normalization (á, é, í, ó, ú, ñ)\n * - Spanish phonetic patterns\n * - Common Spanish word endings\n * - Spanish synonym support\n */\nexport class SpanishProcessor extends BaseLanguageProcessor {\n  readonly language = \"spanish\";\n  readonly displayName = \"Español\";\n  readonly supportedFeatures: FuzzyFeature[] = [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n    \"extra-letters\",\n  ];\n\n  /**\n   * Spanish text normalization with accent handling\n   */\n  normalize(text: string): string {\n    return (\n      text\n        .toLowerCase()\n        .trim()\n        .replace(/\\s+/g, \" \")\n        // Normalize accented characters\n        .replace(/á/g, \"a\")\n        .replace(/é/g, \"e\")\n        .replace(/í/g, \"i\")\n        .replace(/ó/g, \"o\")\n        .replace(/ú/g, \"u\")\n        .replace(/ñ/g, \"n\")\n        .replace(/ü/g, \"u\")\n    );\n  }\n\n  /**\n   * Spanish phonetic matching\n   */\n  getPhoneticCode(word: string): string {\n    const normalized = this.normalize(word);\n    if (normalized.length === 0) return \"\";\n\n    let code = \"\";\n    let prev = \"\";\n\n    for (let i = 0; i < normalized.length; i++) {\n      const char = normalized[i];\n      const next = i < normalized.length - 1 ? normalized[i + 1] : \"\";\n      let digit = \"\";\n\n      switch (char) {\n        case \"a\":\n        case \"e\":\n        case \"i\":\n        case \"o\":\n        case \"u\":\n          digit = \"0\";\n          break;\n        case \"b\":\n        case \"v\": // B and V sound similar in Spanish\n          digit = \"1\";\n          break;\n        case \"c\":\n          if (next === \"h\") {\n            digit = \"2\"; // CH sound\n          } else if (next === \"e\" || next === \"i\") {\n            digit = \"8\"; // CE, CI sounds like S\n          } else {\n            digit = \"4\";\n          }\n          break;\n        case \"d\":\n          digit = \"3\";\n          break;\n        case \"f\":\n          digit = \"5\";\n          break;\n        case \"g\":\n          if (next === \"u\" && i + 2 < normalized.length && (normalized[i + 2] === \"e\" || normalized[i + 2] === \"i\")) {\n            digit = \"4\"; // GUE, GUI\n          } else if (next === \"e\" || next === \"i\") {\n            digit = \"6\"; // GE, GI sound like J\n          } else {\n            digit = \"4\";\n          }\n          break;\n        case \"h\":\n          // H is silent in Spanish\n          continue;\n        case \"j\":\n          digit = \"6\";\n          break;\n        case \"k\":\n          digit = \"4\";\n          break;\n        case \"l\":\n          if (next === \"l\") {\n            digit = \"7\"; // LL sound\n          } else {\n            digit = \"5\";\n          }\n          break;\n        case \"m\":\n          digit = \"6\";\n          break;\n        case \"n\":\n          if (next === \"n\") {\n            digit = \"7\"; // NN sound (rare)\n          } else {\n            digit = \"6\";\n          }\n          break;\n        case \"ñ\":\n          digit = \"7\"; // Ñ sound\n          break;\n        case \"p\":\n          digit = \"1\";\n          break;\n        case \"q\":\n          digit = \"4\";\n          break;\n        case \"r\":\n          if (next === \"r\" || i === 0) {\n            digit = \"8\"; // RR or initial R\n          } else {\n            digit = \"7\";\n          }\n          break;\n        case \"s\":\n          digit = \"8\";\n          break;\n        case \"t\":\n          digit = \"3\";\n          break;\n        case \"w\":\n          digit = \"1\"; // Rare in Spanish\n          break;\n        case \"x\":\n          digit = \"48\";\n          break;\n        case \"y\":\n          digit = \"7\";\n          break;\n        case \"z\":\n          digit = \"8\";\n          break;\n        default:\n          continue;\n      }\n\n      if (digit && digit !== prev) {\n        code += digit;\n      }\n      prev = digit;\n    }\n\n    return code || \"0\";\n  }\n\n  /**\n   * Spanish word endings\n   */\n  protected getCommonEndings(): string[] {\n    return [\n      //\n      \"o\",\n      \"a\",\n      \"os\",\n      \"as\",\n      \"e\",\n      \"es\",\n      \"ar\",\n      \"er\",\n      \"ir\",\n      \"ado\",\n      \"ada\",\n      \"idos\",\n      \"idas\",\n      \"ando\",\n      \"endo\",\n      \"iendo\",\n      \"cion\",\n      \"sion\",\n      \"dad\",\n      \"tad\",\n      \"mente\",\n      \"oso\",\n      \"osa\",\n      \"ito\",\n      \"ita\",\n      \"illo\",\n      \"illa\",\n    ];\n  }\n\n  /**\n   * Spanish synonyms\n   */\n  getSynonyms(word: string): string[] {\n    const synonymMap: Record<string, string[]> = {\n      medico: [\n        //\n        \"doctor\",\n        \"facultativo\",\n      ],\n      hospital: [\n        //\n        \"clinica\",\n        \"sanatorio\",\n      ],\n      escuela: [\n        //\n        \"colegio\",\n        \"instituto\",\n      ],\n      coche: [\n        //\n        \"auto\",\n        \"automovil\",\n        \"vehiculo\",\n      ],\n      casa: [\n        //\n        \"hogar\",\n        \"vivienda\",\n        \"domicilio\",\n      ],\n      calle: [\n        //\n        \"via\",\n        \"avenida\",\n        \"carretera\",\n      ],\n      ciudad: [\n        //\n        \"urbe\",\n        \"poblacion\",\n        \"municipio\",\n      ],\n      trabajo: [\n        //\n        \"empleo\",\n        \"ocupacion\",\n        \"labor\",\n      ],\n      dinero: [\n        //\n        \"plata\",\n        \"efectivo\",\n        \"capital\",\n      ],\n      tiempo: [\n        //\n        \"momento\",\n        \"periodo\",\n        \"duracion\",\n      ],\n      grande: [\n        //\n        \"enorme\",\n        \"gigante\",\n        \"inmenso\",\n      ],\n      pequeno: [\n        //\n        \"chico\",\n        \"diminuto\",\n        \"minusculo\",\n      ],\n      rapido: [\n        //\n        \"veloz\",\n        \"ligero\",\n        \"acelerado\",\n      ],\n      lento: [\n        //\n        \"despacio\",\n        \"pausado\",\n      ],\n      bueno: [\n        //\n        \"excelente\",\n        \"magnifico\",\n        \"estupendo\",\n      ],\n      malo: [\n        //\n        \"pesimo\",\n        \"terrible\",\n        \"horrible\",\n      ],\n    };\n\n    const normalized = this.normalize(word);\n    return synonymMap[normalized] || [];\n  }\n}\n","import { BaseLanguageProcessor } from \"../base/LanguageProcessor.js\";\nimport type { FuzzyFeature } from \"../../core/types.js\";\n\n/**\n * French language processor with specialized features:\n * - Accent normalization (à, é, è, ê, ç, etc.)\n * - French phonetic patterns\n * - Common French word endings\n * - French synonym support\n */\nexport class FrenchProcessor extends BaseLanguageProcessor {\n  readonly language = \"french\";\n  readonly displayName = \"Français\";\n  readonly supportedFeatures: FuzzyFeature[] = [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n    \"extra-letters\",\n  ];\n\n  /**\n   * French text normalization with accent handling\n   */\n  normalize(text: string): string {\n    return (\n      text\n        .toLowerCase()\n        .trim()\n        .replace(/\\s+/g, \" \")\n        // Normalize accented characters\n        .replace(/[àáâãä]/g, \"a\")\n        .replace(/[èéêë]/g, \"e\")\n        .replace(/[ìíîï]/g, \"i\")\n        .replace(/[òóôõö]/g, \"o\")\n        .replace(/[ùúûü]/g, \"u\")\n        .replace(/ç/g, \"c\")\n        .replace(/ñ/g, \"n\")\n        .replace(/ÿ/g, \"y\")\n    );\n  }\n\n  /**\n   * French phonetic matching\n   */\n  getPhoneticCode(word: string): string {\n    const normalized = this.normalize(word);\n    if (normalized.length === 0) return \"\";\n\n    let code = \"\";\n    let prev = \"\";\n\n    for (let i = 0; i < normalized.length; i++) {\n      const char = normalized[i];\n      const next = i < normalized.length - 1 ? normalized[i + 1] : \"\";\n      const next2 = i < normalized.length - 2 ? normalized[i + 2] : \"\";\n      let digit = \"\";\n\n      switch (char) {\n        case \"a\":\n        case \"e\":\n        case \"i\":\n        case \"o\":\n        case \"u\":\n        case \"y\":\n          digit = \"0\";\n          break;\n        case \"b\":\n          digit = \"1\";\n          break;\n        case \"c\":\n          if (next === \"h\") {\n            digit = \"2\"; // CH sound\n          } else if (next === \"e\" || next === \"i\") {\n            digit = \"8\"; // CE, CI sounds like S\n          } else {\n            digit = \"4\";\n          }\n          break;\n        case \"d\":\n          digit = \"3\";\n          break;\n        case \"f\":\n          digit = \"5\";\n          break;\n        case \"g\":\n          if (next === \"n\") {\n            digit = \"6\"; // GN sound\n          } else if (next === \"u\" && (next2 === \"e\" || next2 === \"i\")) {\n            digit = \"4\"; // GUE, GUI\n          } else if (next === \"e\" || next === \"i\") {\n            digit = \"6\"; // GE, GI sound like J\n          } else {\n            digit = \"4\";\n          }\n          break;\n        case \"h\":\n          // H is often silent in French\n          if (i === 0) {\n            digit = \"0\"; // Initial H\n          }\n          break;\n        case \"j\":\n          digit = \"6\";\n          break;\n        case \"k\":\n          digit = \"4\";\n          break;\n        case \"l\":\n          digit = \"5\";\n          break;\n        case \"m\":\n          digit = \"6\";\n          break;\n        case \"n\":\n          digit = \"6\";\n          break;\n        case \"p\":\n          if (next === \"h\") {\n            digit = \"5\"; // PH sounds like F\n          } else {\n            digit = \"1\";\n          }\n          break;\n        case \"q\":\n          digit = \"4\";\n          break;\n        case \"r\":\n          digit = \"7\";\n          break;\n        case \"s\":\n          digit = \"8\";\n          break;\n        case \"t\":\n          if (next === \"h\") {\n            digit = \"3\"; // TH sound\n          } else {\n            digit = \"3\";\n          }\n          break;\n        case \"v\":\n          digit = \"5\";\n          break;\n        case \"w\":\n          digit = \"5\"; // Rare in French\n          break;\n        case \"x\":\n          digit = \"48\";\n          break;\n        case \"z\":\n          digit = \"8\";\n          break;\n        default:\n          continue;\n      }\n\n      if (digit && digit !== prev) {\n        code += digit;\n      }\n      prev = digit;\n    }\n\n    return code || \"0\";\n  }\n\n  /**\n   * French word endings\n   */\n  protected getCommonEndings(): string[] {\n    return [\"e\", \"es\", \"s\", \"x\", \"ent\", \"ant\", \"ment\", \"tion\", \"sion\", \"eur\", \"euse\", \"teur\", \"trice\", \"able\", \"ible\", \"ique\", \"aire\", \"oire\", \"ette\", \"elle\", \"esse\", \"asse\", \"isse\", \"age\", \"isme\", \"iste\", \"ite\", \"ude\", \"ade\"];\n  }\n\n  /**\n   * French synonyms\n   */\n  getSynonyms(word: string): string[] {\n    const synonymMap: Record<string, string[]> = {\n      medecin: [\n        //\n        \"docteur\",\n        \"praticien\",\n      ],\n      hopital: [\n        //\n        \"clinique\",\n        \"centre medical\",\n      ],\n      ecole: [\n        //\n        \"etablissement\",\n        \"institution\",\n      ],\n      voiture: [\n        //\n        \"automobile\",\n        \"vehicule\",\n        \"auto\",\n      ],\n      maison: [\n        //\n        \"domicile\",\n        \"residence\",\n        \"habitation\",\n      ],\n      rue: [\n        //\n        \"avenue\",\n        \"boulevard\",\n        \"voie\",\n      ],\n      ville: [\n        //\n        \"cite\",\n        \"commune\",\n        \"agglomeration\",\n      ],\n      travail: [\n        //\n        \"emploi\",\n        \"occupation\",\n        \"metier\",\n      ],\n      argent: [\n        //\n        \"monnaie\",\n        \"especes\",\n        \"capital\",\n      ],\n      temps: [\n        //\n        \"duree\",\n        \"periode\",\n        \"moment\",\n      ],\n      grand: [\n        //\n        \"enorme\",\n        \"immense\",\n        \"gigantesque\",\n      ],\n      petit: [\n        //\n        \"minuscule\",\n        \"minime\",\n        \"reduit\",\n      ],\n      rapide: [\n        //\n        \"vite\",\n        \"accelere\",\n        \"prompt\",\n      ],\n      lent: [\n        //\n        \"lentement\",\n        \"doucement\",\n      ],\n      bon: [\n        //\n        \"excellent\",\n        \"parfait\",\n        \"formidable\",\n      ],\n      mauvais: [\n        //\n        \"terrible\",\n        \"affreux\",\n        \"horrible\",\n      ],\n      heureux: [\n        //\n        \"joyeux\",\n        \"content\",\n        \"ravi\",\n      ],\n      triste: [\n        //\n        \"malheureux\",\n        \"chagrine\",\n        \"melancolique\",\n      ],\n    };\n\n    const normalized = this.normalize(word);\n    return synonymMap[normalized] || [];\n  }\n\n  /**\n   * French keyboard layout (AZERTY)\n   */\n  protected getKeyboardNeighbors(): Record<string, string[]> {\n    return {\n      a: [\n        //\n        \"z\",\n        \"e\",\n        \"r\",\n        \"q\",\n        \"s\",\n      ],\n      z: [\n        //\n        \"a\",\n        \"e\",\n        \"r\",\n        \"q\",\n        \"s\",\n        \"d\",\n      ],\n      e: [\n        //\n        \"z\",\n        \"r\",\n        \"t\",\n        \"s\",\n        \"d\",\n        \"f\",\n      ],\n      r: [\n        //\n        \"e\",\n        \"t\",\n        \"y\",\n        \"d\",\n        \"f\",\n        \"g\",\n      ],\n      t: [\n        //\n        \"r\",\n        \"y\",\n        \"u\",\n        \"f\",\n        \"g\",\n        \"h\",\n      ],\n      y: [\n        //\n        \"t\",\n        \"u\",\n        \"i\",\n        \"g\",\n        \"h\",\n        \"j\",\n      ],\n      u: [\n        //\n        \"y\",\n        \"i\",\n        \"o\",\n        \"h\",\n        \"j\",\n        \"k\",\n      ],\n      i: [\n        //\n        \"u\",\n        \"o\",\n        \"p\",\n        \"j\",\n        \"k\",\n        \"l\",\n      ],\n      o: [\n        //\n        \"i\",\n        \"p\",\n        \"k\",\n        \"l\",\n        \"m\",\n      ],\n      p: [\n        //\n        \"o\",\n        \"l\",\n        \"m\",\n      ],\n      q: [\n        //\n        \"a\",\n        \"z\",\n        \"s\",\n        \"w\",\n        \"x\",\n      ],\n      s: [\n        //\n        \"a\",\n        \"z\",\n        \"e\",\n        \"q\",\n        \"d\",\n        \"w\",\n        \"x\",\n        \"c\",\n      ],\n      d: [\n        //\n        \"z\",\n        \"e\",\n        \"r\",\n        \"s\",\n        \"f\",\n        \"x\",\n        \"c\",\n        \"v\",\n      ],\n      f: [\n        //\n        \"e\",\n        \"r\",\n        \"t\",\n        \"d\",\n        \"g\",\n        \"c\",\n        \"v\",\n        \"b\",\n      ],\n      g: [\n        //\n        \"r\",\n        \"t\",\n        \"y\",\n        \"f\",\n        \"h\",\n        \"v\",\n        \"b\",\n        \"n\",\n      ],\n      h: [\n        //\n        \"t\",\n        \"y\",\n        \"u\",\n        \"g\",\n        \"j\",\n        \"b\",\n        \"n\",\n      ],\n      j: [\n        //\n        \"y\",\n        \"u\",\n        \"i\",\n        \"h\",\n        \"k\",\n        \"n\",\n      ],\n      k: [\n        //\n        \"u\",\n        \"i\",\n        \"o\",\n        \"j\",\n        \"l\",\n      ],\n      l: [\n        //\n        \"i\",\n        \"o\",\n        \"p\",\n        \"k\",\n        \"m\",\n      ],\n      m: [\n        //\n        \"o\",\n        \"p\",\n        \"l\",\n      ],\n      w: [\n        //\n        \"q\",\n        \"s\",\n        \"x\",\n      ],\n      x: [\n        //\n        \"q\",\n        \"s\",\n        \"d\",\n        \"w\",\n        \"c\",\n      ],\n      c: [\n        //\n        \"s\",\n        \"d\",\n        \"f\",\n        \"x\",\n        \"v\",\n      ],\n      v: [\n        //\n        \"d\",\n        \"f\",\n        \"g\",\n        \"c\",\n        \"b\",\n      ],\n      b: [\n        //\n        \"f\",\n        \"g\",\n        \"h\",\n        \"v\",\n        \"n\",\n      ],\n      n: [\n        //\n        \"g\",\n        \"h\",\n        \"j\",\n        \"b\",\n      ],\n    };\n  }\n}\n","import type { LanguageProcessor } from \"../core/types.js\";\nimport { GermanProcessor } from \"./german/GermanProcessor.js\";\nimport { EnglishProcessor } from \"./english/EnglishProcessor.js\";\nimport { SpanishProcessor } from \"./spanish/SpanishProcessor.js\";\nimport { FrenchProcessor } from \"./french/FrenchProcessor.js\";\n\n/**\n * Registry of all available language processors\n */\nexport class LanguageRegistry {\n  private static processors = new Map<string, LanguageProcessor>([\n    [\"german\", new GermanProcessor()],\n    [\"english\", new EnglishProcessor()],\n    [\"spanish\", new SpanishProcessor()],\n    [\"french\", new FrenchProcessor()],\n  ]);\n\n  /**\n   * Get a language processor by name\n   */\n  static getProcessor(language: string): LanguageProcessor | undefined {\n    return this.processors.get(language.toLowerCase());\n  }\n\n  /**\n   * Get multiple language processors\n   */\n  static getProcessors(languages: string[]): LanguageProcessor[] {\n    return languages.map((lang) => this.getProcessor(lang)).filter((processor): processor is LanguageProcessor => processor !== undefined);\n  }\n\n  /**\n   * Get all available language names\n   */\n  static getAvailableLanguages(): string[] {\n    return Array.from(this.processors.keys());\n  }\n\n  /**\n   * Register a custom language processor\n   */\n  static registerProcessor(processor: LanguageProcessor): void {\n    this.processors.set(processor.language.toLowerCase(), processor);\n  }\n\n  /**\n   * Check if a language is supported\n   */\n  static isSupported(language: string): boolean {\n    return this.processors.has(language.toLowerCase());\n  }\n\n  /**\n   * Get processor info for all languages\n   */\n  static getProcessorInfo(): Array<{\n    language: string;\n    displayName: string;\n    supportedFeatures: string[];\n  }> {\n    return Array.from(this.processors.values()).map((processor) => ({\n      language: processor.language,\n      displayName: processor.displayName,\n      supportedFeatures: processor.supportedFeatures,\n    }));\n  }\n}\n\n// Export individual processors for direct use\nexport { GermanProcessor } from \"./german/GermanProcessor.js\";\nexport { EnglishProcessor } from \"./english/EnglishProcessor.js\";\nexport { SpanishProcessor } from \"./spanish/SpanishProcessor.js\";\nexport { FrenchProcessor } from \"./french/FrenchProcessor.js\";\nexport { BaseLanguageProcessor } from \"./base/LanguageProcessor.js\";\n","/**\n * Memory Pooling Utilities\n * Reuse objects and arrays to reduce GC pressure and improve performance\n */\n\n/**\n * Generic object pool for reusing objects\n * Reduces garbage collection overhead by 30-50%\n */\nexport class ObjectPool<T> {\n  private pool: T[] = [];\n  private factory: () => T;\n  private reset?: (obj: T) => void;\n  private maxSize: number;\n\n  constructor(factory: () => T, maxSize: number = 1000, reset?: (obj: T) => void) {\n    this.factory = factory;\n    this.maxSize = maxSize;\n    this.reset = reset;\n  }\n\n  /**\n   * Get an object from the pool or create a new one\n   */\n  acquire(): T {\n    const obj = this.pool.pop();\n    if (obj !== undefined) {\n      return obj;\n    }\n    return this.factory();\n  }\n\n  /**\n   * Return an object to the pool for reuse\n   */\n  release(obj: T): void {\n    if (this.pool.length < this.maxSize) {\n      if (this.reset) {\n        this.reset(obj);\n      }\n      this.pool.push(obj);\n    }\n  }\n\n  /**\n   * Clear the pool\n   */\n  clear(): void {\n    this.pool = [];\n  }\n\n  /**\n   * Get current pool size\n   */\n  size(): number {\n    return this.pool.length;\n  }\n}\n\n/**\n * Array pool for reusing arrays\n * Particularly useful for temporary arrays in hot paths\n * Note: size parameter is just a hint for pool organization\n */\nexport class ArrayPool<T> {\n  private pool: T[][] = [];\n  private maxSize: number;\n\n  constructor(maxSize: number = 1000) {\n    this.maxSize = maxSize;\n  }\n\n  /**\n   * Get an array from the pool (size is just a hint for organization)\n   */\n  acquire(_size?: number): T[] {\n    if (this.pool.length > 0) {\n      return this.pool.pop()!;\n    }\n    return [];\n  }\n\n  /**\n   * Return an array to the pool for reuse\n   */\n  release(arr: T[]): void {\n    if (this.pool.length < this.maxSize) {\n      // Clear array contents\n      arr.length = 0;\n      this.pool.push(arr);\n    }\n  }\n\n  /**\n   * Clear the pool\n   */\n  clear(): void {\n    this.pool = [];\n  }\n\n  /**\n   * Get total number of pooled arrays\n   */\n  size(): number {\n    return this.pool.length;\n  }\n}\n\n/**\n * Global array pool for common operations\n */\nexport const globalArrayPool = new ArrayPool<any>(500);\n\n/**\n * Helper to use pooled array with automatic cleanup\n */\nexport function withPooledArray<T, R>(\n  size: number,\n  fn: (arr: T[]) => R\n): R {\n  const arr = globalArrayPool.acquire(size) as T[];\n  try {\n    return fn(arr);\n  } finally {\n    globalArrayPool.release(arr);\n  }\n}\n\n/**\n * Map pool for reusing Map objects\n */\nexport class MapPool<K, V> {\n  private pool: Map<K, V>[] = [];\n  private maxSize: number;\n\n  constructor(maxSize: number = 100) {\n    this.maxSize = maxSize;\n  }\n\n  /**\n   * Get a Map from the pool\n   */\n  acquire(): Map<K, V> {\n    const map = this.pool.pop();\n    if (map !== undefined) {\n      return map;\n    }\n    return new Map<K, V>();\n  }\n\n  /**\n   * Return a Map to the pool for reuse\n   */\n  release(map: Map<K, V>): void {\n    if (this.pool.length < this.maxSize) {\n      map.clear();\n      this.pool.push(map);\n    }\n  }\n\n  /**\n   * Clear the pool\n   */\n  clear(): void {\n    this.pool = [];\n  }\n\n  /**\n   * Get current pool size\n   */\n  size(): number {\n    return this.pool.length;\n  }\n}\n\n/**\n * Set pool for reusing Set objects\n */\nexport class SetPool<T> {\n  private pool: Set<T>[] = [];\n  private maxSize: number;\n\n  constructor(maxSize: number = 100) {\n    this.maxSize = maxSize;\n  }\n\n  /**\n   * Get a Set from the pool\n   */\n  acquire(): Set<T> {\n    const set = this.pool.pop();\n    if (set !== undefined) {\n      return set;\n    }\n    return new Set<T>();\n  }\n\n  /**\n   * Return a Set to the pool for reuse\n   */\n  release(set: Set<T>): void {\n    if (this.pool.length < this.maxSize) {\n      set.clear();\n      this.pool.push(set);\n    }\n  }\n\n  /**\n   * Clear the pool\n   */\n  clear(): void {\n    this.pool = [];\n  }\n\n  /**\n   * Get current pool size\n   */\n  size(): number {\n    return this.pool.length;\n  }\n}\n\n/**\n * Global pools for common use cases\n */\nexport const globalMapPool = new MapPool<any, any>(100);\nexport const globalSetPool = new SetPool<any>(100);\n","/**\n * Optimized Levenshtein distance calculation with early termination\n * Performance-focused implementation for fuzzy matching\n * Uses memory pooling to reduce GC pressure by 30-50%\n */\n\nimport { globalArrayPool } from \"../utils/memory-pool.js\";\n\n/**\n * Calculate Levenshtein distance with maximum threshold\n * Returns early if distance exceeds maxDistance for performance\n * \n * @param str1 - First string to compare\n * @param str2 - Second string to compare\n * @param maxDistance - Maximum allowed distance (default: Infinity)\n * @returns Edit distance between strings, or maxDistance + 1 if exceeded\n * \n * @example\n * ```typescript\n * calculateLevenshteinDistance('kitten', 'sitting'); // 3\n * calculateLevenshteinDistance('hello', 'helo', 2); // 1\n * calculateLevenshteinDistance('abc', 'xyz', 1); // 2 (exceeds max)\n * ```\n */\nexport function calculateLevenshteinDistance(\n  //\n  str1: string,\n  str2: string,\n  maxDistance: number = Infinity\n): number {\n  const len1 = str1.length;\n  const len2 = str2.length;\n\n  // Quick checks for performance\n  if (Math.abs(len1 - len2) > maxDistance) {\n    return maxDistance + 1;\n  }\n\n  if (len1 === 0) return len2;\n  if (len2 === 0) return len1;\n  if (str1 === str2) return 0;\n\n  // Use memory pool for arrays to reduce GC pressure\n  const previousRow = globalArrayPool.acquire(len2 + 1) as number[];\n  const currentRow = globalArrayPool.acquire(len2 + 1) as number[];\n\n  try {\n    // Initialize first row\n    for (let j = 0; j <= len2; j++) {\n      previousRow[j] = j;\n    }\n\n    for (let i = 1; i <= len1; i++) {\n      currentRow[0] = i;\n      let minInRow = i;\n\n      for (let j = 1; j <= len2; j++) {\n        const cost = str1[i - 1] === str2[j - 1] ? 0 : 1;\n\n        currentRow[j] = Math.min(\n          currentRow[j - 1] + 1, // insertion\n          previousRow[j] + 1, // deletion\n          previousRow[j - 1] + cost // substitution\n        );\n\n        minInRow = Math.min(minInRow, currentRow[j]);\n      }\n\n      // Early termination if minimum in row exceeds threshold\n      if (minInRow > maxDistance) {\n        return maxDistance + 1;\n      }\n\n      // Copy current to previous for next iteration\n      for (let j = 0; j <= len2; j++) {\n        previousRow[j] = currentRow[j];\n      }\n    }\n\n    return previousRow[len2];\n  } finally {\n    // Always release arrays back to pool\n    globalArrayPool.release(previousRow);\n    globalArrayPool.release(currentRow);\n  }\n}\n\n/**\n * Calculate Damerau-Levenshtein distance (includes transpositions)\n * More expensive but handles character swaps\n */\nexport function calculateDamerauLevenshteinDistance(str1: string, str2: string, maxDistance: number = Infinity): number {\n  const len1 = str1.length;\n  const len2 = str2.length;\n\n  if (Math.abs(len1 - len2) > maxDistance) {\n    return maxDistance + 1;\n  }\n\n  if (len1 === 0) return len2;\n  if (len2 === 0) return len1;\n  if (str1 === str2) return 0;\n\n  const maxLen = Math.max(len1, len2);\n  const H: number[][] = [];\n  const INF = maxLen + 1;\n\n  // Initialize H matrix\n  for (let i = 0; i <= len1 + 1; i++) {\n    H[i] = new Array(len2 + 2).fill(INF);\n  }\n\n  H[0][0] = INF;\n  for (let i = 0; i <= len1; i++) {\n    H[i + 1][0] = INF;\n    H[i + 1][1] = i;\n  }\n  for (let j = 0; j <= len2; j++) {\n    H[0][j + 1] = INF;\n    H[1][j + 1] = j;\n  }\n\n  const charMap = new Map<string, number>();\n\n  for (let i = 1; i <= len1; i++) {\n    let lastMatchCol = 0;\n\n    for (let j = 1; j <= len2; j++) {\n      const char1 = str1[i - 1];\n      const char2 = str2[j - 1];\n      const lastMatchRow = charMap.get(char2) || 0;\n\n      let cost = 1;\n      if (char1 === char2) {\n        cost = 0;\n        lastMatchCol = j;\n      }\n\n      H[i + 1][j + 1] = Math.min(\n        H[i][j] + cost, // substitution\n        H[i + 1][j] + 1, // insertion\n        H[i][j + 1] + 1, // deletion\n        H[lastMatchRow][lastMatchCol] + (i - lastMatchRow - 1) + 1 + (j - lastMatchCol - 1) // transposition\n      );\n    }\n\n    charMap.set(str1[i - 1], i);\n  }\n\n  const result = H[len1 + 1][len2 + 1];\n  return result > maxDistance ? maxDistance + 1 : result;\n}\n\n/**\n * Fast approximate string matching using n-gram similarity\n * Much faster than edit distance for initial filtering\n * Uses memory pooling for Set objects to reduce GC pressure\n * \n * @param str1 - First string to compare\n * @param str2 - Second string to compare\n * @param n - N-gram size (default: 3)\n * @returns Similarity score between 0 and 1\n * \n * @example\n * ```typescript\n * calculateNgramSimilarity('hello', 'hallo'); // ~0.6\n * calculateNgramSimilarity('test', 'test'); // 1.0\n * ```\n */\nexport function calculateNgramSimilarity(str1: string, str2: string, n: number = 3): number {\n  if (str1 === str2) return 1.0;\n  if (str1.length === 0 || str2.length === 0) return 0.0;\n\n  const ngrams1 = generateNgrams(str1, n);\n  const ngrams2 = generateNgrams(str2, n);\n\n  if (ngrams1.length === 0 && ngrams2.length === 0) return 1.0;\n  if (ngrams1.length === 0 || ngrams2.length === 0) return 0.0;\n\n  const set1 = new Set(ngrams1);\n  const set2 = new Set(ngrams2);\n\n  // Calculate intersection size without creating new Set\n  let intersectionSize = 0;\n  for (const item of set1) {\n    if (set2.has(item)) {\n      intersectionSize++;\n    }\n  }\n\n  // Union size = size1 + size2 - intersection\n  const unionSize = set1.size + set2.size - intersectionSize;\n\n  return unionSize > 0 ? intersectionSize / unionSize : 0;\n}\n\n/**\n * Generate n-grams from a string\n * Pre-allocates array for better performance\n * \n * @param str - Input string\n * @param n - N-gram size\n * @returns Array of n-grams\n * \n * @example\n * ```typescript\n * generateNgrams('hello', 3); // ['hel', 'ell', 'llo']\n * generateNgrams('hi', 3); // ['hi']\n * ```\n */\nexport function generateNgrams(str: string, n: number): string[] {\n  if (str.length < n) return [str];\n\n  // Pre-allocate array with exact size needed\n  const count = str.length - n + 1;\n  const ngrams: string[] = new Array(count);\n  \n  for (let i = 0; i < count; i++) {\n    ngrams[i] = str.slice(i, i + n);\n  }\n  \n  return ngrams;\n}\n\n/**\n * Calculate similarity score (0-1) from edit distance\n * \n * @param distance - Edit distance between strings\n * @param maxLength - Maximum length of the two strings\n * @returns Similarity score from 0 to 1 (1 = identical)\n * \n * @example\n * ```typescript\n * distanceToSimilarity(0, 5); // 1.0 (no edits)\n * distanceToSimilarity(2, 10); // 0.8 (2 edits in 10 chars)\n * ```\n */\nexport function distanceToSimilarity(distance: number, maxLength: number): number {\n  if (maxLength === 0) return distance === 0 ? 1.0 : 0.0;\n  return Math.max(0, 1 - distance / maxLength);\n}\n\n/**\n * Check if strings are similar within threshold using fast approximation\n * Uses n-gram pre-filtering before expensive Levenshtein calculation\n * \n * @param str1 - First string to compare\n * @param str2 - Second string to compare\n * @param threshold - Similarity threshold (0-1, default: 0.8)\n * @param maxDistance - Maximum edit distance allowed (default: 2)\n * @returns True if strings are similar enough\n * \n * @example\n * ```typescript\n * areStringsSimilar('hello', 'helo'); // true\n * areStringsSimilar('hello', 'world'); // false\n * ```\n */\nexport function areStringsSimilar(str1: string, str2: string, threshold: number = 0.8, maxDistance: number = 2): boolean {\n  // Quick exact match\n  if (str1 === str2) return true;\n\n  // Quick length check\n  const maxLen = Math.max(str1.length, str2.length);\n  if (Math.abs(str1.length - str2.length) > maxDistance) return false;\n\n  // Use n-gram similarity for fast approximation\n  const ngramSim = calculateNgramSimilarity(str1, str2);\n  if (ngramSim < threshold - 0.2) return false; // Early rejection\n\n  // Calculate actual edit distance only if n-gram similarity is promising\n  const distance = calculateLevenshteinDistance(str1, str2, maxDistance);\n  const similarity = distanceToSimilarity(distance, maxLen);\n\n  return similarity >= threshold;\n}\n","/**\n * Trie (Prefix Tree) for fast prefix matching\n * Provides O(k) lookup where k is the query length, instead of O(n) where n is the number of terms\n */\n\nexport interface TrieNode {\n  children: Map<string, TrieNode>;\n  isEndOfWord: boolean;\n  docIds: Set<number>;\n  term?: string; // Store the full term at leaf nodes\n}\n\nexport class Trie {\n  private root: TrieNode;\n  private size: number;\n\n  constructor() {\n    this.root = this.createNode();\n    this.size = 0;\n  }\n\n  private createNode(): TrieNode {\n    return {\n      children: new Map(),\n      isEndOfWord: false,\n      docIds: new Set(),\n    };\n  }\n\n  /**\n   * Insert a term with associated document IDs\n   */\n  insert(term: string, docIds: number[]): void {\n    if (!term) return;\n\n    let node = this.root;\n\n    for (const char of term) {\n      if (!node.children.has(char)) {\n        node.children.set(char, this.createNode());\n      }\n      node = node.children.get(char)!;\n    }\n\n    node.isEndOfWord = true;\n    node.term = term;\n    docIds.forEach(id => node.docIds.add(id));\n    this.size++;\n  }\n\n  /**\n   * Find all terms that start with the given prefix\n   * Returns array of [term, docIds[]] tuples\n   */\n  findWithPrefix(prefix: string): Array<[string, number[]]> {\n    if (!prefix) return [];\n\n    // Navigate to the prefix node\n    let node = this.root;\n    for (const char of prefix) {\n      if (!node.children.has(char)) {\n        return []; // Prefix not found\n      }\n      node = node.children.get(char)!;\n    }\n\n    // Collect all terms from this node downwards\n    const results: Array<[string, number[]]> = [];\n    this.collectTerms(node, results);\n    return results;\n  }\n\n  /**\n   * Check if exact term exists\n   */\n  has(term: string): boolean {\n    let node = this.root;\n    for (const char of term) {\n      if (!node.children.has(char)) {\n        return false;\n      }\n      node = node.children.get(char)!;\n    }\n    return node.isEndOfWord;\n  }\n\n  /**\n   * Get document IDs for exact term\n   */\n  get(term: string): number[] | null {\n    let node = this.root;\n    for (const char of term) {\n      if (!node.children.has(char)) {\n        return null;\n      }\n      node = node.children.get(char)!;\n    }\n    return node.isEndOfWord ? Array.from(node.docIds) : null;\n  }\n\n  /**\n   * Recursively collect all terms from a node\n   */\n  private collectTerms(node: TrieNode, results: Array<[string, number[]]>): void {\n    if (node.isEndOfWord && node.term) {\n      results.push([node.term, Array.from(node.docIds)]);\n    }\n\n    for (const child of node.children.values()) {\n      this.collectTerms(child, results);\n    }\n  }\n\n  /**\n   * Get the number of terms in the trie\n   */\n  getSize(): number {\n    return this.size;\n  }\n\n  /**\n   * Clear the trie\n   */\n  clear(): void {\n    this.root = this.createNode();\n    this.size = 0;\n  }\n\n  /**\n   * Serialize trie to JSON-compatible format\n   */\n  toJSON(): any {\n    return {\n      root: this.serializeNode(this.root),\n      size: this.size,\n    };\n  }\n\n  /**\n   * Deserialize trie from JSON\n   */\n  static fromJSON(data: any): Trie {\n    const trie = new Trie();\n    trie.root = Trie.deserializeNode(data.root);\n    trie.size = data.size;\n    return trie;\n  }\n\n  private serializeNode(node: TrieNode): any {\n    return {\n      children: Array.from(node.children.entries()).map(([char, child]) => [\n        char,\n        this.serializeNode(child),\n      ]),\n      isEndOfWord: node.isEndOfWord,\n      docIds: Array.from(node.docIds),\n      term: node.term,\n    };\n  }\n\n  private static deserializeNode(data: any): TrieNode {\n    const node: TrieNode = {\n      children: new Map(),\n      isEndOfWord: data.isEndOfWord,\n      docIds: new Set(data.docIds),\n      term: data.term,\n    };\n\n    for (const [char, childData] of data.children) {\n      node.children.set(char, Trie.deserializeNode(childData));\n    }\n\n    return node;\n  }\n}\n","/**\n * BM25 (Best Matching 25) Scoring Algorithm\n * Industry-standard probabilistic ranking function used by search engines\n *\n * BM25 considers:\n * - Term frequency (TF): How often does the term appear?\n * - Inverse document frequency (IDF): How rare is the term?\n * - Document length normalization: Penalize very long documents\n *\n * Formula: BM25(D, Q) = Σ IDF(qi) * (f(qi, D) * (k1 + 1)) / (f(qi, D) + k1 * (1 - b + b * |D| / avgdl))\n *\n * Where:\n * - D = document\n * - Q = query\n * - qi = query term i\n * - f(qi, D) = frequency of qi in D\n * - |D| = length of document D\n * - avgdl = average document length\n * - k1 = term frequency saturation parameter (default: 1.2)\n * - b = length normalization parameter (default: 0.75)\n */\n\nexport interface BM25Config {\n  /** Term frequency saturation parameter (typical: 1.2-2.0) */\n  k1: number;\n  /** Length normalization parameter (typical: 0.5-0.8) */\n  b: number;\n  /** Minimum IDF value to prevent negative scores */\n  minIDF: number;\n}\n\nexport const DEFAULT_BM25_CONFIG: BM25Config = {\n  k1: 1.2,\n  b: 0.75,\n  minIDF: 0.1,\n};\n\n/**\n * Document statistics for BM25 calculation\n */\nexport interface DocumentStats {\n  /** Document ID */\n  docId: number;\n  /** Document length (number of terms) */\n  length: number;\n  /** Term frequencies in this document */\n  termFrequencies: Map<string, number>;\n}\n\n/**\n * Corpus statistics for BM25 calculation\n */\nexport interface CorpusStats {\n  /** Total number of documents */\n  totalDocs: number;\n  /** Average document length */\n  avgDocLength: number;\n  /** Document frequency for each term (how many docs contain the term) */\n  documentFrequencies: Map<string, number>;\n}\n\n/**\n * Calculate IDF (Inverse Document Frequency) for a term\n * IDF = log((N - df + 0.5) / (df + 0.5) + 1)\n *\n * Where:\n * - N = total number of documents\n * - df = document frequency (number of documents containing the term)\n */\nexport function calculateIDF(term: string, corpusStats: CorpusStats, config: BM25Config = DEFAULT_BM25_CONFIG): number {\n  const df = corpusStats.documentFrequencies.get(term) || 0;\n  const N = corpusStats.totalDocs;\n\n  // Prevent division by zero and negative IDF\n  if (df === 0 || N === 0) {\n    return config.minIDF;\n  }\n\n  // BM25 IDF formula with smoothing\n  const idf = Math.log((N - df + 0.5) / (df + 0.5) + 1);\n\n  // Ensure minimum IDF\n  return Math.max(idf, config.minIDF);\n}\n\n/**\n * Calculate BM25 score for a single term in a document\n */\nexport function calculateTermScore(term: string, docStats: DocumentStats, corpusStats: CorpusStats, config: BM25Config = DEFAULT_BM25_CONFIG): number {\n  const tf = docStats.termFrequencies.get(term) || 0;\n\n  // If term not in document, score is 0\n  if (tf === 0) {\n    return 0;\n  }\n\n  const idf = calculateIDF(term, corpusStats, config);\n  const docLength = docStats.length;\n  const avgDocLength = corpusStats.avgDocLength;\n\n  // BM25 formula\n  const numerator = tf * (config.k1 + 1);\n  const denominator = tf + config.k1 * (1 - config.b + config.b * (docLength / avgDocLength));\n\n  return idf * (numerator / denominator);\n}\n\n/**\n * Calculate BM25 score for a query against a document\n * Returns the sum of BM25 scores for all query terms\n */\nexport function calculateBM25Score(queryTerms: string[], docStats: DocumentStats, corpusStats: CorpusStats, config: BM25Config = DEFAULT_BM25_CONFIG): number {\n  let totalScore = 0;\n\n  for (const term of queryTerms) {\n    totalScore += calculateTermScore(term, docStats, corpusStats, config);\n  }\n\n  return totalScore;\n}\n\n/**\n * Build corpus statistics from documents\n * This should be called once during index building\n */\nexport function buildCorpusStats(documents: DocumentStats[]): CorpusStats {\n  const totalDocs = documents.length;\n  let totalLength = 0;\n  const documentFrequencies = new Map<string, number>();\n\n  for (const doc of documents) {\n    totalLength += doc.length;\n\n    // Count unique terms per document (for document frequency)\n    const uniqueTerms = new Set(doc.termFrequencies.keys());\n    for (const term of uniqueTerms) {\n      documentFrequencies.set(term, (documentFrequencies.get(term) || 0) + 1);\n    }\n  }\n\n  const avgDocLength = totalDocs > 0 ? totalLength / totalDocs : 0;\n\n  return {\n    totalDocs,\n    avgDocLength,\n    documentFrequencies,\n  };\n}\n\n/**\n * Normalize BM25 score to 0-1 range for consistency with existing scoring\n * Uses sigmoid function for smooth normalization\n */\nexport function normalizeBM25Score(score: number, maxScore: number = 10): number {\n  if (maxScore === 0) return 0;\n\n  // Sigmoid normalization: 1 / (1 + e^(-x))\n  // Scale score to reasonable range first\n  const scaledScore = (score / maxScore) * 6 - 3; // Map to [-3, 3] range\n  return 1 / (1 + Math.exp(-scaledScore));\n}\n\n/**\n * Combine BM25 score with fuzzy match score\n * Provides a hybrid scoring approach\n */\nexport function combineScores(bm25Score: number, fuzzyScore: number, bm25Weight: number = 0.6, fuzzyWeight: number = 0.4): number {\n  // Normalize weights\n  const totalWeight = bm25Weight + fuzzyWeight;\n  const normalizedBM25Weight = bm25Weight / totalWeight;\n  const normalizedFuzzyWeight = fuzzyWeight / totalWeight;\n\n  // Weighted combination\n  return normalizedBM25Weight * bm25Score + normalizedFuzzyWeight * fuzzyScore;\n}\n","/**\n * Bloom Filter Implementation\n * Probabilistic data structure for fast membership testing\n *\n * Benefits:\n * - O(1) lookup time\n * - Space-efficient (much smaller than Set/Map)\n * - No false negatives (if it says \"no\", it's definitely not there)\n * - Small false positive rate (configurable)\n *\n * Use case: Quickly check if a term exists before expensive lookups\n * Saves 50-70% of lookup time for non-existent terms\n */\n\nexport interface BloomFilterConfig {\n  /** Expected number of elements */\n  expectedElements: number;\n  /** Desired false positive rate (0-1, e.g., 0.01 = 1%) */\n  falsePositiveRate: number;\n}\n\nexport class BloomFilter {\n  private bitArray: Uint8Array;\n  private size: number;\n  private numHashFunctions: number;\n  private numElements: number = 0;\n\n  constructor(config: BloomFilterConfig) {\n    // Calculate optimal bit array size\n    // m = -(n * ln(p)) / (ln(2)^2)\n    // where n = expected elements, p = false positive rate\n    const n = config.expectedElements;\n    const p = config.falsePositiveRate;\n\n    this.size = Math.ceil(-(n * Math.log(p)) / Math.log(2) ** 2);\n\n    // Calculate optimal number of hash functions\n    // k = (m / n) * ln(2)\n    this.numHashFunctions = Math.ceil((this.size / n) * Math.log(2));\n\n    // Use Uint8Array for efficient bit storage (8 bits per byte)\n    this.bitArray = new Uint8Array(Math.ceil(this.size / 8));\n  }\n\n  /**\n   * Add an element to the bloom filter\n   */\n  add(item: string): void {\n    const hashes = this.getHashes(item);\n\n    for (const hash of hashes) {\n      const byteIndex = Math.floor(hash / 8);\n      const bitIndex = hash % 8;\n      this.bitArray[byteIndex] |= 1 << bitIndex;\n    }\n\n    this.numElements++;\n  }\n\n  /**\n   * Check if an element might be in the set\n   * Returns:\n   * - true: element MIGHT be in the set (could be false positive)\n   * - false: element is DEFINITELY NOT in the set (no false negatives)\n   */\n  mightContain(item: string): boolean {\n    const hashes = this.getHashes(item);\n\n    for (const hash of hashes) {\n      const byteIndex = Math.floor(hash / 8);\n      const bitIndex = hash % 8;\n\n      if ((this.bitArray[byteIndex] & (1 << bitIndex)) === 0) {\n        return false; // Definitely not in set\n      }\n    }\n\n    return true; // Might be in set\n  }\n\n  /**\n   * Generate multiple hash values for an item\n   * Uses double hashing technique for efficiency\n   */\n  private getHashes(item: string): number[] {\n    const hash1 = this.hash(item, 0);\n    const hash2 = this.hash(item, 1);\n\n    const hashes: number[] = [];\n\n    for (let i = 0; i < this.numHashFunctions; i++) {\n      // Double hashing: h(i) = (hash1 + i * hash2) mod m\n      const combinedHash = (hash1 + i * hash2) % this.size;\n      hashes.push(Math.abs(combinedHash));\n    }\n\n    return hashes;\n  }\n\n  /**\n   * Simple hash function (FNV-1a variant)\n   */\n  private hash(str: string, seed: number): number {\n    let hash = 2166136261 ^ seed; // FNV offset basis\n\n    for (let i = 0; i < str.length; i++) {\n      hash ^= str.charCodeAt(i);\n      hash += (hash << 1) + (hash << 4) + (hash << 7) + (hash << 8) + (hash << 24);\n    }\n\n    return hash >>> 0; // Convert to unsigned 32-bit integer\n  }\n\n  /**\n   * Get current false positive probability\n   * Actual rate may differ from configured rate as elements are added\n   */\n  getFalsePositiveRate(): number {\n    if (this.numElements === 0) return 0;\n\n    // p = (1 - e^(-kn/m))^k\n    // where k = num hash functions, n = num elements, m = bit array size\n    const k = this.numHashFunctions;\n    const n = this.numElements;\n    const m = this.size;\n\n    return Math.pow(1 - Math.exp((-k * n) / m), k);\n  }\n\n  /**\n   * Get statistics about the bloom filter\n   */\n  getStats(): {\n    size: number;\n    numHashFunctions: number;\n    numElements: number;\n    falsePositiveRate: number;\n    memoryUsage: number;\n  } {\n    return {\n      size: this.size,\n      numHashFunctions: this.numHashFunctions,\n      numElements: this.numElements,\n      falsePositiveRate: this.getFalsePositiveRate(),\n      memoryUsage: this.bitArray.byteLength,\n    };\n  }\n\n  /**\n   * Clear all elements from the filter\n   */\n  clear(): void {\n    this.bitArray.fill(0);\n    this.numElements = 0;\n  }\n\n  /**\n   * Serialize bloom filter to JSON\n   */\n  toJSON(): {\n    bitArray: number[];\n    size: number;\n    numHashFunctions: number;\n    numElements: number;\n  } {\n    return {\n      bitArray: Array.from(this.bitArray),\n      size: this.size,\n      numHashFunctions: this.numHashFunctions,\n      numElements: this.numElements,\n    };\n  }\n\n  /**\n   * Deserialize bloom filter from JSON\n   */\n  static fromJSON(data: { bitArray: number[]; size: number; numHashFunctions: number; numElements: number }): BloomFilter {\n    // Create a dummy filter with minimal config\n    const filter = new BloomFilter({\n      expectedElements: 100,\n      falsePositiveRate: 0.01,\n    });\n\n    // Override with saved data\n    filter.bitArray = new Uint8Array(data.bitArray);\n    filter.size = data.size;\n    filter.numHashFunctions = data.numHashFunctions;\n    filter.numElements = data.numElements;\n\n    return filter;\n  }\n}\n\n/**\n * Create a bloom filter with sensible defaults\n */\nexport function createBloomFilter(expectedElements: number, falsePositiveRate: number = 0.01): BloomFilter {\n  return new BloomFilter({\n    expectedElements,\n    falsePositiveRate,\n  });\n}\n","/**\n * Inverted Index Implementation\n * Optimized for large datasets (1M+ words)\n *\n * Architecture:\n * - Token → [docId1, docId2, ...] (posting lists)\n * - Fast intersection/union operations\n * - BM25-like scoring for relevance\n * - Parallel to existing hash-based index (backwards compatible)\n */\n\nimport type { InvertedIndex, DocumentMetadata, PostingList, FuzzyConfig, LanguageProcessor, SearchMatch } from \"./types.js\";\nimport { generateNgrams, calculateLevenshteinDistance, calculateDamerauLevenshteinDistance } from \"../algorithms/levenshtein.js\";\nimport { Trie } from \"./trie.js\";\nimport { calculateBM25Score, normalizeBM25Score, DEFAULT_BM25_CONFIG, type DocumentStats, type CorpusStats } from \"../algorithms/bm25.js\";\nimport { BloomFilter } from \"../algorithms/bloom-filter.js\";\n\n/**\n * Build inverted index from documents\n * This runs ALONGSIDE the existing index building\n */\nexport function buildInvertedIndex(\n  //\n  words: string[],\n  languageProcessors: LanguageProcessor[],\n  config: FuzzyConfig,\n  featureSet: Set<string>\n): { invertedIndex: InvertedIndex; documents: DocumentMetadata[] } {\n  const documents: DocumentMetadata[] = [];\n  const invertedIndex: InvertedIndex = {\n    termToPostings: new Map(),\n    termTrie: new Trie(), // Initialize Trie for fast prefix matching\n    phoneticToPostings: new Map(),\n    ngramToPostings: new Map(),\n    synonymToPostings: new Map(),\n    fieldIndices: new Map(),\n    totalDocs: 0,\n    avgDocLength: 0,\n  };\n\n  let totalLength = 0;\n  let docId = 0;\n\n  // Build documents and posting lists\n  for (const word of words) {\n    if (!word || word.trim().length < config.minQueryLength) continue;\n\n    const trimmedWord = word.trim();\n\n    // Process with each language processor\n    for (const processor of languageProcessors) {\n      const normalized = processor.normalize(trimmedWord);\n      const phoneticCode = featureSet.has(\"phonetic\") && processor.supportedFeatures.includes(\"phonetic\") ? processor.getPhoneticCode(trimmedWord) : undefined;\n\n      const compoundParts = featureSet.has(\"compound\") && processor.supportedFeatures.includes(\"compound\") ? processor.splitCompoundWords(trimmedWord) : undefined;\n\n      // Create document metadata\n      const doc: DocumentMetadata = {\n        id: docId,\n        word: trimmedWord,\n        normalized,\n        phoneticCode,\n        language: processor.language,\n        compoundParts: compoundParts && compoundParts.length > 1 ? compoundParts : undefined,\n      };\n\n      documents.push(doc);\n      totalLength += normalized.length;\n\n      // Index the normalized term\n      addToPostingList(invertedIndex.termToPostings, normalized, docId);\n      invertedIndex.termTrie!.insert(normalized, [docId]);\n\n      // Index original word (for exact matching)\n      const lowerWord = trimmedWord.toLowerCase();\n      addToPostingList(invertedIndex.termToPostings, lowerWord, docId);\n      invertedIndex.termTrie!.insert(lowerWord, [docId]);\n\n      // Index word variants (prefixes)\n      if (featureSet.has(\"partial-words\")) {\n        const variants = processor.getWordVariants(trimmedWord);\n        variants.forEach((variant) => {\n          addToPostingList(invertedIndex.termToPostings, variant, docId);\n          invertedIndex.termTrie!.insert(variant, [docId]);\n        });\n      }\n\n      // Index phonetic code\n      if (phoneticCode) {\n        addToPostingList(invertedIndex.phoneticToPostings, phoneticCode, docId);\n      }\n\n      // Index n-grams\n      const ngrams = generateNgrams(normalized, config.ngramSize);\n      ngrams.forEach((ngram) => {\n        addToPostingList(invertedIndex.ngramToPostings, ngram, docId);\n      });\n\n      // Index compound parts\n      if (compoundParts && compoundParts.length > 1) {\n        compoundParts.forEach((part) => {\n          const normalizedPart = processor.normalize(part);\n          addToPostingList(invertedIndex.termToPostings, normalizedPart, docId);\n          invertedIndex.termTrie!.insert(normalizedPart, [docId]);\n        });\n      }\n\n      // Index synonyms\n      if (featureSet.has(\"synonyms\")) {\n        const synonyms = processor.getSynonyms(normalized);\n        synonyms.forEach((synonym) => {\n          addToPostingList(invertedIndex.synonymToPostings, synonym, docId);\n        });\n\n        // Custom synonyms\n        if (config.customSynonyms) {\n          const customSynonyms = config.customSynonyms[normalized];\n          if (customSynonyms) {\n            customSynonyms.forEach((synonym) => {\n              addToPostingList(invertedIndex.synonymToPostings, synonym, docId);\n            });\n          }\n        }\n      }\n\n      docId++;\n    }\n  }\n\n  invertedIndex.totalDocs = docId;\n  invertedIndex.avgDocLength = totalLength / Math.max(1, docId);\n\n  // Build BM25 statistics if enabled\n  if (config.useBM25) {\n    const documentFrequencies = new Map<string, number>();\n    const documentLengths = new Map<number, number>();\n\n    // Calculate document frequencies (how many docs contain each term)\n    for (const [term, posting] of invertedIndex.termToPostings.entries()) {\n      documentFrequencies.set(term, posting.docIds.length);\n    }\n\n    // Store document lengths\n    documents.forEach((doc) => {\n      documentLengths.set(doc.id, doc.normalized.length);\n    });\n\n    invertedIndex.bm25Stats = {\n      documentFrequencies,\n      documentLengths,\n    };\n  }\n\n  // Build Bloom Filter if enabled or auto-enable for large datasets\n  const shouldUseBloomFilter = config.useBloomFilter || words.length >= 10000;\n\n  if (shouldUseBloomFilter) {\n    const falsePositiveRate = config.bloomFilterFalsePositiveRate || 0.01;\n    const bloomFilter = new BloomFilter({\n      expectedElements: invertedIndex.termToPostings.size,\n      falsePositiveRate,\n    });\n\n    // Add all terms to bloom filter\n    for (const term of invertedIndex.termToPostings.keys()) {\n      bloomFilter.add(term);\n    }\n\n    invertedIndex.bloomFilter = bloomFilter;\n  }\n\n  return { invertedIndex, documents };\n}\n\n/**\n * Search using inverted index\n * Much faster than hash-based approach for large datasets\n */\nexport function searchInvertedIndex(\n  //\n  invertedIndex: InvertedIndex,\n  documents: DocumentMetadata[],\n  query: string,\n  processors: LanguageProcessor[],\n  config: FuzzyConfig\n): SearchMatch[] {\n  const matches = new Map<number, SearchMatch>();\n  const featureSet = new Set(config.features);\n\n  // Process query with each language processor\n  for (const processor of processors) {\n    const normalizedQuery = processor.normalize(query.trim());\n\n    // 1. Exact term lookup (fastest)\n    findExactMatchesInverted(normalizedQuery, invertedIndex, documents, matches, processor.language);\n\n    // 2. Prefix matches\n    findPrefixMatchesInverted(normalizedQuery, invertedIndex, documents, matches, processor.language);\n\n    // 3. Phonetic matches\n    if (featureSet.has(\"phonetic\") && processor.supportedFeatures.includes(\"phonetic\")) {\n      findPhoneticMatchesInverted(normalizedQuery, processor, invertedIndex, documents, matches);\n    }\n\n    // 4. Synonym matches\n    if (featureSet.has(\"synonyms\")) {\n      findSynonymMatchesInverted(normalizedQuery, invertedIndex, documents, matches);\n    }\n\n    // 5. N-gram matches\n    findNgramMatchesInverted(normalizedQuery, invertedIndex, documents, matches, processor.language, config.ngramSize);\n\n    // 6. Fuzzy matches (most expensive, do last)\n    // OPTIMIZATION: Skip fuzzy matching for very large datasets in fast mode if we have enough good matches\n    const shouldSkipFuzzy = config.performance === \"fast\" && invertedIndex.termToPostings.size > 100000 && matches.size >= config.maxResults * 2;\n\n    if (!shouldSkipFuzzy && (featureSet.has(\"missing-letters\") || featureSet.has(\"extra-letters\") || featureSet.has(\"transpositions\"))) {\n      findFuzzyMatchesInverted(normalizedQuery, invertedIndex, documents, matches, processor, config.maxEditDistance, config);\n    }\n  }\n\n  // Convert to array and return\n  return Array.from(matches.values());\n}\n\n/**\n * Helper: Add document to posting list\n */\nfunction addToPostingList(\n  //\n  postings: Map<string, PostingList>,\n  term: string,\n  docId: number\n): void {\n  let posting = postings.get(term);\n  if (!posting) {\n    posting = { term, docIds: [] };\n    postings.set(term, posting);\n  }\n\n  // Avoid duplicates\n  if (!posting.docIds.includes(docId)) {\n    posting.docIds.push(docId);\n  }\n}\n\n/**\n * Find exact matches in inverted index\n */\nfunction findExactMatchesInverted(\n  //\n  query: string,\n  invertedIndex: InvertedIndex,\n  documents: DocumentMetadata[],\n  matches: Map<number, SearchMatch>,\n  language: string\n): void {\n  // BLOOM FILTER: Fast negative lookup\n  if (invertedIndex.bloomFilter && !invertedIndex.bloomFilter.mightContain(query)) {\n    return; // Definitely not in index, skip expensive lookup\n  }\n\n  const posting = invertedIndex.termToPostings.get(query);\n  if (!posting) return;\n\n  posting.docIds.forEach((docId) => {\n    const doc = documents[docId];\n    if (!doc) return;\n\n    if (!matches.has(docId)) {\n      matches.set(docId, {\n        word: doc.word,\n        normalized: query,\n        matchType: \"exact\",\n        editDistance: 0,\n        language,\n        docId,\n      });\n    }\n  });\n}\n\n/**\n * Find prefix matches in inverted index\n * Now uses Trie for O(k) lookup instead of O(n) iteration!\n */\nfunction findPrefixMatchesInverted(\n  //\n  query: string,\n  invertedIndex: InvertedIndex,\n  documents: DocumentMetadata[],\n  matches: Map<number, SearchMatch>,\n  language: string\n): void {\n  // Use Trie for fast prefix matching (100-1000x faster!)\n  if (invertedIndex.termTrie) {\n    const prefixMatches = invertedIndex.termTrie.findWithPrefix(query);\n\n    for (const [term, docIds] of prefixMatches) {\n      if (term !== query) {\n        // Exclude exact matches (handled separately)\n        docIds.forEach((docId: number) => {\n          const doc = documents[docId];\n          if (!doc) return;\n\n          if (!matches.has(docId)) {\n            matches.set(docId, {\n              word: doc.word,\n              normalized: term,\n              matchType: \"prefix\",\n              language,\n              docId,\n            });\n          }\n        });\n      }\n    }\n  } else {\n    // Fallback to old O(n) method if Trie not available\n    for (const [term, posting] of invertedIndex.termToPostings.entries()) {\n      if (term.startsWith(query) && term !== query) {\n        posting.docIds.forEach((docId) => {\n          const doc = documents[docId];\n          if (!doc) return;\n\n          if (!matches.has(docId)) {\n            matches.set(docId, {\n              word: doc.word,\n              normalized: term,\n              matchType: \"prefix\",\n              language,\n              docId,\n            });\n          }\n        });\n      }\n    }\n  }\n}\n\n/**\n * Find phonetic matches in inverted index\n */\nfunction findPhoneticMatchesInverted(\n  //\n  query: string,\n  processor: LanguageProcessor,\n  invertedIndex: InvertedIndex,\n  documents: DocumentMetadata[],\n  matches: Map<number, SearchMatch>\n): void {\n  const phoneticCode = processor.getPhoneticCode(query);\n  if (!phoneticCode) return;\n\n  const posting = invertedIndex.phoneticToPostings.get(phoneticCode);\n  if (!posting) return;\n\n  posting.docIds.forEach((docId) => {\n    const doc = documents[docId];\n    if (!doc) return;\n\n    if (!matches.has(docId)) {\n      matches.set(docId, {\n        word: doc.word,\n        normalized: query,\n        matchType: \"phonetic\",\n        phoneticCode,\n        language: processor.language,\n        docId,\n      });\n    }\n  });\n}\n\n/**\n * Find synonym matches in inverted index\n */\nfunction findSynonymMatchesInverted(\n  //\n  query: string,\n  invertedIndex: InvertedIndex,\n  documents: DocumentMetadata[],\n  matches: Map<number, SearchMatch>\n): void {\n  const posting = invertedIndex.synonymToPostings.get(query);\n  if (!posting) return;\n\n  posting.docIds.forEach((docId) => {\n    const doc = documents[docId];\n    if (!doc) return;\n\n    if (!matches.has(docId)) {\n      matches.set(docId, {\n        word: doc.word,\n        normalized: query,\n        matchType: \"synonym\",\n        language: \"synonym\",\n        docId,\n      });\n    }\n  });\n}\n\n/**\n * Find n-gram matches in inverted index\n */\nfunction findNgramMatchesInverted(\n  //\n  query: string,\n  invertedIndex: InvertedIndex,\n  documents: DocumentMetadata[],\n  matches: Map<number, SearchMatch>,\n  language: string,\n  ngramSize: number\n): void {\n  if (query.length < ngramSize) return;\n\n  const queryNgrams = generateNgrams(query, ngramSize);\n  const candidateDocs = new Set<number>();\n\n  // Collect all documents that contain at least one n-gram\n  queryNgrams.forEach((ngram) => {\n    const posting = invertedIndex.ngramToPostings.get(ngram);\n    if (posting) {\n      posting.docIds.forEach((docId) => candidateDocs.add(docId));\n    }\n  });\n\n  // Add to matches\n  candidateDocs.forEach((docId) => {\n    const doc = documents[docId];\n    if (!doc) return;\n\n    if (!matches.has(docId)) {\n      matches.set(docId, {\n        word: doc.word,\n        normalized: query,\n        matchType: \"ngram\",\n        language,\n        docId,\n      });\n    }\n  });\n}\n\n/**\n * Find fuzzy matches in inverted index\n * Optimized with length-based pre-filtering (5-10x faster)\n */\nfunction findFuzzyMatchesInverted(\n  //\n  query: string,\n  invertedIndex: InvertedIndex,\n  documents: DocumentMetadata[],\n  matches: Map<number, SearchMatch>,\n  processor: LanguageProcessor,\n  maxDistance: number,\n  config: FuzzyConfig\n): void {\n  const queryLen = query.length;\n  const minLen = queryLen - maxDistance;\n  const maxLen = queryLen + maxDistance;\n\n  // Pre-compute for performance\n  const useTranspositions = config.features?.includes(\"transpositions\");\n\n  // OPTIMIZATION: Dynamic candidate limit based on dataset size\n  // Smaller limit for larger datasets to maintain sub-10ms performance\n  const datasetSize = invertedIndex.termToPostings.size;\n  const MAX_FUZZY_CANDIDATES = datasetSize > 100000 ? 1000 : datasetSize > 50000 ? 1500 : datasetSize > 20000 ? 3000 : datasetSize > 10000 ? 5000 : 8000;\n  let candidatesChecked = 0;\n\n  // OPTIMIZATION: For very large datasets (50K+), use Trie prefix filtering first\n  let termsArray: [string, PostingList][];\n\n  if (datasetSize > 50000 && query.length >= 2 && invertedIndex.termTrie) {\n    // Get prefix matches from Trie (much faster than iterating all terms)\n    // Use longer prefix for 100K+ datasets for better filtering\n    const prefixLength = datasetSize > 100000 ? Math.min(3, query.length) : Math.min(2, query.length);\n    const prefix = query.substring(0, prefixLength);\n    const prefixMatches = invertedIndex.termTrie.findWithPrefix(prefix);\n\n    // Only check terms that share a prefix with the query\n    termsArray = prefixMatches.map(([term, _docIds]: [string, number[]]) => [term, invertedIndex.termToPostings.get(term)] as [string, PostingList | undefined]).filter((entry: [string, PostingList | undefined]): entry is [string, PostingList] => entry[1] !== undefined);\n\n    // If prefix filtering gives us too few candidates, fall back to full search\n    if (termsArray.length < 100) {\n      termsArray = Array.from(invertedIndex.termToPostings.entries());\n    }\n  } else {\n    termsArray = Array.from(invertedIndex.termToPostings.entries());\n  }\n\n  // Sort by length similarity for better early termination\n  termsArray.sort((a, b) => {\n    const aDiff = Math.abs(a[0].length - queryLen);\n    const bDiff = Math.abs(b[0].length - queryLen);\n    return aDiff - bDiff;\n  });\n\n  // Iterate through sorted terms with optimized filtering\n  for (const [term, posting] of termsArray) {\n    // OPTIMIZATION 1: Length-based pre-filter (O(1) check)\n    // This eliminates 80-90% of candidates before expensive Levenshtein\n    const termLen = term.length;\n    if (termLen < minLen || termLen > maxLen) {\n      continue;\n    }\n\n    // OPTIMIZATION 2: Limit candidates in large datasets\n    if (candidatesChecked >= MAX_FUZZY_CANDIDATES) {\n      break;\n    }\n    candidatesChecked++;\n\n    // OPTIMIZATION 3: Early termination if we have enough high-quality matches\n    // More aggressive for large datasets\n    const earlyTerminationThreshold = datasetSize > 50000 ? config.maxResults * 2 : config.maxResults * 3;\n    if (matches.size >= earlyTerminationThreshold) {\n      break;\n    }\n\n    // OPTIMIZATION 4: Skip if first character is too different (cheap check)\n    if (query.length > 0 && term.length > 0) {\n      const firstCharDiff = Math.abs(query.charCodeAt(0) - term.charCodeAt(0));\n      if (firstCharDiff > 10 && maxDistance < 2) {\n        // Allow more variance for higher edit distance\n        continue;\n      }\n    }\n\n    // Now do expensive edit distance calculation\n    const distance = useTranspositions ? calculateDamerauLevenshteinDistance(query, term, maxDistance) : calculateLevenshteinDistance(query, term, maxDistance);\n\n    if (distance <= maxDistance) {\n      posting.docIds.forEach((docId) => {\n        const doc = documents[docId];\n        if (!doc) return;\n\n        const existingMatch = matches.get(docId);\n        // Only update if this is a better match (lower edit distance)\n        if (!existingMatch || (existingMatch.editDistance || Infinity) > distance) {\n          matches.set(docId, {\n            word: doc.word,\n            normalized: term,\n            matchType: \"fuzzy\",\n            editDistance: distance,\n            language: processor.language,\n            docId,\n          });\n        }\n      });\n    }\n  }\n}\n\n/**\n * Calculate BM25 scores for search matches\n * Enhances relevance ranking with statistical scoring\n */\nexport function calculateBM25Scores(matches: SearchMatch[], queryTerms: string[], invertedIndex: InvertedIndex, documents: DocumentMetadata[], config: FuzzyConfig): SearchMatch[] {\n  if (!config.useBM25 || !invertedIndex.bm25Stats) {\n    return matches;\n  }\n\n  const bm25Config = {\n    ...DEFAULT_BM25_CONFIG,\n    ...config.bm25Config,\n  };\n\n  // Build corpus stats from inverted index\n  const corpusStats: CorpusStats = {\n    totalDocs: invertedIndex.totalDocs,\n    avgDocLength: invertedIndex.avgDocLength,\n    documentFrequencies: invertedIndex.bm25Stats.documentFrequencies,\n  };\n\n  // Calculate BM25 score for each match\n  return matches.map((match) => {\n    if (match.docId === undefined) {\n      return match;\n    }\n\n    const doc = documents[match.docId];\n    if (!doc) {\n      return match;\n    }\n\n    // Build document stats\n    const termFrequencies = new Map<string, number>();\n    const normalizedTerms = doc.normalized.toLowerCase().split(/\\s+/);\n\n    for (const term of normalizedTerms) {\n      termFrequencies.set(term, (termFrequencies.get(term) || 0) + 1);\n    }\n\n    const docStats: DocumentStats = {\n      docId: doc.id,\n      length: normalizedTerms.length,\n      termFrequencies,\n    };\n\n    // Calculate BM25 score\n    const bm25Score = calculateBM25Score(queryTerms, docStats, corpusStats, bm25Config);\n    const normalizedBM25 = normalizeBM25Score(bm25Score);\n\n    return {\n      ...match,\n      bm25Score: normalizedBM25,\n    };\n  });\n}\n","/**\n * Match Highlighting Utilities\n * Calculates positions of matched characters for UI highlighting\n */\n\nimport type { MatchHighlight, MatchType, SearchMatch } from \"./types.js\";\n\n/**\n * Calculate highlights for a search match\n */\nexport function calculateHighlights(\n  match: SearchMatch,\n  query: string,\n  displayText: string\n): MatchHighlight[] {\n  const highlights: MatchHighlight[] = [];\n  const normalizedDisplay = displayText.toLowerCase();\n  const normalizedQuery = query.toLowerCase();\n\n  switch (match.matchType) {\n    case \"exact\":\n      // Highlight the entire word\n      highlights.push({\n        start: 0,\n        end: displayText.length,\n        type: \"exact\",\n      });\n      break;\n\n    case \"prefix\":\n      // Highlight the matching prefix\n      const prefixEnd = Math.min(normalizedQuery.length, displayText.length);\n      highlights.push({\n        start: 0,\n        end: prefixEnd,\n        type: \"prefix\",\n      });\n      break;\n\n    case \"substring\":\n      // Find where the query appears in the display text\n      const substringIndex = normalizedDisplay.indexOf(normalizedQuery);\n      if (substringIndex !== -1) {\n        highlights.push({\n          start: substringIndex,\n          end: substringIndex + normalizedQuery.length,\n          type: \"substring\",\n        });\n      }\n      break;\n\n    case \"fuzzy\":\n      // For fuzzy matches, highlight matching characters\n      highlights.push(...calculateFuzzyHighlights(normalizedQuery, normalizedDisplay, \"fuzzy\"));\n      break;\n\n    case \"ngram\":\n      // Highlight n-gram matches\n      highlights.push(...calculateNgramHighlights(normalizedQuery, normalizedDisplay));\n      break;\n\n    case \"phonetic\":\n    case \"synonym\":\n    case \"compound\":\n      // For phonetic/synonym/compound, highlight the whole word\n      highlights.push({\n        start: 0,\n        end: displayText.length,\n        type: match.matchType,\n      });\n      break;\n  }\n\n  return mergeOverlappingHighlights(highlights);\n}\n\n/**\n * Calculate highlights for fuzzy matches using edit distance alignment\n */\nfunction calculateFuzzyHighlights(\n  query: string,\n  text: string,\n  type: MatchType\n): MatchHighlight[] {\n  const highlights: MatchHighlight[] = [];\n  let queryIdx = 0;\n  let textIdx = 0;\n\n  // Simple greedy matching - find matching characters\n  while (queryIdx < query.length && textIdx < text.length) {\n    if (query[queryIdx] === text[textIdx]) {\n      // Found a match\n      const start = textIdx;\n      let end = textIdx + 1;\n\n      // Extend the match as far as possible\n      queryIdx++;\n      textIdx++;\n      while (queryIdx < query.length && textIdx < text.length && query[queryIdx] === text[textIdx]) {\n        end++;\n        queryIdx++;\n        textIdx++;\n      }\n\n      highlights.push({ start, end, type });\n    } else {\n      textIdx++;\n    }\n  }\n\n  return highlights;\n}\n\n/**\n * Calculate highlights for n-gram matches\n */\nfunction calculateNgramHighlights(\n  query: string,\n  text: string\n): MatchHighlight[] {\n  const highlights: MatchHighlight[] = [];\n  const ngramSize = 3;\n\n  // Find all n-grams from query that appear in text\n  for (let i = 0; i <= query.length - ngramSize; i++) {\n    const ngram = query.slice(i, i + ngramSize);\n    let searchStart = 0;\n\n    // Find all occurrences of this n-gram\n    while (true) {\n      const index = text.indexOf(ngram, searchStart);\n      if (index === -1) break;\n\n      highlights.push({\n        start: index,\n        end: index + ngramSize,\n        type: \"ngram\",\n      });\n\n      searchStart = index + 1;\n    }\n  }\n\n  return highlights;\n}\n\n/**\n * Merge overlapping highlights to avoid duplicate highlighting\n */\nfunction mergeOverlappingHighlights(highlights: MatchHighlight[]): MatchHighlight[] {\n  if (highlights.length === 0) return [];\n\n  // Sort by start position\n  const sorted = [...highlights].sort((a, b) => a.start - b.start);\n  const merged: MatchHighlight[] = [sorted[0]];\n\n  for (let i = 1; i < sorted.length; i++) {\n    const current = sorted[i];\n    const last = merged[merged.length - 1];\n\n    if (current.start <= last.end) {\n      // Overlapping - merge them\n      last.end = Math.max(last.end, current.end);\n      // Keep the more specific match type\n      if (getMatchTypePriority(current.type) > getMatchTypePriority(last.type)) {\n        last.type = current.type;\n      }\n    } else {\n      // No overlap - add as new highlight\n      merged.push(current);\n    }\n  }\n\n  return merged;\n}\n\n/**\n * Get priority for match types (higher = more specific)\n */\nfunction getMatchTypePriority(type: MatchType): number {\n  const priorities: Record<MatchType, number> = {\n    exact: 10,\n    prefix: 9,\n    substring: 8,\n    fuzzy: 7,\n    ngram: 6,\n    phonetic: 5,\n    compound: 4,\n    synonym: 3,\n  };\n  return priorities[type] || 0;\n}\n\n/**\n * Format highlighted text for HTML rendering\n */\nexport function formatHighlightedHTML(\n  text: string,\n  highlights: MatchHighlight[],\n  className: string = \"highlight\"\n): string {\n  if (!highlights || highlights.length === 0) {\n    return escapeHTML(text);\n  }\n\n  let result = \"\";\n  let lastEnd = 0;\n\n  for (const highlight of highlights) {\n    // Add text before highlight\n    if (highlight.start > lastEnd) {\n      result += escapeHTML(text.slice(lastEnd, highlight.start));\n    }\n\n    // Add highlighted text\n    const highlightedText = text.slice(highlight.start, highlight.end);\n    result += `<mark class=\"${className} ${className}--${highlight.type}\">${escapeHTML(highlightedText)}</mark>`;\n\n    lastEnd = highlight.end;\n  }\n\n  // Add remaining text\n  if (lastEnd < text.length) {\n    result += escapeHTML(text.slice(lastEnd));\n  }\n\n  return result;\n}\n\n/**\n * Escape HTML special characters\n */\nfunction escapeHTML(text: string): string {\n  const div = typeof document !== \"undefined\" ? document.createElement(\"div\") : null;\n  if (div) {\n    div.textContent = text;\n    return div.innerHTML;\n  }\n  // Fallback for Node.js\n  return text\n    .replace(/&/g, \"&amp;\")\n    .replace(/</g, \"&lt;\")\n    .replace(/>/g, \"&gt;\")\n    .replace(/\"/g, \"&quot;\")\n    .replace(/'/g, \"&#039;\");\n}\n","/**\n * LRU Cache for Search Results\n * Provides 10-100x speedup for repeated queries (e.g., autocomplete)\n */\n\nimport type { SuggestionResult } from \"./types.js\";\n\n/**\n * LRU (Least Recently Used) Cache\n * Automatically evicts oldest entries when capacity is reached\n */\nexport class LRUCache<K, V> {\n  private cache: Map<K, V>;\n  private capacity: number;\n\n  constructor(capacity: number = 100) {\n    this.cache = new Map();\n    this.capacity = capacity;\n  }\n\n  /**\n   * Get value from cache\n   * Moves item to end (most recently used)\n   */\n  get(key: K): V | undefined {\n    if (!this.cache.has(key)) {\n      return undefined;\n    }\n\n    // Move to end (most recently used)\n    const value = this.cache.get(key)!;\n    this.cache.delete(key);\n    this.cache.set(key, value);\n\n    return value;\n  }\n\n  /**\n   * Set value in cache\n   * Evicts oldest entry if capacity exceeded\n   */\n  set(\n    //\n    key: K,\n    value: V\n  ): void {\n    // Remove if exists (to update position)\n    if (this.cache.has(key)) {\n      this.cache.delete(key);\n    }\n\n    // Add to end (most recently used)\n    this.cache.set(key, value);\n\n    // Evict oldest if over capacity\n    if (this.cache.size > this.capacity) {\n      const firstKey = this.cache.keys().next().value as K;\n      if (firstKey !== undefined) {\n        this.cache.delete(firstKey);\n      }\n    }\n  }\n\n  /**\n   * Check if key exists in cache\n   */\n  has(key: K): boolean {\n    return this.cache.has(key);\n  }\n\n  /**\n   * Clear all cached entries\n   */\n  clear(): void {\n    this.cache.clear();\n  }\n\n  /**\n   * Get current cache size\n   */\n  get size(): number {\n    return this.cache.size;\n  }\n\n  /**\n   * Get cache statistics\n   */\n  getStats(): {\n    //\n    size: number;\n    capacity: number;\n    utilization: number;\n  } {\n    return {\n      size: this.cache.size,\n      capacity: this.capacity,\n      utilization: this.cache.size / this.capacity,\n    };\n  }\n}\n\n/**\n * Search Result Cache\n * Caches search results with automatic invalidation\n */\nexport class SearchCache {\n  private cache: LRUCache<string, SuggestionResult[]>;\n  private hits: number = 0;\n  private misses: number = 0;\n\n  constructor(capacity: number = 100) {\n    this.cache = new LRUCache(capacity);\n  }\n\n  /**\n   * Generate cache key from query and options\n   */\n  private getCacheKey(query: string, maxResults?: number, options?: any): string {\n    const optionsKey = options ? JSON.stringify(options) : \"\";\n    return `${query}|${maxResults || \"default\"}|${optionsKey}`;\n  }\n\n  /**\n   * Get cached results\n   */\n  get(query: string, maxResults?: number, options?: any): SuggestionResult[] | undefined {\n    const key = this.getCacheKey(query, maxResults, options);\n    const result = this.cache.get(key);\n\n    if (result) {\n      this.hits++;\n    } else {\n      this.misses++;\n    }\n\n    return result;\n  }\n\n  /**\n   * Set cached results\n   */\n  set(query: string, results: SuggestionResult[], maxResults?: number, options?: any): void {\n    const key = this.getCacheKey(query, maxResults, options);\n    this.cache.set(key, results);\n  }\n\n  /**\n   * Clear cache\n   */\n  clear(): void {\n    this.cache.clear();\n    this.hits = 0;\n    this.misses = 0;\n  }\n\n  /**\n   * Get cache statistics\n   */\n  getStats(): {\n    //\n    size: number;\n    capacity: number;\n    hits: number;\n    misses: number;\n    hitRate: number;\n  } {\n    const cacheStats = this.cache.getStats();\n    const total = this.hits + this.misses;\n    const hitRate = total > 0 ? this.hits / total : 0;\n\n    return {\n      ...cacheStats,\n      hits: this.hits,\n      misses: this.misses,\n      hitRate,\n    };\n  }\n}\n","/**\n * Accent Normalization Utilities\n * Removes diacritics and accents from text for better matching\n */\n\n/**\n * Comprehensive accent/diacritic mapping\n * Maps accented characters to their base forms\n */\nconst ACCENT_MAP: Record<string, string> = {\n  // Latin Extended-A\n  à: \"a\",\n  á: \"a\",\n  â: \"a\",\n  ã: \"a\",\n  ä: \"a\",\n  å: \"a\",\n  ā: \"a\",\n  ă: \"a\",\n  ą: \"a\",\n  À: \"A\",\n  Á: \"A\",\n  Â: \"A\",\n  Ã: \"A\",\n  Ä: \"A\",\n  Å: \"A\",\n  Ā: \"A\",\n  Ă: \"A\",\n  Ą: \"A\",\n\n  è: \"e\",\n  é: \"e\",\n  ê: \"e\",\n  ë: \"e\",\n  ē: \"e\",\n  ĕ: \"e\",\n  ė: \"e\",\n  ę: \"e\",\n  ě: \"e\",\n  È: \"E\",\n  É: \"E\",\n  Ê: \"E\",\n  Ë: \"E\",\n  Ē: \"E\",\n  Ĕ: \"E\",\n  Ė: \"E\",\n  Ę: \"E\",\n  Ě: \"E\",\n\n  ì: \"i\",\n  í: \"i\",\n  î: \"i\",\n  ï: \"i\",\n  ĩ: \"i\",\n  ī: \"i\",\n  ĭ: \"i\",\n  į: \"i\",\n  Ì: \"I\",\n  Í: \"I\",\n  Î: \"I\",\n  Ï: \"I\",\n  Ĩ: \"I\",\n  Ī: \"I\",\n  Ĭ: \"I\",\n  Į: \"I\",\n\n  'ò': 'o', 'ó': 'o', 'ô': 'o', 'õ': 'o', 'ö': 'o', 'ø': 'o', 'ō': 'o', 'ŏ': 'o', 'ő': 'o',\n  'Ò': 'O', 'Ó': 'O', 'Ô': 'O', 'Õ': 'O', 'Ö': 'O', 'Ø': 'O', 'Ō': 'O', 'Ŏ': 'O', 'Ő': 'O',\n\n  'ù': 'u', 'ú': 'u', 'û': 'u', 'ü': 'u', 'ũ': 'u', 'ū': 'u', 'ŭ': 'u', 'ů': 'u', 'ű': 'u', 'ų': 'u',\n  'Ù': 'U', 'Ú': 'U', 'Û': 'U', 'Ü': 'U', 'Ũ': 'U', 'Ū': 'U', 'Ŭ': 'U', 'Ů': 'U', 'Ű': 'U', 'Ų': 'U',\n\n  ý: \"y\",\n  ÿ: \"y\",\n  ŷ: \"y\",\n  Ý: \"Y\",\n  Ÿ: \"Y\",\n  Ŷ: \"Y\",\n\n  ñ: \"n\",\n  ń: \"n\",\n  ņ: \"n\",\n  ň: \"n\",\n  Ñ: \"N\",\n  Ń: \"N\",\n  Ņ: \"N\",\n  Ň: \"N\",\n\n  ç: \"c\",\n  ć: \"c\",\n  ĉ: \"c\",\n  ċ: \"c\",\n  č: \"c\",\n  Ç: \"C\",\n  Ć: \"C\",\n  Ĉ: \"C\",\n  Ċ: \"C\",\n  Č: \"C\",\n\n  ß: \"ss\", // German sharp s\n\n  ð: \"d\",\n  đ: \"d\",\n  Ð: \"D\",\n  Đ: \"D\",\n\n  ĝ: \"g\",\n  ğ: \"g\",\n  ġ: \"g\",\n  ģ: \"g\",\n  Ĝ: \"G\",\n  Ğ: \"G\",\n  Ġ: \"G\",\n  Ģ: \"G\",\n\n  ĥ: \"h\",\n  ħ: \"h\",\n  Ĥ: \"H\",\n  Ħ: \"H\",\n\n  ĵ: \"j\",\n  Ĵ: \"J\",\n\n  ķ: \"k\",\n  Ķ: \"K\",\n\n  ĺ: \"l\",\n  ļ: \"l\",\n  ľ: \"l\",\n  ŀ: \"l\",\n  ł: \"l\",\n  Ĺ: \"L\",\n  Ļ: \"L\",\n  Ľ: \"L\",\n  Ŀ: \"L\",\n  Ł: \"L\",\n\n  ŕ: \"r\",\n  ŗ: \"r\",\n  ř: \"r\",\n  Ŕ: \"R\",\n  Ŗ: \"R\",\n  Ř: \"R\",\n\n  ś: \"s\",\n  ŝ: \"s\",\n  ş: \"s\",\n  š: \"s\",\n  Ś: \"S\",\n  Ŝ: \"S\",\n  Ş: \"S\",\n  Š: \"S\",\n\n  ţ: \"t\",\n  ť: \"t\",\n  ŧ: \"t\",\n  Ţ: \"T\",\n  Ť: \"T\",\n  Ŧ: \"T\",\n\n  ŵ: \"w\",\n  Ŵ: \"W\",\n\n  ź: \"z\",\n  ż: \"z\",\n  ž: \"z\",\n  Ź: \"Z\",\n  Ż: \"Z\",\n  Ž: \"Z\",\n\n  æ: \"ae\",\n  œ: \"oe\",\n  Æ: \"AE\",\n  Œ: \"OE\",\n\n  þ: \"th\",\n  Þ: \"TH\",\n};\n\n/**\n * Cache for accent removal results\n * Dramatically speeds up repeated accent normalization\n */\nconst accentCache = new Map<string, string>();\nconst MAX_CACHE_SIZE = 10000; // TODO: Adjust based on memory constraints\n\n/**\n * Remove accents and diacritics from a string\n * Uses both custom mapping and Unicode normalization with caching\n */\nexport function removeAccents(text: string): string {\n  if (!text) return text;\n\n  // Check cache first (massive speedup for repeated words)\n  const cached = accentCache.get(text);\n  if (cached !== undefined) {\n    return cached;\n  }\n\n  // OPTIMIZATION: Use array join instead of string concatenation\n  const chars: string[] = [];\n  for (let i = 0; i < text.length; i++) {\n    const char = text[i];\n    chars.push(ACCENT_MAP[char] || char);\n  }\n  let result = chars.join('');\n\n  // Second pass: Use Unicode normalization for any remaining accents\n  // NFD = Canonical Decomposition (separates base char from combining marks)\n  // Then remove combining diacritical marks (Unicode range \\u0300-\\u036f)\n  result = result.normalize(\"NFD\").replace(/[\\u0300-\\u036f]/g, \"\");\n\n  // Cache the result (with size limit)\n  if (accentCache.size < MAX_CACHE_SIZE) {\n    accentCache.set(text, result);\n  } else if (accentCache.size === MAX_CACHE_SIZE) {\n    // Clear cache when it gets too large (keep most recent)\n    accentCache.clear();\n    accentCache.set(text, result);\n  }\n\n  return result;\n}\n\n/**\n * Check if a string contains any accented characters\n * Optimized with early return\n */\nexport function hasAccents(text: string): boolean {\n  if (!text) return false;\n\n  // OPTIMIZATION: Check custom map first (fast path)\n  for (let i = 0; i < text.length; i++) {\n    if (ACCENT_MAP[text[i]]) {\n      return true;\n    }\n  }\n\n  // OPTIMIZATION: Only normalize if we didn't find accents in map\n  // Check for combining diacritical marks\n  return /[\\u0300-\\u036f]/.test(text.normalize(\"NFD\"));\n}\n\n/**\n * Normalize text for accent-insensitive comparison\n * Converts to lowercase and removes accents\n */\nexport function normalizeForComparison(text: string): string {\n  return removeAccents(text.toLowerCase());\n}\n\n/**\n * Create accent-insensitive variants of a word\n * Returns both original and accent-free version\n */\nexport function getAccentVariants(word: string): string[] {\n  const normalized = removeAccents(word);\n\n  // If word has accents, return both versions\n  if (normalized !== word) {\n    return [word, normalized];\n  }\n\n  // Otherwise just return original\n  return [word];\n}\n","/**\n * Field Weighting Utilities\n * Support for multi-field search with weighted scoring\n */\n\n/**\n * Extract field values from an object or string\n */\nexport function extractFieldValues(\n  //\n  item: any,\n  fields?: string[]\n): Record<string, string> | null {\n  // If no fields specified, treat item as simple string\n  if (!fields || fields.length === 0) {\n    return null;\n  }\n\n  // If item is a string, can't extract fields\n  if (typeof item === \"string\") {\n    return null;\n  }\n\n  // If item is an object, extract field values\n  if (typeof item === \"object\" && item !== null) {\n    const fieldValues: Record<string, string> = {};\n\n    for (const field of fields) {\n      const value = item[field];\n      if (value !== undefined && value !== null) {\n        fieldValues[field] = String(value);\n      }\n    }\n\n    return Object.keys(fieldValues).length > 0 ? fieldValues : null;\n  }\n\n  return null;\n}\n\n/**\n * Get all searchable text from field values\n */\nexport function getSearchableText(\n  //\n  fieldValues: Record<string, string>\n): string[] {\n  return Object.values(fieldValues).filter((v) => v && v.trim().length > 0);\n}\n\n/**\n * Normalize field weights (ensure all fields have a weight)\n */\nexport function normalizeFieldWeights(\n  //\n  fields: string[],\n  fieldWeights?: Record<string, number>\n): Record<string, number> {\n  const normalized: Record<string, number> = {};\n\n  for (const field of fields) {\n    normalized[field] = fieldWeights?.[field] ?? 1.0;\n  }\n\n  return normalized;\n}\n\n/**\n * Apply field weight to a score\n */\nexport function applyFieldWeight(\n  //\n  baseScore: number,\n  fieldWeight: number\n): number {\n  return Math.min(1.0, baseScore * fieldWeight);\n}\n","/**\n * Stop Words Filtering\n * Common words that should be ignored in search queries\n */\n\n/**\n * Default stop words by language\n */\nexport const DEFAULT_STOP_WORDS: Record<string, string[]> = {\n  english: [\n    //\n    \"a\",\n    \"an\",\n    \"and\",\n    \"are\",\n    \"as\",\n    \"at\",\n    \"be\",\n    \"by\",\n    \"for\",\n    \"from\",\n    \"has\",\n    \"he\",\n    \"in\",\n    \"is\",\n    \"it\",\n    \"its\",\n    \"of\",\n    \"on\",\n    \"that\",\n    \"the\",\n    \"to\",\n    \"was\",\n    \"will\",\n    \"with\",\n    \"the\",\n    \"this\",\n    \"but\",\n    \"they\",\n    \"have\",\n    \"had\",\n    \"what\",\n    \"when\",\n    \"where\",\n    \"who\",\n    \"which\",\n    \"why\",\n    \"how\",\n  ],\n  german: [\n    //\n    \"der\",\n    \"die\",\n    \"das\",\n    \"den\",\n    \"dem\",\n    \"des\",\n    \"ein\",\n    \"eine\",\n    \"einer\",\n    \"eines\",\n    \"einem\",\n    \"einen\",\n    \"und\",\n    \"oder\",\n    \"aber\",\n    \"ist\",\n    \"sind\",\n    \"war\",\n    \"waren\",\n    \"hat\",\n    \"haben\",\n    \"wird\",\n    \"werden\",\n    \"von\",\n    \"zu\",\n    \"im\",\n    \"am\",\n    \"um\",\n    \"auf\",\n    \"für\",\n    \"mit\",\n    \"nach\",\n    \"bei\",\n    \"aus\",\n  ],\n  spanish: [\n    //\n    \"el\",\n    \"la\",\n    \"los\",\n    \"las\",\n    \"un\",\n    \"una\",\n    \"unos\",\n    \"unas\",\n    \"de\",\n    \"del\",\n    \"y\",\n    \"o\",\n    \"pero\",\n    \"es\",\n    \"son\",\n    \"era\",\n    \"fueron\",\n    \"ha\",\n    \"han\",\n    \"en\",\n    \"a\",\n    \"al\",\n    \"con\",\n    \"por\",\n    \"para\",\n    \"sin\",\n    \"sobre\",\n    \"entre\",\n  ],\n  french: [\n    //\n    \"le\",\n    \"la\",\n    \"les\",\n    \"un\",\n    \"une\",\n    \"des\",\n    \"du\",\n    \"de\",\n    \"et\",\n    \"ou\",\n    \"mais\",\n    \"est\",\n    \"sont\",\n    \"était\",\n    \"étaient\",\n    \"a\",\n    \"ont\",\n    \"à\",\n    \"au\",\n    \"aux\",\n    \"avec\",\n    \"pour\",\n    \"par\",\n    \"dans\",\n    \"sur\",\n    \"sous\",\n    \"entre\",\n  ],\n};\n\n/**\n * Filter stop words from a query\n */\nexport function filterStopWords(\n  query: string,\n  stopWords: string[] | Set<string>\n): string {\n  const stopWordsSet = stopWords instanceof Set ? stopWords : new Set(stopWords.map(w => w.toLowerCase()));\n  \n  // Split query into words, preserving original case\n  const words = query.split(/\\s+/);\n  const filtered = words.filter(word => !stopWordsSet.has(word.toLowerCase()));\n  \n  // If all words are stop words, return original query to avoid empty search\n  if (filtered.length === 0) {\n    return query;\n  }\n  \n  return filtered.join(' ');\n}\n\n/**\n * Get stop words for specific languages\n */\nexport function getStopWordsForLanguages(languages: string[]): Set<string> {\n  const stopWords = new Set<string>();\n\n  for (const lang of languages) {\n    const langStopWords = DEFAULT_STOP_WORDS[lang.toLowerCase()];\n    if (langStopWords) {\n      langStopWords.forEach((word) => stopWords.add(word));\n    }\n  }\n\n  return stopWords;\n}\n\n/**\n * Check if a word is a stop word\n */\nexport function isStopWord(word: string, stopWords: string[] | Set<string>): boolean {\n  const stopWordsSet = stopWords instanceof Set ? stopWords : new Set(stopWords.map((w) => w.toLowerCase()));\n  return stopWordsSet.has(word.toLowerCase());\n}\n","/**\n * Word Boundary Utilities\n * Check if matches occur at word boundaries for more precise results\n */\n\n/**\n * Check if a match is at a word boundary\n * A word boundary is:\n * - Start of string\n * - After whitespace\n * - After punctuation\n */\nexport function isWordBoundary(text: string, position: number): boolean {\n  // Start of string is always a word boundary\n  if (position === 0) {\n    return true;\n  }\n\n  // Check the character before the position\n  const charBefore = text[position - 1];\n  \n  // Word boundary if previous character is whitespace or punctuation\n  return /[\\s\\-_.,;:!?()[\\]{}'\"\\/\\\\]/.test(charBefore);\n}\n\n/**\n * Check if a match occurs at word boundaries (both start and end)\n */\nexport function matchesAtWordBoundary(\n  text: string,\n  matchStart: number,\n  matchLength: number\n): boolean {\n  const matchEnd = matchStart + matchLength;\n  \n  // Check start boundary\n  const startBoundary = isWordBoundary(text, matchStart);\n  \n  // Check end boundary (either end of string or followed by boundary character)\n  const endBoundary = matchEnd >= text.length || /[\\s\\-_.,;:!?()[\\]{}'\"\\/\\\\]/.test(text[matchEnd]);\n  \n  return startBoundary && endBoundary;\n}\n\n/**\n * Find all word boundary matches of a pattern in text\n */\nexport function findWordBoundaryMatches(\n  text: string,\n  pattern: string,\n  caseSensitive: boolean = false\n): number[] {\n  const positions: number[] = [];\n  const searchText = caseSensitive ? text : text.toLowerCase();\n  const searchPattern = caseSensitive ? pattern : pattern.toLowerCase();\n  \n  let index = 0;\n  while (index < searchText.length) {\n    const found = searchText.indexOf(searchPattern, index);\n    \n    if (found === -1) {\n      break;\n    }\n    \n    // Check if this match is at a word boundary\n    if (matchesAtWordBoundary(text, found, searchPattern.length)) {\n      positions.push(found);\n    }\n    \n    index = found + 1;\n  }\n  \n  return positions;\n}\n\n/**\n * Check if query matches word with word boundaries\n */\nexport function matchesWord(word: string, query: string, wordBoundaries: boolean): boolean {\n  if (!wordBoundaries) {\n    // No word boundary checking - substring match is fine\n    return word.toLowerCase().includes(query.toLowerCase());\n  }\n  \n  // With word boundaries - must match at word boundary\n  const positions = findWordBoundaryMatches(word, query, false);\n  return positions.length > 0;\n}\n\n/**\n * Check if a word starts with query (prefix match with word boundaries)\n */\nexport function startsWithWord(word: string, query: string, wordBoundaries: boolean): boolean {\n  const wordLower = word.toLowerCase();\n  const queryLower = query.toLowerCase();\n  \n  if (!wordBoundaries) {\n    return wordLower.startsWith(queryLower);\n  }\n  \n  // With word boundaries - check if it starts at position 0 (which is always a boundary)\n  return wordLower.startsWith(queryLower);\n}\n\n/**\n * Parse wildcard pattern (supports * for any characters)\n */\nexport function parseWildcard(pattern: string): RegExp {\n  // Escape special regex characters except *\n  const escaped = pattern.replace(/[.+?^${}()|[\\]\\\\]/g, '\\\\$&');\n  \n  // Replace * with .*\n  const regexPattern = escaped.replace(/\\*/g, '.*');\n  \n  // Create regex with word boundaries if no wildcards\n  return new RegExp(`^${regexPattern}$`, 'i');\n}\n\n/**\n * Check if word matches wildcard pattern\n */\nexport function matchesWildcard(word: string, pattern: string): boolean {\n  const regex = parseWildcard(pattern);\n  return regex.test(word);\n}\n","/**\n * Phrase parser for multi-word query support\n * Extracts quoted phrases and regular terms from search queries\n */\n\nexport interface ParsedQuery {\n  /** Quoted phrases to search as units */\n  phrases: string[];\n  /** Individual search terms */\n  terms: string[];\n  /** Original query string */\n  original: string;\n  /** Whether query contains any phrases */\n  hasPhrases: boolean;\n}\n\n/**\n * Parse a search query to extract phrases and terms\n * Supports both double quotes (\") and single quotes (')\n * \n * @example\n * parseQuery('\"new york\" city')\n * // → { phrases: ['new york'], terms: ['city'], hasPhrases: true }\n * \n * parseQuery('hello world')\n * // → { phrases: [], terms: ['hello', 'world'], hasPhrases: false }\n */\nexport function parseQuery(query: string): ParsedQuery {\n  if (!query || typeof query !== 'string') {\n    return {\n      phrases: [],\n      terms: [],\n      original: query || '',\n      hasPhrases: false,\n    };\n  }\n\n  const phrases: string[] = [];\n  let remaining = query;\n\n  // Extract phrases with double quotes\n  const doubleQuoteRegex = /\"([^\"]+)\"/g;\n  let match;\n  \n  while ((match = doubleQuoteRegex.exec(query)) !== null) {\n    const phrase = match[1].trim();\n    if (phrase) {\n      // Validate phrase length (max 10 words)\n      const wordCount = phrase.split(/\\s+/).length;\n      if (wordCount <= 10) {\n        phrases.push(phrase);\n      }\n    }\n  }\n\n  // Remove double-quoted phrases from remaining text (including empty ones)\n  remaining = remaining.replace(/\"[^\"]*\"/g, ' ');\n\n  // Extract phrases with single quotes\n  const singleQuoteRegex = /'([^']+)'/g;\n  \n  while ((match = singleQuoteRegex.exec(query)) !== null) {\n    const phrase = match[1].trim();\n    if (phrase) {\n      // Validate phrase length (max 10 words)\n      const wordCount = phrase.split(/\\s+/).length;\n      if (wordCount <= 10) {\n        phrases.push(phrase);\n      }\n    }\n  }\n\n  // Remove single-quoted phrases from remaining text (including empty ones)\n  remaining = remaining.replace(/'[^']*'/g, ' ');\n\n  // Extract remaining terms (non-phrase words)\n  const terms = remaining\n    .split(/\\s+/)\n    .map(t => t.trim())\n    .filter(t => t.length > 0);\n\n  return {\n    phrases,\n    terms,\n    original: query,\n    hasPhrases: phrases.length > 0,\n  };\n}\n\n/**\n * Check if a query contains phrase syntax (quotes)\n */\nexport function hasPhraseSyntax(query: string): boolean {\n  if (!query) return false;\n  return /\"[^\"]*\"/.test(query) || /'[^']*'/.test(query);\n}\n\n/**\n * Normalize a phrase for matching (lowercase, trim)\n */\nexport function normalizePhrase(phrase: string): string {\n  return phrase.toLowerCase().trim().replace(/\\s+/g, ' ');\n}\n\n/**\n * Split a phrase into words\n */\nexport function splitPhraseWords(phrase: string): string[] {\n  return phrase\n    .toLowerCase()\n    .trim()\n    .split(/\\s+/)\n    .filter(w => w.length > 0);\n}\n","/**\n * Phrase matching algorithms for multi-word query support\n */\n\nimport { calculateLevenshteinDistance, calculateDamerauLevenshteinDistance } from \"../algorithms/levenshtein.js\";\n\nexport interface PhraseMatchOptions {\n  /** Require exact phrase match (no typos) */\n  exactMatch?: boolean;\n  /** Maximum edit distance per word in phrase */\n  maxEditDistance?: number;\n  /** Score multiplier for phrase matches */\n  proximityBonus?: number;\n  /** Maximum words between phrase words for proximity match */\n  maxProximityDistance?: number;\n  /** Use Damerau-Levenshtein (transpositions) */\n  useTranspositions?: boolean;\n}\n\nexport interface PhraseMatchResult {\n  /** Whether phrase was found */\n  matched: boolean;\n  /** Match score (0-1) */\n  score: number;\n  /** Type of match */\n  matchType: \"exact\" | \"fuzzy\" | \"proximity\" | \"none\";\n  /** Start position in text */\n  startPos?: number;\n  /** End position in text */\n  endPos?: number;\n  /** Words that matched */\n  matchedWords?: string[];\n}\n\nconst DEFAULT_OPTIONS: Required<PhraseMatchOptions> = {\n  exactMatch: false,\n  maxEditDistance: 1,\n  proximityBonus: 1.5,\n  maxProximityDistance: 3,\n  useTranspositions: false,\n};\n\n/**\n * Match a phrase in text with various strategies\n */\nexport function matchPhrase(\n  //\n  text: string,\n  phrase: string,\n  options: PhraseMatchOptions = {}\n): PhraseMatchResult {\n  const opts = { ...DEFAULT_OPTIONS, ...options };\n\n  if (!text || !phrase) {\n    return { matched: false, score: 0, matchType: \"none\" };\n  }\n\n  const normalizedText = text.toLowerCase();\n  const normalizedPhrase = phrase.toLowerCase();\n\n  // Strategy 1: Exact phrase match (highest score)\n  const exactMatch = findExactPhrase(normalizedText, normalizedPhrase);\n  if (exactMatch.matched) {\n    return { ...exactMatch, score: 1.0, matchType: \"exact\" };\n  }\n\n  // If exact match required, stop here\n  if (opts.exactMatch) {\n    return { matched: false, score: 0, matchType: \"none\" };\n  }\n\n  // Strategy 2: Fuzzy phrase match (allow typos)\n  const fuzzyMatch = findFuzzyPhrase(normalizedText, normalizedPhrase, opts.maxEditDistance, opts.useTranspositions);\n  if (fuzzyMatch.matched) {\n    return { ...fuzzyMatch, matchType: \"fuzzy\" };\n  }\n\n  // Strategy 3: Proximity match (words nearby)\n  const proximityMatch = findProximityMatch(normalizedText, normalizedPhrase, opts.maxProximityDistance);\n  if (proximityMatch.matched) {\n    return { ...proximityMatch, matchType: \"proximity\" };\n  }\n\n  return { matched: false, score: 0, matchType: \"none\" };\n}\n\n/**\n * Find exact phrase in text\n */\nfunction findExactPhrase(\n  //\n  text: string,\n  phrase: string\n): PhraseMatchResult {\n  const index = text.indexOf(phrase);\n\n  if (index !== -1) {\n    return {\n      matched: true,\n      score: 1.0,\n      matchType: \"exact\",\n      startPos: index,\n      endPos: index + phrase.length,\n    };\n  }\n\n  return { matched: false, score: 0, matchType: \"none\" };\n}\n\n/**\n * Find phrase with fuzzy matching (allow typos)\n */\nfunction findFuzzyPhrase(\n  //\n  text: string,\n  phrase: string,\n  maxEditDistance: number,\n  useTranspositions: boolean\n): PhraseMatchResult {\n  const phraseWords = phrase.split(/\\s+/);\n  const textWords = text.split(/\\s+/);\n\n  // Try to find consecutive words that match the phrase\n  for (let i = 0; i <= textWords.length - phraseWords.length; i++) {\n    const segment = textWords.slice(i, i + phraseWords.length);\n\n    // Check if this segment matches the phrase with fuzzy matching\n    let totalDistance = 0;\n    let allMatch = true;\n\n    for (let j = 0; j < phraseWords.length; j++) {\n      const distance = useTranspositions ? calculateDamerauLevenshteinDistance(phraseWords[j], segment[j], maxEditDistance) : calculateLevenshteinDistance(phraseWords[j], segment[j], maxEditDistance);\n\n      if (distance > maxEditDistance) {\n        allMatch = false;\n        break;\n      }\n      totalDistance += distance;\n    }\n\n    if (allMatch) {\n      // Calculate score based on edit distance\n      const maxPossibleDistance = phraseWords.length * maxEditDistance;\n      const score = maxPossibleDistance > 0 ? 0.7 + 0.2 * (1 - totalDistance / maxPossibleDistance) : 0.9;\n\n      return {\n        matched: true,\n        score,\n        matchType: \"fuzzy\",\n        matchedWords: segment,\n      };\n    }\n  }\n\n  return { matched: false, score: 0, matchType: \"none\" };\n}\n\n/**\n * Find words in proximity (nearby but not necessarily consecutive)\n */\nfunction findProximityMatch(\n  //\n  text: string,\n  phrase: string,\n  maxDistance: number\n): PhraseMatchResult {\n  const phraseWords = phrase.split(/\\s+/);\n  const textWords = text.split(/\\s+/);\n\n  // Find positions of each phrase word in text\n  const positions: number[][] = phraseWords.map(() => []);\n\n  textWords.forEach((word, index) => {\n    phraseWords.forEach((phraseWord, phraseIndex) => {\n      if (word === phraseWord || word.includes(phraseWord) || phraseWord.includes(word)) {\n        positions[phraseIndex].push(index);\n      }\n    });\n  });\n\n  // Check if all words were found\n  if (positions.some((p) => p.length === 0)) {\n    return { matched: false, score: 0, matchType: \"none\" };\n  }\n\n  // Find the best combination where words are close together\n  let bestDistance = Infinity;\n  let bestPositions: number[] = [];\n\n  function findBestCombination(wordIndex: number, currentPositions: number[]): void {\n    if (wordIndex === phraseWords.length) {\n      // Calculate total distance\n      const sorted = [...currentPositions].sort((a, b) => a - b);\n      const distance = sorted[sorted.length - 1] - sorted[0];\n\n      if (distance < bestDistance) {\n        bestDistance = distance;\n        bestPositions = [...currentPositions];\n      }\n      return;\n    }\n\n    for (const pos of positions[wordIndex]) {\n      findBestCombination(wordIndex + 1, [...currentPositions, pos]);\n    }\n  }\n\n  findBestCombination(0, []);\n\n  // Check if words are within max distance\n  if (bestDistance <= maxDistance) {\n    // Score based on proximity (closer = higher score)\n    const score = 0.5 + 0.2 * (1 - bestDistance / maxDistance);\n\n    return {\n      matched: true,\n      score,\n      matchType: \"proximity\",\n      matchedWords: bestPositions.map((i) => textWords[i]),\n    };\n  }\n\n  return { matched: false, score: 0, matchType: \"none\" };\n}\n\n/**\n * Calculate phrase match score for a text\n * Returns 0 if no match, or a boosted score if phrase matches\n */\nexport function calculatePhraseScore(\n  //\n  text: string,\n  phrase: string,\n  baseScore: number,\n  options: PhraseMatchOptions = {}\n): number {\n  const match = matchPhrase(text, phrase, options);\n\n  if (!match.matched) {\n    return 0;\n  }\n\n  // Apply proximity bonus\n  const bonus = options.proximityBonus || 1.5;\n  return Math.min(1.0, baseScore * match.score * bonus);\n}\n","/**\n * Language auto-detection utility\n * Uses character-based heuristics to detect languages in text\n */\n\nexport interface LanguageDetectionResult {\n  /** Detected languages */\n  languages: string[];\n  /** Confidence scores for each language (0-1) */\n  confidence: Record<string, number>;\n  /** Primary language (highest confidence) */\n  primary: string;\n}\n\n/**\n * Detect languages from text using character-based heuristics\n * Detects multiple languages if present in the same text\n * \n * @param text - Text to analyze\n * @returns Array of detected language codes\n * \n * @example\n * detectLanguages('Müller café hello')\n * // → ['english', 'german', 'french']\n */\nexport function detectLanguages(text: string): string[] {\n  if (!text || text.trim().length === 0) {\n    return ['english']; // Default fallback\n  }\n\n  const detected = new Set<string>();\n\n  // Always include English as base language\n  detected.add('english');\n\n  // German indicators: ä, ö, ü, ß\n  if (/[äöüßÄÖÜ]/.test(text)) {\n    detected.add('german');\n  }\n\n  // French indicators: é, è, ê, à, ç, œ, etc.\n  if (/[àâäæçéèêëïîôùûüÿœÀÂÄÆÇÉÈÊËÏÎÔÙÛÜŸŒ]/.test(text)) {\n    detected.add('french');\n  }\n\n  // Spanish indicators: ñ, á, é, í, ó, ú, ¿, ¡\n  if (/[áéíóúñüÁÉÍÓÚÑÜ¿¡]/.test(text)) {\n    detected.add('spanish');\n  }\n\n  return Array.from(detected);\n}\n\n/**\n * Detect languages with confidence scores\n * Provides more detailed information about language detection\n * \n * @param text - Text to analyze\n * @returns Detection result with confidence scores\n */\nexport function detectLanguagesWithConfidence(text: string): LanguageDetectionResult {\n  if (!text || text.trim().length === 0) {\n    return {\n      languages: ['english'],\n      confidence: { english: 1.0 },\n      primary: 'english',\n    };\n  }\n\n  const confidence: Record<string, number> = {\n    english: 0.5, // Base confidence for English\n  };\n\n  const textLength = text.length;\n\n  // Count German characters\n  const germanChars = (text.match(/[äöüßÄÖÜ]/g) || []).length;\n  if (germanChars > 0) {\n    confidence.german = Math.min(1.0, 0.5 + (germanChars / textLength) * 10);\n  }\n\n  // Count French characters\n  const frenchChars = (text.match(/[àâäæçéèêëïîôùûüÿœÀÂÄÆÇÉÈÊËÏÎÔÙÛÜŸŒ]/g) || []).length;\n  if (frenchChars > 0) {\n    confidence.french = Math.min(1.0, 0.5 + (frenchChars / textLength) * 10);\n  }\n\n  // Count Spanish characters\n  const spanishChars = (text.match(/[áéíóúñüÁÉÍÓÚÑÜ¿¡]/g) || []).length;\n  if (spanishChars > 0) {\n    confidence.spanish = Math.min(1.0, 0.5 + (spanishChars / textLength) * 10);\n  }\n\n  // Determine languages (confidence > 0.5)\n  const languages = Object.entries(confidence)\n    .filter(([_, conf]) => conf >= 0.5)\n    .map(([lang]) => lang);\n\n  // Find primary language (highest confidence)\n  const primary = Object.entries(confidence)\n    .sort(([, a], [, b]) => b - a)[0][0];\n\n  return {\n    languages,\n    confidence,\n    primary,\n  };\n}\n\n/**\n * Sample text from a dataset for language detection\n * Takes first N items to avoid processing entire large datasets\n * \n * @param words - Array of words or objects\n * @param sampleSize - Number of items to sample (default: 100)\n * @returns Combined sample text\n */\nexport function sampleTextForDetection(words: (string | any)[], sampleSize: number = 100): string {\n  const sample = words.slice(0, Math.min(sampleSize, words.length));\n  \n  return sample\n    .map(item => {\n      if (typeof item === 'string') {\n        return item;\n      } else if (typeof item === 'object' && item !== null) {\n        // Extract text from object fields\n        return Object.values(item)\n          .filter(v => typeof v === 'string')\n          .join(' ');\n      }\n      return '';\n    })\n    .join(' ');\n}\n\n/**\n * Check if a language code is valid\n */\nexport function isValidLanguage(lang: string): boolean {\n  const validLanguages = ['english', 'german', 'french', 'spanish', 'auto'];\n  return validLanguages.includes(lang.toLowerCase());\n}\n\n/**\n * Normalize language codes\n * Handles common variations and aliases\n */\nexport function normalizeLanguageCode(lang: string): string {\n  const normalized = lang.toLowerCase().trim();\n  \n  // Handle aliases\n  const aliases: Record<string, string> = {\n    'en': 'english',\n    'de': 'german',\n    'fr': 'french',\n    'es': 'spanish',\n    'eng': 'english',\n    'deu': 'german',\n    'fra': 'french',\n    'esp': 'spanish',\n  };\n  \n  return aliases[normalized] || normalized;\n}\n","/**\n * FQL Lexer (Tokenizer)\n * Converts FQL query strings into tokens for parsing\n */\n\nexport const TokenType = {\n  TERM: \"TERM\",\n  QUOTED: \"QUOTED\",\n  AND: \"AND\",\n  OR: \"OR\",\n  NOT: \"NOT\",\n  LPAREN: \"LPAREN\",\n  RPAREN: \"RPAREN\",\n  COLON: \"COLON\",\n  EXACT: \"EXACT\",\n  FUZZY: \"FUZZY\",\n  PHONETIC: \"PHONETIC\",\n  PREFIX: \"PREFIX\",\n  REGEX: \"REGEX\",\n  COMPOUND: \"COMPOUND\",\n  LANG: \"LANG\",\n  SCORE: \"SCORE\",\n  SCORE_OP: \"SCORE_OP\",\n  NUMBER: \"NUMBER\",\n  EOF: \"EOF\",\n} as const;\n\nexport type TokenType = (typeof TokenType)[keyof typeof TokenType];\n\nexport interface Token {\n  type: TokenType;\n  value: string;\n  position: number;\n}\n\nexport class FQLLexer {\n  private input: string = \"\";\n  private position: number = 0;\n  private tokens: Token[] = [];\n\n  /**\n   * Tokenize an FQL query string\n   */\n  tokenize(input: string): Token[] {\n    this.input = input.trim();\n    this.position = 0;\n    this.tokens = [];\n\n    while (this.position < this.input.length) {\n      this.skipWhitespace();\n\n      if (this.position >= this.input.length) break;\n\n      const char = this.input[this.position];\n\n      // Parentheses\n      if (char === \"(\") {\n        this.tokens.push({ type: TokenType.LPAREN, value: \"(\", position: this.position });\n        this.position++;\n        continue;\n      }\n\n      if (char === \")\") {\n        this.tokens.push({ type: TokenType.RPAREN, value: \")\", position: this.position });\n        this.position++;\n        continue;\n      }\n\n      // Colon\n      if (char === \":\") {\n        this.tokens.push({ type: TokenType.COLON, value: \":\", position: this.position });\n        this.position++;\n        continue;\n      }\n\n      // Quoted strings\n      if (char === '\"' || char === \"'\") {\n        this.tokenizeQuotedString(char);\n        continue;\n      }\n\n      // Numbers (for score thresholds)\n      if (this.isDigit(char)) {\n        this.tokenizeNumber();\n        continue;\n      }\n\n      // Keywords and terms\n      if (this.isAlpha(char)) {\n        this.tokenizeKeywordOrTerm();\n        continue;\n      }\n\n      // Score operators (>, <, >=, <=)\n      if (char === \">\" || char === \"<\") {\n        this.tokenizeScoreOperator();\n        continue;\n      }\n\n      // Unknown character - skip it\n      this.position++;\n    }\n\n    // Add EOF token\n    this.tokens.push({ type: TokenType.EOF, value: \"\", position: this.position });\n\n    return this.tokens;\n  }\n\n  private skipWhitespace(): void {\n    while (this.position < this.input.length && /\\s/.test(this.input[this.position])) {\n      this.position++;\n    }\n  }\n\n  private isAlpha(char: string): boolean {\n    return /[a-zA-ZäöüßÄÖÜàâäæçéèêëïîôùûüÿœÀÂÄÆÇÉÈÊËÏÎÔÙÛÜŸŒáéíóúñüÁÉÍÓÚÑÜ_]/.test(char);\n  }\n\n  private isDigit(char: string): boolean {\n    return /[0-9.]/.test(char);\n  }\n\n  private isAlphaNumeric(char: string): boolean {\n    return this.isAlpha(char) || this.isDigit(char);\n  }\n\n  private tokenizeQuotedString(quote: string): void {\n    const start = this.position;\n    this.position++; // Skip opening quote\n\n    let value = \"\";\n    while (this.position < this.input.length && this.input[this.position] !== quote) {\n      value += this.input[this.position];\n      this.position++;\n    }\n\n    if (this.position >= this.input.length) {\n      throw new Error(`Unclosed quote at position ${start}`);\n    }\n\n    this.position++; // Skip closing quote\n\n    this.tokens.push({ type: TokenType.QUOTED, value, position: start });\n  }\n\n  private tokenizeNumber(): void {\n    const start = this.position;\n    let value = \"\";\n\n    while (this.position < this.input.length && this.isDigit(this.input[this.position])) {\n      value += this.input[this.position];\n      this.position++;\n    }\n\n    this.tokens.push({ type: TokenType.NUMBER, value, position: start });\n  }\n\n  private tokenizeKeywordOrTerm(): void {\n    const start = this.position;\n    let value = \"\";\n\n    while (this.position < this.input.length && this.isAlphaNumeric(this.input[this.position])) {\n      value += this.input[this.position];\n      this.position++;\n    }\n\n    const upperValue = value.toUpperCase();\n\n    // Check for keywords\n    switch (upperValue) {\n      case \"AND\":\n        this.tokens.push({ type: TokenType.AND, value: upperValue, position: start });\n        break;\n      case \"OR\":\n        this.tokens.push({ type: TokenType.OR, value: upperValue, position: start });\n        break;\n      case \"NOT\":\n        this.tokens.push({ type: TokenType.NOT, value: upperValue, position: start });\n        break;\n      case \"EXACT\":\n        this.tokens.push({ type: TokenType.EXACT, value: upperValue, position: start });\n        break;\n      case \"FUZZY\":\n        this.tokens.push({ type: TokenType.FUZZY, value: upperValue, position: start });\n        break;\n      case \"PHONETIC\":\n        this.tokens.push({ type: TokenType.PHONETIC, value: upperValue, position: start });\n        break;\n      case \"PREFIX\":\n        this.tokens.push({ type: TokenType.PREFIX, value: upperValue, position: start });\n        break;\n      case \"REGEX\":\n        this.tokens.push({ type: TokenType.REGEX, value: upperValue, position: start });\n        break;\n      case \"COMPOUND\":\n        this.tokens.push({ type: TokenType.COMPOUND, value: upperValue, position: start });\n        break;\n      case \"LANG\":\n        this.tokens.push({ type: TokenType.LANG, value: upperValue, position: start });\n        break;\n      case \"SCORE\":\n        this.tokens.push({ type: TokenType.SCORE, value: upperValue, position: start });\n        break;\n      default:\n        // Regular term (preserve original case)\n        this.tokens.push({ type: TokenType.TERM, value, position: start });\n        break;\n    }\n  }\n\n  private tokenizeScoreOperator(): void {\n    const start = this.position;\n    let value = this.input[this.position];\n    this.position++;\n\n    // Check for >= or <=\n    if (this.position < this.input.length && this.input[this.position] === \"=\") {\n      value += \"=\";\n      this.position++;\n    }\n\n    this.tokens.push({ type: TokenType.SCORE_OP, value, position: start });\n  }\n}\n","/**\n * FQL Parser\n * Converts tokens into an Abstract Syntax Tree (AST)\n */\n\nimport type { Token } from \"./lexer.js\";\nimport { TokenType } from \"./lexer.js\";\nimport type { FQLNode, TermNode, PhraseNode, AndNode, OrNode, NotNode, FilterNode, FieldNode, ScoreNode, LangNode } from \"./ast.js\";\n\nexport class FQLSyntaxError extends Error {\n  public position: number;\n  \n  constructor(message: string, position: number) {\n    super(message);\n    this.name = \"FQLSyntaxError\";\n    this.position = position;\n  }\n}\n\nexport class FQLParser {\n  private tokens: Token[] = [];\n  private current: number = 0;\n\n  /**\n   * Parse tokens into an AST\n   */\n  parse(tokens: Token[]): FQLNode {\n    this.tokens = tokens;\n    this.current = 0;\n\n    if (this.tokens.length === 0 || this.tokens[0].type === TokenType.EOF) {\n      throw new FQLSyntaxError(\"Empty query\", 0);\n    }\n\n    const ast = this.parseExpression();\n\n    // Ensure we consumed all tokens\n    if (!this.isAtEnd()) {\n      throw new FQLSyntaxError(`Unexpected token '${this.peek().value}' at position ${this.peek().position}`, this.peek().position);\n    }\n\n    return ast;\n  }\n\n  /**\n   * expression → or_expr\n   */\n  private parseExpression(): FQLNode {\n    return this.parseOrExpression();\n  }\n\n  /**\n   * or_expr → and_expr ( OR and_expr )*\n   */\n  private parseOrExpression(): FQLNode {\n    let left = this.parseAndExpression();\n\n    while (this.match(TokenType.OR)) {\n      const right = this.parseAndExpression();\n      left = {\n        type: \"or\",\n        left,\n        right,\n      } as OrNode;\n    }\n\n    return left;\n  }\n\n  /**\n   * and_expr → not_expr ( AND not_expr )*\n   */\n  private parseAndExpression(): FQLNode {\n    let left = this.parseNotExpression();\n\n    while (this.match(TokenType.AND)) {\n      const right = this.parseNotExpression();\n      left = {\n        type: \"and\",\n        left,\n        right,\n      } as AndNode;\n    }\n\n    return left;\n  }\n\n  /**\n   * not_expr → NOT? primary\n   */\n  private parseNotExpression(): FQLNode {\n    if (this.match(TokenType.NOT)) {\n      const child = this.parsePrimary();\n      return {\n        type: \"not\",\n        child,\n      } as NotNode;\n    }\n\n    return this.parsePrimary();\n  }\n\n  /**\n   * primary → filter | field | lang | score | term | phrase | grouped\n   */\n  private parsePrimary(): FQLNode {\n    // Grouped expression: ( expression )\n    if (this.match(TokenType.LPAREN)) {\n      const expr = this.parseExpression();\n      if (!this.match(TokenType.RPAREN)) {\n        throw new FQLSyntaxError(`Expected ')' at position ${this.peek().position}`, this.peek().position);\n      }\n      return expr;\n    }\n\n    // Filter: EXACT:value, FUZZY:value, etc.\n    if (this.check(TokenType.EXACT) || this.check(TokenType.FUZZY) || this.check(TokenType.PHONETIC) || this.check(TokenType.PREFIX) || this.check(TokenType.REGEX) || this.check(TokenType.COMPOUND)) {\n      return this.parseFilter();\n    }\n\n    // Language: LANG:german term\n    if (this.check(TokenType.LANG)) {\n      return this.parseLang();\n    }\n\n    // Quoted phrase\n    if (this.check(TokenType.QUOTED)) {\n      const token = this.advance();\n      const phrase: PhraseNode = {\n        type: \"phrase\",\n        value: token.value,\n      };\n\n      // Check for SCORE filter after phrase\n      if (this.check(TokenType.SCORE)) {\n        return this.parseScore(phrase);\n      }\n\n      return phrase;\n    }\n\n    // Term (could be field:value or just term)\n    if (this.check(TokenType.TERM)) {\n      const token = this.advance();\n\n      // Check if it's a field selector: term:expression\n      if (this.match(TokenType.COLON)) {\n        const child = this.parsePrimary();\n        const field: FieldNode = {\n          type: \"field\",\n          field: token.value,\n          child,\n        };\n        return field;\n      }\n\n      // Just a regular term\n      const term: TermNode = {\n        type: \"term\",\n        value: token.value,\n      };\n\n      // Check for SCORE filter after term\n      if (this.check(TokenType.SCORE)) {\n        return this.parseScore(term);\n      }\n\n      return term;\n    }\n\n    throw new FQLSyntaxError(`Unexpected token '${this.peek().value}' at position ${this.peek().position}`, this.peek().position);\n  }\n\n  /**\n   * filter → (EXACT|FUZZY|PHONETIC|PREFIX|REGEX|COMPOUND) COLON value\n   */\n  private parseFilter(): FQLNode {\n    const filterToken = this.advance();\n    const filterType = filterToken.value.toLowerCase() as \"exact\" | \"fuzzy\" | \"phonetic\" | \"prefix\" | \"regex\" | \"compound\";\n\n    if (!this.match(TokenType.COLON)) {\n      throw new FQLSyntaxError(`Expected ':' after ${filterToken.value} at position ${this.peek().position}`, this.peek().position);\n    }\n\n    let value: string;\n\n    if (this.check(TokenType.QUOTED)) {\n      value = this.advance().value;\n    } else if (this.check(TokenType.TERM)) {\n      value = this.advance().value;\n    } else {\n      throw new FQLSyntaxError(`Expected value after ${filterToken.value}: at position ${this.peek().position}`, this.peek().position);\n    }\n\n    const filter: FilterNode = {\n      type: \"filter\",\n      filterType,\n      value,\n    };\n\n    // Check for SCORE filter after filter\n    if (this.check(TokenType.SCORE)) {\n      return this.parseScore(filter);\n    }\n\n    return filter;\n  }\n\n  /**\n   * lang → LANG COLON TERM expression\n   */\n  private parseLang(): LangNode {\n    this.advance(); // Consume LANG\n\n    if (!this.match(TokenType.COLON)) {\n      throw new FQLSyntaxError(`Expected ':' after LANG at position ${this.peek().position}`, this.peek().position);\n    }\n\n    if (!this.check(TokenType.TERM)) {\n      throw new FQLSyntaxError(`Expected language name after LANG: at position ${this.peek().position}`, this.peek().position);\n    }\n\n    const language = this.advance().value;\n    const child = this.parsePrimary();\n\n    return {\n      type: \"lang\",\n      language,\n      child,\n    };\n  }\n\n  /**\n   * score → expression SCORE (>|<|>=|<=) NUMBER\n   */\n  private parseScore(child: FQLNode): ScoreNode {\n    this.advance(); // Consume SCORE\n\n    if (!this.check(TokenType.SCORE_OP)) {\n      throw new FQLSyntaxError(`Expected score operator (>, <, >=, <=) at position ${this.peek().position}`, this.peek().position);\n    }\n\n    const operator = this.advance().value as \">\" | \"<\" | \">=\" | \"<=\";\n\n    if (!this.check(TokenType.NUMBER)) {\n      throw new FQLSyntaxError(`Expected number after ${operator} at position ${this.peek().position}`, this.peek().position);\n    }\n\n    const threshold = parseFloat(this.advance().value);\n\n    if (isNaN(threshold) || threshold < 0 || threshold > 1) {\n      throw new FQLSyntaxError(`Score threshold must be between 0 and 1`, this.previous().position);\n    }\n\n    return {\n      type: \"score\",\n      operator,\n      threshold,\n      child,\n    };\n  }\n\n  // Helper methods\n\n  private match(...types: TokenType[]): boolean {\n    for (const type of types) {\n      if (this.check(type)) {\n        this.advance();\n        return true;\n      }\n    }\n    return false;\n  }\n\n  private check(type: TokenType): boolean {\n    if (this.isAtEnd()) return false;\n    return this.peek().type === type;\n  }\n\n  private advance(): Token {\n    if (!this.isAtEnd()) this.current++;\n    return this.previous();\n  }\n\n  private isAtEnd(): boolean {\n    return this.peek().type === TokenType.EOF;\n  }\n\n  private peek(): Token {\n    return this.tokens[this.current];\n  }\n\n  private previous(): Token {\n    return this.tokens[this.current - 1];\n  }\n}\n","/**\n * FQL Abstract Syntax Tree (AST) Node Types\n */\n\nexport type FQLNode = TermNode | PhraseNode | AndNode | OrNode | NotNode | FilterNode | FieldNode | ScoreNode | LangNode;\n\n/**\n * Simple term node\n */\nexport interface TermNode {\n  type: \"term\";\n  value: string;\n}\n\n/**\n * Quoted phrase node\n */\nexport interface PhraseNode {\n  type: \"phrase\";\n  value: string;\n}\n\n/**\n * AND operator node (intersection)\n */\nexport interface AndNode {\n  type: \"and\";\n  left: FQLNode;\n  right: FQLNode;\n}\n\n/**\n * OR operator node (union)\n */\nexport interface OrNode {\n  type: \"or\";\n  left: FQLNode;\n  right: FQLNode;\n}\n\n/**\n * NOT operator node (exclusion)\n */\nexport interface NotNode {\n  type: \"not\";\n  child: FQLNode;\n}\n\n/**\n * Match type filter node\n */\nexport interface FilterNode {\n  type: \"filter\";\n  filterType: \"exact\" | \"fuzzy\" | \"phonetic\" | \"prefix\" | \"regex\" | \"compound\";\n  value: string;\n}\n\n/**\n * Field selector node\n */\nexport interface FieldNode {\n  type: \"field\";\n  field: string;\n  child: FQLNode;\n}\n\n/**\n * Score filter node\n */\nexport interface ScoreNode {\n  type: \"score\";\n  operator: \">\" | \"<\" | \">=\" | \"<=\";\n  threshold: number;\n  child: FQLNode;\n}\n\n/**\n * Language filter node\n */\nexport interface LangNode {\n  type: \"lang\";\n  language: string;\n  child: FQLNode;\n}\n\n/**\n * Helper to check node type\n */\nexport function isTermNode(node: FQLNode): node is TermNode {\n  return node.type === \"term\";\n}\n\nexport function isPhraseNode(node: FQLNode): node is PhraseNode {\n  return node.type === \"phrase\";\n}\n\nexport function isAndNode(node: FQLNode): node is AndNode {\n  return node.type === \"and\";\n}\n\nexport function isOrNode(node: FQLNode): node is OrNode {\n  return node.type === \"or\";\n}\n\nexport function isNotNode(node: FQLNode): node is NotNode {\n  return node.type === \"not\";\n}\n\nexport function isFilterNode(node: FQLNode): node is FilterNode {\n  return node.type === \"filter\";\n}\n\nexport function isFieldNode(node: FQLNode): node is FieldNode {\n  return node.type === \"field\";\n}\n\nexport function isScoreNode(node: FQLNode): node is ScoreNode {\n  return node.type === \"score\";\n}\n\nexport function isLangNode(node: FQLNode): node is LangNode {\n  return node.type === \"lang\";\n}\n","/**\n * FQL Executor\n * Executes FQL AST against a fuzzy index\n */\n\nimport type { FuzzyIndex, SuggestionResult, SearchOptions } from \"../core/types.js\";\nimport type { FQLNode } from \"./ast.js\";\nimport { isAndNode, isOrNode, isNotNode, isTermNode, isPhraseNode, isFilterNode, isFieldNode, isScoreNode, isLangNode } from \"./ast.js\";\nimport { getSuggestions } from \"../core/index.js\";\n\nexport class FQLTimeoutError extends Error {\n  constructor(message: string) {\n    super(message);\n    this.name = \"FQLTimeoutError\";\n  }\n}\n\nexport class FQLExecutor {\n  private index: FuzzyIndex;\n  private options: SearchOptions;\n  private startTime: number = 0;\n  private timeout: number = 5000; // Default 5 seconds\n\n  constructor(index: FuzzyIndex, options: SearchOptions = {}) {\n    this.index = index;\n    this.options = options;\n    this.timeout = options.fqlOptions?.timeout || 5000;\n  }\n\n  /**\n   * Execute an FQL AST and return results\n   */\n  execute(ast: FQLNode): SuggestionResult[] {\n    this.startTime = Date.now();\n    return this.executeNode(ast);\n  }\n\n  private checkTimeout(): void {\n    if (Date.now() - this.startTime > this.timeout) {\n      throw new FQLTimeoutError(`Query execution timeout after ${this.timeout}ms`);\n    }\n  }\n\n  private executeNode(node: FQLNode): SuggestionResult[] {\n    this.checkTimeout();\n\n    if (isAndNode(node)) {\n      return this.executeAnd(node);\n    }\n\n    if (isOrNode(node)) {\n      return this.executeOr(node);\n    }\n\n    if (isNotNode(node)) {\n      return this.executeNot(node);\n    }\n\n    if (isTermNode(node)) {\n      return this.executeTerm(node.value);\n    }\n\n    if (isPhraseNode(node)) {\n      return this.executePhrase(node.value);\n    }\n\n    if (isFilterNode(node)) {\n      return this.executeFilter(node);\n    }\n\n    if (isFieldNode(node)) {\n      return this.executeField(node);\n    }\n\n    if (isScoreNode(node)) {\n      return this.executeScore(node);\n    }\n\n    if (isLangNode(node)) {\n      return this.executeLang(node);\n    }\n\n    return [];\n  }\n\n  /**\n   * Execute AND - intersection of results\n   */\n  private executeAnd(node: { left: FQLNode; right: FQLNode }): SuggestionResult[] {\n    const leftResults = this.executeNode(node.left);\n    const rightResults = this.executeNode(node.right);\n\n    // Intersection: items that appear in both\n    const rightDisplays = new Set(rightResults.map((r) => r.display));\n    const intersection = leftResults.filter((r) => rightDisplays.has(r.display));\n\n    // Sort by score\n    return intersection.sort((a, b) => b.score - a.score);\n  }\n\n  /**\n   * Execute OR - union of results\n   */\n  private executeOr(node: { left: FQLNode; right: FQLNode }): SuggestionResult[] {\n    const leftResults = this.executeNode(node.left);\n    const rightResults = this.executeNode(node.right);\n\n    // Union: combine and deduplicate\n    const resultMap = new Map<string, SuggestionResult>();\n\n    for (const result of leftResults) {\n      resultMap.set(result.display, result);\n    }\n\n    for (const result of rightResults) {\n      const existing = resultMap.get(result.display);\n      // Keep higher score\n      if (!existing || result.score > existing.score) {\n        resultMap.set(result.display, result);\n      }\n    }\n\n    // Sort by score\n    return Array.from(resultMap.values()).sort((a, b) => b.score - a.score);\n  }\n\n  /**\n   * Execute NOT - exclusion of results\n   */\n  private executeNot(node: { child: FQLNode }): SuggestionResult[] {\n    const childResults = this.executeNode(node.child);\n    const excludeDisplays = new Set(childResults.map((r) => r.display));\n\n    // Get all results and exclude\n    const allResults = getSuggestions(this.index, \"\", this.index.base.length, this.options);\n    return allResults.filter((r) => !excludeDisplays.has(r.display)).sort((a, b) => b.score - a.score);\n  }\n\n  /**\n   * Execute simple term search\n   */\n  private executeTerm(term: string): SuggestionResult[] {\n    return getSuggestions(this.index, term, this.index.base.length, this.options);\n  }\n\n  /**\n   * Execute phrase search\n   */\n  private executePhrase(phrase: string): SuggestionResult[] {\n    // Use existing phrase search with quotes\n    return getSuggestions(this.index, `\"${phrase}\"`, this.index.base.length, this.options);\n  }\n\n  /**\n   * Execute filter (EXACT, FUZZY, PHONETIC, etc.)\n   */\n  private executeFilter(node: { filterType: string; value: string }): SuggestionResult[] {\n    const { filterType, value } = node;\n\n    // Get all results for the value\n    const results = getSuggestions(this.index, value, this.index.base.length, this.options);\n\n    // Filter by match type\n    switch (filterType) {\n      case \"exact\":\n        return results.filter((r) => (r as any)._debug_matchType === \"exact\");\n\n      case \"fuzzy\":\n        return results.filter((r) => (r as any)._debug_matchType === \"fuzzy\");\n\n      case \"phonetic\":\n        return results.filter((r) => (r as any)._debug_matchType === \"phonetic\");\n\n      case \"prefix\":\n        return results.filter((r) => (r as any)._debug_matchType === \"prefix\");\n\n      case \"compound\":\n        return results.filter((r) => (r as any)._debug_matchType === \"compound\");\n\n      case \"regex\":\n        return this.executeRegex(value);\n\n      default:\n        return results;\n    }\n  }\n\n  /**\n   * Execute regex pattern\n   */\n  private executeRegex(pattern: string): SuggestionResult[] {\n    // Check if regex is allowed\n    if (!this.options.fqlOptions?.allowRegex) {\n      throw new Error(\"Regex not enabled. Set fqlOptions.allowRegex = true\");\n    }\n\n    try {\n      const regex = new RegExp(pattern);\n      const results: SuggestionResult[] = [];\n\n      for (const word of this.index.base) {\n        if (regex.test(word)) {\n          results.push({\n            display: word,\n            baseWord: word,\n            score: 1.0,\n            isSynonym: false,\n            language: \"unknown\",\n            _debug_matchType: \"regex\",\n          } as any);\n        }\n      }\n\n      return results;\n    } catch (error) {\n      throw new Error(`Invalid regex pattern: ${pattern}`);\n    }\n  }\n\n  /**\n   * Execute field selector\n   */\n  private executeField(node: { field: string; child: FQLNode }): SuggestionResult[] {\n    // Execute child query\n    const childResults = this.executeNode(node.child);\n\n    // Filter by field if multi-field index\n    if (!this.index.fieldData) {\n      // No field data, return all results\n      return childResults;\n    }\n\n    // Filter results that match the field\n    return childResults.filter((result) => {\n      if (result.field === node.field) {\n        return true;\n      }\n      return false;\n    });\n  }\n\n  /**\n   * Execute score filter\n   */\n  private executeScore(node: { operator: string; threshold: number; child: FQLNode }): SuggestionResult[] {\n    const childResults = this.executeNode(node.child);\n    const { operator, threshold } = node;\n\n    return childResults.filter((result) => {\n      switch (operator) {\n        case \">\":\n          return result.score > threshold;\n        case \"<\":\n          return result.score < threshold;\n        case \">=\":\n          return result.score >= threshold;\n        case \"<=\":\n          return result.score <= threshold;\n        default:\n          return true;\n      }\n    });\n  }\n\n  /**\n   * Execute language filter\n   */\n  private executeLang(node: { language: string; child: FQLNode }): SuggestionResult[] {\n    const childResults = this.executeNode(node.child);\n    const targetLang = node.language.toLowerCase();\n\n    return childResults.filter((result) => {\n      return result.language?.toLowerCase() === targetLang;\n    });\n  }\n}\n","/**\n * FQL (Fuzzy Query Language) - Main entry point\n */\n\nimport type { FuzzyIndex, SuggestionResult, SearchOptions } from \"../core/types.js\";\nimport { FQLLexer } from \"./lexer.js\";\nimport { FQLParser, FQLSyntaxError } from \"./parser.js\";\nimport { FQLExecutor, FQLTimeoutError } from \"./executor.js\";\n\n/**\n * Check if a query is an FQL query\n */\nexport function isFQLQuery(query: string): boolean {\n  const trimmed = query.trim();\n  return trimmed.startsWith(\"fql(\") && trimmed.endsWith(\")\");\n}\n\n/**\n * Extract FQL query from fql(...) wrapper\n */\nexport function extractFQLQuery(query: string): string {\n  const trimmed = query.trim();\n  if (!isFQLQuery(trimmed)) {\n    throw new Error(\"Not a valid FQL query. Must be wrapped in fql(...)\");\n  }\n  \n  // Remove fql( and )\n  return trimmed.slice(4, -1).trim();\n}\n\n/**\n * Execute an FQL query\n */\nexport function executeFQLQuery(\n  index: FuzzyIndex,\n  query: string,\n  maxResults?: number,\n  options: SearchOptions = {}\n): SuggestionResult[] {\n  try {\n    // Extract query from fql(...)\n    const fqlQuery = extractFQLQuery(query);\n    \n    // Lexer: tokenize\n    const lexer = new FQLLexer();\n    const tokens = lexer.tokenize(fqlQuery);\n    \n    // Parser: build AST\n    const parser = new FQLParser();\n    const ast = parser.parse(tokens);\n    \n    // Executor: run query\n    const executor = new FQLExecutor(index, options);\n    const results = executor.execute(ast);\n    \n    // Apply maxResults limit\n    const limit = maxResults || options.maxResults || 10;\n    return results.slice(0, limit);\n  } catch (error) {\n    // Re-throw FQL-specific errors\n    if (error instanceof FQLSyntaxError || error instanceof FQLTimeoutError) {\n      throw error;\n    }\n    \n    // Wrap other errors\n    throw new Error(`FQL execution error: ${(error as Error).message}`);\n  }\n}\n\n// Export all FQL components\nexport { FQLLexer } from \"./lexer.js\";\nexport { FQLParser, FQLSyntaxError } from \"./parser.js\";\nexport { FQLExecutor, FQLTimeoutError } from \"./executor.js\";\nexport type { FQLNode } from \"./ast.js\";\nexport { TokenType } from \"./lexer.js\";\n","import type {\n  //\n  FuzzyIndex,\n  FuzzyConfig,\n  SuggestionResult,\n  SearchMatch,\n  BuildIndexOptions,\n  SearchOptions,\n  LanguageProcessor,\n} from \"./types.js\";\nimport {\n  //\n  mergeConfig,\n  validateConfig,\n} from \"./config.js\";\nimport {\n  //\n  LanguageRegistry,\n} from \"../languages/index.js\";\nimport {\n  //\n  calculateLevenshteinDistance,\n  calculateDamerauLevenshteinDistance,\n  calculateNgramSimilarity,\n} from \"../algorithms/levenshtein.js\";\nimport {\n  //\n  buildInvertedIndex,\n  searchInvertedIndex,\n  calculateBM25Scores,\n} from \"./inverted-index.js\";\nimport {\n  //\n  calculateHighlights,\n} from \"./highlighting.js\";\nimport {\n  //\n  SearchCache,\n} from \"./cache.js\";\nimport { removeAccents } from \"../utils/accent-normalization.js\";\nimport { extractFieldValues, normalizeFieldWeights } from \"./field-weighting.js\";\nimport { filterStopWords } from \"../utils/stop-words.js\";\nimport { matchesWord, matchesWildcard } from \"../utils/word-boundaries.js\";\nimport { parseQuery } from \"../utils/phrase-parser.js\";\nimport { matchPhrase } from \"./phrase-matching.js\";\nimport { detectLanguages, sampleTextForDetection } from \"../utils/language-detection.js\";\nimport { isFQLQuery, executeFQLQuery } from \"../fql/index.js\";\n\n/**\n * Builds a fuzzy search index from an array of words or objects.\n * \n * This is the primary function for creating a searchable index. It processes each word/object\n * through language-specific processors, builds various indices (phonetic, n-gram, synonym),\n * and automatically enables optimizations like inverted index for large datasets (10k+ items).\n * \n * @param words - Array of strings to index, or objects with fields to search across\n * @param options - Configuration options for index building\n * @param options.config - Fuzzy search configuration (languages, features, thresholds)\n * @param options.languageProcessors - Custom language processors (overrides default)\n * @param options.onProgress - Callback for tracking indexing progress (processed, total)\n * @param options.useInvertedIndex - Force inverted index usage (auto-enabled for 10k+ words)\n * @param options.fields - Field names for multi-field search (required when indexing objects)\n * @param options.fieldWeights - Weight multipliers for field scoring (e.g., {title: 2.0, description: 1.0})\n * \n * @returns A searchable fuzzy index containing all processed data and metadata\n * \n * @throws {Error} If no language processors found for specified languages\n * @throws {Error} If objects are provided without specifying fields via options.fields\n * \n * @example\n * ```typescript\n * // Simple string array\n * const index = buildFuzzyIndex(['apple', 'banana', 'cherry'], {\n *   config: { languages: ['english'], performance: 'fast' }\n * });\n * \n * // Multi-field objects\n * const products = [\n *   { name: 'iPhone', description: 'Smartphone', price: 999 },\n *   { name: 'MacBook', description: 'Laptop', price: 1999 }\n * ];\n * const index = buildFuzzyIndex(products, {\n *   fields: ['name', 'description'],\n *   fieldWeights: { name: 2.0, description: 1.0 }\n * });\n * \n * // With progress tracking\n * const index = buildFuzzyIndex(largeDataset, {\n *   onProgress: (processed, total) => {\n *     console.log(`Indexing: ${(processed/total*100).toFixed(1)}%`);\n *   }\n * });\n * ```\n * \n * @see {@link getSuggestions} for searching the index\n * @see {@link BuildIndexOptions} for all configuration options\n * @see {@link FuzzyConfig} for fuzzy search settings\n */\nexport function buildFuzzyIndex(words: (string | any)[] = [], options: BuildIndexOptions = {}): FuzzyIndex {\n  // AUTO-DETECTION: Detect languages if not explicitly specified\n  const userSpecifiedLanguages = options.config?.languages;\n  const shouldAutoDetect = !userSpecifiedLanguages || userSpecifiedLanguages.includes('auto');\n  \n  const config = mergeConfig(options.config);\n  \n  if (shouldAutoDetect) {\n    const sampleText = sampleTextForDetection(words, 100);\n    const detectedLanguages = detectLanguages(sampleText);\n    config.languages = detectedLanguages;\n  }\n  \n  validateConfig(config);\n\n  // Convert features array to Set for O(1) lookup performance\n  const featureSet = new Set(config.features);\n\n  const languageProcessors = options.languageProcessors || LanguageRegistry.getProcessors(config.languages);\n\n  if (languageProcessors.length === 0) {\n    throw new Error(`No language processors found for: ${config.languages.join(\", \")}`);\n  }\n\n  // Check if we're doing multi-field search\n  const hasFields = options.fields && options.fields.length > 0;\n  const isObjectArray = words.length > 0 && typeof words[0] === \"object\" && words[0] !== null;\n\n  // Validate: if objects are provided, fields must be specified\n  if (isObjectArray && !hasFields) {\n    throw new Error(\"When indexing objects, you must specify which fields to index via options.fields\");\n  }\n\n  const index: FuzzyIndex = {\n    base: [],\n    variantToBase: new Map(),\n    phoneticToBase: new Map(),\n    ngramIndex: new Map(),\n    synonymMap: new Map(),\n    languageProcessors: new Map(),\n    config,\n  };\n\n  // Store field configuration if provided\n  if (hasFields) {\n    index.fields = options.fields;\n    index.fieldWeights = normalizeFieldWeights(options.fields!, options.fieldWeights);\n    index.fieldData = new Map();\n  }\n\n  // Store language processors\n  languageProcessors.forEach((processor) => {\n    index.languageProcessors.set(processor.language, processor);\n  });\n\n  const processedWords = new Set<string>();\n  let processed = 0;\n\n  for (const item of words) {\n    if (!item) continue;\n\n    // Handle multi-field objects\n    if (hasFields && isObjectArray) {\n      const fieldValues = extractFieldValues(item, options.fields);\n      if (!fieldValues) continue;\n\n      // Generate a unique ID for this object (use first field value as base)\n      const baseId = Object.values(fieldValues)[0] || `item_${processed}`;\n\n      // Store field data\n      index.fieldData!.set(baseId, fieldValues);\n\n      // Index each field separately\n      for (const [fieldName, fieldValue] of Object.entries(fieldValues)) {\n        if (!fieldValue || fieldValue.trim().length < config.minQueryLength) continue;\n\n        const trimmedValue = fieldValue.trim();\n\n        // Add to base if not already there\n        if (!processedWords.has(baseId.toLowerCase())) {\n          processedWords.add(baseId.toLowerCase());\n          index.base.push(baseId);\n        }\n\n        // Process this field value with each language processor\n        for (const processor of languageProcessors) {\n          processWordWithProcessorAndField(trimmedValue, baseId, fieldName, processor, index, config, featureSet);\n        }\n      }\n    } else {\n      // Handle simple string array (backwards compatible)\n      const word = typeof item === \"string\" ? item : String(item);\n      if (word.trim().length < config.minQueryLength) continue;\n\n      const trimmedWord = word.trim();\n      if (processedWords.has(trimmedWord.toLowerCase())) continue;\n\n      processedWords.add(trimmedWord.toLowerCase());\n      index.base.push(trimmedWord);\n\n      // Process with each language processor\n      for (const processor of languageProcessors) {\n        processWordWithProcessor(trimmedWord, processor, index, config, featureSet);\n      }\n    }\n\n    processed++;\n    if (options.onProgress) {\n      options.onProgress(processed, words.length);\n    }\n  }\n\n  // INVERTED INDEX: Build if enabled or auto-enable for large datasets\n  // Also force inverted index if BM25 or Bloom Filter is enabled\n  const shouldUseInvertedIndex = options.useInvertedIndex || config.useInvertedIndex || config.useBM25 || config.useBloomFilter || words.length >= 10000;\n\n  if (shouldUseInvertedIndex) {\n    const { invertedIndex, documents } = buildInvertedIndex(words, languageProcessors, config, featureSet);\n    index.invertedIndex = invertedIndex;\n    index.documents = documents;\n  }\n\n  // CACHE: Initialize search result cache if enabled (default: true)\n  const enableCache = config.enableCache !== false; // Default to true\n  if (enableCache) {\n    const cacheSize = config.cacheSize || 100;\n    index._cache = new SearchCache(cacheSize);\n  }\n\n  return index;\n}\n\n/**\n * Process a word with a specific language processor\n */\nfunction processWordWithProcessor(word: string, processor: LanguageProcessor, index: FuzzyIndex, config: FuzzyConfig, featureSet: Set<string>): void {\n  const normalized = processor.normalize(word);\n\n  // Add base word mapping\n  addToVariantMap(index.variantToBase, normalized, word);\n  addToVariantMap(index.variantToBase, word.toLowerCase(), word);\n  // Also add the original word as-is for exact matching\n  addToVariantMap(index.variantToBase, word, word);\n\n  // Add accent-insensitive variants\n  const accentFreeWord = removeAccents(word);\n  if (accentFreeWord !== word) {\n    // Add the accent-free version in multiple forms\n    addToVariantMap(index.variantToBase, accentFreeWord, word); // Original case\n    addToVariantMap(index.variantToBase, accentFreeWord.toLowerCase(), word); // Lowercase\n    const normalizedAccentFree = processor.normalize(accentFreeWord);\n    if (normalizedAccentFree !== accentFreeWord.toLowerCase()) {\n      addToVariantMap(index.variantToBase, normalizedAccentFree, word); // Processor normalized\n    }\n  }\n\n  // Generate and index variants\n  if (featureSet.has(\"partial-words\")) {\n    const variants = processor.getWordVariants(word);\n    variants.forEach((variant) => {\n      addToVariantMap(index.variantToBase, variant, word);\n    });\n  }\n\n  // Generate phonetic codes\n  if (featureSet.has(\"phonetic\") && processor.supportedFeatures.includes(\"phonetic\")) {\n    const phoneticCode = processor.getPhoneticCode(word);\n    if (phoneticCode) {\n      addToVariantMap(index.phoneticToBase, phoneticCode, word);\n    }\n  }\n\n  // Generate n-grams for partial matching\n  const ngrams = generateNgrams(normalized, config.ngramSize);\n  ngrams.forEach((ngram: string) => {\n    addToVariantMap(index.ngramIndex, ngram, word);\n  });\n\n  // Handle compound words\n  if (featureSet.has(\"compound\") && processor.supportedFeatures.includes(\"compound\")) {\n    const compoundParts = processor.splitCompoundWords(word);\n    compoundParts.forEach((part) => {\n      if (part !== word) {\n        addToVariantMap(index.variantToBase, processor.normalize(part), word);\n      }\n    });\n  }\n\n  // Add synonyms\n  if (featureSet.has(\"synonyms\")) {\n    const synonyms = processor.getSynonyms(normalized);\n    synonyms.forEach((synonym) => {\n      addToVariantMap(index.synonymMap, synonym, word);\n    });\n\n    // Add custom synonyms\n    if (config.customSynonyms) {\n      const customSynonyms = config.customSynonyms[normalized];\n      if (customSynonyms) {\n        customSynonyms.forEach((synonym) => {\n          addToVariantMap(index.synonymMap, synonym, word);\n        });\n      }\n    }\n  }\n}\n\n/**\n * Process a word with field information for multi-field search\n */\nfunction processWordWithProcessorAndField(fieldValue: string, baseId: string, fieldName: string, processor: LanguageProcessor, index: FuzzyIndex, config: FuzzyConfig, featureSet: Set<string>): void {\n  const normalized = processor.normalize(fieldValue);\n\n  // Add base word mapping with field metadata\n  addToVariantMapWithField(index.variantToBase, normalized, baseId, fieldName);\n  addToVariantMapWithField(index.variantToBase, fieldValue.toLowerCase(), baseId, fieldName);\n  addToVariantMapWithField(index.variantToBase, fieldValue, baseId, fieldName);\n\n  // Add accent-insensitive variants\n  const accentFreeWord = removeAccents(fieldValue);\n  if (accentFreeWord !== fieldValue) {\n    addToVariantMapWithField(index.variantToBase, accentFreeWord, baseId, fieldName);\n    addToVariantMapWithField(index.variantToBase, accentFreeWord.toLowerCase(), baseId, fieldName);\n    const normalizedAccentFree = processor.normalize(accentFreeWord);\n    if (normalizedAccentFree !== accentFreeWord.toLowerCase()) {\n      addToVariantMapWithField(index.variantToBase, normalizedAccentFree, baseId, fieldName);\n    }\n  }\n\n  // Generate and index variants\n  if (featureSet.has(\"partial-words\")) {\n    const variants = processor.getWordVariants(fieldValue);\n    variants.forEach((variant) => {\n      addToVariantMapWithField(index.variantToBase, variant, baseId, fieldName);\n    });\n  }\n\n  // Generate phonetic codes\n  if (featureSet.has(\"phonetic\") && processor.supportedFeatures.includes(\"phonetic\")) {\n    const phoneticCode = processor.getPhoneticCode(fieldValue);\n    if (phoneticCode) {\n      addToVariantMapWithField(index.phoneticToBase, phoneticCode, baseId, fieldName);\n    }\n  }\n\n  // Generate n-grams for partial matching\n  const ngrams = generateNgrams(normalized, config.ngramSize);\n  ngrams.forEach((ngram: string) => {\n    addToVariantMapWithField(index.ngramIndex, ngram, baseId, fieldName);\n  });\n\n  // Handle compound words\n  if (featureSet.has(\"compound\") && processor.supportedFeatures.includes(\"compound\")) {\n    const parts = processor.splitCompoundWords(fieldValue);\n    parts.forEach((part) => {\n      if (part.length >= config.minQueryLength) {\n        addToVariantMapWithField(index.variantToBase, part, baseId, fieldName);\n        addToVariantMapWithField(index.variantToBase, processor.normalize(part), baseId, fieldName);\n      }\n    });\n  }\n\n  // Add synonyms\n  if (featureSet.has(\"synonyms\")) {\n    const synonyms = processor.getSynonyms(normalized);\n    synonyms.forEach((synonym) => {\n      addToVariantMapWithField(index.synonymMap, synonym, baseId, fieldName);\n    });\n\n    // Add custom synonyms\n    if (config.customSynonyms) {\n      const customSynonyms = config.customSynonyms[normalized];\n      if (customSynonyms) {\n        customSynonyms.forEach((synonym) => {\n          addToVariantMapWithField(index.synonymMap, synonym, baseId, fieldName);\n        });\n      }\n    }\n  }\n}\n\n/**\n * Helper function to add mappings to variant maps with field information\n */\nfunction addToVariantMapWithField(map: Map<string, Set<string>>, key: string, value: string, _fieldName: string): void {\n  // For now, we'll use a simple approach: store the value with field metadata\n  // The field information will be tracked separately in the index\n  // _fieldName is prefixed with _ to indicate it's reserved for future use\n  if (!map.has(key)) {\n    map.set(key, new Set());\n  }\n  map.get(key)!.add(value);\n}\n\n/**\n * Helper function to add mappings to variant maps\n */\nfunction addToVariantMap(map: Map<string, Set<string>>, key: string, value: string): void {\n  if (!map.has(key)) {\n    map.set(key, new Set());\n  }\n  map.get(key)!.add(value);\n}\n\n/**\n * Searches multiple queries at once with automatic deduplication.\n * \n * This function efficiently processes multiple search queries by deduplicating identical\n * queries and leveraging the search cache. Perfect for batch processing or multi-field forms.\n * \n * @param index - The fuzzy search index to search against\n * @param queries - Array of search query strings\n * @param maxResults - Maximum results per query (optional, defaults to index config)\n * @param options - Search options to apply to all queries\n * \n * @returns Object mapping each unique query to its search results\n * \n * @example\n * ```typescript\n * const results = batchSearch(index, ['apple', 'banana', 'apple', 'cherry']);\n * // Returns: { apple: [...], banana: [...], cherry: [...] }\n * // Note: 'apple' only searched once despite appearing twice\n * \n * // With options\n * const results = batchSearch(index, ['app', 'ban'], 5, {\n *   includeHighlights: true,\n *   fuzzyThreshold: 0.8\n * });\n * ```\n * \n * @see {@link getSuggestions} for single query search\n */\nexport function batchSearch(index: FuzzyIndex, queries: string[], maxResults?: number, options: SearchOptions = {}): Record<string, SuggestionResult[]> {\n  const results: Record<string, SuggestionResult[]> = {};\n  const uniqueQueries = [...new Set(queries)]; // Deduplicate\n\n  for (const query of uniqueQueries) {\n    results[query] = getSuggestions(index, query, maxResults, options);\n  }\n\n  return results;\n}\n\n/**\n * Searches the index for fuzzy matches to the query string.\n * \n * This is the primary search function. It automatically selects the optimal search strategy\n * (inverted index for large datasets, hash-based for smaller ones), handles phrase search,\n * FQL queries, stop word filtering, and caching for performance.\n * \n * @param index - The fuzzy search index to search against\n * @param query - The search query string (supports phrases in quotes, FQL with fql() wrapper)\n * @param maxResults - Maximum number of results to return (optional, defaults to index config)\n * @param options - Search options to customize behavior\n * @param options.fuzzyThreshold - Override fuzzy matching threshold (0-1, higher = stricter)\n * @param options.languages - Filter to specific languages\n * @param options.matchTypes - Filter to specific match types (exact, fuzzy, phonetic, etc.)\n * @param options.debug - Include debug information in results\n * @param options.includeHighlights - Include match position highlights for UI rendering\n * @param options.enableFQL - Enable Fuzzy Query Language support (AND, OR, NOT operators)\n * \n * @returns Array of suggestion results sorted by relevance score (highest first)\n * \n * @example\n * ```typescript\n * // Basic search\n * const results = getSuggestions(index, 'hospitl', 5);\n * // Returns: [{ display: 'Hospital', score: 0.92, ... }]\n * \n * // With highlights for UI\n * const results = getSuggestions(index, 'app', 10, {\n *   includeHighlights: true\n * });\n * // Results include highlight positions for rendering\n * \n * // Phrase search\n * const results = getSuggestions(index, '\"new york\"');\n * // Finds multi-word phrases\n * \n * // FQL query\n * const results = getSuggestions(index, 'fql(doctor AND berlin)', 10, {\n *   enableFQL: true\n * });\n * \n * // With debug info\n * const results = getSuggestions(index, 'query', 5, { debug: true });\n * // Results include timing and match details\n * ```\n * \n * @see {@link buildFuzzyIndex} for creating the index\n * @see {@link batchSearch} for searching multiple queries\n */\nexport function getSuggestions(index: FuzzyIndex, query: string, maxResults?: number, options: SearchOptions = {}): SuggestionResult[] {\n  const config = index.config;\n  const limit = maxResults || options.maxResults || config.maxResults;\n  const threshold = options.fuzzyThreshold || config.fuzzyThreshold;\n\n  if (!query || query.trim().length < config.minQueryLength) {\n    return [];\n  }\n\n  // FQL: Check if FQL is enabled and query is FQL\n  if (options.enableFQL && isFQLQuery(query)) {\n    return executeFQLQuery(index, query, limit, options);\n  }\n\n  // PHRASE SEARCH: Check if query contains phrases\n  const parsedQuery = parseQuery(query);\n  \n  // If query has phrases, use phrase search\n  if (parsedQuery.hasPhrases) {\n    return searchWithPhrases(index, parsedQuery, limit, threshold, options);\n  }\n\n  // STOP WORDS: Filter stop words from query if enabled\n  let processedQuery = query;\n  if (config.enableStopWords && config.stopWords && config.stopWords.length > 0) {\n    processedQuery = filterStopWords(query, config.stopWords);\n  }\n\n  // CACHE: Check cache first (use processed query for cache key)\n  if (index._cache) {\n    const cached = index._cache.get(processedQuery, limit, options);\n    if (cached) {\n      return cached; // Cache hit - return immediately!\n    }\n  }\n\n  // Get active language processors\n  const activeLanguages = options.languages || config.languages;\n  const processors = activeLanguages.map((lang) => index.languageProcessors.get(lang)).filter((p): p is LanguageProcessor => p !== undefined);\n\n  if (processors.length === 0) {\n    return [];\n  }\n\n  // AUTO-DETECTION: Use inverted index if available\n  if (index.invertedIndex && index.documents) {\n    const results = getSuggestionsInverted(index, processedQuery, limit, threshold, processors, options);\n    // Cache the results\n    if (index._cache) {\n      index._cache.set(processedQuery, results, limit, options);\n    }\n    return results;\n  }\n\n  // CLASSIC: Use hash-based approach (existing implementation)\n  const matches = new Map<string, SearchMatch>();\n\n  // Process query with each language processor\n  for (const processor of processors) {\n    const normalizedQuery = processor.normalize(processedQuery.trim());\n\n    // Find matches using different strategies\n    findExactMatches(normalizedQuery, index, matches, processor.language);\n    findPrefixMatches(normalizedQuery, index, matches, processor.language);\n    findPhoneticMatches(normalizedQuery, processor, index, matches);\n    findSynonymMatches(normalizedQuery, index, matches);\n    findNgramMatches(normalizedQuery, index, matches, processor.language, config.ngramSize);\n\n    if (config.features.includes(\"missing-letters\") || config.features.includes(\"extra-letters\") || config.features.includes(\"transpositions\")) {\n      findFuzzyMatches(normalizedQuery, index, matches, processor, config);\n    }\n  }\n\n  // Convert matches to results and rank them\n  const results = Array.from(matches.values())\n    .map((match) => createSuggestionResult(match, processedQuery, threshold, index, options))\n    .filter((result): result is SuggestionResult => result !== null)\n    .sort((a, b) => b.score - a.score)\n    .slice(0, limit);\n\n  // Cache the results\n  if (index._cache) {\n    index._cache.set(processedQuery, results, limit, options);\n  }\n\n  return results;\n}\n\n/**\n * Find exact matches\n */\nfunction findExactMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>, language: string): void {\n  const wordBoundaries = index.config.wordBoundaries || false;\n\n  // Check for wildcard pattern\n  if (query.includes(\"*\")) {\n    // Wildcard search\n    for (const baseWord of index.base) {\n      if (matchesWildcard(baseWord, query)) {\n        if (!matches.has(baseWord)) {\n          matches.set(baseWord, {\n            word: baseWord,\n            normalized: query,\n            matchType: \"exact\",\n            editDistance: 0,\n            language,\n          });\n        }\n      }\n    }\n    return;\n  }\n\n  // Check for exact matches in the variant map\n  const exactMatches = index.variantToBase.get(query);\n  if (exactMatches) {\n    exactMatches.forEach((word) => {\n      // With word boundaries, verify the match\n      if (wordBoundaries && !matchesWord(word, query, wordBoundaries)) {\n        return;\n      }\n\n      // Always add exact matches, even if already found with lower score\n      const existing = matches.get(word);\n      if (!existing || existing.matchType !== \"exact\") {\n        matches.set(word, {\n          word,\n          normalized: query,\n          matchType: \"exact\",\n          editDistance: 0,\n          language,\n        });\n      }\n    });\n  }\n\n  // Also check if the query exactly matches any base word (case-insensitive)\n  const queryLower = query.toLowerCase();\n  for (const baseWord of index.base) {\n    if (baseWord.toLowerCase() === queryLower) {\n      if (!matches.has(baseWord)) {\n        matches.set(baseWord, {\n          word: baseWord,\n          normalized: query,\n          matchType: \"exact\",\n          editDistance: 0,\n          language,\n        });\n      }\n    }\n  }\n}\n\n/**\n * Find prefix matches\n */\nfunction findPrefixMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>, language: string): void {\n  const wordBoundaries = index.config.wordBoundaries || false;\n\n  for (const [variant, words] of index.variantToBase.entries()) {\n    if (variant.startsWith(query) && variant !== query) {\n      words.forEach((word) => {\n        // With word boundaries, verify the match\n        if (wordBoundaries && !matchesWord(word, query, wordBoundaries)) {\n          return;\n        }\n\n        if (!matches.has(word)) {\n          matches.set(word, {\n            word,\n            normalized: variant,\n            matchType: \"prefix\",\n            language,\n          });\n        }\n      });\n    }\n  }\n}\n\n/**\n * Find phonetic matches\n */\nfunction findPhoneticMatches(query: string, processor: LanguageProcessor, index: FuzzyIndex, matches: Map<string, SearchMatch>): void {\n  if (!processor.supportedFeatures.includes(\"phonetic\")) return;\n\n  const phoneticCode = processor.getPhoneticCode(query);\n  if (phoneticCode) {\n    const phoneticMatches = index.phoneticToBase.get(phoneticCode);\n    if (phoneticMatches) {\n      phoneticMatches.forEach((word) => {\n        if (!matches.has(word)) {\n          matches.set(word, {\n            word,\n            normalized: query,\n            matchType: \"phonetic\",\n            phoneticCode,\n            language: processor.language,\n          });\n        }\n      });\n    }\n  }\n}\n\n/**\n * Find synonym matches\n */\nfunction findSynonymMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>): void {\n  const synonymMatches = index.synonymMap.get(query);\n  if (synonymMatches) {\n    synonymMatches.forEach((word) => {\n      if (!matches.has(word)) {\n        matches.set(word, {\n          word,\n          normalized: query,\n          matchType: \"synonym\",\n          language: \"synonym\",\n        });\n      }\n    });\n  }\n}\n\n/**\n * Find n-gram matches\n */\nfunction findNgramMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>, language: string, ngramSize: number): void {\n  if (query.length < ngramSize) return;\n\n  const queryNgrams = generateNgrams(query, ngramSize);\n  const candidateWords = new Set<string>();\n\n  queryNgrams.forEach((ngram) => {\n    const ngramMatches = index.ngramIndex.get(ngram);\n    if (ngramMatches) {\n      ngramMatches.forEach((word) => candidateWords.add(word));\n    }\n  });\n\n  candidateWords.forEach((word) => {\n    if (!matches.has(word)) {\n      matches.set(word, {\n        word,\n        normalized: query,\n        matchType: \"ngram\",\n        language,\n      });\n    }\n  });\n}\n\n/**\n * Find fuzzy matches using edit distance\n */\nfunction findFuzzyMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>, processor: LanguageProcessor, config: FuzzyConfig): void {\n  const maxDistance = config.maxEditDistance;\n\n  for (const [variant, words] of index.variantToBase.entries()) {\n    if (Math.abs(variant.length - query.length) <= maxDistance) {\n      // Use Damerau-Levenshtein if transpositions feature is enabled\n      const useTranspositions = index.config.features?.includes(\"transpositions\");\n      const distance = useTranspositions ? calculateDamerauLevenshteinDistance(query, variant, maxDistance) : calculateLevenshteinDistance(query, variant, maxDistance);\n\n      if (distance <= maxDistance) {\n        words.forEach((word) => {\n          const existingMatch = matches.get(word);\n          // Don't replace exact or prefix matches with fuzzy matches\n          if (!existingMatch || (existingMatch.matchType !== \"exact\" && existingMatch.matchType !== \"prefix\" && (existingMatch.editDistance || Infinity) > distance)) {\n            matches.set(word, {\n              word,\n              normalized: variant,\n              matchType: \"fuzzy\",\n              editDistance: distance,\n              language: processor.language,\n            });\n          }\n        });\n      }\n    }\n  }\n}\n\n/**\n * Create a suggestion result from a search match\n */\nfunction createSuggestionResult(match: SearchMatch, originalQuery: string, threshold: number, index: FuzzyIndex, options?: SearchOptions): SuggestionResult | null {\n  let score = calculateMatchScore(match, originalQuery);\n\n  // Combine with BM25 score if available\n  if (match.bm25Score !== undefined && index.config.useBM25) {\n    const bm25Weight = index.config.bm25Weight || 0.6;\n    const fuzzyWeight = 1 - bm25Weight;\n    score = bm25Weight * match.bm25Score + fuzzyWeight * score;\n  }\n\n  // Apply field weight if present\n  if (match.fieldWeight) {\n    score = Math.min(1.0, score * match.fieldWeight);\n  }\n\n  if (score < threshold) {\n    return null;\n  }\n\n  const result: SuggestionResult = {\n    display: match.word,\n    baseWord: match.word,\n    isSynonym: match.matchType === \"synonym\",\n    score,\n    language: match.language,\n    // @ts-ignore - temporary debug property\n    _debug_matchType: match.matchType,\n  };\n\n  // Add field information if this is a multi-field search\n  if (index.fieldData && index.fieldData.has(match.word)) {\n    result.fields = index.fieldData.get(match.word);\n    result.field = match.field;\n  }\n\n  // Add highlights if requested\n  if (options?.includeHighlights) {\n    result.highlights = calculateHighlights(match, originalQuery, match.word);\n  }\n\n  return result;\n}\n\n/**\n * Calculate match score (0-1, higher is better)\n */\nfunction calculateMatchScore(\n  //\n  match: SearchMatch,\n  query: string\n): number {\n  const queryLen = query.length;\n  const wordLen = match.word.length;\n  const maxLen = Math.max(queryLen, wordLen);\n\n  let score = 0.5; // Base score\n\n  switch (match.matchType) {\n    case \"exact\":\n      score = 1.0;\n      break;\n    case \"prefix\":\n      score = 0.9 - (wordLen - queryLen) / (maxLen * 2);\n      break;\n    case \"substring\":\n      score = 0.8;\n      break;\n    case \"phonetic\":\n      score = 0.7;\n      break;\n    case \"fuzzy\":\n      if (match.editDistance !== undefined) {\n        score = Math.max(0.3, 1.0 - match.editDistance / maxLen);\n      }\n      break;\n    case \"synonym\":\n      score = 0.6;\n      break;\n    case \"compound\":\n      score = 0.75;\n      break;\n    case \"ngram\":\n      score = calculateNgramSimilarity(query.toLowerCase(), match.normalized, 3) * 0.8;\n      break;\n  }\n\n  // Boost score for shorter words (more likely to be what user wants)\n  // But don't boost exact matches - they should stay at 1.0\n  if (wordLen <= queryLen + 2 && match.matchType !== \"exact\") {\n    score += 0.1;\n  }\n\n  return Math.min(1.0, Math.max(0.0, score));\n}\n\n/**\n * Generate n-grams from a string\n */\nfunction generateNgrams(\n  //\n  str: string,\n  n: number\n): string[] {\n  if (str.length < n) return [str];\n\n  const ngrams: string[] = [];\n  for (let i = 0; i <= str.length - n; i++) {\n    ngrams.push(str.slice(i, i + n));\n  }\n  return ngrams;\n}\n\n/**\n * Get suggestions using inverted index (for large datasets)\n * This is a wrapper that converts inverted index results to the same format\n */\nfunction getSuggestionsInverted(\n  //\n  index: FuzzyIndex,\n  query: string,\n  limit: number,\n  threshold: number,\n  processors: LanguageProcessor[],\n  options?: SearchOptions\n): SuggestionResult[] {\n  if (!index.invertedIndex || !index.documents) {\n    throw new Error(\"Inverted index not available\");\n  }\n\n  // Use inverted index search\n  let matches = searchInvertedIndex(index.invertedIndex, index.documents, query, processors, index.config);\n\n  // Calculate BM25 scores if enabled\n  if (index.config.useBM25) {\n    const queryTerms = query.toLowerCase().split(/\\s+/).filter(t => t.length > 0);\n    matches = calculateBM25Scores(matches, queryTerms, index.invertedIndex, index.documents, index.config);\n  }\n\n  // Convert to suggestion results (same as classic approach)\n  const results = matches\n    .map((match) => createSuggestionResult(match, query, threshold, index, options))\n    .filter((result): result is SuggestionResult => result !== null)\n    .sort((a, b) => b.score - a.score)\n    .slice(0, limit);\n\n  return results;\n}\n\n/**\n * Search with phrase support\n * Handles queries containing quoted phrases\n */\nfunction searchWithPhrases(\n  index: FuzzyIndex,\n  parsedQuery: ReturnType<typeof parseQuery>,\n  limit: number,\n  threshold: number,\n  options: SearchOptions\n): SuggestionResult[] {\n  const config = index.config;\n  const useTranspositions = config.features.includes('transpositions');\n  \n  // Get phrase match options\n  const phraseOptions = {\n    exactMatch: false,\n    maxEditDistance: 1,\n    proximityBonus: 1.5,\n    maxProximityDistance: 3,\n    useTranspositions,\n  };\n\n  // Search all base words for phrase matches\n  const phraseMatches = new Map<string, { score: number; phraseCount: number }>();\n\n  // For each phrase, find matching words\n  for (const phrase of parsedQuery.phrases) {\n    for (const word of index.base) {\n      const match = matchPhrase(word, phrase, phraseOptions);\n      \n      if (match.matched) {\n        const existing = phraseMatches.get(word);\n        const newScore = match.score * phraseOptions.proximityBonus;\n        \n        if (existing) {\n          // Multiple phrases matched - boost even more\n          phraseMatches.set(word, {\n            score: Math.max(existing.score, newScore),\n            phraseCount: existing.phraseCount + 1,\n          });\n        } else {\n          phraseMatches.set(word, { score: newScore, phraseCount: 1 });\n        }\n      }\n    }\n  }\n\n  // If we have regular terms too, search for them\n  let termMatches = new Map<string, SearchMatch>();\n  \n  if (parsedQuery.terms.length > 0) {\n    const termQuery = parsedQuery.terms.join(' ');\n    const processors = config.languages\n      .map((lang) => index.languageProcessors.get(lang))\n      .filter((p): p is LanguageProcessor => p !== undefined);\n\n    for (const processor of processors) {\n      const normalizedQuery = processor.normalize(termQuery);\n      \n      // Use existing search strategies for terms\n      findExactMatches(normalizedQuery, index, termMatches, processor.language);\n      findPrefixMatches(normalizedQuery, index, termMatches, processor.language);\n      findPhoneticMatches(normalizedQuery, processor, index, termMatches);\n      findNgramMatches(normalizedQuery, index, termMatches, processor.language, config.ngramSize);\n      \n      if (config.features.includes(\"missing-letters\") || config.features.includes(\"extra-letters\") || config.features.includes(\"transpositions\")) {\n        findFuzzyMatches(normalizedQuery, index, termMatches, processor, config);\n      }\n    }\n  }\n\n  // Combine phrase and term matches\n  const combinedResults = new Map<string, SuggestionResult>();\n\n  // Add phrase matches\n  for (const [word, phraseData] of phraseMatches.entries()) {\n    const result: SuggestionResult = {\n      display: word,\n      baseWord: word,\n      isSynonym: false,\n      score: phraseData.score,\n    };\n    \n    // If word also matched terms, boost score even more\n    const termMatch = termMatches.get(word);\n    if (termMatch) {\n      result.score = Math.min(1.0, result.score * 1.2);\n    }\n    \n    combinedResults.set(word, result);\n  }\n\n  // Add term matches that didn't match phrases (with lower priority)\n  for (const [word, match] of termMatches.entries()) {\n    if (!combinedResults.has(word)) {\n      const result = createSuggestionResult(match, parsedQuery.terms.join(' '), threshold, index, options);\n      if (result) {\n        // Reduce score slightly since it didn't match the phrase\n        result.score *= 0.8;\n        combinedResults.set(word, result);\n      }\n    }\n  }\n\n  // Sort and limit results\n  const results = Array.from(combinedResults.values())\n    .filter(r => r.score >= threshold)\n    .sort((a, b) => b.score - a.score)\n    .slice(0, limit);\n\n  // Cache the results\n  if (index._cache) {\n    index._cache.set(parsedQuery.original, results, limit, options);\n  }\n\n  return results;\n}\n\n/**\n * Update an existing index by adding new items\n * Much faster than rebuilding the entire index\n * \n * @param index - Existing fuzzy index to update\n * @param newItems - New items to add (strings or objects)\n * @param options - Optional configuration (uses index's existing config by default)\n * @returns Updated index (mutates the original)\n * \n * @example\n * const index = buildFuzzyIndex(['apple', 'banana']);\n * updateIndex(index, ['cherry', 'date']);\n * // Index now contains: apple, banana, cherry, date\n */\nexport function updateIndex(\n  index: FuzzyIndex,\n  newItems: (string | any)[] = [],\n  options: Partial<BuildIndexOptions> = {}\n): FuzzyIndex {\n  if (!index || !index.config) {\n    throw new Error('Invalid index provided');\n  }\n\n  if (!newItems || newItems.length === 0) {\n    return index;\n  }\n\n  // Use existing index configuration\n  const config = index.config;\n  const featureSet = new Set(config.features);\n  \n  // Get language processors from index\n  const languageProcessors = Array.from(index.languageProcessors.values());\n  \n  if (languageProcessors.length === 0) {\n    throw new Error('No language processors found in index');\n  }\n\n  // Check if we're doing multi-field search\n  const hasFields = index.fields && index.fields.length > 0;\n  const isObjectArray = newItems.length > 0 && typeof newItems[0] === 'object' && newItems[0] !== null;\n\n  // Validate: if objects are provided, fields must be specified\n  if (isObjectArray && !hasFields) {\n    throw new Error('Index was not built with fields, cannot add objects');\n  }\n\n  // Track existing words to avoid duplicates\n  const existingWords = new Set(index.base.map(w => w.toLowerCase()));\n  let processed = 0;\n\n  for (const item of newItems) {\n    if (!item) continue;\n\n    // Handle multi-field objects\n    if (hasFields && isObjectArray) {\n      const fieldValues = extractFieldValues(item, index.fields);\n      if (!fieldValues) continue;\n\n      // Generate a unique ID for this object\n      const baseId = Object.values(fieldValues)[0] || `item_${index.base.length + processed}`;\n\n      // Skip if already exists\n      if (existingWords.has(baseId.toLowerCase())) continue;\n\n      // Store field data\n      if (index.fieldData) {\n        index.fieldData.set(baseId, fieldValues);\n      }\n\n      // Add to base\n      existingWords.add(baseId.toLowerCase());\n      index.base.push(baseId);\n\n      // Index each field separately\n      for (const [fieldName, fieldValue] of Object.entries(fieldValues)) {\n        if (!fieldValue || fieldValue.trim().length < config.minQueryLength) continue;\n\n        const trimmedValue = fieldValue.trim();\n\n        // Process this field value with each language processor\n        for (const processor of languageProcessors) {\n          processWordWithProcessorAndField(trimmedValue, baseId, fieldName, processor, index, config, featureSet);\n        }\n      }\n    } else {\n      // Handle simple string array\n      const word = typeof item === 'string' ? item : String(item);\n      if (word.trim().length < config.minQueryLength) continue;\n\n      const trimmedWord = word.trim();\n      \n      // Skip if already exists\n      if (existingWords.has(trimmedWord.toLowerCase())) continue;\n\n      existingWords.add(trimmedWord.toLowerCase());\n      index.base.push(trimmedWord);\n\n      // Process with each language processor\n      for (const processor of languageProcessors) {\n        processWordWithProcessor(trimmedWord, processor, index, config, featureSet);\n      }\n    }\n\n    processed++;\n    if (options.onProgress) {\n      options.onProgress(processed, newItems.length);\n    }\n  }\n\n  // Update inverted index if it exists\n  if (index.invertedIndex && index.documents) {\n    const { invertedIndex, documents } = buildInvertedIndex(\n      index.base,\n      languageProcessors,\n      config,\n      featureSet\n    );\n    index.invertedIndex = invertedIndex;\n    index.documents = documents;\n  }\n\n  // Clear cache since index has changed\n  if (index._cache) {\n    index._cache.clear();\n  }\n\n  return index;\n}\n\n/**\n * Remove items from an existing index\n * \n * @param index - Existing fuzzy index to update\n * @param itemsToRemove - Items to remove (exact matches)\n * @returns Updated index (mutates the original)\n * \n * @example\n * const index = buildFuzzyIndex(['apple', 'banana', 'cherry']);\n * removeFromIndex(index, ['banana']);\n * // Index now contains: apple, cherry\n */\nexport function removeFromIndex(\n  index: FuzzyIndex,\n  itemsToRemove: string[] = []\n): FuzzyIndex {\n  if (!index || !index.config) {\n    throw new Error('Invalid index provided');\n  }\n\n  if (!itemsToRemove || itemsToRemove.length === 0) {\n    return index;\n  }\n\n  // Create set of items to remove (case-insensitive)\n  const toRemove = new Set(itemsToRemove.map(item => item.toLowerCase()));\n\n  // Remove from base array\n  index.base = index.base.filter(word => !toRemove.has(word.toLowerCase()));\n\n  // Remove from variant maps\n  for (const [variant, baseWords] of index.variantToBase.entries()) {\n    const filtered = new Set(Array.from(baseWords).filter((word: string) => !toRemove.has(word.toLowerCase())));\n    if (filtered.size === 0) {\n      index.variantToBase.delete(variant);\n    } else {\n      index.variantToBase.set(variant, filtered);\n    }\n  }\n\n  // Remove from phonetic map\n  for (const [phonetic, baseWords] of index.phoneticToBase.entries()) {\n    const filtered = new Set(Array.from(baseWords).filter((word: string) => !toRemove.has(word.toLowerCase())));\n    if (filtered.size === 0) {\n      index.phoneticToBase.delete(phonetic);\n    } else {\n      index.phoneticToBase.set(phonetic, filtered);\n    }\n  }\n\n  // Remove from ngram index\n  for (const [ngram, baseWords] of index.ngramIndex.entries()) {\n    const filtered = new Set(Array.from(baseWords).filter((word: string) => !toRemove.has(word.toLowerCase())));\n    if (filtered.size === 0) {\n      index.ngramIndex.delete(ngram);\n    } else {\n      index.ngramIndex.set(ngram, filtered);\n    }\n  }\n\n  // Remove from synonym map\n  for (const [synonym, baseWords] of index.synonymMap.entries()) {\n    const filtered = new Set(Array.from(baseWords).filter((word: string) => !toRemove.has(word.toLowerCase())));\n    if (filtered.size === 0) {\n      index.synonymMap.delete(synonym);\n    } else {\n      index.synonymMap.set(synonym, filtered);\n    }\n  }\n\n  // Remove from field data if exists\n  if (index.fieldData) {\n    for (const item of itemsToRemove) {\n      index.fieldData.delete(item);\n    }\n  }\n\n  // Rebuild inverted index if it exists\n  if (index.invertedIndex && index.documents) {\n    const config = index.config;\n    const featureSet = new Set(config.features);\n    const languageProcessors = Array.from(index.languageProcessors.values());\n    \n    const { invertedIndex, documents } = buildInvertedIndex(\n      index.base,\n      languageProcessors,\n      config,\n      featureSet\n    );\n    index.invertedIndex = invertedIndex;\n    index.documents = documents;\n  }\n\n  // Clear cache since index has changed\n  if (index._cache) {\n    index._cache.clear();\n  }\n\n  return index;\n}\n","/**\n * Index Serialization\n * Save and load fuzzy search indices for 100x faster startup\n */\n\nimport type { FuzzyIndex } from \"./types.js\";\nimport { SearchCache } from \"./cache.js\";\n\n/**\n * Serializable index format (JSON-compatible)\n */\ninterface SerializedIndex {\n  version: string;\n  base: string[];\n  variantToBase: [string, string[]][];\n  phoneticToBase: [string, string[]][];\n  ngramIndex: [string, string[]][];\n  synonymMap: [string, string[]][];\n  config: any;\n  languageProcessorNames: string[];\n  invertedIndex?: any;\n  documents?: any[];\n}\n\n/**\n * Serialize a FuzzyIndex to JSON string\n */\nexport function serializeIndex(index: FuzzyIndex): string {\n  const serialized: SerializedIndex = {\n    version: \"1.0\",\n    base: index.base,\n    variantToBase: Array.from(index.variantToBase.entries()).map(([k, v]) => [k, Array.from(v)]),\n    phoneticToBase: Array.from(index.phoneticToBase.entries()).map(([k, v]) => [k, Array.from(v)]),\n    ngramIndex: Array.from(index.ngramIndex.entries()).map(([k, v]) => [k, Array.from(v)]),\n    synonymMap: Array.from(index.synonymMap.entries()).map(([k, v]) => [k, Array.from(v)]),\n    config: index.config,\n    languageProcessorNames: Array.from(index.languageProcessors.keys()),\n  };\n\n  // Serialize inverted index if present\n  if (index.invertedIndex) {\n    serialized.invertedIndex = {\n      termToPostings: Array.from(index.invertedIndex.termToPostings.entries()),\n      phoneticToPostings: Array.from(index.invertedIndex.phoneticToPostings.entries()),\n      ngramToPostings: Array.from(index.invertedIndex.ngramToPostings.entries()),\n      synonymToPostings: Array.from(index.invertedIndex.synonymToPostings.entries()),\n      totalDocs: index.invertedIndex.totalDocs,\n      avgDocLength: index.invertedIndex.avgDocLength,\n    };\n  }\n\n  // Serialize documents if present\n  if (index.documents) {\n    serialized.documents = index.documents;\n  }\n\n  return JSON.stringify(serialized);\n}\n\n/**\n * Deserialize a FuzzyIndex from JSON string\n */\nexport async function deserializeIndex(json: string): Promise<FuzzyIndex> {\n  const data: SerializedIndex = JSON.parse(json);\n\n  // Reconstruct Maps from arrays\n  const variantToBase = new Map(data.variantToBase.map(([k, v]) => [k, new Set(v)]));\n  const phoneticToBase = new Map(data.phoneticToBase.map(([k, v]) => [k, new Set(v)]));\n  const ngramIndex = new Map(data.ngramIndex.map(([k, v]) => [k, new Set(v)]));\n  const synonymMap = new Map(data.synonymMap.map(([k, v]) => [k, new Set(v)]));\n\n  // Reconstruct language processors (need to import them)\n  const { LanguageRegistry } = await import(\"../languages/index.js\");\n  const languageProcessors = new Map();\n  for (const langName of data.languageProcessorNames) {\n    const processor = LanguageRegistry.getProcessor(langName);\n    if (processor) {\n      languageProcessors.set(langName, processor);\n    }\n  }\n\n  const index: FuzzyIndex = {\n    base: data.base,\n    variantToBase,\n    phoneticToBase,\n    ngramIndex,\n    synonymMap,\n    languageProcessors,\n    config: data.config,\n  };\n\n  // Reconstruct inverted index if present\n  if (data.invertedIndex) {\n    index.invertedIndex = {\n      termToPostings: new Map(data.invertedIndex.termToPostings),\n      phoneticToPostings: new Map(data.invertedIndex.phoneticToPostings),\n      ngramToPostings: new Map(data.invertedIndex.ngramToPostings),\n      synonymToPostings: new Map(data.invertedIndex.synonymToPostings),\n      totalDocs: data.invertedIndex.totalDocs,\n      avgDocLength: data.invertedIndex.avgDocLength,\n    };\n  }\n\n  // Reconstruct documents if present\n  if (data.documents) {\n    index.documents = data.documents;\n  }\n\n  // Reconstruct cache if enabled in config\n  if (data.config.enableCache !== false) {\n    const cacheSize = data.config.cacheSize || 100;\n    index._cache = new SearchCache(cacheSize);\n  }\n\n  return index;\n}\n\n/**\n * Save index to localStorage (browser)\n */\nexport function saveIndexToLocalStorage(index: FuzzyIndex, key: string = \"fuzzy-search-index\"): void {\n  if (typeof localStorage === \"undefined\") {\n    throw new Error(\"localStorage is not available\");\n  }\n  const serialized = serializeIndex(index);\n  localStorage.setItem(key, serialized);\n}\n\n/**\n * Load index from localStorage (browser)\n */\nexport async function loadIndexFromLocalStorage(key: string = \"fuzzy-search-index\"): Promise<FuzzyIndex | null> {\n  if (typeof localStorage === \"undefined\") {\n    throw new Error(\"localStorage is not available\");\n  }\n  const serialized = localStorage.getItem(key);\n  if (!serialized) {\n    return null;\n  }\n  return await deserializeIndex(serialized);\n}\n\n/**\n * Get serialized index size in bytes\n */\nexport function getSerializedSize(index: FuzzyIndex): number {\n  const serialized = serializeIndex(index);\n  return new Blob([serialized]).size;\n}\n","/**\n * Data Indexer Utility\n * Extract unique words from various data formats for fuzzy search indexing\n */\n\nexport interface DataToIndexOptions {\n  /** Minimum word length to include (default: 2) */\n  minLength?: number;\n  /** Split text into words (default: true) */\n  splitWords?: boolean;\n  /** Remove stop words (default: false) */\n  stopWords?: string[] | false;\n  /** Overlap between chunks in characters (default: 0) */\n  overlap?: number;\n  /** Size of each chunk in characters (default: 0 = no chunking) */\n  chunkSize?: number;\n  /** Split strategy for chunking (default: 'word') */\n  splitOn?: \"word\" | \"sentence\" | \"paragraph\";\n  /** Data format (default: 'string') */\n  format?: \"string\" | \"html\" | \"json\" | \"base64\" | \"url\";\n  /** Remove numbers (default: false) */\n  removeNumbers?: boolean;\n  /** Case sensitive (default: false) */\n  caseSensitive?: boolean;\n}\n\n/**\n * Extract unique words from various data formats\n * Returns an array of unique words that can be used as a dictionary for fuzzy search\n *\n * @param content - The content to extract words from\n * @param options - Configuration options\n * @returns Array of unique words (no duplicates)\n *\n * @example\n * // Simple text\n * const words = dataToIndex(\"Hello world! Hello again.\");\n * // → ['hello', 'world', 'again']\n *\n * @example\n * // HTML content\n * const words = dataToIndex(\"<h1>Title</h1><p>Content here</p>\", { format: 'html' });\n * // → ['title', 'content', 'here']\n *\n * @example\n * // JSON data\n * const data = [{ name: \"John\", city: \"NYC\" }, { name: \"Jane\", city: \"LA\" }];\n * const words = dataToIndex(JSON.stringify(data), { format: 'json' });\n * // → ['john', 'nyc', 'jane', 'la']\n */\nexport function dataToIndex(\n  //\n  content: string,\n  options: DataToIndexOptions = {}\n): string[] {\n  const {\n    //\n    minLength = 2,\n    splitWords = true,\n    stopWords = false,\n    overlap = 0,\n    chunkSize = 0,\n    splitOn = \"word\",\n    format = \"string\",\n    removeNumbers = false,\n    caseSensitive = false,\n  } = options;\n\n  let text = content;\n\n  // Step 1: Handle different formats\n  switch (format) {\n    case \"base64\":\n      try {\n        text = atob(content);\n      } catch (e) {\n        console.error(\"Failed to decode base64:\", e);\n        return [];\n      }\n      break;\n\n    case \"html\":\n      text = stripHTML(content);\n      break;\n\n    case \"json\":\n      text = extractFromJSON(content);\n      break;\n\n    case \"url\":\n      // URL format requires async, so we'll throw an error\n      throw new Error(\"URL format requires async. Use dataToIndexAsync() instead.\");\n\n    case \"string\":\n    default:\n      // Already a string, no conversion needed\n      break;\n  }\n\n  // Step 2: Apply chunking if specified\n  if (chunkSize > 0) {\n    const chunks = chunkText(text, chunkSize, overlap, splitOn);\n    text = chunks.join(\" \");\n  }\n\n  // Step 3: Extract words\n  let words: string[] = [];\n\n  if (splitWords) {\n    // Split on whitespace and punctuation\n    words = text.split(/[\\s\\-_.,;:!?()[\\]{}'\"\\/\\\\]+/).filter((word) => word.length > 0);\n  } else {\n    words = [text];\n  }\n\n  // Step 4: Clean and filter words\n  words = words\n    .map((word) => {\n      // Remove leading/trailing punctuation (but preserve unicode letters)\n      word = word.replace(/^[^\\p{L}\\p{N}]+|[^\\p{L}\\p{N}]+$/gu, \"\");\n\n      // Convert case\n      if (!caseSensitive) {\n        word = word.toLowerCase();\n      }\n\n      return word;\n    })\n    .filter((word) => {\n      // Filter by minimum length\n      if (word.length < minLength) return false;\n\n      // Filter numbers if requested\n      if (removeNumbers && /^\\d+$/.test(word)) return false;\n\n      return true;\n    });\n\n  // Step 5: Remove stop words if specified\n  if (stopWords && Array.isArray(stopWords)) {\n    const stopWordsSet = new Set(stopWords.map((w) => w.toLowerCase()));\n    words = words.filter((word) => !stopWordsSet.has(word.toLowerCase()));\n  }\n\n  // Step 6: Remove duplicates and return\n  return Array.from(new Set(words));\n}\n\n/**\n * Strip HTML tags and extract text content\n */\nfunction stripHTML(html: string): string {\n  // Remove script and style tags with their content\n  let text = html.replace(/<script\\b[^<]*(?:(?!<\\/script>)<[^<]*)*<\\/script>/gi, \" \");\n  text = text.replace(/<style\\b[^<]*(?:(?!<\\/style>)<[^<]*)*<\\/style>/gi, \" \");\n\n  // Remove HTML comments\n  text = text.replace(/<!--[\\s\\S]*?-->/g, \" \");\n\n  // Remove all HTML tags\n  text = text.replace(/<[^>]+>/g, \" \");\n\n  // Decode common HTML entities\n  text = text\n    .replace(/&nbsp;/g, \" \")\n    .replace(/&amp;/g, \"&\")\n    .replace(/&lt;/g, \"<\")\n    .replace(/&gt;/g, \">\")\n    .replace(/&quot;/g, '\"')\n    .replace(/&#39;/g, \"'\")\n    .replace(/&apos;/g, \"'\");\n\n  // Normalize whitespace\n  text = text.replace(/\\s+/g, \" \").trim();\n\n  return text;\n}\n\n/**\n * Extract string values from JSON\n */\nfunction extractFromJSON(jsonString: string): string {\n  try {\n    const data = JSON.parse(jsonString);\n    const values: string[] = [];\n\n    function extractValues(obj: any, depth: number = 0): void {\n      // Limit recursion depth to prevent stack overflow\n      if (depth > 10) return;\n\n      if (typeof obj === \"string\") {\n        values.push(obj);\n      } else if (Array.isArray(obj)) {\n        obj.forEach((item) => extractValues(item, depth + 1));\n      } else if (typeof obj === \"object\" && obj !== null) {\n        Object.values(obj).forEach((value) => extractValues(value, depth + 1));\n      }\n    }\n\n    extractValues(data);\n    return values.join(\" \");\n  } catch (e) {\n    console.error(\"Failed to parse JSON:\", e);\n    return \"\";\n  }\n}\n\n/**\n * Chunk text into smaller pieces\n */\nfunction chunkText(\n  //\n  text: string,\n  chunkSize: number,\n  overlap: number,\n  splitOn: \"word\" | \"sentence\" | \"paragraph\"\n): string[] {\n  const chunks: string[] = [];\n\n  if (splitOn === \"paragraph\") {\n    // Split on double newlines\n    const paragraphs = text.split(/\\n\\n+/);\n    let currentChunk = \"\";\n\n    for (const para of paragraphs) {\n      if ((currentChunk + para).length <= chunkSize) {\n        currentChunk += (currentChunk ? \"\\n\\n\" : \"\") + para;\n      } else {\n        if (currentChunk) chunks.push(currentChunk);\n        currentChunk = para;\n      }\n    }\n    if (currentChunk) chunks.push(currentChunk);\n  } else if (splitOn === \"sentence\") {\n    // Split on sentence boundaries\n    const sentences = text.split(/[.!?]+\\s+/);\n    let currentChunk = \"\";\n\n    for (const sentence of sentences) {\n      if ((currentChunk + sentence).length <= chunkSize) {\n        currentChunk += (currentChunk ? \" \" : \"\") + sentence;\n      } else {\n        if (currentChunk) chunks.push(currentChunk);\n        currentChunk = sentence;\n      }\n    }\n    if (currentChunk) chunks.push(currentChunk);\n  } else {\n    // Split on words (default)\n    const words = text.split(/\\s+/);\n    let currentChunk = \"\";\n\n    for (const word of words) {\n      if ((currentChunk + \" \" + word).length <= chunkSize) {\n        currentChunk += (currentChunk ? \" \" : \"\") + word;\n      } else {\n        if (currentChunk) chunks.push(currentChunk);\n\n        // Add overlap\n        if (overlap > 0 && currentChunk) {\n          const overlapWords = currentChunk.split(/\\s+/).slice(-Math.ceil(overlap / 10));\n          currentChunk = overlapWords.join(\" \") + \" \" + word;\n        } else {\n          currentChunk = word;\n        }\n      }\n    }\n    if (currentChunk) chunks.push(currentChunk);\n  }\n\n  return chunks;\n}\n\n/**\n * Async version for URL fetching\n * @param content - URL or content string\n * @param options - Configuration options\n * @returns Promise<string[]> Array of unique words\n */\nexport async function dataToIndexAsync(\n  //\n  content: string,\n  options: DataToIndexOptions = {}\n): Promise<string[]> {\n  const { format = \"string\" } = options;\n\n  if (format === \"url\") {\n    try {\n      const response = await fetch(content);\n      const html = await response.text();\n      return dataToIndex(html, { ...options, format: \"html\" });\n    } catch (e) {\n      console.error(\"Failed to fetch URL:\", e);\n      return [];\n    }\n  }\n\n  return dataToIndex(content, options);\n}\n","/**\n * FuzzyFindJS - A powerful, multi-language optimized fuzzy search library\n *\n * @example\n * ```typescript\n * import { buildFuzzyIndex, getSuggestions } from 'fuzzyfindjs';\n *\n * const dictionary = ['Krankenhaus', 'Schule', 'Kindergarten'];\n * const index = buildFuzzyIndex(dictionary);\n * const results = getSuggestions(index, 'krankenh', 5);\n * ```\n */\n\n// Core functionality\nexport {\n  //\n  buildFuzzyIndex,\n  getSuggestions,\n  batchSearch,\n  updateIndex,\n  removeFromIndex,\n} from \"./core/index.js\";\n\nimport {\n  //\n  buildFuzzyIndex,\n  getSuggestions,\n} from \"./core/index.js\";\n\n// Highlighting utilities (for UI rendering)\nexport {\n  //\n  calculateHighlights,\n  formatHighlightedHTML,\n} from \"./core/highlighting.js\";\n\n// Cache utilities (for advanced users)\nexport {\n  //\n  SearchCache,\n  LRUCache,\n} from \"./core/cache.js\";\n\n// Serialization utilities (save/load indices)\nexport {\n  //\n  serializeIndex,\n  deserializeIndex,\n  saveIndexToLocalStorage,\n  loadIndexFromLocalStorage,\n  getSerializedSize,\n} from \"./core/serialization.js\";\n\n// Accent normalization utilities\nexport {\n  //\n  removeAccents,\n  hasAccents,\n  normalizeForComparison,\n  getAccentVariants,\n} from \"./utils/accent-normalization.js\";\n\n// Stop words utilities\nexport {\n  //\n  filterStopWords,\n  getStopWordsForLanguages,\n  isStopWord,\n  DEFAULT_STOP_WORDS,\n} from \"./utils/stop-words.js\";\n\n// Word boundary utilities\nexport {\n  //\n  isWordBoundary,\n  matchesAtWordBoundary,\n  findWordBoundaryMatches,\n  matchesWord,\n  matchesWildcard,\n} from \"./utils/word-boundaries.js\";\n\n// Data indexing utilities\nexport {\n  //\n  dataToIndex,\n  dataToIndexAsync,\n} from \"./utils/data-indexer.js\";\nexport type {\n  //\n  DataToIndexOptions,\n} from \"./utils/data-indexer.js\";\n\n// Phrase parsing utilities\nexport {\n  //\n  parseQuery,\n  hasPhraseSyntax,\n  normalizePhrase,\n  splitPhraseWords,\n} from \"./utils/phrase-parser.js\";\nexport type {\n  //\n  ParsedQuery,\n} from \"./utils/phrase-parser.js\";\n\n// Language detection utilities\nexport {\n  //\n  detectLanguages,\n  detectLanguagesWithConfidence,\n  sampleTextForDetection,\n  isValidLanguage,\n  normalizeLanguageCode,\n} from \"./utils/language-detection.js\";\nexport type {\n  //\n  LanguageDetectionResult,\n} from \"./utils/language-detection.js\";\n\n// Configuration\nexport {\n  //\n  DEFAULT_CONFIG,\n  PERFORMANCE_CONFIGS,\n  mergeConfig,\n} from \"./core/config.js\";\n\n// Types\nexport type {\n  //\n  FuzzyIndex,\n  FuzzyConfig,\n  SuggestionResult,\n  SearchMatch,\n  MatchType,\n  FuzzyFeature,\n  LanguageProcessor,\n  BuildIndexOptions,\n  SearchOptions,\n  DebugInfo,\n  SuggestionResultWithDebug,\n} from \"./core/types.js\";\n\n// Language processors\nexport {\n  //\n  LanguageRegistry,\n  GermanProcessor,\n  EnglishProcessor,\n  SpanishProcessor,\n  FrenchProcessor,\n  BaseLanguageProcessor,\n} from \"./languages/index.js\";\n\n// Algorithms (for advanced users)\nexport {\n  //\n  calculateLevenshteinDistance,\n  calculateDamerauLevenshteinDistance,\n  calculateNgramSimilarity,\n  distanceToSimilarity,\n  areStringsSimilar,\n} from \"./algorithms/levenshtein.js\";\nexport {\n  //\n  calculateBM25Score,\n  calculateIDF,\n  normalizeBM25Score,\n  combineScores,\n  buildCorpusStats,\n  DEFAULT_BM25_CONFIG,\n} from \"./algorithms/bm25.js\";\nexport type {\n  //\n  BM25Config,\n  DocumentStats,\n  CorpusStats,\n} from \"./algorithms/bm25.js\";\nexport {\n  //\n  BloomFilter,\n  createBloomFilter,\n} from \"./algorithms/bloom-filter.js\";\nexport type {\n  //\n  BloomFilterConfig,\n} from \"./algorithms/bloom-filter.js\";\n\n// Memory pooling utilities (for performance optimization)\nexport {\n  //\n  ObjectPool,\n  ArrayPool,\n  MapPool,\n  SetPool,\n  withPooledArray,\n  globalArrayPool,\n  globalMapPool,\n  globalSetPool,\n} from \"./utils/memory-pool.js\";\n\n/**\n * Creates a fuzzy search instance with sensible defaults - the easiest way to get started.\n * \n * This convenience function combines index building and searching into a simple API.\n * It's perfect for quick prototyping and simple use cases. For advanced features,\n * use {@link buildFuzzyIndex} and {@link getSuggestions} directly.\n * \n * @param dictionary - Array of strings to make searchable\n * @param options - Simple configuration options\n * @param options.languages - Languages to enable (default: ['english'])\n * @param options.performance - Performance mode: 'fast', 'balanced', or 'comprehensive' (default: 'balanced')\n * @param options.maxResults - Maximum results to return per search (default: 5)\n * \n * @returns Object with search() method and the underlying index\n * @returns {Function} search - Function to search the index: (query: string, maxResults?: number) => SuggestionResult[]\n * @returns {FuzzyIndex} index - The underlying fuzzy index (for advanced usage)\n * \n * @example\n * ```typescript\n * // Quick start - one line setup\n * const search = createFuzzySearch(['apple', 'banana', 'cherry']);\n * const results = search.search('aple');\n * // Returns: [{ display: 'apple', score: 0.9, ... }]\n * \n * // With options\n * const search = createFuzzySearch(['Krankenhaus', 'Apotheke'], {\n *   languages: ['german'],\n *   performance: 'comprehensive',\n *   maxResults: 10\n * });\n * \n * // Access underlying index for advanced features\n * const { search: searchFn, index } = createFuzzySearch(['hello', 'world']);\n * console.log(index.base); // ['hello', 'world']\n * ```\n * \n * @see {@link buildFuzzyIndex} for advanced index building\n * @see {@link getSuggestions} for advanced search options\n */\nexport function createFuzzySearch(\n  //\n  dictionary: string[],\n  options: {\n    languages?: string[];\n    performance?: \"fast\" | \"balanced\" | \"comprehensive\";\n    maxResults?: number;\n  } = {}\n) {\n  const index = buildFuzzyIndex(dictionary, {\n    config: {\n      languages: options.languages || [\"english\"],\n      performance: options.performance || \"balanced\",\n      maxResults: options.maxResults || 5,\n    },\n  });\n\n  return {\n    search: (query: string, maxResults?: number) => getSuggestions(index, query, maxResults),\n    index,\n  };\n}\n\n/**\n * Version information\n */\nexport const VERSION = \"1.0.13\";\n"],"names":["DEFAULT_CONFIG","PERFORMANCE_CONFIGS","LANGUAGE_FEATURES","mergeConfig","userConfig","baseConfig","performanceConfig","mergedConfig","recommendedFeatures","lang","feature","validateConfig","config","BaseLanguageProcessor","text","word","normalized","code","consonantMap","i","char","digit","variants","commonEndings","ending","_word","char1","char2","neighbors","ngrams","str1","str2","matrix","len1","len2","j","cost","GermanProcessor","prev","next","parts","commonPrefixes","commonSuffixes","commonWords","prefix","remainder","suffix","leftPart","rightPart","part","germanEndings","synonymMap","EnglishProcessor","metaphone","current","length","englishEndings","base","SpanishProcessor","FrenchProcessor","next2","LanguageRegistry","language","languages","processor","ObjectPool","factory","maxSize","reset","obj","ArrayPool","_size","arr","globalArrayPool","withPooledArray","size","fn","MapPool","map","SetPool","set","globalMapPool","globalSetPool","calculateLevenshteinDistance","maxDistance","previousRow","currentRow","minInRow","calculateDamerauLevenshteinDistance","maxLen","H","INF","charMap","lastMatchCol","lastMatchRow","result","calculateNgramSimilarity","ngrams1","generateNgrams","ngrams2","set1","set2","intersectionSize","item","unionSize","str","n","count","distanceToSimilarity","distance","maxLength","areStringsSimilar","threshold","Trie","term","docIds","node","id","results","child","data","trie","childData","DEFAULT_BM25_CONFIG","calculateIDF","corpusStats","df","N","idf","calculateTermScore","docStats","tf","docLength","avgDocLength","numerator","denominator","calculateBM25Score","queryTerms","totalScore","buildCorpusStats","documents","totalDocs","totalLength","documentFrequencies","doc","uniqueTerms","normalizeBM25Score","score","maxScore","scaledScore","combineScores","bm25Score","fuzzyScore","bm25Weight","fuzzyWeight","totalWeight","normalizedBM25Weight","normalizedFuzzyWeight","BloomFilter","p","hashes","hash","byteIndex","bitIndex","hash1","hash2","combinedHash","seed","k","m","filter","createBloomFilter","expectedElements","falsePositiveRate","buildInvertedIndex","words","languageProcessors","featureSet","invertedIndex","docId","trimmedWord","phoneticCode","compoundParts","addToPostingList","lowerWord","variant","ngram","normalizedPart","synonym","customSynonyms","documentLengths","posting","bloomFilter","searchInvertedIndex","query","processors","matches","normalizedQuery","findExactMatchesInverted","findPrefixMatchesInverted","findPhoneticMatchesInverted","findSynonymMatchesInverted","findNgramMatchesInverted","findFuzzyMatchesInverted","postings","prefixMatches","ngramSize","queryNgrams","candidateDocs","queryLen","minLen","useTranspositions","datasetSize","MAX_FUZZY_CANDIDATES","candidatesChecked","termsArray","prefixLength","_docIds","entry","a","aDiff","bDiff","termLen","earlyTerminationThreshold","existingMatch","calculateBM25Scores","bm25Config","match","termFrequencies","normalizedTerms","normalizedBM25","calculateHighlights","displayText","highlights","normalizedDisplay","prefixEnd","substringIndex","calculateFuzzyHighlights","calculateNgramHighlights","mergeOverlappingHighlights","type","queryIdx","textIdx","start","end","searchStart","index","sorted","b","merged","last","getMatchTypePriority","formatHighlightedHTML","className","escapeHTML","lastEnd","highlight","highlightedText","div","LRUCache","capacity","key","value","firstKey","SearchCache","maxResults","options","optionsKey","cacheStats","total","hitRate","ACCENT_MAP","accentCache","MAX_CACHE_SIZE","removeAccents","cached","chars","hasAccents","normalizeForComparison","getAccentVariants","extractFieldValues","fields","fieldValues","field","normalizeFieldWeights","fieldWeights","DEFAULT_STOP_WORDS","filterStopWords","stopWords","stopWordsSet","w","filtered","getStopWordsForLanguages","langStopWords","isStopWord","isWordBoundary","position","charBefore","matchesAtWordBoundary","matchStart","matchLength","matchEnd","startBoundary","endBoundary","findWordBoundaryMatches","pattern","caseSensitive","positions","searchText","searchPattern","found","matchesWord","wordBoundaries","parseWildcard","regexPattern","matchesWildcard","parseQuery","phrases","remaining","doubleQuoteRegex","phrase","singleQuoteRegex","terms","t","hasPhraseSyntax","normalizePhrase","splitPhraseWords","DEFAULT_OPTIONS","matchPhrase","opts","normalizedText","normalizedPhrase","exactMatch","findExactPhrase","fuzzyMatch","findFuzzyPhrase","proximityMatch","findProximityMatch","maxEditDistance","phraseWords","textWords","segment","totalDistance","allMatch","maxPossibleDistance","phraseWord","phraseIndex","bestDistance","bestPositions","findBestCombination","wordIndex","currentPositions","pos","detectLanguages","detected","detectLanguagesWithConfidence","confidence","textLength","germanChars","frenchChars","spanishChars","_","conf","primary","sampleTextForDetection","sampleSize","v","isValidLanguage","normalizeLanguageCode","TokenType","FQLLexer","input","quote","upperValue","FQLSyntaxError","message","FQLParser","tokens","ast","left","right","expr","token","filterToken","filterType","operator","types","isTermNode","isPhraseNode","isAndNode","isOrNode","isNotNode","isFilterNode","isFieldNode","isScoreNode","isLangNode","FQLTimeoutError","FQLExecutor","leftResults","rightResults","rightDisplays","r","resultMap","existing","childResults","excludeDisplays","getSuggestions","regex","targetLang","isFQLQuery","trimmed","extractFQLQuery","executeFQLQuery","fqlQuery","limit","error","buildFuzzyIndex","userSpecifiedLanguages","shouldAutoDetect","sampleText","detectedLanguages","hasFields","isObjectArray","processedWords","processed","baseId","fieldName","fieldValue","trimmedValue","processWordWithProcessorAndField","processWordWithProcessor","cacheSize","addToVariantMap","accentFreeWord","normalizedAccentFree","addToVariantMapWithField","_fieldName","batchSearch","queries","uniqueQueries","parsedQuery","searchWithPhrases","processedQuery","getSuggestionsInverted","findExactMatches","findPrefixMatches","findPhoneticMatches","findSynonymMatches","findNgramMatches","findFuzzyMatches","createSuggestionResult","baseWord","exactMatches","queryLower","phoneticMatches","synonymMatches","candidateWords","ngramMatches","originalQuery","calculateMatchScore","wordLen","phraseOptions","phraseMatches","newScore","termMatches","termQuery","combinedResults","phraseData","updateIndex","newItems","existingWords","removeFromIndex","itemsToRemove","toRemove","baseWords","phonetic","serializeIndex","serialized","deserializeIndex","json","variantToBase","phoneticToBase","ngramIndex","langName","saveIndexToLocalStorage","loadIndexFromLocalStorage","getSerializedSize","dataToIndex","content","minLength","splitWords","overlap","chunkSize","splitOn","format","removeNumbers","e","stripHTML","extractFromJSON","chunkText","html","jsonString","extractValues","depth","values","chunks","paragraphs","currentChunk","para","sentences","sentence","dataToIndexAsync","createFuzzySearch","dictionary","VERSION"],"mappings":"oOAUO,MAAMA,EAA8B,CACzC,UAAW,CAAC,SAAS,EACrB,SAAU,CAAC,WAAY,WAAY,WAAY,qBAAsB,gBAAiB,kBAAmB,gBAAiB,gBAAgB,EAC1I,YAAa,WACb,WAAY,GACZ,eAAgB,EAChB,eAAgB,IAChB,gBAAiB,EACjB,UAAW,CACb,EAKaC,EAA4D,CACvE,KAAM,CACJ,YAAa,OACb,SAAU,CAAC,gBAAiB,iBAAiB,EAC7C,gBAAiB,EACjB,eAAgB,GAChB,WAAY,CAAA,EAEd,SAAU,CACR,YAAa,WACb,SAAU,CAAC,WAAY,gBAAiB,kBAAmB,oBAAoB,EAC/E,gBAAiB,EACjB,eAAgB,IAChB,WAAY,CAAA,EAEd,cAAe,CACb,YAAa,gBACb,SAAU,CAAC,WAAY,WAAY,WAAY,qBAAsB,gBAAiB,kBAAmB,gBAAiB,gBAAgB,EAC1I,gBAAiB,EACjB,eAAgB,GAChB,WAAY,EAAA,CAEhB,EAKaC,GAAoD,CAC/D,OAAQ,CAEN,WACA,WACA,WACA,qBACA,gBACA,kBACA,eAAA,EAEF,QAAS,CAEP,WACA,WACA,qBACA,gBACA,kBACA,gBAAA,EAEF,QAAS,CAEP,WACA,WACA,qBACA,gBACA,iBAAA,EAEF,OAAQ,CAEN,WACA,WACA,qBACA,gBACA,iBAAA,CAEJ,EAKO,SAASC,GAAYC,EAAmC,GAAiB,CAC9E,MAAMC,EAAa,CAAE,GAAGL,CAAA,EAGxB,GAAII,EAAW,aAAeA,EAAW,cAAgB,WAAY,CACnE,MAAME,EAAoBL,EAAoBG,EAAW,WAAW,EACpE,OAAO,OAAOC,EAAYC,CAAiB,CAC7C,CAGA,MAAMC,EAAe,CAAE,GAAGF,EAAY,GAAGD,CAAA,EAGzC,GAAI,CAACA,EAAW,UAAYA,EAAW,UAAW,CAChD,MAAMI,MAA0B,IAEhC,UAAWC,KAAQL,EAAW,WACPF,GAAkBO,CAAI,GAAKP,GAAkB,SACrD,QAASQ,GAAYF,EAAoB,IAAIE,CAAO,CAAC,EAGpEH,EAAa,SAAW,MAAM,KAAKC,CAAmB,CACxD,CAEA,OAAOD,CACT,CAKO,SAASI,GAAeC,EAA2B,CACxD,GAAIA,EAAO,WAAa,EACtB,MAAM,IAAI,MAAM,+BAA+B,EAGjD,GAAIA,EAAO,eAAiB,EAC1B,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIA,EAAO,eAAiB,GAAKA,EAAO,eAAiB,EACvD,MAAM,IAAI,MAAM,wCAAwC,EAG1D,GAAIA,EAAO,gBAAkB,EAC3B,MAAM,IAAI,MAAM,sCAAsC,EAGxD,GAAIA,EAAO,UAAY,EACrB,MAAM,IAAI,MAAM,8BAA8B,EAGhD,GAAIA,EAAO,UAAU,SAAW,EAC9B,MAAM,IAAI,MAAM,yCAAyC,CAE7D,CC5IO,MAAeC,CAAmD,CAQvE,UAAUC,EAAsB,CAC9B,OAAOA,EAAK,cAAc,OAAO,QAAQ,OAAQ,GAAG,CACtD,CAKA,gBAAgBC,EAAsB,CAEpC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,SAAW,EAAG,MAAO,GAEpC,IAAIC,EAAOD,EAAW,CAAC,EAAE,YAAA,EACzB,MAAME,EAAuC,CAC3C,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,GAAA,EAGL,QAASC,EAAI,EAAGA,EAAIH,EAAW,QAAUC,EAAK,OAAS,EAAGE,IAAK,CAC7D,MAAMC,EAAOJ,EAAWG,CAAC,EACnBE,EAAQH,EAAaE,CAAI,EAC3BC,GAASA,IAAUJ,EAAKA,EAAK,OAAS,CAAC,IACzCA,GAAQI,EAEZ,CAEA,OAAOJ,EAAK,OAAO,EAAG,GAAG,CAC3B,CAKA,mBAAmBF,EAAwB,CACzC,MAAO,CAACA,CAAI,CACd,CAKA,gBAAgBA,EAAwB,CACtC,MAAMO,MAAe,IACfN,EAAa,KAAK,UAAUD,CAAI,EAEtCO,EAAS,IAAIN,CAAU,EACvBM,EAAS,IAAIP,CAAI,EAGjB,MAAMQ,EAAgB,KAAK,iBAAA,EAC3B,UAAWC,KAAUD,EACfP,EAAW,SAASQ,CAAM,GAAKR,EAAW,OAASQ,EAAO,OAAS,GACrEF,EAAS,IAAIN,EAAW,MAAM,EAAG,CAACQ,EAAO,MAAM,CAAC,EAKpD,GAAIR,EAAW,OAAS,EACtB,QAASG,EAAI,EAAGA,EAAIH,EAAW,OAAQG,IACrCG,EAAS,IAAIN,EAAW,MAAM,EAAGG,CAAC,CAAC,EAIvC,OAAO,MAAM,KAAKG,CAAQ,CAC5B,CAKU,kBAA6B,CACrC,MAAO,CAEL,IACA,KACA,KACA,MACA,KACA,KAAA,CAEJ,CAKA,YAAYG,EAAyB,CACnC,MAAO,CAAA,CACT,CAKA,oBAAoBC,EAAeC,EAAwB,CAEzD,MAAMC,EADoB,KAAK,qBAAA,EACKF,EAAM,YAAA,CAAa,EACvD,OAAOE,EAAYA,EAAU,SAASD,EAAM,YAAA,CAAa,EAAI,EAC/D,CAKU,sBAAiD,CACzD,MAAO,CACL,EAAG,CAAC,IAAK,IAAK,GAAG,EACjB,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,GAAG,EACtB,EAAG,CAAC,IAAK,GAAG,EACZ,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAC1C,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAC1C,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAC1C,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAC1C,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAC1C,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EACrC,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAChC,EAAG,CAAC,IAAK,IAAK,IAAK,GAAG,EACtB,EAAG,CAAC,IAAK,IAAK,GAAG,EACjB,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,GAAG,CAAA,CAE1B,CAKA,eAAeZ,EAAc,EAAY,EAAa,CACpD,MAAMC,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,OAAS,EAAG,MAAO,CAACA,CAAU,EAE7C,MAAMa,EAAmB,CAAA,EACzB,QAASV,EAAI,EAAGA,GAAKH,EAAW,OAAS,EAAGG,IAC1CU,EAAO,KAAKb,EAAW,MAAMG,EAAGA,EAAI,CAAC,CAAC,EAExC,OAAOU,CACT,CAKA,sBAAsBC,EAAcC,EAAsB,CACxD,MAAMC,EAAqB,CAAA,EACrBC,EAAOH,EAAK,OACZI,EAAOH,EAAK,OAGlB,QAASZ,EAAI,EAAGA,GAAKc,EAAMd,IACzBa,EAAOb,CAAC,EAAI,CAACA,CAAC,EAEhB,QAASgB,EAAI,EAAGA,GAAKD,EAAMC,IACzBH,EAAO,CAAC,EAAEG,CAAC,EAAIA,EAIjB,QAAShB,EAAI,EAAGA,GAAKc,EAAMd,IACzB,QAASgB,EAAI,EAAGA,GAAKD,EAAMC,IAAK,CAC9B,MAAMC,EAAON,EAAKX,EAAI,CAAC,IAAMY,EAAKI,EAAI,CAAC,EAAI,EAAI,EAC/CH,EAAOb,CAAC,EAAEgB,CAAC,EAAI,KAAK,IAClBH,EAAOb,EAAI,CAAC,EAAEgB,CAAC,EAAI,EACnBH,EAAOb,CAAC,EAAEgB,EAAI,CAAC,EAAI,EACnBH,EAAOb,EAAI,CAAC,EAAEgB,EAAI,CAAC,EAAIC,CAAA,CAE3B,CAGF,OAAOJ,EAAOC,CAAI,EAAEC,CAAI,CAC1B,CACF,CCjMO,MAAMG,UAAwBxB,CAAsB,CAChD,SAAW,SACX,YAAc,UACd,kBAAoC,CAAC,WAAY,WAAY,WAAY,qBAAsB,gBAAiB,kBAAmB,eAAe,EAK3J,UAAUC,EAAsB,CAC9B,OACEA,EACG,cACA,KAAA,EACA,QAAQ,OAAQ,GAAG,EAEnB,QAAQ,KAAM,IAAI,EAClB,QAAQ,KAAM,IAAI,EAClB,QAAQ,KAAM,IAAI,EAClB,QAAQ,KAAM,IAAI,CAEzB,CAKA,gBAAgBC,EAAsB,CACpC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,SAAW,EAAG,MAAO,GAEpC,IAAIC,EAAO,GACPqB,EAAO,GAEX,QAASnB,EAAI,EAAGA,EAAIH,EAAW,OAAQG,IAAK,CAC1C,MAAMC,EAAOJ,EAAWG,CAAC,EACnBoB,EAAOpB,EAAIH,EAAW,OAAS,EAAIA,EAAWG,EAAI,CAAC,EAAI,GAC7D,IAAIE,EAAQ,GAEZ,OAAQD,EAAA,CACN,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACHC,EAAQ,IACR,MACF,IAAK,IAEH,SACF,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACL,IAAK,IACCkB,IAAS,KAAOA,IAAS,KAAOA,IAAS,IAC3ClB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACL,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACL,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCF,IAAM,EACJoB,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,IAC3IlB,EAAQ,IAERA,EAAQ,IAGNiB,IAAS,KAAOA,IAAS,IAC3BjB,EAAQ,IACCkB,IAAS,KAETA,IAAS,KAAOA,IAAS,IADlClB,EAAQ,IAIRA,EAAQ,IAGZ,MACF,IAAK,IACCiB,IAAS,KAAOA,IAAS,KAAOA,IAAS,IAC3CjB,EAAQ,IAERA,EAAQ,KAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,QACE,QAAA,CAIAA,GAASA,IAAUiB,IACrBrB,GAAQI,GAEViB,EAAOjB,CACT,CAEA,OAAOJ,GAAQ,GACjB,CAMA,mBAAmBF,EAAwB,CACzC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,OAAS,EAAG,MAAO,CAACD,CAAI,EAEvC,MAAMyB,EAAkB,CAAA,EAClBC,EAAiB,KAAK,kBAAA,EACtBC,EAAiB,KAAK,kBAAA,EACtBC,EAAc,KAAK,eAAA,EAGzB,UAAWC,KAAUH,EACnB,GAAIzB,EAAW,WAAW4B,CAAM,GAAK5B,EAAW,OAAS4B,EAAO,OAAS,EAAG,CAC1E,MAAMC,EAAY7B,EAAW,MAAM4B,EAAO,MAAM,EAChDJ,EAAM,KAAKI,CAAM,EACjBJ,EAAM,KAAK,GAAG,KAAK,mBAAmBK,CAAS,CAAC,EAChD,KACF,CAGF,GAAIL,EAAM,SAAW,GAEnB,UAAWM,KAAUJ,EACnB,GAAI1B,EAAW,SAAS8B,CAAM,GAAK9B,EAAW,OAAS8B,EAAO,OAAS,EAAG,CACxE,MAAMD,EAAY7B,EAAW,MAAM,EAAG,CAAC8B,EAAO,MAAM,EACpDN,EAAM,KAAK,GAAG,KAAK,mBAAmBK,CAAS,CAAC,EAChDL,EAAM,KAAKM,CAAM,EACjB,KACF,EAIJ,GAAIN,EAAM,SAAW,EAEnB,QAAS,EAAI,EAAG,GAAKxB,EAAW,OAAS,EAAG,IAAK,CAC/C,MAAM+B,EAAW/B,EAAW,MAAM,EAAG,CAAC,EAChCgC,EAAYhC,EAAW,MAAM,CAAC,EAEpC,GAAI2B,EAAY,IAAII,CAAQ,GAAKC,EAAU,QAAU,EAAG,CACtDR,EAAM,KAAKO,CAAQ,EACnBP,EAAM,KAAK,GAAG,KAAK,mBAAmBQ,CAAS,CAAC,EAChD,KACF,CACF,CAGF,OAAOR,EAAM,OAAS,EAAIA,EAAQ,CAACzB,CAAI,CACzC,CAKA,gBAAgBA,EAAwB,CACtC,MAAMO,MAAe,IACfN,EAAa,KAAK,UAAUD,CAAI,EAEtCO,EAAS,IAAIN,CAAU,EACvBM,EAAS,IAAIP,CAAI,EAGK,KAAK,mBAAmBA,CAAI,EACpC,QAASkC,GAAS3B,EAAS,IAAI,KAAK,UAAU2B,CAAI,CAAC,CAAC,EAGlE,MAAMC,EAAgB,KAAK,iBAAA,EAC3B,UAAW1B,KAAU0B,EACflC,EAAW,SAASQ,CAAM,GAAKR,EAAW,OAASQ,EAAO,OAAS,GACrEF,EAAS,IAAIN,EAAW,MAAM,EAAG,CAACQ,EAAO,MAAM,CAAC,EAKpD,GAAIR,EAAW,OAAS,EACtB,QAASG,EAAI,EAAGA,EAAIH,EAAW,OAAQG,IACrCG,EAAS,IAAIN,EAAW,MAAM,EAAGG,CAAC,CAAC,EAIvC,OAAO,MAAM,KAAKG,CAAQ,CAC5B,CAKU,kBAA6B,CACrC,MAAO,CAEL,KACA,IACA,KACA,IACA,IACA,IACA,KACA,IACA,MACA,OACA,OACA,SACA,OACA,OACA,OACA,KACA,OACA,MACA,MACA,MAAA,CAEJ,CAKA,YAAYP,EAAwB,CAClC,MAAMoC,EAAuC,CAC3C,KAAM,CAEJ,SACA,YACA,KAAA,EAEF,YAAa,CAEX,SACA,SACA,UAAA,EAEF,OAAQ,CAEN,sBACA,aAAA,EAEF,KAAM,CAEJ,QACA,WACA,KAAA,EAEF,KAAM,CAEJ,WACA,OACA,UAAA,EAEF,QAAS,CAEP,MACA,QACA,OAAA,EAEF,MAAO,CAEL,MACA,WACA,WAAA,EAEF,OAAQ,CAEN,MACA,QACA,YAAA,EAEF,KAAM,CAEJ,WACA,UACA,UAAA,EAEF,KAAM,CAEJ,QACA,UACA,UAAA,CACF,EAGInC,EAAa,KAAK,UAAUD,CAAI,EACtC,OAAOoC,EAAWnC,CAAU,GAAK,CAAA,CACnC,CAKU,sBAAiD,CACzD,MAAO,CACL,EAAG,CAED,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IAAA,EAEF,EAAG,CAED,IACA,KACA,IACA,IAAA,EAEF,GAAI,CAEF,IACA,IAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IAAA,EAEF,GAAI,CAEF,IACA,IACA,KACA,IACA,IAAA,EAEF,GAAI,CAEF,KACA,IAAA,EAEF,EAAG,CAED,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,GAAA,CACF,CAEJ,CAKQ,mBAA8B,CACpC,MAAO,CAAC,KAAM,MAAO,OAAQ,MAAO,MAAO,KAAM,KAAM,MAAO,MAAO,MAAO,QAAS,SAAU,QAAS,QAAS,QAAS,WAAY,QAAQ,CAChJ,CAKQ,mBAA8B,CACpC,MAAO,CAAC,OAAQ,QAAS,UAAW,MAAO,MAAO,OAAQ,MAAO,OAAQ,QAAS,OAAQ,OAAQ,OAAQ,MAAO,SAAU,SAAS,CACtI,CAKQ,gBAA8B,CACpC,OAAO,IAAI,IAAI,CAAC,UAAW,SAAU,SAAU,UAAW,MAAO,MAAO,QAAS,QAAS,OAAQ,OAAQ,OAAQ,OAAQ,QAAS,SAAU,OAAQ,QAAS,QAAS,UAAW,UAAW,UAAW,QAAS,OAAQ,OAAQ,OAAQ,OAAQ,MAAO,MAAO,OAAQ,SAAU,MAAO,QAAS,SAAU,QAAS,OAAQ,OAAQ,QAAS,WAAY,QAAS,OAAQ,MAAO,QAAS,SAAU,QAAS,SAAU,OAAQ,OAAQ,OAAO,CAAC,CACjb,CACF,CC/jBO,MAAMoC,UAAyBvC,CAAsB,CACjD,SAAW,UACX,YAAc,UACd,kBAAoC,CAE3C,WACA,WACA,qBACA,gBACA,kBACA,gBACA,gBAAA,EAMF,UAAUC,EAAsB,CAC9B,OACEA,EACG,YAAA,EACA,OACA,QAAQ,OAAQ,GAAG,EAEnB,QAAQ,SAAU,UAAU,EAC5B,QAAQ,SAAU,QAAQ,EAC1B,QAAQ,OAAQ,MAAM,EACtB,QAAQ,OAAQ,MAAM,EACtB,QAAQ,OAAQ,OAAO,EACvB,QAAQ,OAAQ,OAAO,EACvB,QAAQ,MAAO,QAAQ,EACvB,QAAQ,MAAO,KAAK,EACpB,QAAQ,KAAM,EAAE,CAEvB,CAKA,gBAAgBC,EAAsB,CACpC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EAAE,QAAQ,UAAW,EAAE,EAC7D,GAAIC,EAAW,SAAW,EAAG,MAAO,GAEpC,IAAIqC,EAAY,GACZC,EAAU,EACd,MAAMC,EAASvC,EAAW,OAO1B,KAJIA,EAAW,WAAW,IAAI,GAAKA,EAAW,WAAW,IAAI,GAAKA,EAAW,WAAW,IAAI,GAAKA,EAAW,WAAW,IAAI,KACzHsC,EAAU,GAGLA,EAAUC,GAAUF,EAAU,OAAS,GAAG,CAC/C,MAAMjC,EAAOJ,EAAWsC,CAAO,EACzBf,EAAOe,EAAU,EAAIC,EAASvC,EAAWsC,EAAU,CAAC,EAAI,GACxDhB,EAAOgB,EAAU,EAAItC,EAAWsC,EAAU,CAAC,EAAI,GAErD,OAAQlC,EAAA,CACN,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACCkC,IAAY,IAAGD,GAAajC,EAAK,YAAA,GACrC,MACF,IAAK,IACCkC,IAAYC,EAAS,GAAKjB,IAAS,MAGrCe,GAAa,KAEf,MACF,IAAK,IACCd,IAAS,KACXc,GAAa,IACbC,KACSf,IAAS,KAAOA,IAAS,KAAOA,IAAS,IAClDc,GAAa,IAEbA,GAAa,IAEf,MACF,IAAK,IACCd,IAAS,KACXc,GAAa,IACbC,KAEAD,GAAa,IAEf,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACCd,IAAS,KAAOe,IAAY,IAErBf,IAAS,KAClBc,GAAa,IACbC,KACSf,IAAS,KAAOA,IAAS,KAAOA,IAAS,IAClDc,GAAa,IAEbA,GAAa,KAEf,MACF,IAAK,KACCC,IAAY,GAAK,QAAQ,SAAShB,CAAI,GAAK,QAAQ,SAASC,CAAI,KAClEc,GAAa,KAEf,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACCf,IAAS,MACXe,GAAa,KAEf,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACCd,IAAS,KACXc,GAAa,IACbC,KAEAD,GAAa,IAEf,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACCd,IAAS,KACXc,GAAa,IACbC,KAEAD,GAAa,IAEf,MACF,IAAK,IACCd,IAAS,KACXc,GAAa,IACbC,KACSf,IAAS,KAAOe,EAAU,EAAIC,IAAWvC,EAAWsC,EAAU,CAAC,IAAM,KAAOtC,EAAWsC,EAAU,CAAC,IAAM,KACjHD,GAAa,IAEbA,GAAa,IAEf,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACC,QAAQ,SAASd,CAAI,IACvBc,GAAa,KAEf,MACF,IAAK,IACHA,GAAa,KACb,MACF,IAAK,IACC,QAAQ,SAASd,CAAI,IACvBc,GAAa,KAEf,MACF,IAAK,IACHA,GAAa,IACb,KAAA,CAEJC,GACF,CAEA,OAAOD,GAAa,GACtB,CAKA,gBAAgBtC,EAAwB,CACtC,MAAMO,MAAe,IACfN,EAAa,KAAK,UAAUD,CAAI,EAEtCO,EAAS,IAAIN,CAAU,EACvBM,EAAS,IAAIP,CAAI,EAGjB,MAAMyC,EAAiB,KAAK,iBAAA,EAC5B,UAAWhC,KAAUgC,EACfxC,EAAW,SAASQ,CAAM,GAAKR,EAAW,OAASQ,EAAO,OAAS,GACrEF,EAAS,IAAIN,EAAW,MAAM,EAAG,CAACQ,EAAO,MAAM,CAAC,EAapD,GARIR,EAAW,SAAS,GAAG,GAAKA,EAAW,OAAS,GAClDM,EAAS,IAAIN,EAAW,MAAM,EAAG,EAAE,CAAC,EAEjCA,EAAW,SAAS,GAAG,GAC1BM,EAAS,IAAIN,EAAa,GAAG,EAI3BA,EAAW,SAAS,KAAK,GAAKA,EAAW,OAAS,EAAG,CACvD,MAAMyC,EAAOzC,EAAW,MAAM,EAAG,EAAE,EACnCM,EAAS,IAAImC,CAAI,EACjBnC,EAAS,IAAImC,EAAO,GAAG,CACzB,CACA,GAAIzC,EAAW,SAAS,IAAI,GAAKA,EAAW,OAAS,EAAG,CACtD,MAAMyC,EAAOzC,EAAW,MAAM,EAAG,EAAE,EACnCM,EAAS,IAAImC,CAAI,EACjBnC,EAAS,IAAImC,EAAO,GAAG,CACzB,CAGA,GAAIzC,EAAW,OAAS,EACtB,QAASG,EAAI,EAAGA,EAAIH,EAAW,OAAQG,IACrCG,EAAS,IAAIN,EAAW,MAAM,EAAGG,CAAC,CAAC,EAIvC,OAAO,MAAM,KAAKG,CAAQ,CAC5B,CAKU,kBAA6B,CACrC,MAAO,CAEL,IACA,KACA,KACA,MACA,KACA,MACA,KACA,OACA,OACA,OACA,OACA,OACA,OACA,MACA,OACA,MACA,OACA,KACA,MACA,KACA,MACA,MACA,MACA,KAAA,CAEJ,CAKA,YAAYP,EAAwB,CAClC,MAAMoC,EAAuC,CAC3C,OAAQ,CAEN,YACA,QACA,MACA,IAAA,EAEF,SAAU,CAER,SACA,iBACA,WAAA,EAEF,OAAQ,CAEN,UACA,cACA,UACA,YAAA,EAEF,IAAK,CAEH,UACA,aACA,MAAA,EAEF,MAAO,CAEL,OACA,YACA,WACA,UAAA,EAEF,OAAQ,CAEN,OACA,SACA,OACA,WAAA,EAEF,KAAM,CAEJ,OACA,eACA,YAAA,EAEF,KAAM,CAEJ,MACA,aACA,aACA,QAAA,EAEF,MAAO,CAEL,OACA,WACA,QACA,SAAA,EAEF,KAAM,CAEJ,WACA,SACA,SACA,MAAA,EAEF,IAAK,CAEH,QACA,OACA,WACA,UACA,OAAA,EAEF,MAAO,CAEL,SACA,OACA,YACA,QAAA,EAEF,KAAM,CAEJ,QACA,QACA,SACA,OAAA,EAEF,KAAM,CAEJ,WACA,UACA,WAAA,EAEF,KAAM,CAEJ,YACA,QACA,YACA,MAAA,EAEF,IAAK,CAEH,OACA,WACA,QACA,UAAA,EAEF,MAAO,CAEL,SACA,WACA,OACA,SAAA,EAEF,IAAK,CAEH,UACA,YACA,aACA,WAAA,CACF,EAGInC,EAAa,KAAK,UAAUD,CAAI,EACtC,OAAOoC,EAAWnC,CAAU,GAAK,CAAA,CACnC,CACF,CC/YO,MAAM0C,UAAyB7C,CAAsB,CACjD,SAAW,UACX,YAAc,UACd,kBAAoC,CAE3C,WACA,WACA,qBACA,gBACA,kBACA,eAAA,EAMF,UAAUC,EAAsB,CAC9B,OACEA,EACG,YAAA,EACA,KAAA,EACA,QAAQ,OAAQ,GAAG,EAEnB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,CAExB,CAKA,gBAAgBC,EAAsB,CACpC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,SAAW,EAAG,MAAO,GAEpC,IAAIC,EAAO,GACPqB,EAAO,GAEX,QAASnB,EAAI,EAAGA,EAAIH,EAAW,OAAQG,IAAK,CAC1C,MAAMC,EAAOJ,EAAWG,CAAC,EACnBoB,EAAOpB,EAAIH,EAAW,OAAS,EAAIA,EAAWG,EAAI,CAAC,EAAI,GAC7D,IAAIE,EAAQ,GAEZ,OAAQD,EAAA,CACN,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACHC,EAAQ,IACR,MACF,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCkB,IAAS,IACXlB,EAAQ,IACCkB,IAAS,KAAOA,IAAS,IAClClB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCkB,IAAS,KAAOpB,EAAI,EAAIH,EAAW,SAAWA,EAAWG,EAAI,CAAC,IAAM,KAAOH,EAAWG,EAAI,CAAC,IAAM,KACnGE,EAAQ,IACCkB,IAAS,KAAOA,IAAS,IAClClB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IAEH,SACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCkB,IAAS,IACXlB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCkB,IAAS,IACXlB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCkB,IAAS,KAAOpB,IAAM,EACxBE,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,KACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,QACE,QAAA,CAGAA,GAASA,IAAUiB,IACrBrB,GAAQI,GAEViB,EAAOjB,CACT,CAEA,OAAOJ,GAAQ,GACjB,CAKU,kBAA6B,CACrC,MAAO,CAEL,IACA,IACA,KACA,KACA,IACA,KACA,KACA,KACA,KACA,MACA,MACA,OACA,OACA,OACA,OACA,QACA,OACA,OACA,MACA,MACA,QACA,MACA,MACA,MACA,MACA,OACA,MAAA,CAEJ,CAKA,YAAYF,EAAwB,CAClC,MAAMoC,EAAuC,CAC3C,OAAQ,CAEN,SACA,aAAA,EAEF,SAAU,CAER,UACA,WAAA,EAEF,QAAS,CAEP,UACA,WAAA,EAEF,MAAO,CAEL,OACA,YACA,UAAA,EAEF,KAAM,CAEJ,QACA,WACA,WAAA,EAEF,MAAO,CAEL,MACA,UACA,WAAA,EAEF,OAAQ,CAEN,OACA,YACA,WAAA,EAEF,QAAS,CAEP,SACA,YACA,OAAA,EAEF,OAAQ,CAEN,QACA,WACA,SAAA,EAEF,OAAQ,CAEN,UACA,UACA,UAAA,EAEF,OAAQ,CAEN,SACA,UACA,SAAA,EAEF,QAAS,CAEP,QACA,WACA,WAAA,EAEF,OAAQ,CAEN,QACA,SACA,WAAA,EAEF,MAAO,CAEL,WACA,SAAA,EAEF,MAAO,CAEL,YACA,YACA,WAAA,EAEF,KAAM,CAEJ,SACA,WACA,UAAA,CACF,EAGInC,EAAa,KAAK,UAAUD,CAAI,EACtC,OAAOoC,EAAWnC,CAAU,GAAK,CAAA,CACnC,CACF,CCvSO,MAAM2C,UAAwB9C,CAAsB,CAChD,SAAW,SACX,YAAc,WACd,kBAAoC,CAE3C,WACA,WACA,qBACA,gBACA,kBACA,eAAA,EAMF,UAAUC,EAAsB,CAC9B,OACEA,EACG,cACA,KAAA,EACA,QAAQ,OAAQ,GAAG,EAEnB,QAAQ,WAAY,GAAG,EACvB,QAAQ,UAAW,GAAG,EACtB,QAAQ,UAAW,GAAG,EACtB,QAAQ,WAAY,GAAG,EACvB,QAAQ,UAAW,GAAG,EACtB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,CAExB,CAKA,gBAAgBC,EAAsB,CACpC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,SAAW,EAAG,MAAO,GAEpC,IAAIC,EAAO,GACPqB,EAAO,GAEX,QAASnB,EAAI,EAAGA,EAAIH,EAAW,OAAQG,IAAK,CAC1C,MAAMC,EAAOJ,EAAWG,CAAC,EACnBoB,EAAOpB,EAAIH,EAAW,OAAS,EAAIA,EAAWG,EAAI,CAAC,EAAI,GACvDyC,EAAQzC,EAAIH,EAAW,OAAS,EAAIA,EAAWG,EAAI,CAAC,EAAI,GAC9D,IAAIE,EAAQ,GAEZ,OAAQD,EAAA,CACN,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACHC,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCkB,IAAS,IACXlB,EAAQ,IACCkB,IAAS,KAAOA,IAAS,IAClClB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCkB,IAAS,IACXlB,EAAQ,IACCkB,IAAS,MAAQqB,IAAU,KAAOA,IAAU,KACrDvC,EAAQ,IACCkB,IAAS,KAAOA,IAAS,IAClClB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IAECF,IAAM,IACRE,EAAQ,KAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCkB,IAAS,IACXlB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IAEDA,EAAQ,IAIV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,KACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,QACE,QAAA,CAGAA,GAASA,IAAUiB,IACrBrB,GAAQI,GAEViB,EAAOjB,CACT,CAEA,OAAOJ,GAAQ,GACjB,CAKU,kBAA6B,CACrC,MAAO,CAAC,IAAK,KAAM,IAAK,IAAK,MAAO,MAAO,OAAQ,OAAQ,OAAQ,MAAO,OAAQ,OAAQ,QAAS,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,MAAO,OAAQ,OAAQ,MAAO,MAAO,KAAK,CAC/N,CAKA,YAAYF,EAAwB,CAClC,MAAMoC,EAAuC,CAC3C,QAAS,CAEP,UACA,WAAA,EAEF,QAAS,CAEP,WACA,gBAAA,EAEF,MAAO,CAEL,gBACA,aAAA,EAEF,QAAS,CAEP,aACA,WACA,MAAA,EAEF,OAAQ,CAEN,WACA,YACA,YAAA,EAEF,IAAK,CAEH,SACA,YACA,MAAA,EAEF,MAAO,CAEL,OACA,UACA,eAAA,EAEF,QAAS,CAEP,SACA,aACA,QAAA,EAEF,OAAQ,CAEN,UACA,UACA,SAAA,EAEF,MAAO,CAEL,QACA,UACA,QAAA,EAEF,MAAO,CAEL,SACA,UACA,aAAA,EAEF,MAAO,CAEL,YACA,SACA,QAAA,EAEF,OAAQ,CAEN,OACA,WACA,QAAA,EAEF,KAAM,CAEJ,YACA,WAAA,EAEF,IAAK,CAEH,YACA,UACA,YAAA,EAEF,QAAS,CAEP,WACA,UACA,UAAA,EAEF,QAAS,CAEP,SACA,UACA,MAAA,EAEF,OAAQ,CAEN,aACA,WACA,cAAA,CACF,EAGInC,EAAa,KAAK,UAAUD,CAAI,EACtC,OAAOoC,EAAWnC,CAAU,GAAK,CAAA,CACnC,CAKU,sBAAiD,CACzD,MAAO,CACL,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,GAAA,CACF,CAEJ,CACF,CC9fO,MAAM6C,CAAiB,CAC5B,OAAe,WAAa,IAAI,IAA+B,CAC7D,CAAC,SAAU,IAAIxB,CAAiB,EAChC,CAAC,UAAW,IAAIe,CAAkB,EAClC,CAAC,UAAW,IAAIM,CAAkB,EAClC,CAAC,SAAU,IAAIC,CAAiB,CAAA,CACjC,EAKD,OAAO,aAAaG,EAAiD,CACnE,OAAO,KAAK,WAAW,IAAIA,EAAS,aAAa,CACnD,CAKA,OAAO,cAAcC,EAA0C,CAC7D,OAAOA,EAAU,IAAKtD,GAAS,KAAK,aAAaA,CAAI,CAAC,EAAE,OAAQuD,GAA8CA,IAAc,MAAS,CACvI,CAKA,OAAO,uBAAkC,CACvC,OAAO,MAAM,KAAK,KAAK,WAAW,MAAM,CAC1C,CAKA,OAAO,kBAAkBA,EAAoC,CAC3D,KAAK,WAAW,IAAIA,EAAU,SAAS,YAAA,EAAeA,CAAS,CACjE,CAKA,OAAO,YAAYF,EAA2B,CAC5C,OAAO,KAAK,WAAW,IAAIA,EAAS,aAAa,CACnD,CAKA,OAAO,kBAIJ,CACD,OAAO,MAAM,KAAK,KAAK,WAAW,QAAQ,EAAE,IAAKE,IAAe,CAC9D,SAAUA,EAAU,SACpB,YAAaA,EAAU,YACvB,kBAAmBA,EAAU,iBAAA,EAC7B,CACJ,CACF,0NCzDO,MAAMC,EAAc,CACjB,KAAY,CAAA,EACZ,QACA,MACA,QAER,YAAYC,EAAkBC,EAAkB,IAAMC,EAA0B,CAC9E,KAAK,QAAUF,EACf,KAAK,QAAUC,EACf,KAAK,MAAQC,CACf,CAKA,SAAa,CACX,MAAMC,EAAM,KAAK,KAAK,IAAA,EACtB,OAAIA,IAAQ,OACHA,EAEF,KAAK,QAAA,CACd,CAKA,QAAQA,EAAc,CAChB,KAAK,KAAK,OAAS,KAAK,UACtB,KAAK,OACP,KAAK,MAAMA,CAAG,EAEhB,KAAK,KAAK,KAAKA,CAAG,EAEtB,CAKA,OAAc,CACZ,KAAK,KAAO,CAAA,CACd,CAKA,MAAe,CACb,OAAO,KAAK,KAAK,MACnB,CACF,CAOO,MAAMC,EAAa,CAChB,KAAc,CAAA,EACd,QAER,YAAYH,EAAkB,IAAM,CAClC,KAAK,QAAUA,CACjB,CAKA,QAAQI,EAAqB,CAC3B,OAAI,KAAK,KAAK,OAAS,EACd,KAAK,KAAK,IAAA,EAEZ,CAAA,CACT,CAKA,QAAQC,EAAgB,CAClB,KAAK,KAAK,OAAS,KAAK,UAE1BA,EAAI,OAAS,EACb,KAAK,KAAK,KAAKA,CAAG,EAEtB,CAKA,OAAc,CACZ,KAAK,KAAO,CAAA,CACd,CAKA,MAAe,CACb,OAAO,KAAK,KAAK,MACnB,CACF,CAKO,MAAMC,EAAkB,IAAIH,GAAe,GAAG,EAK9C,SAASI,GACdC,EACAC,EACG,CACH,MAAMJ,EAAMC,EAAgB,QAAQE,CAAI,EACxC,GAAI,CACF,OAAOC,EAAGJ,CAAG,CACf,QAAA,CACEC,EAAgB,QAAQD,CAAG,CAC7B,CACF,CAKO,MAAMK,EAAc,CACjB,KAAoB,CAAA,EACpB,QAER,YAAYV,EAAkB,IAAK,CACjC,KAAK,QAAUA,CACjB,CAKA,SAAqB,CACnB,MAAMW,EAAM,KAAK,KAAK,IAAA,EACtB,OAAIA,IAAQ,OACHA,MAEE,GACb,CAKA,QAAQA,EAAsB,CACxB,KAAK,KAAK,OAAS,KAAK,UAC1BA,EAAI,MAAA,EACJ,KAAK,KAAK,KAAKA,CAAG,EAEtB,CAKA,OAAc,CACZ,KAAK,KAAO,CAAA,CACd,CAKA,MAAe,CACb,OAAO,KAAK,KAAK,MACnB,CACF,CAKO,MAAMC,EAAW,CACd,KAAiB,CAAA,EACjB,QAER,YAAYZ,EAAkB,IAAK,CACjC,KAAK,QAAUA,CACjB,CAKA,SAAkB,CAChB,MAAMa,EAAM,KAAK,KAAK,IAAA,EACtB,OAAIA,IAAQ,OACHA,MAEE,GACb,CAKA,QAAQA,EAAmB,CACrB,KAAK,KAAK,OAAS,KAAK,UAC1BA,EAAI,MAAA,EACJ,KAAK,KAAK,KAAKA,CAAG,EAEtB,CAKA,OAAc,CACZ,KAAK,KAAO,CAAA,CACd,CAKA,MAAe,CACb,OAAO,KAAK,KAAK,MACnB,CACF,CAKO,MAAMC,GAAgB,IAAIJ,GAAkB,GAAG,EACzCK,GAAgB,IAAIH,GAAa,GAAG,EC1M1C,SAASI,EAEdrD,EACAC,EACAqD,EAAsB,IACd,CACR,MAAMnD,EAAOH,EAAK,OACZI,EAAOH,EAAK,OAGlB,GAAI,KAAK,IAAIE,EAAOC,CAAI,EAAIkD,EAC1B,OAAOA,EAAc,EAGvB,GAAInD,IAAS,EAAG,OAAOC,EACvB,GAAIA,IAAS,EAAG,OAAOD,EACvB,GAAIH,IAASC,EAAM,MAAO,GAG1B,MAAMsD,EAAcZ,EAAgB,QAAQvC,EAAO,CAAC,EAC9CoD,EAAab,EAAgB,QAAQvC,EAAO,CAAC,EAEnD,GAAI,CAEF,QAASC,EAAI,EAAGA,GAAKD,EAAMC,IACzBkD,EAAYlD,CAAC,EAAIA,EAGnB,QAAS,EAAI,EAAG,GAAKF,EAAM,IAAK,CAC9BqD,EAAW,CAAC,EAAI,EAChB,IAAIC,EAAW,EAEf,QAASpD,EAAI,EAAGA,GAAKD,EAAMC,IAAK,CAC9B,MAAMC,EAAON,EAAK,EAAI,CAAC,IAAMC,EAAKI,EAAI,CAAC,EAAI,EAAI,EAE/CmD,EAAWnD,CAAC,EAAI,KAAK,IACnBmD,EAAWnD,EAAI,CAAC,EAAI,EACpBkD,EAAYlD,CAAC,EAAI,EACjBkD,EAAYlD,EAAI,CAAC,EAAIC,CAAA,EAGvBmD,EAAW,KAAK,IAAIA,EAAUD,EAAWnD,CAAC,CAAC,CAC7C,CAGA,GAAIoD,EAAWH,EACb,OAAOA,EAAc,EAIvB,QAASjD,EAAI,EAAGA,GAAKD,EAAMC,IACzBkD,EAAYlD,CAAC,EAAImD,EAAWnD,CAAC,CAEjC,CAEA,OAAOkD,EAAYnD,CAAI,CACzB,QAAA,CAEEuC,EAAgB,QAAQY,CAAW,EACnCZ,EAAgB,QAAQa,CAAU,CACpC,CACF,CAMO,SAASE,EAAoC1D,EAAcC,EAAcqD,EAAsB,IAAkB,CACtH,MAAMnD,EAAOH,EAAK,OACZI,EAAOH,EAAK,OAElB,GAAI,KAAK,IAAIE,EAAOC,CAAI,EAAIkD,EAC1B,OAAOA,EAAc,EAGvB,GAAInD,IAAS,EAAG,OAAOC,EACvB,GAAIA,IAAS,EAAG,OAAOD,EACvB,GAAIH,IAASC,EAAM,MAAO,GAE1B,MAAM0D,EAAS,KAAK,IAAIxD,EAAMC,CAAI,EAC5BwD,EAAgB,CAAA,EAChBC,EAAMF,EAAS,EAGrB,QAAStE,EAAI,EAAGA,GAAKc,EAAO,EAAGd,IAC7BuE,EAAEvE,CAAC,EAAI,IAAI,MAAMe,EAAO,CAAC,EAAE,KAAKyD,CAAG,EAGrCD,EAAE,CAAC,EAAE,CAAC,EAAIC,EACV,QAASxE,EAAI,EAAGA,GAAKc,EAAMd,IACzBuE,EAAEvE,EAAI,CAAC,EAAE,CAAC,EAAIwE,EACdD,EAAEvE,EAAI,CAAC,EAAE,CAAC,EAAIA,EAEhB,QAASgB,EAAI,EAAGA,GAAKD,EAAMC,IACzBuD,EAAE,CAAC,EAAEvD,EAAI,CAAC,EAAIwD,EACdD,EAAE,CAAC,EAAEvD,EAAI,CAAC,EAAIA,EAGhB,MAAMyD,MAAc,IAEpB,QAASzE,EAAI,EAAGA,GAAKc,EAAMd,IAAK,CAC9B,IAAI0E,EAAe,EAEnB,QAAS1D,EAAI,EAAGA,GAAKD,EAAMC,IAAK,CAC9B,MAAMT,EAAQI,EAAKX,EAAI,CAAC,EAClBQ,EAAQI,EAAKI,EAAI,CAAC,EAClB2D,EAAeF,EAAQ,IAAIjE,CAAK,GAAK,EAE3C,IAAIS,EAAO,EACPV,IAAUC,IACZS,EAAO,EACPyD,EAAe1D,GAGjBuD,EAAEvE,EAAI,CAAC,EAAEgB,EAAI,CAAC,EAAI,KAAK,IACrBuD,EAAEvE,CAAC,EAAEgB,CAAC,EAAIC,EACVsD,EAAEvE,EAAI,CAAC,EAAEgB,CAAC,EAAI,EACduD,EAAEvE,CAAC,EAAEgB,EAAI,CAAC,EAAI,EACduD,EAAEI,CAAY,EAAED,CAAY,GAAK1E,EAAI2E,EAAe,GAAK,GAAK3D,EAAI0D,EAAe,EAAA,CAErF,CAEAD,EAAQ,IAAI9D,EAAKX,EAAI,CAAC,EAAGA,CAAC,CAC5B,CAEA,MAAM4E,EAASL,EAAEzD,EAAO,CAAC,EAAEC,EAAO,CAAC,EACnC,OAAO6D,EAASX,EAAcA,EAAc,EAAIW,CAClD,CAkBO,SAASC,EAAyBlE,EAAcC,EAAc,EAAY,EAAW,CAC1F,GAAID,IAASC,EAAM,MAAO,GAC1B,GAAID,EAAK,SAAW,GAAKC,EAAK,SAAW,EAAG,MAAO,GAEnD,MAAMkE,EAAUC,EAAepE,EAAM,CAAC,EAChCqE,EAAUD,EAAenE,EAAM,CAAC,EAEtC,GAAIkE,EAAQ,SAAW,GAAKE,EAAQ,SAAW,EAAG,MAAO,GACzD,GAAIF,EAAQ,SAAW,GAAKE,EAAQ,SAAW,EAAG,MAAO,GAEzD,MAAMC,EAAO,IAAI,IAAIH,CAAO,EACtBI,EAAO,IAAI,IAAIF,CAAO,EAG5B,IAAIG,EAAmB,EACvB,UAAWC,KAAQH,EACbC,EAAK,IAAIE,CAAI,GACfD,IAKJ,MAAME,EAAYJ,EAAK,KAAOC,EAAK,KAAOC,EAE1C,OAAOE,EAAY,EAAIF,EAAmBE,EAAY,CACxD,CAgBO,SAASN,EAAeO,EAAaC,EAAqB,CAC/D,GAAID,EAAI,OAASC,EAAG,MAAO,CAACD,CAAG,EAG/B,MAAME,EAAQF,EAAI,OAASC,EAAI,EACzB7E,EAAmB,IAAI,MAAM8E,CAAK,EAExC,QAASxF,EAAI,EAAGA,EAAIwF,EAAOxF,IACzBU,EAAOV,CAAC,EAAIsF,EAAI,MAAMtF,EAAGA,EAAIuF,CAAC,EAGhC,OAAO7E,CACT,CAeO,SAAS+E,GAAqBC,EAAkBC,EAA2B,CAChF,OAAIA,IAAc,EAAUD,IAAa,EAAI,EAAM,EAC5C,KAAK,IAAI,EAAG,EAAIA,EAAWC,CAAS,CAC7C,CAkBO,SAASC,GAAkBjF,EAAcC,EAAciF,EAAoB,GAAK5B,EAAsB,EAAY,CAEvH,GAAItD,IAASC,EAAM,MAAO,GAG1B,MAAM0D,EAAS,KAAK,IAAI3D,EAAK,OAAQC,EAAK,MAAM,EAKhD,GAJI,KAAK,IAAID,EAAK,OAASC,EAAK,MAAM,EAAIqD,GAGzBY,EAAyBlE,EAAMC,CAAI,EACrCiF,EAAY,GAAK,MAAO,GAGvC,MAAMH,EAAW1B,EAA6BrD,EAAMC,EAAMqD,CAAW,EAGrE,OAFmBwB,GAAqBC,EAAUpB,CAAM,GAEnCuB,CACvB,CCvQO,MAAMC,CAAK,CACR,KACA,KAER,aAAc,CACZ,KAAK,KAAO,KAAK,WAAA,EACjB,KAAK,KAAO,CACd,CAEQ,YAAuB,CAC7B,MAAO,CACL,aAAc,IACd,YAAa,GACb,WAAY,GAAI,CAEpB,CAKA,OAAOC,EAAcC,EAAwB,CAC3C,GAAI,CAACD,EAAM,OAEX,IAAIE,EAAO,KAAK,KAEhB,UAAWhG,KAAQ8F,EACZE,EAAK,SAAS,IAAIhG,CAAI,GACzBgG,EAAK,SAAS,IAAIhG,EAAM,KAAK,YAAY,EAE3CgG,EAAOA,EAAK,SAAS,IAAIhG,CAAI,EAG/BgG,EAAK,YAAc,GACnBA,EAAK,KAAOF,EACZC,EAAO,QAAQE,GAAMD,EAAK,OAAO,IAAIC,CAAE,CAAC,EACxC,KAAK,MACP,CAMA,eAAezE,EAA2C,CACxD,GAAI,CAACA,EAAQ,MAAO,CAAA,EAGpB,IAAIwE,EAAO,KAAK,KAChB,UAAWhG,KAAQwB,EAAQ,CACzB,GAAI,CAACwE,EAAK,SAAS,IAAIhG,CAAI,EACzB,MAAO,CAAA,EAETgG,EAAOA,EAAK,SAAS,IAAIhG,CAAI,CAC/B,CAGA,MAAMkG,EAAqC,CAAA,EAC3C,YAAK,aAAaF,EAAME,CAAO,EACxBA,CACT,CAKA,IAAIJ,EAAuB,CACzB,IAAIE,EAAO,KAAK,KAChB,UAAWhG,KAAQ8F,EAAM,CACvB,GAAI,CAACE,EAAK,SAAS,IAAIhG,CAAI,EACzB,MAAO,GAETgG,EAAOA,EAAK,SAAS,IAAIhG,CAAI,CAC/B,CACA,OAAOgG,EAAK,WACd,CAKA,IAAIF,EAA+B,CACjC,IAAIE,EAAO,KAAK,KAChB,UAAWhG,KAAQ8F,EAAM,CACvB,GAAI,CAACE,EAAK,SAAS,IAAIhG,CAAI,EACzB,OAAO,KAETgG,EAAOA,EAAK,SAAS,IAAIhG,CAAI,CAC/B,CACA,OAAOgG,EAAK,YAAc,MAAM,KAAKA,EAAK,MAAM,EAAI,IACtD,CAKQ,aAAaA,EAAgBE,EAA0C,CACzEF,EAAK,aAAeA,EAAK,MAC3BE,EAAQ,KAAK,CAACF,EAAK,KAAM,MAAM,KAAKA,EAAK,MAAM,CAAC,CAAC,EAGnD,UAAWG,KAASH,EAAK,SAAS,OAAA,EAChC,KAAK,aAAaG,EAAOD,CAAO,CAEpC,CAKA,SAAkB,CAChB,OAAO,KAAK,IACd,CAKA,OAAc,CACZ,KAAK,KAAO,KAAK,WAAA,EACjB,KAAK,KAAO,CACd,CAKA,QAAc,CACZ,MAAO,CACL,KAAM,KAAK,cAAc,KAAK,IAAI,EAClC,KAAM,KAAK,IAAA,CAEf,CAKA,OAAO,SAASE,EAAiB,CAC/B,MAAMC,EAAO,IAAIR,EACjB,OAAAQ,EAAK,KAAOR,EAAK,gBAAgBO,EAAK,IAAI,EAC1CC,EAAK,KAAOD,EAAK,KACVC,CACT,CAEQ,cAAcL,EAAqB,CACzC,MAAO,CACL,SAAU,MAAM,KAAKA,EAAK,SAAS,SAAS,EAAE,IAAI,CAAC,CAAChG,EAAMmG,CAAK,IAAM,CACnEnG,EACA,KAAK,cAAcmG,CAAK,CAAA,CACzB,EACD,YAAaH,EAAK,YAClB,OAAQ,MAAM,KAAKA,EAAK,MAAM,EAC9B,KAAMA,EAAK,IAAA,CAEf,CAEA,OAAe,gBAAgBI,EAAqB,CAClD,MAAMJ,EAAiB,CACrB,aAAc,IACd,YAAaI,EAAK,YAClB,OAAQ,IAAI,IAAIA,EAAK,MAAM,EAC3B,KAAMA,EAAK,IAAA,EAGb,SAAW,CAACpG,EAAMsG,CAAS,IAAKF,EAAK,SACnCJ,EAAK,SAAS,IAAIhG,EAAM6F,EAAK,gBAAgBS,CAAS,CAAC,EAGzD,OAAON,CACT,CACF,CC/IO,MAAMO,EAAkC,CAC7C,GAAI,IACJ,EAAG,IACH,OAAQ,EACV,EAkCO,SAASC,GAAaV,EAAcW,EAA0BjH,EAAqB+G,EAA6B,CACrH,MAAMG,EAAKD,EAAY,oBAAoB,IAAIX,CAAI,GAAK,EAClDa,EAAIF,EAAY,UAGtB,GAAIC,IAAO,GAAKC,IAAM,EACpB,OAAOnH,EAAO,OAIhB,MAAMoH,EAAM,KAAK,KAAKD,EAAID,EAAK,KAAQA,EAAK,IAAO,CAAC,EAGpD,OAAO,KAAK,IAAIE,EAAKpH,EAAO,MAAM,CACpC,CAKO,SAASqH,GAAmBf,EAAcgB,EAAyBL,EAA0BjH,EAAqB+G,EAA6B,CACpJ,MAAMQ,EAAKD,EAAS,gBAAgB,IAAIhB,CAAI,GAAK,EAGjD,GAAIiB,IAAO,EACT,MAAO,GAGT,MAAMH,EAAMJ,GAAaV,EAAMW,EAAajH,CAAM,EAC5CwH,EAAYF,EAAS,OACrBG,EAAeR,EAAY,aAG3BS,EAAYH,GAAMvH,EAAO,GAAK,GAC9B2H,EAAcJ,EAAKvH,EAAO,IAAM,EAAIA,EAAO,EAAIA,EAAO,GAAKwH,EAAYC,IAE7E,OAAOL,GAAOM,EAAYC,EAC5B,CAMO,SAASC,GAAmBC,EAAsBP,EAAyBL,EAA0BjH,EAAqB+G,EAA6B,CAC5J,IAAIe,EAAa,EAEjB,UAAWxB,KAAQuB,EACjBC,GAAcT,GAAmBf,EAAMgB,EAAUL,EAAajH,CAAM,EAGtE,OAAO8H,CACT,CAMO,SAASC,GAAiBC,EAAyC,CACxE,MAAMC,EAAYD,EAAU,OAC5B,IAAIE,EAAc,EAClB,MAAMC,MAA0B,IAEhC,UAAWC,KAAOJ,EAAW,CAC3BE,GAAeE,EAAI,OAGnB,MAAMC,EAAc,IAAI,IAAID,EAAI,gBAAgB,MAAM,EACtD,UAAW9B,KAAQ+B,EACjBF,EAAoB,IAAI7B,GAAO6B,EAAoB,IAAI7B,CAAI,GAAK,GAAK,CAAC,CAE1E,CAEA,MAAMmB,EAAeQ,EAAY,EAAIC,EAAcD,EAAY,EAE/D,MAAO,CACL,UAAAA,EACA,aAAAR,EACA,oBAAAU,CAAA,CAEJ,CAMO,SAASG,GAAmBC,EAAeC,EAAmB,GAAY,CAC/E,GAAIA,IAAa,EAAG,MAAO,GAI3B,MAAMC,EAAeF,EAAQC,EAAY,EAAI,EAC7C,MAAO,IAAK,EAAI,KAAK,IAAI,CAACC,CAAW,EACvC,CAMO,SAASC,GAAcC,EAAmBC,EAAoBC,EAAqB,GAAKC,EAAsB,GAAa,CAEhI,MAAMC,EAAcF,EAAaC,EAC3BE,EAAuBH,EAAaE,EACpCE,EAAwBH,EAAcC,EAG5C,OAAOC,EAAuBL,EAAYM,EAAwBL,CACpE,CCzJO,MAAMM,CAAY,CACf,SACA,KACA,iBACA,YAAsB,EAE9B,YAAYlJ,EAA2B,CAIrC,MAAM,EAAIA,EAAO,iBACXmJ,EAAInJ,EAAO,kBAEjB,KAAK,KAAO,KAAK,KAAK,EAAE,EAAI,KAAK,IAAImJ,CAAC,GAAK,KAAK,IAAI,CAAC,GAAK,CAAC,EAI3D,KAAK,iBAAmB,KAAK,KAAM,KAAK,KAAO,EAAK,KAAK,IAAI,CAAC,CAAC,EAG/D,KAAK,SAAW,IAAI,WAAW,KAAK,KAAK,KAAK,KAAO,CAAC,CAAC,CACzD,CAKA,IAAIxD,EAAoB,CACtB,MAAMyD,EAAS,KAAK,UAAUzD,CAAI,EAElC,UAAW0D,KAAQD,EAAQ,CACzB,MAAME,EAAY,KAAK,MAAMD,EAAO,CAAC,EAC/BE,EAAWF,EAAO,EACxB,KAAK,SAASC,CAAS,GAAK,GAAKC,CACnC,CAEA,KAAK,aACP,CAQA,aAAa5D,EAAuB,CAClC,MAAMyD,EAAS,KAAK,UAAUzD,CAAI,EAElC,UAAW0D,KAAQD,EAAQ,CACzB,MAAME,EAAY,KAAK,MAAMD,EAAO,CAAC,EAC/BE,EAAWF,EAAO,EAExB,IAAK,KAAK,SAASC,CAAS,EAAK,GAAKC,KAAe,EACnD,MAAO,EAEX,CAEA,MAAO,EACT,CAMQ,UAAU5D,EAAwB,CACxC,MAAM6D,EAAQ,KAAK,KAAK7D,EAAM,CAAC,EACzB8D,EAAQ,KAAK,KAAK9D,EAAM,CAAC,EAEzByD,EAAmB,CAAA,EAEzB,QAAS7I,EAAI,EAAGA,EAAI,KAAK,iBAAkBA,IAAK,CAE9C,MAAMmJ,GAAgBF,EAAQjJ,EAAIkJ,GAAS,KAAK,KAChDL,EAAO,KAAK,KAAK,IAAIM,CAAY,CAAC,CACpC,CAEA,OAAON,CACT,CAKQ,KAAKvD,EAAa8D,EAAsB,CAC9C,IAAIN,EAAO,WAAaM,EAExB,QAASpJ,EAAI,EAAGA,EAAIsF,EAAI,OAAQtF,IAC9B8I,GAAQxD,EAAI,WAAWtF,CAAC,EACxB8I,IAASA,GAAQ,IAAMA,GAAQ,IAAMA,GAAQ,IAAMA,GAAQ,IAAMA,GAAQ,IAG3E,OAAOA,IAAS,CAClB,CAMA,sBAA+B,CAC7B,GAAI,KAAK,cAAgB,EAAG,MAAO,GAInC,MAAMO,EAAI,KAAK,iBACT,EAAI,KAAK,YACTC,EAAI,KAAK,KAEf,OAAO,KAAK,IAAI,EAAI,KAAK,IAAK,CAACD,EAAI,EAAKC,CAAC,EAAGD,CAAC,CAC/C,CAKA,UAME,CACA,MAAO,CACL,KAAM,KAAK,KACX,iBAAkB,KAAK,iBACvB,YAAa,KAAK,YAClB,kBAAmB,KAAK,qBAAA,EACxB,YAAa,KAAK,SAAS,UAAA,CAE/B,CAKA,OAAc,CACZ,KAAK,SAAS,KAAK,CAAC,EACpB,KAAK,YAAc,CACrB,CAKA,QAKE,CACA,MAAO,CACL,SAAU,MAAM,KAAK,KAAK,QAAQ,EAClC,KAAM,KAAK,KACX,iBAAkB,KAAK,iBACvB,YAAa,KAAK,WAAA,CAEtB,CAKA,OAAO,SAAShD,EAAwG,CAEtH,MAAMkD,EAAS,IAAIZ,EAAY,CAC7B,iBAAkB,IAClB,kBAAmB,GAAA,CACpB,EAGD,OAAAY,EAAO,SAAW,IAAI,WAAWlD,EAAK,QAAQ,EAC9CkD,EAAO,KAAOlD,EAAK,KACnBkD,EAAO,iBAAmBlD,EAAK,iBAC/BkD,EAAO,YAAclD,EAAK,YAEnBkD,CACT,CACF,CAKO,SAASC,GAAkBC,EAA0BC,EAA4B,IAAmB,CACzG,OAAO,IAAIf,EAAY,CACrB,iBAAAc,EACA,kBAAAC,CAAA,CACD,CACH,CCpLO,SAASC,EAEdC,EACAC,EACApK,EACAqK,EACiE,CACjE,MAAMrC,EAAgC,CAAA,EAChCsC,EAA+B,CACnC,mBAAoB,IACpB,SAAU,IAAIjE,EACd,uBAAwB,IACxB,oBAAqB,IACrB,sBAAuB,IACvB,iBAAkB,IAClB,UAAW,EACX,aAAc,CAAA,EAGhB,IAAI6B,EAAc,EACdqC,EAAQ,EAGZ,UAAWpK,KAAQgK,EAAO,CACxB,GAAI,CAAChK,GAAQA,EAAK,OAAO,OAASH,EAAO,eAAgB,SAEzD,MAAMwK,EAAcrK,EAAK,KAAA,EAGzB,UAAWiD,KAAagH,EAAoB,CAC1C,MAAMhK,EAAagD,EAAU,UAAUoH,CAAW,EAC5CC,EAAeJ,EAAW,IAAI,UAAU,GAAKjH,EAAU,kBAAkB,SAAS,UAAU,EAAIA,EAAU,gBAAgBoH,CAAW,EAAI,OAEzIE,EAAgBL,EAAW,IAAI,UAAU,GAAKjH,EAAU,kBAAkB,SAAS,UAAU,EAAIA,EAAU,mBAAmBoH,CAAW,EAAI,OAG7IpC,EAAwB,CAC5B,GAAImC,EACJ,KAAMC,EACN,WAAApK,EACA,aAAAqK,EACA,SAAUrH,EAAU,SACpB,cAAesH,GAAiBA,EAAc,OAAS,EAAIA,EAAgB,MAAA,EAG7E1C,EAAU,KAAKI,CAAG,EAClBF,GAAe9H,EAAW,OAG1BuK,EAAiBL,EAAc,eAAgBlK,EAAYmK,CAAK,EAChED,EAAc,SAAU,OAAOlK,EAAY,CAACmK,CAAK,CAAC,EAGlD,MAAMK,EAAYJ,EAAY,YAAA,EAkC9B,GAjCAG,EAAiBL,EAAc,eAAgBM,EAAWL,CAAK,EAC/DD,EAAc,SAAU,OAAOM,EAAW,CAACL,CAAK,CAAC,EAG7CF,EAAW,IAAI,eAAe,GACfjH,EAAU,gBAAgBoH,CAAW,EAC7C,QAASK,GAAY,CAC5BF,EAAiBL,EAAc,eAAgBO,EAASN,CAAK,EAC7DD,EAAc,SAAU,OAAOO,EAAS,CAACN,CAAK,CAAC,CACjD,CAAC,EAICE,GACFE,EAAiBL,EAAc,mBAAoBG,EAAcF,CAAK,EAIzDjF,EAAelF,EAAYJ,EAAO,SAAS,EACnD,QAAS8K,GAAU,CACxBH,EAAiBL,EAAc,gBAAiBQ,EAAOP,CAAK,CAC9D,CAAC,EAGGG,GAAiBA,EAAc,OAAS,GAC1CA,EAAc,QAASrI,GAAS,CAC9B,MAAM0I,EAAiB3H,EAAU,UAAUf,CAAI,EAC/CsI,EAAiBL,EAAc,eAAgBS,EAAgBR,CAAK,EACpED,EAAc,SAAU,OAAOS,EAAgB,CAACR,CAAK,CAAC,CACxD,CAAC,EAICF,EAAW,IAAI,UAAU,IACVjH,EAAU,YAAYhD,CAAU,EACxC,QAAS4K,GAAY,CAC5BL,EAAiBL,EAAc,kBAAmBU,EAAST,CAAK,CAClE,CAAC,EAGGvK,EAAO,gBAAgB,CACzB,MAAMiL,EAAiBjL,EAAO,eAAeI,CAAU,EACnD6K,GACFA,EAAe,QAASD,GAAY,CAClCL,EAAiBL,EAAc,kBAAmBU,EAAST,CAAK,CAClE,CAAC,CAEL,CAGFA,GACF,CACF,CAMA,GAJAD,EAAc,UAAYC,EAC1BD,EAAc,aAAepC,EAAc,KAAK,IAAI,EAAGqC,CAAK,EAGxDvK,EAAO,QAAS,CAClB,MAAMmI,MAA0B,IAC1B+C,MAAsB,IAG5B,SAAW,CAAC5E,EAAM6E,CAAO,IAAKb,EAAc,eAAe,UACzDnC,EAAoB,IAAI7B,EAAM6E,EAAQ,OAAO,MAAM,EAIrDnD,EAAU,QAASI,GAAQ,CACzB8C,EAAgB,IAAI9C,EAAI,GAAIA,EAAI,WAAW,MAAM,CACnD,CAAC,EAEDkC,EAAc,UAAY,CACxB,oBAAAnC,EACA,gBAAA+C,CAAA,CAEJ,CAKA,GAF6BlL,EAAO,gBAAkBmK,EAAM,QAAU,IAE5C,CACxB,MAAMF,EAAoBjK,EAAO,8BAAgC,IAC3DoL,EAAc,IAAIlC,EAAY,CAClC,iBAAkBoB,EAAc,eAAe,KAC/C,kBAAAL,CAAA,CACD,EAGD,UAAW3D,KAAQgE,EAAc,eAAe,KAAA,EAC9Cc,EAAY,IAAI9E,CAAI,EAGtBgE,EAAc,YAAcc,CAC9B,CAEA,MAAO,CAAE,cAAAd,EAAe,UAAAtC,CAAA,CAC1B,CAMO,SAASqD,GAEdf,EACAtC,EACAsD,EACAC,EACAvL,EACe,CACf,MAAMwL,MAAc,IACdnB,EAAa,IAAI,IAAIrK,EAAO,QAAQ,EAG1C,UAAWoD,KAAamI,EAAY,CAClC,MAAME,EAAkBrI,EAAU,UAAUkI,EAAM,MAAM,EAGxDI,GAAyBD,EAAiBnB,EAAetC,EAAWwD,EAASpI,EAAU,QAAQ,EAG/FuI,GAA0BF,EAAiBnB,EAAetC,EAAWwD,EAASpI,EAAU,QAAQ,EAG5FiH,EAAW,IAAI,UAAU,GAAKjH,EAAU,kBAAkB,SAAS,UAAU,GAC/EwI,GAA4BH,EAAiBrI,EAAWkH,EAAetC,EAAWwD,CAAO,EAIvFnB,EAAW,IAAI,UAAU,GAC3BwB,GAA2BJ,EAAiBnB,EAAetC,EAAWwD,CAAO,EAI/EM,GAAyBL,EAAiBnB,EAAetC,EAAWwD,EAASpI,EAAU,SAAUpD,EAAO,SAAS,EAM7G,EAFoBA,EAAO,cAAgB,QAAUsK,EAAc,eAAe,KAAO,KAAUkB,EAAQ,MAAQxL,EAAO,WAAa,KAElHqK,EAAW,IAAI,iBAAiB,GAAKA,EAAW,IAAI,eAAe,GAAKA,EAAW,IAAI,gBAAgB,IAC9H0B,GAAyBN,EAAiBnB,EAAetC,EAAWwD,EAASpI,EAAWpD,EAAO,gBAAiBA,CAAM,CAE1H,CAGA,OAAO,MAAM,KAAKwL,EAAQ,OAAA,CAAQ,CACpC,CAKA,SAASb,EAEPqB,EACA1F,EACAiE,EACM,CACN,IAAIY,EAAUa,EAAS,IAAI1F,CAAI,EAC1B6E,IACHA,EAAU,CAAE,KAAA7E,EAAM,OAAQ,EAAC,EAC3B0F,EAAS,IAAI1F,EAAM6E,CAAO,GAIvBA,EAAQ,OAAO,SAASZ,CAAK,GAChCY,EAAQ,OAAO,KAAKZ,CAAK,CAE7B,CAKA,SAASmB,GAEPJ,EACAhB,EACAtC,EACAwD,EACAtI,EACM,CAEN,GAAIoH,EAAc,aAAe,CAACA,EAAc,YAAY,aAAagB,CAAK,EAC5E,OAGF,MAAMH,EAAUb,EAAc,eAAe,IAAIgB,CAAK,EACjDH,GAELA,EAAQ,OAAO,QAASZ,GAAU,CAChC,MAAMnC,EAAMJ,EAAUuC,CAAK,EACtBnC,IAEAoD,EAAQ,IAAIjB,CAAK,GACpBiB,EAAQ,IAAIjB,EAAO,CACjB,KAAMnC,EAAI,KACV,WAAYkD,EACZ,UAAW,QACX,aAAc,EACd,SAAApI,EACA,MAAAqH,CAAA,CACD,EAEL,CAAC,CACH,CAMA,SAASoB,GAEPL,EACAhB,EACAtC,EACAwD,EACAtI,EACM,CAEN,GAAIoH,EAAc,SAAU,CAC1B,MAAM2B,EAAgB3B,EAAc,SAAS,eAAegB,CAAK,EAEjE,SAAW,CAAChF,EAAMC,CAAM,IAAK0F,EACvB3F,IAASgF,GAEX/E,EAAO,QAASgE,GAAkB,CAChC,MAAMnC,EAAMJ,EAAUuC,CAAK,EACtBnC,IAEAoD,EAAQ,IAAIjB,CAAK,GACpBiB,EAAQ,IAAIjB,EAAO,CACjB,KAAMnC,EAAI,KACV,WAAY9B,EACZ,UAAW,SACX,SAAApD,EACA,MAAAqH,CAAA,CACD,EAEL,CAAC,CAGP,KAEE,UAAW,CAACjE,EAAM6E,CAAO,IAAKb,EAAc,eAAe,UACrDhE,EAAK,WAAWgF,CAAK,GAAKhF,IAASgF,GACrCH,EAAQ,OAAO,QAASZ,GAAU,CAChC,MAAMnC,EAAMJ,EAAUuC,CAAK,EACtBnC,IAEAoD,EAAQ,IAAIjB,CAAK,GACpBiB,EAAQ,IAAIjB,EAAO,CACjB,KAAMnC,EAAI,KACV,WAAY9B,EACZ,UAAW,SACX,SAAApD,EACA,MAAAqH,CAAA,CACD,EAEL,CAAC,CAIT,CAKA,SAASqB,GAEPN,EACAlI,EACAkH,EACAtC,EACAwD,EACM,CACN,MAAMf,EAAerH,EAAU,gBAAgBkI,CAAK,EACpD,GAAI,CAACb,EAAc,OAEnB,MAAMU,EAAUb,EAAc,mBAAmB,IAAIG,CAAY,EAC5DU,GAELA,EAAQ,OAAO,QAASZ,GAAU,CAChC,MAAMnC,EAAMJ,EAAUuC,CAAK,EACtBnC,IAEAoD,EAAQ,IAAIjB,CAAK,GACpBiB,EAAQ,IAAIjB,EAAO,CACjB,KAAMnC,EAAI,KACV,WAAYkD,EACZ,UAAW,WACX,aAAAb,EACA,SAAUrH,EAAU,SACpB,MAAAmH,CAAA,CACD,EAEL,CAAC,CACH,CAKA,SAASsB,GAEPP,EACAhB,EACAtC,EACAwD,EACM,CACN,MAAML,EAAUb,EAAc,kBAAkB,IAAIgB,CAAK,EACpDH,GAELA,EAAQ,OAAO,QAASZ,GAAU,CAChC,MAAMnC,EAAMJ,EAAUuC,CAAK,EACtBnC,IAEAoD,EAAQ,IAAIjB,CAAK,GACpBiB,EAAQ,IAAIjB,EAAO,CACjB,KAAMnC,EAAI,KACV,WAAYkD,EACZ,UAAW,UACX,SAAU,UACV,MAAAf,CAAA,CACD,EAEL,CAAC,CACH,CAKA,SAASuB,GAEPR,EACAhB,EACAtC,EACAwD,EACAtI,EACAgJ,EACM,CACN,GAAIZ,EAAM,OAASY,EAAW,OAE9B,MAAMC,EAAc7G,EAAegG,EAAOY,CAAS,EAC7CE,MAAoB,IAG1BD,EAAY,QAASrB,GAAU,CAC7B,MAAMK,EAAUb,EAAc,gBAAgB,IAAIQ,CAAK,EACnDK,GACFA,EAAQ,OAAO,QAASZ,GAAU6B,EAAc,IAAI7B,CAAK,CAAC,CAE9D,CAAC,EAGD6B,EAAc,QAAS7B,GAAU,CAC/B,MAAMnC,EAAMJ,EAAUuC,CAAK,EACtBnC,IAEAoD,EAAQ,IAAIjB,CAAK,GACpBiB,EAAQ,IAAIjB,EAAO,CACjB,KAAMnC,EAAI,KACV,WAAYkD,EACZ,UAAW,QACX,SAAApI,EACA,MAAAqH,CAAA,CACD,EAEL,CAAC,CACH,CAMA,SAASwB,GAEPT,EACAhB,EACAtC,EACAwD,EACApI,EACAoB,EACAxE,EACM,CACN,MAAMqM,EAAWf,EAAM,OACjBgB,EAASD,EAAW7H,EACpBK,EAASwH,EAAW7H,EAGpB+H,EAAoBvM,EAAO,UAAU,SAAS,gBAAgB,EAI9DwM,EAAclC,EAAc,eAAe,KAC3CmC,EAAuBD,EAAc,IAAS,IAAOA,EAAc,IAAQ,KAAOA,EAAc,IAAQ,IAAOA,EAAc,IAAQ,IAAO,IAClJ,IAAIE,EAAoB,EAGpBC,EAEJ,GAAIH,EAAc,KAASlB,EAAM,QAAU,GAAKhB,EAAc,SAAU,CAGtE,MAAMsC,EAAeJ,EAAc,IAAS,KAAK,IAAI,EAAGlB,EAAM,MAAM,EAAI,KAAK,IAAI,EAAGA,EAAM,MAAM,EAC1FtJ,EAASsJ,EAAM,UAAU,EAAGsB,CAAY,EAI9CD,EAHsBrC,EAAc,SAAS,eAAetI,CAAM,EAGvC,IAAI,CAAC,CAACsE,EAAMuG,CAAO,IAA0B,CAACvG,EAAMgE,EAAc,eAAe,IAAIhE,CAAI,CAAC,CAAsC,EAAE,OAAQwG,GAA6EA,EAAM,CAAC,IAAM,MAAS,EAGpQH,EAAW,OAAS,MACtBA,EAAa,MAAM,KAAKrC,EAAc,eAAe,SAAS,EAElE,MACEqC,EAAa,MAAM,KAAKrC,EAAc,eAAe,SAAS,EAIhEqC,EAAW,KAAK,CAACI,EAAG,IAAM,CACxB,MAAMC,EAAQ,KAAK,IAAID,EAAE,CAAC,EAAE,OAASV,CAAQ,EACvCY,EAAQ,KAAK,IAAI,EAAE,CAAC,EAAE,OAASZ,CAAQ,EAC7C,OAAOW,EAAQC,CACjB,CAAC,EAGD,SAAW,CAAC3G,EAAM6E,CAAO,IAAKwB,EAAY,CAGxC,MAAMO,EAAU5G,EAAK,OACrB,GAAI4G,EAAUZ,GAAUY,EAAUrI,EAChC,SAIF,GAAI6H,GAAqBD,EACvB,MAEFC,IAIA,MAAMS,EAA4BX,EAAc,IAAQxM,EAAO,WAAa,EAAIA,EAAO,WAAa,EACpG,GAAIwL,EAAQ,MAAQ2B,EAClB,MAIF,GAAI7B,EAAM,OAAS,GAAKhF,EAAK,OAAS,GACd,KAAK,IAAIgF,EAAM,WAAW,CAAC,EAAIhF,EAAK,WAAW,CAAC,CAAC,EACnD,IAAM9B,EAAc,EAEtC,SAKJ,MAAMyB,EAAWsG,EAAoB3H,EAAoC0G,EAAOhF,EAAM9B,CAAW,EAAID,EAA6B+G,EAAOhF,EAAM9B,CAAW,EAEtJyB,GAAYzB,GACd2G,EAAQ,OAAO,QAASZ,GAAU,CAChC,MAAMnC,GAAMJ,EAAUuC,CAAK,EAC3B,GAAI,CAACnC,GAAK,OAEV,MAAMgF,GAAgB5B,EAAQ,IAAIjB,CAAK,GAEnC,CAAC6C,KAAkBA,GAAc,cAAgB,KAAYnH,IAC/DuF,EAAQ,IAAIjB,EAAO,CACjB,KAAMnC,GAAI,KACV,WAAY9B,EACZ,UAAW,QACX,aAAcL,EACd,SAAU7C,EAAU,SACpB,MAAAmH,CAAA,CACD,CAEL,CAAC,CAEL,CACF,CAMO,SAAS8C,GAAoB7B,EAAwB3D,EAAsByC,EAA8BtC,EAA+BhI,EAAoC,CACjL,GAAI,CAACA,EAAO,SAAW,CAACsK,EAAc,UACpC,OAAOkB,EAGT,MAAM8B,EAAa,CACjB,GAAGvG,EACH,GAAG/G,EAAO,UAAA,EAINiH,EAA2B,CAC/B,UAAWqD,EAAc,UACzB,aAAcA,EAAc,aAC5B,oBAAqBA,EAAc,UAAU,mBAAA,EAI/C,OAAOkB,EAAQ,IAAK+B,GAAU,CAC5B,GAAIA,EAAM,QAAU,OAClB,OAAOA,EAGT,MAAMnF,EAAMJ,EAAUuF,EAAM,KAAK,EACjC,GAAI,CAACnF,EACH,OAAOmF,EAIT,MAAMC,MAAsB,IACtBC,EAAkBrF,EAAI,WAAW,YAAA,EAAc,MAAM,KAAK,EAEhE,UAAW9B,KAAQmH,EACjBD,EAAgB,IAAIlH,GAAOkH,EAAgB,IAAIlH,CAAI,GAAK,GAAK,CAAC,EAGhE,MAAMgB,EAA0B,CAC9B,MAAOc,EAAI,GACX,OAAQqF,EAAgB,OACxB,gBAAAD,CAAA,EAII7E,EAAYf,GAAmBC,EAAYP,EAAUL,EAAaqG,CAAU,EAC5EI,EAAiBpF,GAAmBK,CAAS,EAEnD,MAAO,CACL,GAAG4E,EACH,UAAWG,CAAA,CAEf,CAAC,CACH,CCzlBO,SAASC,GACdJ,EACAjC,EACAsC,EACkB,CAClB,MAAMC,EAA+B,CAAA,EAC/BC,EAAoBF,EAAY,YAAA,EAChCnC,EAAkBH,EAAM,YAAA,EAE9B,OAAQiC,EAAM,UAAA,CACZ,IAAK,QAEHM,EAAW,KAAK,CACd,MAAO,EACP,IAAKD,EAAY,OACjB,KAAM,OAAA,CACP,EACD,MAEF,IAAK,SAEH,MAAMG,EAAY,KAAK,IAAItC,EAAgB,OAAQmC,EAAY,MAAM,EACrEC,EAAW,KAAK,CACd,MAAO,EACP,IAAKE,EACL,KAAM,QAAA,CACP,EACD,MAEF,IAAK,YAEH,MAAMC,EAAiBF,EAAkB,QAAQrC,CAAe,EAC5DuC,IAAmB,IACrBH,EAAW,KAAK,CACd,MAAOG,EACP,IAAKA,EAAiBvC,EAAgB,OACtC,KAAM,WAAA,CACP,EAEH,MAEF,IAAK,QAEHoC,EAAW,KAAK,GAAGI,GAAyBxC,EAAiBqC,EAAmB,OAAO,CAAC,EACxF,MAEF,IAAK,QAEHD,EAAW,KAAK,GAAGK,GAAyBzC,EAAiBqC,CAAiB,CAAC,EAC/E,MAEF,IAAK,WACL,IAAK,UACL,IAAK,WAEHD,EAAW,KAAK,CACd,MAAO,EACP,IAAKD,EAAY,OACjB,KAAML,EAAM,SAAA,CACb,EACD,KAAA,CAGJ,OAAOY,GAA2BN,CAAU,CAC9C,CAKA,SAASI,GACP3C,EACApL,EACAkO,EACkB,CAClB,MAAMP,EAA+B,CAAA,EACrC,IAAIQ,EAAW,EACXC,EAAU,EAGd,KAAOD,EAAW/C,EAAM,QAAUgD,EAAUpO,EAAK,QAC/C,GAAIoL,EAAM+C,CAAQ,IAAMnO,EAAKoO,CAAO,EAAG,CAErC,MAAMC,EAAQD,EACd,IAAIE,EAAMF,EAAU,EAKpB,IAFAD,IACAC,IACOD,EAAW/C,EAAM,QAAUgD,EAAUpO,EAAK,QAAUoL,EAAM+C,CAAQ,IAAMnO,EAAKoO,CAAO,GACzFE,IACAH,IACAC,IAGFT,EAAW,KAAK,CAAE,MAAAU,EAAO,IAAAC,EAAK,KAAAJ,EAAM,CACtC,MACEE,IAIJ,OAAOT,CACT,CAKA,SAASK,GACP5C,EACApL,EACkB,CAClB,MAAM2N,EAA+B,CAAA,EAIrC,QAAStN,EAAI,EAAGA,GAAK+K,EAAM,OAAS,EAAW/K,IAAK,CAClD,MAAMuK,EAAQQ,EAAM,MAAM/K,EAAGA,EAAI,CAAS,EAC1C,IAAIkO,EAAc,EAGlB,OAAa,CACX,MAAMC,EAAQxO,EAAK,QAAQ4K,EAAO2D,CAAW,EAC7C,GAAIC,IAAU,GAAI,MAElBb,EAAW,KAAK,CACd,MAAOa,EACP,IAAKA,EAAQ,EACb,KAAM,OAAA,CACP,EAEDD,EAAcC,EAAQ,CACxB,CACF,CAEA,OAAOb,CACT,CAKA,SAASM,GAA2BN,EAAgD,CAClF,GAAIA,EAAW,SAAW,EAAG,MAAO,CAAA,EAGpC,MAAMc,EAAS,CAAC,GAAGd,CAAU,EAAE,KAAK,CAACd,EAAG6B,IAAM7B,EAAE,MAAQ6B,EAAE,KAAK,EACzDC,EAA2B,CAACF,EAAO,CAAC,CAAC,EAE3C,QAASpO,EAAI,EAAGA,EAAIoO,EAAO,OAAQpO,IAAK,CACtC,MAAMmC,EAAUiM,EAAOpO,CAAC,EAClBuO,EAAOD,EAAOA,EAAO,OAAS,CAAC,EAEjCnM,EAAQ,OAASoM,EAAK,KAExBA,EAAK,IAAM,KAAK,IAAIA,EAAK,IAAKpM,EAAQ,GAAG,EAErCqM,GAAqBrM,EAAQ,IAAI,EAAIqM,GAAqBD,EAAK,IAAI,IACrEA,EAAK,KAAOpM,EAAQ,OAItBmM,EAAO,KAAKnM,CAAO,CAEvB,CAEA,OAAOmM,CACT,CAKA,SAASE,GAAqBX,EAAyB,CAWrD,MAV8C,CAC5C,MAAO,GACP,OAAQ,EACR,UAAW,EACX,MAAO,EACP,MAAO,EACP,SAAU,EACV,SAAU,EACV,QAAS,CAAA,EAEOA,CAAI,GAAK,CAC7B,CAKO,SAASY,GACd9O,EACA2N,EACAoB,EAAoB,YACZ,CACR,GAAI,CAACpB,GAAcA,EAAW,SAAW,EACvC,OAAOqB,EAAWhP,CAAI,EAGxB,IAAIiF,EAAS,GACTgK,EAAU,EAEd,UAAWC,KAAavB,EAAY,CAE9BuB,EAAU,MAAQD,IACpBhK,GAAU+J,EAAWhP,EAAK,MAAMiP,EAASC,EAAU,KAAK,CAAC,GAI3D,MAAMC,EAAkBnP,EAAK,MAAMkP,EAAU,MAAOA,EAAU,GAAG,EACjEjK,GAAU,gBAAgB8J,CAAS,IAAIA,CAAS,KAAKG,EAAU,IAAI,KAAKF,EAAWG,CAAe,CAAC,UAEnGF,EAAUC,EAAU,GACtB,CAGA,OAAID,EAAUjP,EAAK,SACjBiF,GAAU+J,EAAWhP,EAAK,MAAMiP,CAAO,CAAC,GAGnChK,CACT,CAKA,SAAS+J,EAAWhP,EAAsB,CACxC,MAAMoP,EAAM,OAAO,SAAa,IAAc,SAAS,cAAc,KAAK,EAAI,KAC9E,OAAIA,GACFA,EAAI,YAAcpP,EACXoP,EAAI,WAGNpP,EACJ,QAAQ,KAAM,OAAO,EACrB,QAAQ,KAAM,MAAM,EACpB,QAAQ,KAAM,MAAM,EACpB,QAAQ,KAAM,QAAQ,EACtB,QAAQ,KAAM,QAAQ,CAC3B,CC1OO,MAAMqP,EAAe,CAClB,MACA,SAER,YAAYC,EAAmB,IAAK,CAClC,KAAK,UAAY,IACjB,KAAK,SAAWA,CAClB,CAMA,IAAIC,EAAuB,CACzB,GAAI,CAAC,KAAK,MAAM,IAAIA,CAAG,EACrB,OAIF,MAAMC,EAAQ,KAAK,MAAM,IAAID,CAAG,EAChC,YAAK,MAAM,OAAOA,CAAG,EACrB,KAAK,MAAM,IAAIA,EAAKC,CAAK,EAElBA,CACT,CAMA,IAEED,EACAC,EACM,CAUN,GARI,KAAK,MAAM,IAAID,CAAG,GACpB,KAAK,MAAM,OAAOA,CAAG,EAIvB,KAAK,MAAM,IAAIA,EAAKC,CAAK,EAGrB,KAAK,MAAM,KAAO,KAAK,SAAU,CACnC,MAAMC,EAAW,KAAK,MAAM,KAAA,EAAO,OAAO,MACtCA,IAAa,QACf,KAAK,MAAM,OAAOA,CAAQ,CAE9B,CACF,CAKA,IAAIF,EAAiB,CACnB,OAAO,KAAK,MAAM,IAAIA,CAAG,CAC3B,CAKA,OAAc,CACZ,KAAK,MAAM,MAAA,CACb,CAKA,IAAI,MAAe,CACjB,OAAO,KAAK,MAAM,IACpB,CAKA,UAKE,CACA,MAAO,CACL,KAAM,KAAK,MAAM,KACjB,SAAU,KAAK,SACf,YAAa,KAAK,MAAM,KAAO,KAAK,QAAA,CAExC,CACF,CAMO,MAAMG,CAAY,CACf,MACA,KAAe,EACf,OAAiB,EAEzB,YAAYJ,EAAmB,IAAK,CAClC,KAAK,MAAQ,IAAID,GAASC,CAAQ,CACpC,CAKQ,YAAYlE,EAAeuE,EAAqBC,EAAuB,CAC7E,MAAMC,EAAaD,EAAU,KAAK,UAAUA,CAAO,EAAI,GACvD,MAAO,GAAGxE,CAAK,IAAIuE,GAAc,SAAS,IAAIE,CAAU,EAC1D,CAKA,IAAIzE,EAAeuE,EAAqBC,EAA+C,CACrF,MAAML,EAAM,KAAK,YAAYnE,EAAOuE,EAAYC,CAAO,EACjD3K,EAAS,KAAK,MAAM,IAAIsK,CAAG,EAEjC,OAAItK,EACF,KAAK,OAEL,KAAK,SAGAA,CACT,CAKA,IAAImG,EAAe5E,EAA6BmJ,EAAqBC,EAAqB,CACxF,MAAML,EAAM,KAAK,YAAYnE,EAAOuE,EAAYC,CAAO,EACvD,KAAK,MAAM,IAAIL,EAAK/I,CAAO,CAC7B,CAKA,OAAc,CACZ,KAAK,MAAM,MAAA,EACX,KAAK,KAAO,EACZ,KAAK,OAAS,CAChB,CAKA,UAOE,CACA,MAAMsJ,EAAa,KAAK,MAAM,SAAA,EACxBC,EAAQ,KAAK,KAAO,KAAK,OACzBC,EAAUD,EAAQ,EAAI,KAAK,KAAOA,EAAQ,EAEhD,MAAO,CACL,GAAGD,EACH,KAAM,KAAK,KACX,OAAQ,KAAK,OACb,QAAAE,CAAA,CAEJ,CACF,CCxKA,MAAMC,GAAqC,CAEzC,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IACrF,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAErF,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAC/F,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAE/F,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,KAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,KACH,EAAG,KACH,EAAG,KACH,EAAG,KAEH,EAAG,KACH,EAAG,IACL,EAMMC,MAAkB,IAClBC,GAAiB,IAMhB,SAASC,EAAcpQ,EAAsB,CAClD,GAAI,CAACA,EAAM,OAAOA,EAGlB,MAAMqQ,EAASH,EAAY,IAAIlQ,CAAI,EACnC,GAAIqQ,IAAW,OACb,OAAOA,EAIT,MAAMC,EAAkB,CAAA,EACxB,QAASjQ,EAAI,EAAGA,EAAIL,EAAK,OAAQK,IAAK,CACpC,MAAMC,EAAON,EAAKK,CAAC,EACnBiQ,EAAM,KAAKL,GAAW3P,CAAI,GAAKA,CAAI,CACrC,CACA,IAAI2E,EAASqL,EAAM,KAAK,EAAE,EAK1B,OAAArL,EAASA,EAAO,UAAU,KAAK,EAAE,QAAQ,mBAAoB,EAAE,EAG3DiL,EAAY,KAAOC,GACrBD,EAAY,IAAIlQ,EAAMiF,CAAM,EACnBiL,EAAY,OAASC,KAE9BD,EAAY,MAAA,EACZA,EAAY,IAAIlQ,EAAMiF,CAAM,GAGvBA,CACT,CAMO,SAASsL,GAAWvQ,EAAuB,CAChD,GAAI,CAACA,EAAM,MAAO,GAGlB,QAASK,EAAI,EAAGA,EAAIL,EAAK,OAAQK,IAC/B,GAAI4P,GAAWjQ,EAAKK,CAAC,CAAC,EACpB,MAAO,GAMX,MAAO,kBAAkB,KAAKL,EAAK,UAAU,KAAK,CAAC,CACrD,CAMO,SAASwQ,GAAuBxQ,EAAsB,CAC3D,OAAOoQ,EAAcpQ,EAAK,aAAa,CACzC,CAMO,SAASyQ,GAAkBxQ,EAAwB,CACxD,MAAMC,EAAakQ,EAAcnQ,CAAI,EAGrC,OAAIC,IAAeD,EACV,CAACA,EAAMC,CAAU,EAInB,CAACD,CAAI,CACd,CCjQO,SAASyQ,GAEdjL,EACAkL,EAC+B,CAO/B,GALI,CAACA,GAAUA,EAAO,SAAW,GAK7B,OAAOlL,GAAS,SAClB,OAAO,KAIT,GAAI,OAAOA,GAAS,UAAYA,IAAS,KAAM,CAC7C,MAAMmL,EAAsC,CAAA,EAE5C,UAAWC,KAASF,EAAQ,CAC1B,MAAMnB,EAAQ/J,EAAKoL,CAAK,EACGrB,GAAU,OACnCoB,EAAYC,CAAK,EAAI,OAAOrB,CAAK,EAErC,CAEA,OAAO,OAAO,KAAKoB,CAAW,EAAE,OAAS,EAAIA,EAAc,IAC7D,CAEA,OAAO,IACT,CAeO,SAASE,GAEdH,EACAI,EACwB,CACxB,MAAM7Q,EAAqC,CAAA,EAE3C,UAAW2Q,KAASF,EAClBzQ,EAAW2Q,CAAK,EAAIE,IAAeF,CAAK,GAAK,EAG/C,OAAO3Q,CACT,CCzDO,MAAM8Q,GAA+C,CAC1D,QAAS,CAEP,IACA,KACA,MACA,MACA,KACA,KACA,KACA,KACA,MACA,OACA,MACA,KACA,KACA,KACA,KACA,MACA,KACA,KACA,OACA,MACA,KACA,MACA,OACA,OACA,MACA,OACA,MACA,OACA,OACA,MACA,OACA,OACA,QACA,MACA,QACA,MACA,KAAA,EAEF,OAAQ,CAEN,MACA,MACA,MACA,MACA,MACA,MACA,MACA,OACA,QACA,QACA,QACA,QACA,MACA,OACA,OACA,MACA,OACA,MACA,QACA,MACA,QACA,OACA,SACA,MACA,KACA,KACA,KACA,KACA,MACA,MACA,MACA,OACA,MACA,KAAA,EAEF,QAAS,CAEP,KACA,KACA,MACA,MACA,KACA,MACA,OACA,OACA,KACA,MACA,IACA,IACA,OACA,KACA,MACA,MACA,SACA,KACA,MACA,KACA,IACA,KACA,MACA,MACA,OACA,MACA,QACA,OAAA,EAEF,OAAQ,CAEN,KACA,KACA,MACA,KACA,MACA,MACA,KACA,KACA,KACA,KACA,OACA,MACA,OACA,QACA,UACA,IACA,MACA,IACA,KACA,MACA,OACA,OACA,MACA,OACA,MACA,OACA,OAAA,CAEJ,EAKO,SAASC,GACd7F,EACA8F,EACQ,CACR,MAAMC,EAAeD,aAAqB,IAAMA,EAAY,IAAI,IAAIA,EAAU,IAAIE,GAAKA,EAAE,YAAA,CAAa,CAAC,EAIjGC,EADQjG,EAAM,MAAM,KAAK,EACR,OAAOnL,GAAQ,CAACkR,EAAa,IAAIlR,EAAK,YAAA,CAAa,CAAC,EAG3E,OAAIoR,EAAS,SAAW,EACfjG,EAGFiG,EAAS,KAAK,GAAG,CAC1B,CAKO,SAASC,GAAyBrO,EAAkC,CACzE,MAAMiO,MAAgB,IAEtB,UAAWvR,KAAQsD,EAAW,CAC5B,MAAMsO,EAAgBP,GAAmBrR,EAAK,YAAA,CAAa,EACvD4R,GACFA,EAAc,QAAStR,GAASiR,EAAU,IAAIjR,CAAI,CAAC,CAEvD,CAEA,OAAOiR,CACT,CAKO,SAASM,GAAWvR,EAAciR,EAA4C,CAEnF,OADqBA,aAAqB,IAAMA,EAAY,IAAI,IAAIA,EAAU,IAAKE,GAAMA,EAAE,YAAA,CAAa,CAAC,GACrF,IAAInR,EAAK,YAAA,CAAa,CAC5C,CCpLO,SAASwR,GAAezR,EAAc0R,EAA2B,CAEtE,GAAIA,IAAa,EACf,MAAO,GAIT,MAAMC,EAAa3R,EAAK0R,EAAW,CAAC,EAGpC,MAAO,6BAA6B,KAAKC,CAAU,CACrD,CAKO,SAASC,GACd5R,EACA6R,EACAC,EACS,CACT,MAAMC,EAAWF,EAAaC,EAGxBE,EAAgBP,GAAezR,EAAM6R,CAAU,EAG/CI,EAAcF,GAAY/R,EAAK,QAAU,6BAA6B,KAAKA,EAAK+R,CAAQ,CAAC,EAE/F,OAAOC,GAAiBC,CAC1B,CAKO,SAASC,GACdlS,EACAmS,EACAC,EAAyB,GACf,CACV,MAAMC,EAAsB,CAAA,EACtBC,EAAaF,EAAgBpS,EAAOA,EAAK,YAAA,EACzCuS,EAAgBH,EAAgBD,EAAUA,EAAQ,YAAA,EAExD,IAAI3D,EAAQ,EACZ,KAAOA,EAAQ8D,EAAW,QAAQ,CAChC,MAAME,EAAQF,EAAW,QAAQC,EAAe/D,CAAK,EAErD,GAAIgE,IAAU,GACZ,MAIEZ,GAAsB5R,EAAMwS,EAAOD,EAAc,MAAM,GACzDF,EAAU,KAAKG,CAAK,EAGtBhE,EAAQgE,EAAQ,CAClB,CAEA,OAAOH,CACT,CAKO,SAASI,EAAYxS,EAAcmL,EAAesH,EAAkC,CACzF,OAAKA,EAMaR,GAAwBjS,EAAMmL,EAAO,EAAK,EAC3C,OAAS,EALjBnL,EAAK,YAAA,EAAc,SAASmL,EAAM,aAAa,CAM1D,CAoBO,SAASuH,GAAcR,EAAyB,CAKrD,MAAMS,EAHUT,EAAQ,QAAQ,qBAAsB,MAAM,EAG/B,QAAQ,MAAO,IAAI,EAGhD,OAAO,IAAI,OAAO,IAAIS,CAAY,IAAK,GAAG,CAC5C,CAKO,SAASC,GAAgB5S,EAAckS,EAA0B,CAEtE,OADcQ,GAAcR,CAAO,EACtB,KAAKlS,CAAI,CACxB,CCjGO,SAAS6S,GAAW1H,EAA4B,CACrD,GAAI,CAACA,GAAS,OAAOA,GAAU,SAC7B,MAAO,CACL,QAAS,CAAA,EACT,MAAO,CAAA,EACP,SAAUA,GAAS,GACnB,WAAY,EAAA,EAIhB,MAAM2H,EAAoB,CAAA,EAC1B,IAAIC,EAAY5H,EAGhB,MAAM6H,EAAmB,aACzB,IAAI5F,EAEJ,MAAQA,EAAQ4F,EAAiB,KAAK7H,CAAK,KAAO,MAAM,CACtD,MAAM8H,EAAS7F,EAAM,CAAC,EAAE,KAAA,EACpB6F,GAEgBA,EAAO,MAAM,KAAK,EAAE,QACrB,IACfH,EAAQ,KAAKG,CAAM,CAGzB,CAGAF,EAAYA,EAAU,QAAQ,WAAY,GAAG,EAG7C,MAAMG,EAAmB,aAEzB,MAAQ9F,EAAQ8F,EAAiB,KAAK/H,CAAK,KAAO,MAAM,CACtD,MAAM8H,EAAS7F,EAAM,CAAC,EAAE,KAAA,EACpB6F,GAEgBA,EAAO,MAAM,KAAK,EAAE,QACrB,IACfH,EAAQ,KAAKG,CAAM,CAGzB,CAGAF,EAAYA,EAAU,QAAQ,WAAY,GAAG,EAG7C,MAAMI,EAAQJ,EACX,MAAM,KAAK,EACX,IAAIK,GAAKA,EAAE,KAAA,CAAM,EACjB,OAAOA,GAAKA,EAAE,OAAS,CAAC,EAE3B,MAAO,CACL,QAAAN,EACA,MAAAK,EACA,SAAUhI,EACV,WAAY2H,EAAQ,OAAS,CAAA,CAEjC,CAKO,SAASO,GAAgBlI,EAAwB,CACtD,OAAKA,EACE,UAAU,KAAKA,CAAK,GAAK,UAAU,KAAKA,CAAK,EADjC,EAErB,CAKO,SAASmI,GAAgBL,EAAwB,CACtD,OAAOA,EAAO,cAAc,OAAO,QAAQ,OAAQ,GAAG,CACxD,CAKO,SAASM,GAAiBN,EAA0B,CACzD,OAAOA,EACJ,YAAA,EACA,KAAA,EACA,MAAM,KAAK,EACX,OAAO9B,GAAKA,EAAE,OAAS,CAAC,CAC7B,CC/EA,MAAMqC,GAAgD,CACpD,WAAY,GACZ,gBAAiB,EACjB,eAAgB,IAChB,qBAAsB,EACtB,kBAAmB,EACrB,EAKO,SAASC,GAEd1T,EACAkT,EACAtD,EAA8B,CAAA,EACX,CACnB,MAAM+D,EAAO,CAAE,GAAGF,GAAiB,GAAG7D,CAAA,EAEtC,GAAI,CAAC5P,GAAQ,CAACkT,EACZ,MAAO,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,EAGhD,MAAMU,EAAiB5T,EAAK,YAAA,EACtB6T,EAAmBX,EAAO,YAAA,EAG1BY,EAAaC,GAAgBH,EAAgBC,CAAgB,EACnE,GAAIC,EAAW,QACb,MAAO,CAAE,GAAGA,EAAY,MAAO,EAAK,UAAW,OAAA,EAIjD,GAAIH,EAAK,WACP,MAAO,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,EAIhD,MAAMK,EAAaC,GAAgBL,EAAgBC,EAAkBF,EAAK,gBAAiBA,EAAK,iBAAiB,EACjH,GAAIK,EAAW,QACb,MAAO,CAAE,GAAGA,EAAY,UAAW,OAAA,EAIrC,MAAME,EAAiBC,GAAmBP,EAAgBC,EAAkBF,EAAK,oBAAoB,EACrG,OAAIO,EAAe,QACV,CAAE,GAAGA,EAAgB,UAAW,WAAA,EAGlC,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,CAChD,CAKA,SAASH,GAEP/T,EACAkT,EACmB,CACnB,MAAM1E,EAAQxO,EAAK,QAAQkT,CAAM,EAEjC,OAAI1E,IAAU,GACL,CACL,QAAS,GACT,MAAO,EACP,UAAW,QACX,SAAUA,EACV,OAAQA,EAAQ0E,EAAO,MAAA,EAIpB,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,CAChD,CAKA,SAASe,GAEPjU,EACAkT,EACAkB,EACA/H,EACmB,CACnB,MAAMgI,EAAcnB,EAAO,MAAM,KAAK,EAChCoB,EAAYtU,EAAK,MAAM,KAAK,EAGlC,QAASK,EAAI,EAAGA,GAAKiU,EAAU,OAASD,EAAY,OAAQhU,IAAK,CAC/D,MAAMkU,EAAUD,EAAU,MAAMjU,EAAGA,EAAIgU,EAAY,MAAM,EAGzD,IAAIG,EAAgB,EAChBC,EAAW,GAEf,QAASpT,EAAI,EAAGA,EAAIgT,EAAY,OAAQhT,IAAK,CAC3C,MAAM0E,EAAWsG,EAAoB3H,EAAoC2P,EAAYhT,CAAC,EAAGkT,EAAQlT,CAAC,EAAG+S,CAAe,EAAI/P,EAA6BgQ,EAAYhT,CAAC,EAAGkT,EAAQlT,CAAC,EAAG+S,CAAe,EAEhM,GAAIrO,EAAWqO,EAAiB,CAC9BK,EAAW,GACX,KACF,CACAD,GAAiBzO,CACnB,CAEA,GAAI0O,EAAU,CAEZ,MAAMC,EAAsBL,EAAY,OAASD,EAGjD,MAAO,CACL,QAAS,GACT,MAJYM,EAAsB,EAAI,GAAM,IAAO,EAAIF,EAAgBE,GAAuB,GAK9F,UAAW,QACX,aAAcH,CAAA,CAElB,CACF,CAEA,MAAO,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,CAChD,CAKA,SAASJ,GAEPnU,EACAkT,EACA5O,EACmB,CACnB,MAAM+P,EAAcnB,EAAO,MAAM,KAAK,EAChCoB,EAAYtU,EAAK,MAAM,KAAK,EAG5BqS,EAAwBgC,EAAY,IAAI,IAAM,CAAA,CAAE,EAWtD,GATAC,EAAU,QAAQ,CAACrU,EAAMuO,IAAU,CACjC6F,EAAY,QAAQ,CAACM,EAAYC,IAAgB,EAC3C3U,IAAS0U,GAAc1U,EAAK,SAAS0U,CAAU,GAAKA,EAAW,SAAS1U,CAAI,IAC9EoS,EAAUuC,CAAW,EAAE,KAAKpG,CAAK,CAErC,CAAC,CACH,CAAC,EAGG6D,EAAU,KAAMpJ,GAAMA,EAAE,SAAW,CAAC,EACtC,MAAO,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,EAIhD,IAAI4L,EAAe,IACfC,EAA0B,CAAA,EAE9B,SAASC,EAAoBC,EAAmBC,EAAkC,CAChF,GAAID,IAAcX,EAAY,OAAQ,CAEpC,MAAM5F,EAAS,CAAC,GAAGwG,CAAgB,EAAE,KAAK,CAACpI,EAAG6B,IAAM7B,EAAI6B,CAAC,EACnD3I,EAAW0I,EAAOA,EAAO,OAAS,CAAC,EAAIA,EAAO,CAAC,EAEjD1I,EAAW8O,IACbA,EAAe9O,EACf+O,EAAgB,CAAC,GAAGG,CAAgB,GAEtC,MACF,CAEA,UAAWC,KAAO7C,EAAU2C,CAAS,EACnCD,EAAoBC,EAAY,EAAG,CAAC,GAAGC,EAAkBC,CAAG,CAAC,CAEjE,CAKA,OAHAH,EAAoB,EAAG,EAAE,EAGrBF,GAAgBvQ,EAIX,CACL,QAAS,GACT,MAJY,GAAM,IAAO,EAAIuQ,EAAevQ,GAK5C,UAAW,YACX,aAAcwQ,EAAc,IAAKzU,GAAMiU,EAAUjU,CAAC,CAAC,CAAA,EAIhD,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,CAChD,CCtMO,SAAS8U,GAAgBnV,EAAwB,CACtD,GAAI,CAACA,GAAQA,EAAK,KAAA,EAAO,SAAW,EAClC,MAAO,CAAC,SAAS,EAGnB,MAAMoV,MAAe,IAGrB,OAAAA,EAAS,IAAI,SAAS,EAGlB,YAAY,KAAKpV,CAAI,GACvBoV,EAAS,IAAI,QAAQ,EAInB,uCAAuC,KAAKpV,CAAI,GAClDoV,EAAS,IAAI,QAAQ,EAInB,qBAAqB,KAAKpV,CAAI,GAChCoV,EAAS,IAAI,SAAS,EAGjB,MAAM,KAAKA,CAAQ,CAC5B,CASO,SAASC,GAA8BrV,EAAuC,CACnF,GAAI,CAACA,GAAQA,EAAK,KAAA,EAAO,SAAW,EAClC,MAAO,CACL,UAAW,CAAC,SAAS,EACrB,WAAY,CAAE,QAAS,CAAA,EACvB,QAAS,SAAA,EAIb,MAAMsV,EAAqC,CACzC,QAAS,EAAA,EAGLC,EAAavV,EAAK,OAGlBwV,GAAexV,EAAK,MAAM,YAAY,GAAK,CAAA,GAAI,OACjDwV,EAAc,IAChBF,EAAW,OAAS,KAAK,IAAI,EAAK,GAAOE,EAAcD,EAAc,EAAE,GAIzE,MAAME,GAAezV,EAAK,MAAM,uCAAuC,GAAK,CAAA,GAAI,OAC5EyV,EAAc,IAChBH,EAAW,OAAS,KAAK,IAAI,EAAK,GAAOG,EAAcF,EAAc,EAAE,GAIzE,MAAMG,GAAgB1V,EAAK,MAAM,qBAAqB,GAAK,CAAA,GAAI,OAC3D0V,EAAe,IACjBJ,EAAW,QAAU,KAAK,IAAI,EAAK,GAAOI,EAAeH,EAAc,EAAE,GAI3E,MAAMtS,EAAY,OAAO,QAAQqS,CAAU,EACxC,OAAO,CAAC,CAACK,EAAGC,CAAI,IAAMA,GAAQ,EAAG,EACjC,IAAI,CAAC,CAACjW,CAAI,IAAMA,CAAI,EAGjBkW,EAAU,OAAO,QAAQP,CAAU,EACtC,KAAK,CAAC,CAAA,CAAGzI,CAAC,EAAG,CAAA,CAAG6B,CAAC,IAAMA,EAAI7B,CAAC,EAAE,CAAC,EAAE,CAAC,EAErC,MAAO,CACL,UAAA5J,EACA,WAAAqS,EACA,QAAAO,CAAA,CAEJ,CAUO,SAASC,GAAuB7L,EAAyB8L,EAAqB,IAAa,CAGhG,OAFe9L,EAAM,MAAM,EAAG,KAAK,IAAI8L,EAAY9L,EAAM,MAAM,CAAC,EAG7D,IAAIxE,GACC,OAAOA,GAAS,SACXA,EACE,OAAOA,GAAS,UAAYA,IAAS,KAEvC,OAAO,OAAOA,CAAI,EACtB,OAAOuQ,GAAK,OAAOA,GAAM,QAAQ,EACjC,KAAK,GAAG,EAEN,EACR,EACA,KAAK,GAAG,CACb,CAKO,SAASC,GAAgBtW,EAAuB,CAErD,MADuB,CAAC,UAAW,SAAU,SAAU,UAAW,MAAM,EAClD,SAASA,EAAK,YAAA,CAAa,CACnD,CAMO,SAASuW,GAAsBvW,EAAsB,CAC1D,MAAMO,EAAaP,EAAK,YAAA,EAAc,KAAA,EActC,MAXwC,CACtC,GAAM,UACN,GAAM,SACN,GAAM,SACN,GAAM,UACN,IAAO,UACP,IAAO,SACP,IAAO,SACP,IAAO,SAAA,EAGMO,CAAU,GAAKA,CAChC,CC9JO,MAAMiW,EAAY,CACvB,KAAM,OACN,OAAQ,SACR,IAAK,MACL,GAAI,KACJ,IAAK,MACL,OAAQ,SACR,OAAQ,SACR,MAAO,QACP,MAAO,QACP,MAAO,QACP,SAAU,WACV,OAAQ,SACR,MAAO,QACP,SAAU,WACV,KAAM,OACN,MAAO,QACP,SAAU,WACV,OAAQ,SACR,IAAK,KACP,EAUO,MAAMC,EAAS,CACZ,MAAgB,GAChB,SAAmB,EACnB,OAAkB,CAAA,EAK1B,SAASC,EAAwB,CAK/B,IAJA,KAAK,MAAQA,EAAM,KAAA,EACnB,KAAK,SAAW,EAChB,KAAK,OAAS,CAAA,EAEP,KAAK,SAAW,KAAK,MAAM,SAChC,KAAK,eAAA,EAED,OAAK,UAAY,KAAK,MAAM,UAHQ,CAKxC,MAAM/V,EAAO,KAAK,MAAM,KAAK,QAAQ,EAGrC,GAAIA,IAAS,IAAK,CAChB,KAAK,OAAO,KAAK,CAAE,KAAM6V,EAAU,OAAQ,MAAO,IAAK,SAAU,KAAK,QAAA,CAAU,EAChF,KAAK,WACL,QACF,CAEA,GAAI7V,IAAS,IAAK,CAChB,KAAK,OAAO,KAAK,CAAE,KAAM6V,EAAU,OAAQ,MAAO,IAAK,SAAU,KAAK,QAAA,CAAU,EAChF,KAAK,WACL,QACF,CAGA,GAAI7V,IAAS,IAAK,CAChB,KAAK,OAAO,KAAK,CAAE,KAAM6V,EAAU,MAAO,MAAO,IAAK,SAAU,KAAK,QAAA,CAAU,EAC/E,KAAK,WACL,QACF,CAGA,GAAI7V,IAAS,KAAOA,IAAS,IAAK,CAChC,KAAK,qBAAqBA,CAAI,EAC9B,QACF,CAGA,GAAI,KAAK,QAAQA,CAAI,EAAG,CACtB,KAAK,eAAA,EACL,QACF,CAGA,GAAI,KAAK,QAAQA,CAAI,EAAG,CACtB,KAAK,sBAAA,EACL,QACF,CAGA,GAAIA,IAAS,KAAOA,IAAS,IAAK,CAChC,KAAK,sBAAA,EACL,QACF,CAGA,KAAK,UACP,CAGA,YAAK,OAAO,KAAK,CAAE,KAAM6V,EAAU,IAAK,MAAO,GAAI,SAAU,KAAK,QAAA,CAAU,EAErE,KAAK,MACd,CAEQ,gBAAuB,CAC7B,KAAO,KAAK,SAAW,KAAK,MAAM,QAAU,KAAK,KAAK,KAAK,MAAM,KAAK,QAAQ,CAAC,GAC7E,KAAK,UAET,CAEQ,QAAQ7V,EAAuB,CACrC,MAAO,mEAAmE,KAAKA,CAAI,CACrF,CAEQ,QAAQA,EAAuB,CACrC,MAAO,SAAS,KAAKA,CAAI,CAC3B,CAEQ,eAAeA,EAAuB,CAC5C,OAAO,KAAK,QAAQA,CAAI,GAAK,KAAK,QAAQA,CAAI,CAChD,CAEQ,qBAAqBgW,EAAqB,CAChD,MAAMjI,EAAQ,KAAK,SACnB,KAAK,WAEL,IAAImB,EAAQ,GACZ,KAAO,KAAK,SAAW,KAAK,MAAM,QAAU,KAAK,MAAM,KAAK,QAAQ,IAAM8G,GACxE9G,GAAS,KAAK,MAAM,KAAK,QAAQ,EACjC,KAAK,WAGP,GAAI,KAAK,UAAY,KAAK,MAAM,OAC9B,MAAM,IAAI,MAAM,8BAA8BnB,CAAK,EAAE,EAGvD,KAAK,WAEL,KAAK,OAAO,KAAK,CAAE,KAAM8H,EAAU,OAAQ,MAAA3G,EAAO,SAAUnB,EAAO,CACrE,CAEQ,gBAAuB,CAC7B,MAAMA,EAAQ,KAAK,SACnB,IAAImB,EAAQ,GAEZ,KAAO,KAAK,SAAW,KAAK,MAAM,QAAU,KAAK,QAAQ,KAAK,MAAM,KAAK,QAAQ,CAAC,GAChFA,GAAS,KAAK,MAAM,KAAK,QAAQ,EACjC,KAAK,WAGP,KAAK,OAAO,KAAK,CAAE,KAAM2G,EAAU,OAAQ,MAAA3G,EAAO,SAAUnB,EAAO,CACrE,CAEQ,uBAA8B,CACpC,MAAMA,EAAQ,KAAK,SACnB,IAAImB,EAAQ,GAEZ,KAAO,KAAK,SAAW,KAAK,MAAM,QAAU,KAAK,eAAe,KAAK,MAAM,KAAK,QAAQ,CAAC,GACvFA,GAAS,KAAK,MAAM,KAAK,QAAQ,EACjC,KAAK,WAGP,MAAM+G,EAAa/G,EAAM,YAAA,EAGzB,OAAQ+G,EAAA,CACN,IAAK,MACH,KAAK,OAAO,KAAK,CAAE,KAAMJ,EAAU,IAAK,MAAOI,EAAY,SAAUlI,CAAA,CAAO,EAC5E,MACF,IAAK,KACH,KAAK,OAAO,KAAK,CAAE,KAAM8H,EAAU,GAAI,MAAOI,EAAY,SAAUlI,CAAA,CAAO,EAC3E,MACF,IAAK,MACH,KAAK,OAAO,KAAK,CAAE,KAAM8H,EAAU,IAAK,MAAOI,EAAY,SAAUlI,CAAA,CAAO,EAC5E,MACF,IAAK,QACH,KAAK,OAAO,KAAK,CAAE,KAAM8H,EAAU,MAAO,MAAOI,EAAY,SAAUlI,CAAA,CAAO,EAC9E,MACF,IAAK,QACH,KAAK,OAAO,KAAK,CAAE,KAAM8H,EAAU,MAAO,MAAOI,EAAY,SAAUlI,CAAA,CAAO,EAC9E,MACF,IAAK,WACH,KAAK,OAAO,KAAK,CAAE,KAAM8H,EAAU,SAAU,MAAOI,EAAY,SAAUlI,CAAA,CAAO,EACjF,MACF,IAAK,SACH,KAAK,OAAO,KAAK,CAAE,KAAM8H,EAAU,OAAQ,MAAOI,EAAY,SAAUlI,CAAA,CAAO,EAC/E,MACF,IAAK,QACH,KAAK,OAAO,KAAK,CAAE,KAAM8H,EAAU,MAAO,MAAOI,EAAY,SAAUlI,CAAA,CAAO,EAC9E,MACF,IAAK,WACH,KAAK,OAAO,KAAK,CAAE,KAAM8H,EAAU,SAAU,MAAOI,EAAY,SAAUlI,CAAA,CAAO,EACjF,MACF,IAAK,OACH,KAAK,OAAO,KAAK,CAAE,KAAM8H,EAAU,KAAM,MAAOI,EAAY,SAAUlI,CAAA,CAAO,EAC7E,MACF,IAAK,QACH,KAAK,OAAO,KAAK,CAAE,KAAM8H,EAAU,MAAO,MAAOI,EAAY,SAAUlI,CAAA,CAAO,EAC9E,MACF,QAEE,KAAK,OAAO,KAAK,CAAE,KAAM8H,EAAU,KAAM,MAAA3G,EAAO,SAAUnB,EAAO,EACjE,KAAA,CAEN,CAEQ,uBAA8B,CACpC,MAAMA,EAAQ,KAAK,SACnB,IAAImB,EAAQ,KAAK,MAAM,KAAK,QAAQ,EACpC,KAAK,WAGD,KAAK,SAAW,KAAK,MAAM,QAAU,KAAK,MAAM,KAAK,QAAQ,IAAM,MACrEA,GAAS,IACT,KAAK,YAGP,KAAK,OAAO,KAAK,CAAE,KAAM2G,EAAU,SAAU,MAAA3G,EAAO,SAAUnB,EAAO,CACvE,CACF,CCvNO,MAAMmI,UAAuB,KAAM,CACjC,SAEP,YAAYC,EAAiB/E,EAAkB,CAC7C,MAAM+E,CAAO,EACb,KAAK,KAAO,iBACZ,KAAK,SAAW/E,CAClB,CACF,CAEO,MAAMgF,EAAU,CACb,OAAkB,CAAA,EAClB,QAAkB,EAK1B,MAAMC,EAA0B,CAI9B,GAHA,KAAK,OAASA,EACd,KAAK,QAAU,EAEX,KAAK,OAAO,SAAW,GAAK,KAAK,OAAO,CAAC,EAAE,OAASR,EAAU,IAChE,MAAM,IAAIK,EAAe,cAAe,CAAC,EAG3C,MAAMI,EAAM,KAAK,gBAAA,EAGjB,GAAI,CAAC,KAAK,UACR,MAAM,IAAIJ,EAAe,qBAAqB,KAAK,KAAA,EAAO,KAAK,iBAAiB,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAG9H,OAAOI,CACT,CAKQ,iBAA2B,CACjC,OAAO,KAAK,kBAAA,CACd,CAKQ,mBAA6B,CACnC,IAAIC,EAAO,KAAK,mBAAA,EAEhB,KAAO,KAAK,MAAMV,EAAU,EAAE,GAAG,CAC/B,MAAMW,EAAQ,KAAK,mBAAA,EACnBD,EAAO,CACL,KAAM,KACN,KAAAA,EACA,MAAAC,CAAA,CAEJ,CAEA,OAAOD,CACT,CAKQ,oBAA8B,CACpC,IAAIA,EAAO,KAAK,mBAAA,EAEhB,KAAO,KAAK,MAAMV,EAAU,GAAG,GAAG,CAChC,MAAMW,EAAQ,KAAK,mBAAA,EACnBD,EAAO,CACL,KAAM,MACN,KAAAA,EACA,MAAAC,CAAA,CAEJ,CAEA,OAAOD,CACT,CAKQ,oBAA8B,CACpC,OAAI,KAAK,MAAMV,EAAU,GAAG,EAEnB,CACL,KAAM,MACN,MAHY,KAAK,aAAA,CAGjB,EAIG,KAAK,aAAA,CACd,CAKQ,cAAwB,CAE9B,GAAI,KAAK,MAAMA,EAAU,MAAM,EAAG,CAChC,MAAMY,EAAO,KAAK,gBAAA,EAClB,GAAI,CAAC,KAAK,MAAMZ,EAAU,MAAM,EAC9B,MAAM,IAAIK,EAAe,4BAA4B,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAEnG,OAAOO,CACT,CAGA,GAAI,KAAK,MAAMZ,EAAU,KAAK,GAAK,KAAK,MAAMA,EAAU,KAAK,GAAK,KAAK,MAAMA,EAAU,QAAQ,GAAK,KAAK,MAAMA,EAAU,MAAM,GAAK,KAAK,MAAMA,EAAU,KAAK,GAAK,KAAK,MAAMA,EAAU,QAAQ,EAC9L,OAAO,KAAK,YAAA,EAId,GAAI,KAAK,MAAMA,EAAU,IAAI,EAC3B,OAAO,KAAK,UAAA,EAId,GAAI,KAAK,MAAMA,EAAU,MAAM,EAAG,CAEhC,MAAMjD,EAAqB,CACzB,KAAM,SACN,MAHY,KAAK,QAAA,EAGJ,KAAA,EAIf,OAAI,KAAK,MAAMiD,EAAU,KAAK,EACrB,KAAK,WAAWjD,CAAM,EAGxBA,CACT,CAGA,GAAI,KAAK,MAAMiD,EAAU,IAAI,EAAG,CAC9B,MAAMa,EAAQ,KAAK,QAAA,EAGnB,GAAI,KAAK,MAAMb,EAAU,KAAK,EAAG,CAC/B,MAAM1P,EAAQ,KAAK,aAAA,EAMnB,MALyB,CACvB,KAAM,QACN,MAAOuQ,EAAM,MACb,MAAAvQ,CAAA,CAGJ,CAGA,MAAML,EAAiB,CACrB,KAAM,OACN,MAAO4Q,EAAM,KAAA,EAIf,OAAI,KAAK,MAAMb,EAAU,KAAK,EACrB,KAAK,WAAW/P,CAAI,EAGtBA,CACT,CAEA,MAAM,IAAIoQ,EAAe,qBAAqB,KAAK,KAAA,EAAO,KAAK,iBAAiB,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,CAC9H,CAKQ,aAAuB,CAC7B,MAAMS,EAAc,KAAK,QAAA,EACnBC,EAAaD,EAAY,MAAM,YAAA,EAErC,GAAI,CAAC,KAAK,MAAMd,EAAU,KAAK,EAC7B,MAAM,IAAIK,EAAe,sBAAsBS,EAAY,KAAK,gBAAgB,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAG9H,IAAIzH,EAEJ,GAAI,KAAK,MAAM2G,EAAU,MAAM,EAC7B3G,EAAQ,KAAK,UAAU,cACd,KAAK,MAAM2G,EAAU,IAAI,EAClC3G,EAAQ,KAAK,UAAU,UAEvB,OAAM,IAAIgH,EAAe,wBAAwBS,EAAY,KAAK,iBAAiB,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAGjI,MAAMrN,EAAqB,CACzB,KAAM,SACN,WAAAsN,EACA,MAAA1H,CAAA,EAIF,OAAI,KAAK,MAAM2G,EAAU,KAAK,EACrB,KAAK,WAAWvM,CAAM,EAGxBA,CACT,CAKQ,WAAsB,CAG5B,GAFA,KAAK,QAAA,EAED,CAAC,KAAK,MAAMuM,EAAU,KAAK,EAC7B,MAAM,IAAIK,EAAe,uCAAuC,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAG9G,GAAI,CAAC,KAAK,MAAML,EAAU,IAAI,EAC5B,MAAM,IAAIK,EAAe,kDAAkD,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAGzH,MAAMxT,EAAW,KAAK,QAAA,EAAU,MAC1ByD,EAAQ,KAAK,aAAA,EAEnB,MAAO,CACL,KAAM,OACN,SAAAzD,EACA,MAAAyD,CAAA,CAEJ,CAKQ,WAAWA,EAA2B,CAG5C,GAFA,KAAK,QAAA,EAED,CAAC,KAAK,MAAM0P,EAAU,QAAQ,EAChC,MAAM,IAAIK,EAAe,sDAAsD,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAG7H,MAAMW,EAAW,KAAK,QAAA,EAAU,MAEhC,GAAI,CAAC,KAAK,MAAMhB,EAAU,MAAM,EAC9B,MAAM,IAAIK,EAAe,yBAAyBW,CAAQ,gBAAgB,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAGxH,MAAMjR,EAAY,WAAW,KAAK,QAAA,EAAU,KAAK,EAEjD,GAAI,MAAMA,CAAS,GAAKA,EAAY,GAAKA,EAAY,EACnD,MAAM,IAAIsQ,EAAe,0CAA2C,KAAK,SAAA,EAAW,QAAQ,EAG9F,MAAO,CACL,KAAM,QACN,SAAAW,EACA,UAAAjR,EACA,MAAAO,CAAA,CAEJ,CAIQ,SAAS2Q,EAA6B,CAC5C,UAAWlJ,KAAQkJ,EACjB,GAAI,KAAK,MAAMlJ,CAAI,EACjB,YAAK,QAAA,EACE,GAGX,MAAO,EACT,CAEQ,MAAMA,EAA0B,CACtC,OAAI,KAAK,QAAA,EAAkB,GACpB,KAAK,OAAO,OAASA,CAC9B,CAEQ,SAAiB,CACvB,OAAK,KAAK,WAAW,KAAK,UACnB,KAAK,SAAA,CACd,CAEQ,SAAmB,CACzB,OAAO,KAAK,KAAA,EAAO,OAASiI,EAAU,GACxC,CAEQ,MAAc,CACpB,OAAO,KAAK,OAAO,KAAK,OAAO,CACjC,CAEQ,UAAkB,CACxB,OAAO,KAAK,OAAO,KAAK,QAAU,CAAC,CACrC,CACF,CC/MO,SAASkB,GAAW/Q,EAAiC,CAC1D,OAAOA,EAAK,OAAS,MACvB,CAEO,SAASgR,GAAahR,EAAmC,CAC9D,OAAOA,EAAK,OAAS,QACvB,CAEO,SAASiR,GAAUjR,EAAgC,CACxD,OAAOA,EAAK,OAAS,KACvB,CAEO,SAASkR,GAASlR,EAA+B,CACtD,OAAOA,EAAK,OAAS,IACvB,CAEO,SAASmR,GAAUnR,EAAgC,CACxD,OAAOA,EAAK,OAAS,KACvB,CAEO,SAASoR,GAAapR,EAAmC,CAC9D,OAAOA,EAAK,OAAS,QACvB,CAEO,SAASqR,GAAYrR,EAAkC,CAC5D,OAAOA,EAAK,OAAS,OACvB,CAEO,SAASsR,GAAYtR,EAAkC,CAC5D,OAAOA,EAAK,OAAS,OACvB,CAEO,SAASuR,GAAWvR,EAAiC,CAC1D,OAAOA,EAAK,OAAS,MACvB,CChHO,MAAMwR,WAAwB,KAAM,CACzC,YAAYrB,EAAiB,CAC3B,MAAMA,CAAO,EACb,KAAK,KAAO,iBACd,CACF,CAEO,MAAMsB,EAAY,CACf,MACA,QACA,UAAoB,EACpB,QAAkB,IAE1B,YAAYvJ,EAAmBoB,EAAyB,GAAI,CAC1D,KAAK,MAAQpB,EACb,KAAK,QAAUoB,EACf,KAAK,QAAUA,EAAQ,YAAY,SAAW,GAChD,CAKA,QAAQgH,EAAkC,CACxC,YAAK,UAAY,KAAK,IAAA,EACf,KAAK,YAAYA,CAAG,CAC7B,CAEQ,cAAqB,CAC3B,GAAI,KAAK,IAAA,EAAQ,KAAK,UAAY,KAAK,QACrC,MAAM,IAAIkB,GAAgB,iCAAiC,KAAK,OAAO,IAAI,CAE/E,CAEQ,YAAYxR,EAAmC,CAGrD,OAFA,KAAK,aAAA,EAEDiR,GAAUjR,CAAI,EACT,KAAK,WAAWA,CAAI,EAGzBkR,GAASlR,CAAI,EACR,KAAK,UAAUA,CAAI,EAGxBmR,GAAUnR,CAAI,EACT,KAAK,WAAWA,CAAI,EAGzB+Q,GAAW/Q,CAAI,EACV,KAAK,YAAYA,EAAK,KAAK,EAGhCgR,GAAahR,CAAI,EACZ,KAAK,cAAcA,EAAK,KAAK,EAGlCoR,GAAapR,CAAI,EACZ,KAAK,cAAcA,CAAI,EAG5BqR,GAAYrR,CAAI,EACX,KAAK,aAAaA,CAAI,EAG3BsR,GAAYtR,CAAI,EACX,KAAK,aAAaA,CAAI,EAG3BuR,GAAWvR,CAAI,EACV,KAAK,YAAYA,CAAI,EAGvB,CAAA,CACT,CAKQ,WAAWA,EAA6D,CAC9E,MAAM0R,EAAc,KAAK,YAAY1R,EAAK,IAAI,EACxC2R,EAAe,KAAK,YAAY3R,EAAK,KAAK,EAG1C4R,EAAgB,IAAI,IAAID,EAAa,IAAKE,GAAMA,EAAE,OAAO,CAAC,EAIhE,OAHqBH,EAAY,OAAQG,GAAMD,EAAc,IAAIC,EAAE,OAAO,CAAC,EAGvD,KAAK,CAAC,EAAGzJ,IAAMA,EAAE,MAAQ,EAAE,KAAK,CACtD,CAKQ,UAAUpI,EAA6D,CAC7E,MAAM0R,EAAc,KAAK,YAAY1R,EAAK,IAAI,EACxC2R,EAAe,KAAK,YAAY3R,EAAK,KAAK,EAG1C8R,MAAgB,IAEtB,UAAWnT,KAAU+S,EACnBI,EAAU,IAAInT,EAAO,QAASA,CAAM,EAGtC,UAAWA,KAAUgT,EAAc,CACjC,MAAMI,EAAWD,EAAU,IAAInT,EAAO,OAAO,GAEzC,CAACoT,GAAYpT,EAAO,MAAQoT,EAAS,QACvCD,EAAU,IAAInT,EAAO,QAASA,CAAM,CAExC,CAGA,OAAO,MAAM,KAAKmT,EAAU,OAAA,CAAQ,EAAE,KAAK,CAACvL,EAAG6B,IAAMA,EAAE,MAAQ7B,EAAE,KAAK,CACxE,CAKQ,WAAWvG,EAA8C,CAC/D,MAAMgS,EAAe,KAAK,YAAYhS,EAAK,KAAK,EAC1CiS,EAAkB,IAAI,IAAID,EAAa,IAAK,GAAM,EAAE,OAAO,CAAC,EAIlE,OADmBE,EAAe,KAAK,MAAO,GAAI,KAAK,MAAM,KAAK,OAAQ,KAAK,OAAO,EACpE,OAAQ,GAAM,CAACD,EAAgB,IAAI,EAAE,OAAO,CAAC,EAAE,KAAK,CAAC1L,EAAG6B,IAAMA,EAAE,MAAQ7B,EAAE,KAAK,CACnG,CAKQ,YAAYzG,EAAkC,CACpD,OAAOoS,EAAe,KAAK,MAAOpS,EAAM,KAAK,MAAM,KAAK,OAAQ,KAAK,OAAO,CAC9E,CAKQ,cAAc8M,EAAoC,CAExD,OAAOsF,EAAe,KAAK,MAAO,IAAItF,CAAM,IAAK,KAAK,MAAM,KAAK,OAAQ,KAAK,OAAO,CACvF,CAKQ,cAAc5M,EAAiE,CACrF,KAAM,CAAE,WAAA4Q,EAAY,MAAA1H,CAAA,EAAUlJ,EAGxBE,EAAUgS,EAAe,KAAK,MAAOhJ,EAAO,KAAK,MAAM,KAAK,OAAQ,KAAK,OAAO,EAGtF,OAAQ0H,EAAA,CACN,IAAK,QACH,OAAO1Q,EAAQ,OAAQ,GAAO,EAAU,mBAAqB,OAAO,EAEtE,IAAK,QACH,OAAOA,EAAQ,OAAQ,GAAO,EAAU,mBAAqB,OAAO,EAEtE,IAAK,WACH,OAAOA,EAAQ,OAAQ,GAAO,EAAU,mBAAqB,UAAU,EAEzE,IAAK,SACH,OAAOA,EAAQ,OAAQ,GAAO,EAAU,mBAAqB,QAAQ,EAEvE,IAAK,WACH,OAAOA,EAAQ,OAAQ,GAAO,EAAU,mBAAqB,UAAU,EAEzE,IAAK,QACH,OAAO,KAAK,aAAagJ,CAAK,EAEhC,QACE,OAAOhJ,CAAA,CAEb,CAKQ,aAAa2L,EAAqC,CAExD,GAAI,CAAC,KAAK,QAAQ,YAAY,WAC5B,MAAM,IAAI,MAAM,qDAAqD,EAGvE,GAAI,CACF,MAAMsG,EAAQ,IAAI,OAAOtG,CAAO,EAC1B3L,EAA8B,CAAA,EAEpC,UAAWvG,KAAQ,KAAK,MAAM,KACxBwY,EAAM,KAAKxY,CAAI,GACjBuG,EAAQ,KAAK,CACX,QAASvG,EACT,SAAUA,EACV,MAAO,EACP,UAAW,GACX,SAAU,UACV,iBAAkB,OAAA,CACZ,EAIZ,OAAOuG,CACT,MAAgB,CACd,MAAM,IAAI,MAAM,0BAA0B2L,CAAO,EAAE,CACrD,CACF,CAKQ,aAAa7L,EAA6D,CAEhF,MAAMgS,EAAe,KAAK,YAAYhS,EAAK,KAAK,EAGhD,OAAK,KAAK,MAAM,UAMTgS,EAAa,OAAQrT,GACtBA,EAAO,QAAUqB,EAAK,KAI3B,EATQgS,CAUX,CAKQ,aAAahS,EAAmF,CACtG,MAAMgS,EAAe,KAAK,YAAYhS,EAAK,KAAK,EAC1C,CAAE,SAAA6Q,EAAU,UAAAjR,CAAA,EAAcI,EAEhC,OAAOgS,EAAa,OAAQrT,GAAW,CACrC,OAAQkS,EAAA,CACN,IAAK,IACH,OAAOlS,EAAO,MAAQiB,EACxB,IAAK,IACH,OAAOjB,EAAO,MAAQiB,EACxB,IAAK,KACH,OAAOjB,EAAO,OAASiB,EACzB,IAAK,KACH,OAAOjB,EAAO,OAASiB,EACzB,QACE,MAAO,EAAA,CAEb,CAAC,CACH,CAKQ,YAAYI,EAAgE,CAClF,MAAMgS,EAAe,KAAK,YAAYhS,EAAK,KAAK,EAC1CoS,EAAapS,EAAK,SAAS,YAAA,EAEjC,OAAOgS,EAAa,OAAQrT,GACnBA,EAAO,UAAU,YAAA,IAAkByT,CAC3C,CACH,CACF,CCvQO,SAASC,GAAWvN,EAAwB,CACjD,MAAMwN,EAAUxN,EAAM,KAAA,EACtB,OAAOwN,EAAQ,WAAW,MAAM,GAAKA,EAAQ,SAAS,GAAG,CAC3D,CAKO,SAASC,GAAgBzN,EAAuB,CACrD,MAAMwN,EAAUxN,EAAM,KAAA,EACtB,GAAI,CAACuN,GAAWC,CAAO,EACrB,MAAM,IAAI,MAAM,oDAAoD,EAItE,OAAOA,EAAQ,MAAM,EAAG,EAAE,EAAE,KAAA,CAC9B,CAKO,SAASE,GACdtK,EACApD,EACAuE,EACAC,EAAyB,CAAA,EACL,CACpB,GAAI,CAEF,MAAMmJ,EAAWF,GAAgBzN,CAAK,EAIhCuL,EADQ,IAAIP,GAAA,EACG,SAAS2C,CAAQ,EAIhCnC,EADS,IAAIF,GAAA,EACA,MAAMC,CAAM,EAIzBnQ,EADW,IAAIuR,GAAYvJ,EAAOoB,CAAO,EACtB,QAAQgH,CAAG,EAG9BoC,EAAQrJ,GAAcC,EAAQ,YAAc,GAClD,OAAOpJ,EAAQ,MAAM,EAAGwS,CAAK,CAC/B,OAASC,EAAO,CAEd,MAAIA,aAAiBzC,GAAkByC,aAAiBnB,GAChDmB,EAIF,IAAI,MAAM,wBAAyBA,EAAgB,OAAO,EAAE,CACpE,CACF,CC+BO,SAASC,GAAgBjP,EAA0B,GAAI2F,EAA6B,CAAA,EAAgB,CAEzG,MAAMuJ,EAAyBvJ,EAAQ,QAAQ,UACzCwJ,EAAmB,CAACD,GAA0BA,EAAuB,SAAS,MAAM,EAEpFrZ,EAAST,GAAYuQ,EAAQ,MAAM,EAEzC,GAAIwJ,EAAkB,CACpB,MAAMC,EAAavD,GAAuB7L,EAAO,GAAG,EAC9CqP,EAAoBnE,GAAgBkE,CAAU,EACpDvZ,EAAO,UAAYwZ,CACrB,CAEAzZ,GAAeC,CAAM,EAGrB,MAAMqK,EAAa,IAAI,IAAIrK,EAAO,QAAQ,EAEpCoK,EAAqB0F,EAAQ,oBAAsB7M,EAAiB,cAAcjD,EAAO,SAAS,EAExG,GAAIoK,EAAmB,SAAW,EAChC,MAAM,IAAI,MAAM,qCAAqCpK,EAAO,UAAU,KAAK,IAAI,CAAC,EAAE,EAIpF,MAAMyZ,EAAY3J,EAAQ,QAAUA,EAAQ,OAAO,OAAS,EACtD4J,EAAgBvP,EAAM,OAAS,GAAK,OAAOA,EAAM,CAAC,GAAM,UAAYA,EAAM,CAAC,IAAM,KAGvF,GAAIuP,GAAiB,CAACD,EACpB,MAAM,IAAI,MAAM,kFAAkF,EAGpG,MAAM/K,EAAoB,CACxB,KAAM,CAAA,EACN,kBAAmB,IACnB,mBAAoB,IACpB,eAAgB,IAChB,eAAgB,IAChB,uBAAwB,IACxB,OAAA1O,CAAA,EAIEyZ,IACF/K,EAAM,OAASoB,EAAQ,OACvBpB,EAAM,aAAesC,GAAsBlB,EAAQ,OAASA,EAAQ,YAAY,EAChFpB,EAAM,cAAgB,KAIxBtE,EAAmB,QAAShH,GAAc,CACxCsL,EAAM,mBAAmB,IAAItL,EAAU,SAAUA,CAAS,CAC5D,CAAC,EAED,MAAMuW,MAAqB,IAC3B,IAAIC,EAAY,EAEhB,UAAWjU,KAAQwE,EACjB,GAAKxE,EAGL,IAAI8T,GAAaC,EAAe,CAC9B,MAAM5I,EAAcF,GAAmBjL,EAAMmK,EAAQ,MAAM,EAC3D,GAAI,CAACgB,EAAa,SAGlB,MAAM+I,EAAS,OAAO,OAAO/I,CAAW,EAAE,CAAC,GAAK,QAAQ8I,CAAS,GAGjElL,EAAM,UAAW,IAAImL,EAAQ/I,CAAW,EAGxC,SAAW,CAACgJ,EAAWC,CAAU,IAAK,OAAO,QAAQjJ,CAAW,EAAG,CACjE,GAAI,CAACiJ,GAAcA,EAAW,OAAO,OAAS/Z,EAAO,eAAgB,SAErE,MAAMga,EAAeD,EAAW,KAAA,EAG3BJ,EAAe,IAAIE,EAAO,YAAA,CAAa,IAC1CF,EAAe,IAAIE,EAAO,aAAa,EACvCnL,EAAM,KAAK,KAAKmL,CAAM,GAIxB,UAAWzW,KAAagH,EACtB6P,GAAiCD,EAAcH,EAAQC,EAAW1W,EAAWsL,EAAO1O,EAAQqK,CAAU,CAE1G,CACF,KAAO,CAEL,MAAMlK,EAAO,OAAOwF,GAAS,SAAWA,EAAO,OAAOA,CAAI,EAC1D,GAAIxF,EAAK,KAAA,EAAO,OAASH,EAAO,eAAgB,SAEhD,MAAMwK,EAAcrK,EAAK,KAAA,EACzB,GAAIwZ,EAAe,IAAInP,EAAY,YAAA,CAAa,EAAG,SAEnDmP,EAAe,IAAInP,EAAY,aAAa,EAC5CkE,EAAM,KAAK,KAAKlE,CAAW,EAG3B,UAAWpH,KAAagH,EACtB8P,GAAyB1P,EAAapH,EAAWsL,EAAO1O,EAAQqK,CAAU,CAE9E,CAEAuP,IACI9J,EAAQ,YACVA,EAAQ,WAAW8J,EAAWzP,EAAM,MAAM,EAQ9C,GAF+B2F,EAAQ,kBAAoB9P,EAAO,kBAAoBA,EAAO,SAAWA,EAAO,gBAAkBmK,EAAM,QAAU,IAErH,CAC1B,KAAM,CAAE,cAAAG,EAAe,UAAAtC,GAAckC,EAAmBC,EAAOC,EAAoBpK,EAAQqK,CAAU,EACrGqE,EAAM,cAAgBpE,EACtBoE,EAAM,UAAY1G,CACpB,CAIA,GADoBhI,EAAO,cAAgB,GAC1B,CACf,MAAMma,EAAYna,EAAO,WAAa,IACtC0O,EAAM,OAAS,IAAIkB,EAAYuK,CAAS,CAC1C,CAEA,OAAOzL,CACT,CAKA,SAASwL,GAAyB/Z,EAAciD,EAA8BsL,EAAmB1O,EAAqBqK,EAA+B,CACnJ,MAAMjK,EAAagD,EAAU,UAAUjD,CAAI,EAG3Cia,EAAgB1L,EAAM,cAAetO,EAAYD,CAAI,EACrDia,EAAgB1L,EAAM,cAAevO,EAAK,YAAA,EAAeA,CAAI,EAE7Dia,EAAgB1L,EAAM,cAAevO,EAAMA,CAAI,EAG/C,MAAMka,EAAiB/J,EAAcnQ,CAAI,EACzC,GAAIka,IAAmBla,EAAM,CAE3Bia,EAAgB1L,EAAM,cAAe2L,EAAgBla,CAAI,EACzDia,EAAgB1L,EAAM,cAAe2L,EAAe,YAAA,EAAela,CAAI,EACvE,MAAMma,EAAuBlX,EAAU,UAAUiX,CAAc,EAC3DC,IAAyBD,EAAe,eAC1CD,EAAgB1L,EAAM,cAAe4L,EAAsBna,CAAI,CAEnE,CAWA,GARIkK,EAAW,IAAI,eAAe,GACfjH,EAAU,gBAAgBjD,CAAI,EACtC,QAAS0K,GAAY,CAC5BuP,EAAgB1L,EAAM,cAAe7D,EAAS1K,CAAI,CACpD,CAAC,EAICkK,EAAW,IAAI,UAAU,GAAKjH,EAAU,kBAAkB,SAAS,UAAU,EAAG,CAClF,MAAMqH,EAAerH,EAAU,gBAAgBjD,CAAI,EAC/CsK,GACF2P,EAAgB1L,EAAM,eAAgBjE,EAActK,CAAI,CAE5D,CAmBA,GAhBemF,EAAelF,EAAYJ,EAAO,SAAS,EACnD,QAAS8K,GAAkB,CAChCsP,EAAgB1L,EAAM,WAAY5D,EAAO3K,CAAI,CAC/C,CAAC,EAGGkK,EAAW,IAAI,UAAU,GAAKjH,EAAU,kBAAkB,SAAS,UAAU,GACzDA,EAAU,mBAAmBjD,CAAI,EACzC,QAASkC,GAAS,CAC1BA,IAASlC,GACXia,EAAgB1L,EAAM,cAAetL,EAAU,UAAUf,CAAI,EAAGlC,CAAI,CAExE,CAAC,EAICkK,EAAW,IAAI,UAAU,IACVjH,EAAU,YAAYhD,CAAU,EACxC,QAAS4K,GAAY,CAC5BoP,EAAgB1L,EAAM,WAAY1D,EAAS7K,CAAI,CACjD,CAAC,EAGGH,EAAO,gBAAgB,CACzB,MAAMiL,EAAiBjL,EAAO,eAAeI,CAAU,EACnD6K,GACFA,EAAe,QAASD,GAAY,CAClCoP,EAAgB1L,EAAM,WAAY1D,EAAS7K,CAAI,CACjD,CAAC,CAEL,CAEJ,CAKA,SAAS8Z,GAAiCF,EAAoBF,EAAgBC,EAAmB1W,EAA8BsL,EAAmB1O,EAAqBqK,EAA+B,CACpM,MAAMjK,EAAagD,EAAU,UAAU2W,CAAU,EAGjDQ,EAAyB7L,EAAM,cAAetO,EAAYyZ,CAAiB,EAC3EU,EAAyB7L,EAAM,cAAeqL,EAAW,YAAA,EAAeF,CAAiB,EACzFU,EAAyB7L,EAAM,cAAeqL,EAAYF,CAAiB,EAG3E,MAAMQ,EAAiB/J,EAAcyJ,CAAU,EAC/C,GAAIM,IAAmBN,EAAY,CACjCQ,EAAyB7L,EAAM,cAAe2L,EAAgBR,CAAiB,EAC/EU,EAAyB7L,EAAM,cAAe2L,EAAe,YAAA,EAAeR,CAAiB,EAC7F,MAAMS,EAAuBlX,EAAU,UAAUiX,CAAc,EAC3DC,IAAyBD,EAAe,eAC1CE,EAAyB7L,EAAM,cAAe4L,EAAsBT,CAAiB,CAEzF,CAWA,GARIxP,EAAW,IAAI,eAAe,GACfjH,EAAU,gBAAgB2W,CAAU,EAC5C,QAASlP,GAAY,CAC5B0P,EAAyB7L,EAAM,cAAe7D,EAASgP,CAAiB,CAC1E,CAAC,EAICxP,EAAW,IAAI,UAAU,GAAKjH,EAAU,kBAAkB,SAAS,UAAU,EAAG,CAClF,MAAMqH,EAAerH,EAAU,gBAAgB2W,CAAU,EACrDtP,GACF8P,EAAyB7L,EAAM,eAAgBjE,EAAcoP,CAAiB,CAElF,CAoBA,GAjBevU,EAAelF,EAAYJ,EAAO,SAAS,EACnD,QAAS8K,GAAkB,CAChCyP,EAAyB7L,EAAM,WAAY5D,EAAO+O,CAAiB,CACrE,CAAC,EAGGxP,EAAW,IAAI,UAAU,GAAKjH,EAAU,kBAAkB,SAAS,UAAU,GACjEA,EAAU,mBAAmB2W,CAAU,EAC/C,QAAS1X,GAAS,CAClBA,EAAK,QAAUrC,EAAO,iBACxBua,EAAyB7L,EAAM,cAAerM,EAAMwX,CAAiB,EACrEU,EAAyB7L,EAAM,cAAetL,EAAU,UAAUf,CAAI,EAAGwX,CAAiB,EAE9F,CAAC,EAICxP,EAAW,IAAI,UAAU,IACVjH,EAAU,YAAYhD,CAAU,EACxC,QAAS4K,GAAY,CAC5BuP,EAAyB7L,EAAM,WAAY1D,EAAS6O,CAAiB,CACvE,CAAC,EAGG7Z,EAAO,gBAAgB,CACzB,MAAMiL,EAAiBjL,EAAO,eAAeI,CAAU,EACnD6K,GACFA,EAAe,QAASD,GAAY,CAClCuP,EAAyB7L,EAAM,WAAY1D,EAAS6O,CAAiB,CACvE,CAAC,CAEL,CAEJ,CAKA,SAASU,EAAyBrW,EAA+BuL,EAAaC,EAAe8K,EAA0B,CAIhHtW,EAAI,IAAIuL,CAAG,GACdvL,EAAI,IAAIuL,EAAK,IAAI,GAAK,EAExBvL,EAAI,IAAIuL,CAAG,EAAG,IAAIC,CAAK,CACzB,CAKA,SAAS0K,EAAgBlW,EAA+BuL,EAAaC,EAAqB,CACnFxL,EAAI,IAAIuL,CAAG,GACdvL,EAAI,IAAIuL,EAAK,IAAI,GAAK,EAExBvL,EAAI,IAAIuL,CAAG,EAAG,IAAIC,CAAK,CACzB,CA8BO,SAAS+K,GAAY/L,EAAmBgM,EAAmB7K,EAAqBC,EAAyB,CAAA,EAAwC,CACtJ,MAAMpJ,EAA8C,CAAA,EAC9CiU,EAAgB,CAAC,GAAG,IAAI,IAAID,CAAO,CAAC,EAE1C,UAAWpP,KAASqP,EAClBjU,EAAQ4E,CAAK,EAAIoN,EAAehK,EAAOpD,EAAOuE,EAAYC,CAAO,EAGnE,OAAOpJ,CACT,CAmDO,SAASgS,EAAehK,EAAmBpD,EAAeuE,EAAqBC,EAAyB,CAAA,EAAwB,CACrI,MAAM9P,EAAS0O,EAAM,OACfwK,EAAQrJ,GAAcC,EAAQ,YAAc9P,EAAO,WACnDoG,EAAY0J,EAAQ,gBAAkB9P,EAAO,eAEnD,GAAI,CAACsL,GAASA,EAAM,OAAO,OAAStL,EAAO,eACzC,MAAO,CAAA,EAIT,GAAI8P,EAAQ,WAAa+I,GAAWvN,CAAK,EACvC,OAAO0N,GAAgBtK,EAAOpD,EAAO4N,EAAOpJ,CAAO,EAIrD,MAAM8K,EAAc5H,GAAW1H,CAAK,EAGpC,GAAIsP,EAAY,WACd,OAAOC,GAAkBnM,EAAOkM,EAAa1B,EAAO9S,EAAW0J,CAAO,EAIxE,IAAIgL,EAAiBxP,EAMrB,GALItL,EAAO,iBAAmBA,EAAO,WAAaA,EAAO,UAAU,OAAS,IAC1E8a,EAAiB3J,GAAgB7F,EAAOtL,EAAO,SAAS,GAItD0O,EAAM,OAAQ,CAChB,MAAM6B,EAAS7B,EAAM,OAAO,IAAIoM,EAAgB5B,EAAOpJ,CAAO,EAC9D,GAAIS,EACF,OAAOA,CAEX,CAIA,MAAMhF,GADkBuE,EAAQ,WAAa9P,EAAO,WACjB,IAAKH,GAAS6O,EAAM,mBAAmB,IAAI7O,CAAI,CAAC,EAAE,OAAQsJ,GAA8BA,IAAM,MAAS,EAE1I,GAAIoC,EAAW,SAAW,EACxB,MAAO,CAAA,EAIT,GAAImD,EAAM,eAAiBA,EAAM,UAAW,CAC1C,MAAMhI,EAAUqU,GAAuBrM,EAAOoM,EAAgB5B,EAAO9S,EAAWmF,EAAYuE,CAAO,EAEnG,OAAIpB,EAAM,QACRA,EAAM,OAAO,IAAIoM,EAAgBpU,EAASwS,EAAOpJ,CAAO,EAEnDpJ,CACT,CAGA,MAAM8E,MAAc,IAGpB,UAAWpI,KAAamI,EAAY,CAClC,MAAME,EAAkBrI,EAAU,UAAU0X,EAAe,MAAM,EAGjEE,GAAiBvP,EAAiBiD,EAAOlD,EAASpI,EAAU,QAAQ,EACpE6X,GAAkBxP,EAAiBiD,EAAOlD,EAASpI,EAAU,QAAQ,EACrE8X,GAAoBzP,EAAiBrI,EAAWsL,EAAOlD,CAAO,EAC9D2P,GAAmB1P,EAAiBiD,EAAOlD,CAAO,EAClD4P,GAAiB3P,EAAiBiD,EAAOlD,EAASpI,EAAU,SAAUpD,EAAO,SAAS,GAElFA,EAAO,SAAS,SAAS,iBAAiB,GAAKA,EAAO,SAAS,SAAS,eAAe,GAAKA,EAAO,SAAS,SAAS,gBAAgB,IACvIqb,GAAiB5P,EAAiBiD,EAAOlD,EAASpI,EAAWpD,CAAM,CAEvE,CAGA,MAAM0G,EAAU,MAAM,KAAK8E,EAAQ,QAAQ,EACxC,IAAK+B,GAAU+N,EAAuB/N,EAAOuN,EAAgB1U,EAAWsI,EAAOoB,CAAO,CAAC,EACvF,OAAQ3K,GAAuCA,IAAW,IAAI,EAC9D,KAAK,CAAC4H,EAAG6B,IAAMA,EAAE,MAAQ7B,EAAE,KAAK,EAChC,MAAM,EAAGmM,CAAK,EAGjB,OAAIxK,EAAM,QACRA,EAAM,OAAO,IAAIoM,EAAgBpU,EAASwS,EAAOpJ,CAAO,EAGnDpJ,CACT,CAKA,SAASsU,GAAiB1P,EAAeoD,EAAmBlD,EAAmCtI,EAAwB,CACrH,MAAM0P,EAAiBlE,EAAM,OAAO,gBAAkB,GAGtD,GAAIpD,EAAM,SAAS,GAAG,EAAG,CAEvB,UAAWiQ,KAAY7M,EAAM,KACvBqE,GAAgBwI,EAAUjQ,CAAK,IAC5BE,EAAQ,IAAI+P,CAAQ,GACvB/P,EAAQ,IAAI+P,EAAU,CACpB,KAAMA,EACN,WAAYjQ,EACZ,UAAW,QACX,aAAc,EACd,SAAApI,CAAA,CACD,GAIP,MACF,CAGA,MAAMsY,EAAe9M,EAAM,cAAc,IAAIpD,CAAK,EAC9CkQ,GACFA,EAAa,QAASrb,GAAS,CAE7B,GAAIyS,GAAkB,CAACD,EAAYxS,EAAMmL,EAAOsH,CAAc,EAC5D,OAIF,MAAM2F,EAAW/M,EAAQ,IAAIrL,CAAI,GAC7B,CAACoY,GAAYA,EAAS,YAAc,UACtC/M,EAAQ,IAAIrL,EAAM,CAChB,KAAAA,EACA,WAAYmL,EACZ,UAAW,QACX,aAAc,EACd,SAAApI,CAAA,CACD,CAEL,CAAC,EAIH,MAAMuY,EAAanQ,EAAM,YAAA,EACzB,UAAWiQ,KAAY7M,EAAM,KACvB6M,EAAS,YAAA,IAAkBE,IACxBjQ,EAAQ,IAAI+P,CAAQ,GACvB/P,EAAQ,IAAI+P,EAAU,CACpB,KAAMA,EACN,WAAYjQ,EACZ,UAAW,QACX,aAAc,EACd,SAAApI,CAAA,CACD,EAIT,CAKA,SAAS+X,GAAkB3P,EAAeoD,EAAmBlD,EAAmCtI,EAAwB,CACtH,MAAM0P,EAAiBlE,EAAM,OAAO,gBAAkB,GAEtD,SAAW,CAAC7D,EAASV,CAAK,IAAKuE,EAAM,cAAc,UAC7C7D,EAAQ,WAAWS,CAAK,GAAKT,IAAYS,GAC3CnB,EAAM,QAAShK,GAAS,CAElByS,GAAkB,CAACD,EAAYxS,EAAMmL,EAAOsH,CAAc,GAIzDpH,EAAQ,IAAIrL,CAAI,GACnBqL,EAAQ,IAAIrL,EAAM,CAChB,KAAAA,EACA,WAAY0K,EACZ,UAAW,SACX,SAAA3H,CAAA,CACD,CAEL,CAAC,CAGP,CAKA,SAASgY,GAAoB5P,EAAelI,EAA8BsL,EAAmBlD,EAAyC,CACpI,GAAI,CAACpI,EAAU,kBAAkB,SAAS,UAAU,EAAG,OAEvD,MAAMqH,EAAerH,EAAU,gBAAgBkI,CAAK,EACpD,GAAIb,EAAc,CAChB,MAAMiR,EAAkBhN,EAAM,eAAe,IAAIjE,CAAY,EACzDiR,GACFA,EAAgB,QAASvb,GAAS,CAC3BqL,EAAQ,IAAIrL,CAAI,GACnBqL,EAAQ,IAAIrL,EAAM,CAChB,KAAAA,EACA,WAAYmL,EACZ,UAAW,WACX,aAAAb,EACA,SAAUrH,EAAU,QAAA,CACrB,CAEL,CAAC,CAEL,CACF,CAKA,SAAS+X,GAAmB7P,EAAeoD,EAAmBlD,EAAyC,CACrG,MAAMmQ,EAAiBjN,EAAM,WAAW,IAAIpD,CAAK,EAC7CqQ,GACFA,EAAe,QAASxb,GAAS,CAC1BqL,EAAQ,IAAIrL,CAAI,GACnBqL,EAAQ,IAAIrL,EAAM,CAChB,KAAAA,EACA,WAAYmL,EACZ,UAAW,UACX,SAAU,SAAA,CACX,CAEL,CAAC,CAEL,CAKA,SAAS8P,GAAiB9P,EAAeoD,EAAmBlD,EAAmCtI,EAAkBgJ,EAAyB,CACxI,GAAIZ,EAAM,OAASY,EAAW,OAE9B,MAAMC,EAAc7G,EAAegG,EAAOY,CAAS,EAC7C0P,MAAqB,IAE3BzP,EAAY,QAASrB,GAAU,CAC7B,MAAM+Q,EAAenN,EAAM,WAAW,IAAI5D,CAAK,EAC3C+Q,GACFA,EAAa,QAAS1b,GAASyb,EAAe,IAAIzb,CAAI,CAAC,CAE3D,CAAC,EAEDyb,EAAe,QAASzb,GAAS,CAC1BqL,EAAQ,IAAIrL,CAAI,GACnBqL,EAAQ,IAAIrL,EAAM,CAChB,KAAAA,EACA,WAAYmL,EACZ,UAAW,QACX,SAAApI,CAAA,CACD,CAEL,CAAC,CACH,CAKA,SAASmY,GAAiB/P,EAAeoD,EAAmBlD,EAAmCpI,EAA8BpD,EAA2B,CACtJ,MAAMwE,EAAcxE,EAAO,gBAE3B,SAAW,CAAC6K,EAASV,CAAK,IAAKuE,EAAM,cAAc,UACjD,GAAI,KAAK,IAAI7D,EAAQ,OAASS,EAAM,MAAM,GAAK9G,EAAa,CAG1D,MAAMyB,EADoByI,EAAM,OAAO,UAAU,SAAS,gBAAgB,EACrC9J,EAAoC0G,EAAOT,EAASrG,CAAW,EAAID,EAA6B+G,EAAOT,EAASrG,CAAW,EAE5JyB,GAAYzB,GACd2F,EAAM,QAAShK,GAAS,CACtB,MAAMiN,EAAgB5B,EAAQ,IAAIrL,CAAI,GAElC,CAACiN,GAAkBA,EAAc,YAAc,SAAWA,EAAc,YAAc,WAAaA,EAAc,cAAgB,KAAYnH,IAC/IuF,EAAQ,IAAIrL,EAAM,CAChB,KAAAA,EACA,WAAY0K,EACZ,UAAW,QACX,aAAc5E,EACd,SAAU7C,EAAU,QAAA,CACrB,CAEL,CAAC,CAEL,CAEJ,CAKA,SAASkY,EAAuB/N,EAAoBuO,EAAuB1V,EAAmBsI,EAAmBoB,EAAkD,CACjK,IAAIvH,EAAQwT,GAAoBxO,EAAOuO,CAAa,EAGpD,GAAIvO,EAAM,YAAc,QAAamB,EAAM,OAAO,QAAS,CACzD,MAAM7F,EAAa6F,EAAM,OAAO,YAAc,GACxC5F,EAAc,EAAID,EACxBN,EAAQM,EAAa0E,EAAM,UAAYzE,EAAcP,CACvD,CAOA,GAJIgF,EAAM,cACRhF,EAAQ,KAAK,IAAI,EAAKA,EAAQgF,EAAM,WAAW,GAG7ChF,EAAQnC,EACV,OAAO,KAGT,MAAMjB,EAA2B,CAC/B,QAASoI,EAAM,KACf,SAAUA,EAAM,KAChB,UAAWA,EAAM,YAAc,UAC/B,MAAAhF,EACA,SAAUgF,EAAM,SAEhB,iBAAkBA,EAAM,SAAA,EAI1B,OAAImB,EAAM,WAAaA,EAAM,UAAU,IAAInB,EAAM,IAAI,IACnDpI,EAAO,OAASuJ,EAAM,UAAU,IAAInB,EAAM,IAAI,EAC9CpI,EAAO,MAAQoI,EAAM,OAInBuC,GAAS,oBACX3K,EAAO,WAAawI,GAAoBJ,EAAOuO,EAAevO,EAAM,IAAI,GAGnEpI,CACT,CAKA,SAAS4W,GAEPxO,EACAjC,EACQ,CACR,MAAMe,EAAWf,EAAM,OACjB0Q,EAAUzO,EAAM,KAAK,OACrB1I,EAAS,KAAK,IAAIwH,EAAU2P,CAAO,EAEzC,IAAIzT,EAAQ,GAEZ,OAAQgF,EAAM,UAAA,CACZ,IAAK,QACHhF,EAAQ,EACR,MACF,IAAK,SACHA,EAAQ,IAAOyT,EAAU3P,IAAaxH,EAAS,GAC/C,MACF,IAAK,YACH0D,EAAQ,GACR,MACF,IAAK,WACHA,EAAQ,GACR,MACF,IAAK,QACCgF,EAAM,eAAiB,SACzBhF,EAAQ,KAAK,IAAI,GAAK,EAAMgF,EAAM,aAAe1I,CAAM,GAEzD,MACF,IAAK,UACH0D,EAAQ,GACR,MACF,IAAK,WACHA,EAAQ,IACR,MACF,IAAK,QACHA,EAAQnD,EAAyBkG,EAAM,YAAA,EAAeiC,EAAM,WAAY,CAAC,EAAI,GAC7E,KAAA,CAKJ,OAAIyO,GAAW3P,EAAW,GAAKkB,EAAM,YAAc,UACjDhF,GAAS,IAGJ,KAAK,IAAI,EAAK,KAAK,IAAI,EAAKA,CAAK,CAAC,CAC3C,CAKA,SAASjD,EAEPO,EACAC,EACU,CACV,GAAID,EAAI,OAASC,EAAG,MAAO,CAACD,CAAG,EAE/B,MAAM5E,EAAmB,CAAA,EACzB,QAASV,EAAI,EAAGA,GAAKsF,EAAI,OAASC,EAAGvF,IACnCU,EAAO,KAAK4E,EAAI,MAAMtF,EAAGA,EAAIuF,CAAC,CAAC,EAEjC,OAAO7E,CACT,CAMA,SAAS8Z,GAEPrM,EACApD,EACA4N,EACA9S,EACAmF,EACAuE,EACoB,CACpB,GAAI,CAACpB,EAAM,eAAiB,CAACA,EAAM,UACjC,MAAM,IAAI,MAAM,8BAA8B,EAIhD,IAAIlD,EAAUH,GAAoBqD,EAAM,cAAeA,EAAM,UAAWpD,EAAOC,EAAYmD,EAAM,MAAM,EAGvG,GAAIA,EAAM,OAAO,QAAS,CACxB,MAAM7G,EAAayD,EAAM,YAAA,EAAc,MAAM,KAAK,EAAE,OAAOiI,GAAKA,EAAE,OAAS,CAAC,EAC5E/H,EAAU6B,GAAoB7B,EAAS3D,EAAY6G,EAAM,cAAeA,EAAM,UAAWA,EAAM,MAAM,CACvG,CASA,OANgBlD,EACb,IAAK+B,GAAU+N,EAAuB/N,EAAOjC,EAAOlF,EAAWsI,EAAOoB,CAAO,CAAC,EAC9E,OAAQ3K,GAAuCA,IAAW,IAAI,EAC9D,KAAK,CAAC4H,EAAG6B,IAAMA,EAAE,MAAQ7B,EAAE,KAAK,EAChC,MAAM,EAAGmM,CAAK,CAGnB,CAMA,SAAS2B,GACPnM,EACAkM,EACA1B,EACA9S,EACA0J,EACoB,CACpB,MAAM9P,EAAS0O,EAAM,OAIfuN,EAAgB,CACpB,WAAY,GACZ,gBAAiB,EACjB,eAAgB,IAChB,qBAAsB,EACtB,kBARwBjc,EAAO,SAAS,SAAS,gBAAgB,CAQjE,EAIIkc,MAAoB,IAG1B,UAAW9I,KAAUwH,EAAY,QAC/B,UAAWza,KAAQuO,EAAM,KAAM,CAC7B,MAAMnB,EAAQqG,GAAYzT,EAAMiT,EAAQ6I,CAAa,EAErD,GAAI1O,EAAM,QAAS,CACjB,MAAMgL,EAAW2D,EAAc,IAAI/b,CAAI,EACjCgc,EAAW5O,EAAM,MAAQ0O,EAAc,eAEzC1D,EAEF2D,EAAc,IAAI/b,EAAM,CACtB,MAAO,KAAK,IAAIoY,EAAS,MAAO4D,CAAQ,EACxC,YAAa5D,EAAS,YAAc,CAAA,CACrC,EAED2D,EAAc,IAAI/b,EAAM,CAAE,MAAOgc,EAAU,YAAa,EAAG,CAE/D,CACF,CAIF,IAAIC,MAAkB,IAEtB,GAAIxB,EAAY,MAAM,OAAS,EAAG,CAChC,MAAMyB,EAAYzB,EAAY,MAAM,KAAK,GAAG,EACtCrP,EAAavL,EAAO,UACvB,IAAKH,GAAS6O,EAAM,mBAAmB,IAAI7O,CAAI,CAAC,EAChD,OAAQsJ,GAA8BA,IAAM,MAAS,EAExD,UAAW/F,KAAamI,EAAY,CAClC,MAAME,EAAkBrI,EAAU,UAAUiZ,CAAS,EAGrDrB,GAAiBvP,EAAiBiD,EAAO0N,EAAahZ,EAAU,QAAQ,EACxE6X,GAAkBxP,EAAiBiD,EAAO0N,EAAahZ,EAAU,QAAQ,EACzE8X,GAAoBzP,EAAiBrI,EAAWsL,EAAO0N,CAAW,EAClEhB,GAAiB3P,EAAiBiD,EAAO0N,EAAahZ,EAAU,SAAUpD,EAAO,SAAS,GAEtFA,EAAO,SAAS,SAAS,iBAAiB,GAAKA,EAAO,SAAS,SAAS,eAAe,GAAKA,EAAO,SAAS,SAAS,gBAAgB,IACvIqb,GAAiB5P,EAAiBiD,EAAO0N,EAAahZ,EAAWpD,CAAM,CAE3E,CACF,CAGA,MAAMsc,MAAsB,IAG5B,SAAW,CAACnc,EAAMoc,CAAU,IAAKL,EAAc,UAAW,CACxD,MAAM/W,EAA2B,CAC/B,QAAShF,EACT,SAAUA,EACV,UAAW,GACX,MAAOoc,EAAW,KAAA,EAIFH,EAAY,IAAIjc,CAAI,IAEpCgF,EAAO,MAAQ,KAAK,IAAI,EAAKA,EAAO,MAAQ,GAAG,GAGjDmX,EAAgB,IAAInc,EAAMgF,CAAM,CAClC,CAGA,SAAW,CAAChF,EAAMoN,CAAK,IAAK6O,EAAY,UACtC,GAAI,CAACE,EAAgB,IAAInc,CAAI,EAAG,CAC9B,MAAMgF,EAASmW,EAAuB/N,EAAOqN,EAAY,MAAM,KAAK,GAAG,EAAGxU,EAAWsI,EAAOoB,CAAO,EAC/F3K,IAEFA,EAAO,OAAS,GAChBmX,EAAgB,IAAInc,EAAMgF,CAAM,EAEpC,CAIF,MAAMuB,EAAU,MAAM,KAAK4V,EAAgB,QAAQ,EAChD,OAAOjE,GAAKA,EAAE,OAASjS,CAAS,EAChC,KAAK,CAAC2G,EAAG6B,IAAMA,EAAE,MAAQ7B,EAAE,KAAK,EAChC,MAAM,EAAGmM,CAAK,EAGjB,OAAIxK,EAAM,QACRA,EAAM,OAAO,IAAIkM,EAAY,SAAUlU,EAASwS,EAAOpJ,CAAO,EAGzDpJ,CACT,CAgBO,SAAS8V,GACd9N,EACA+N,EAA6B,CAAA,EAC7B3M,EAAsC,CAAA,EAC1B,CACZ,GAAI,CAACpB,GAAS,CAACA,EAAM,OACnB,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GAAI,CAAC+N,GAAYA,EAAS,SAAW,EACnC,OAAO/N,EAIT,MAAM1O,EAAS0O,EAAM,OACfrE,EAAa,IAAI,IAAIrK,EAAO,QAAQ,EAGpCoK,EAAqB,MAAM,KAAKsE,EAAM,mBAAmB,QAAQ,EAEvE,GAAItE,EAAmB,SAAW,EAChC,MAAM,IAAI,MAAM,uCAAuC,EAIzD,MAAMqP,EAAY/K,EAAM,QAAUA,EAAM,OAAO,OAAS,EAClDgL,EAAgB+C,EAAS,OAAS,GAAK,OAAOA,EAAS,CAAC,GAAM,UAAYA,EAAS,CAAC,IAAM,KAGhG,GAAI/C,GAAiB,CAACD,EACpB,MAAM,IAAI,MAAM,qDAAqD,EAIvE,MAAMiD,EAAgB,IAAI,IAAIhO,EAAM,KAAK,IAAI4C,GAAKA,EAAE,YAAA,CAAa,CAAC,EAClE,IAAIsI,EAAY,EAEhB,UAAWjU,KAAQ8W,EACjB,GAAK9W,EAGL,IAAI8T,GAAaC,EAAe,CAC9B,MAAM5I,EAAcF,GAAmBjL,EAAM+I,EAAM,MAAM,EACzD,GAAI,CAACoC,EAAa,SAGlB,MAAM+I,EAAS,OAAO,OAAO/I,CAAW,EAAE,CAAC,GAAK,QAAQpC,EAAM,KAAK,OAASkL,CAAS,GAGrF,GAAI8C,EAAc,IAAI7C,EAAO,YAAA,CAAa,EAAG,SAGzCnL,EAAM,WACRA,EAAM,UAAU,IAAImL,EAAQ/I,CAAW,EAIzC4L,EAAc,IAAI7C,EAAO,aAAa,EACtCnL,EAAM,KAAK,KAAKmL,CAAM,EAGtB,SAAW,CAACC,EAAWC,CAAU,IAAK,OAAO,QAAQjJ,CAAW,EAAG,CACjE,GAAI,CAACiJ,GAAcA,EAAW,OAAO,OAAS/Z,EAAO,eAAgB,SAErE,MAAMga,EAAeD,EAAW,KAAA,EAGhC,UAAW3W,KAAagH,EACtB6P,GAAiCD,EAAcH,EAAQC,EAAW1W,EAAWsL,EAAO1O,EAAQqK,CAAU,CAE1G,CACF,KAAO,CAEL,MAAMlK,EAAO,OAAOwF,GAAS,SAAWA,EAAO,OAAOA,CAAI,EAC1D,GAAIxF,EAAK,KAAA,EAAO,OAASH,EAAO,eAAgB,SAEhD,MAAMwK,EAAcrK,EAAK,KAAA,EAGzB,GAAIuc,EAAc,IAAIlS,EAAY,YAAA,CAAa,EAAG,SAElDkS,EAAc,IAAIlS,EAAY,aAAa,EAC3CkE,EAAM,KAAK,KAAKlE,CAAW,EAG3B,UAAWpH,KAAagH,EACtB8P,GAAyB1P,EAAapH,EAAWsL,EAAO1O,EAAQqK,CAAU,CAE9E,CAEAuP,IACI9J,EAAQ,YACVA,EAAQ,WAAW8J,EAAW6C,EAAS,MAAM,EAKjD,GAAI/N,EAAM,eAAiBA,EAAM,UAAW,CAC1C,KAAM,CAAE,cAAApE,EAAe,UAAAtC,CAAA,EAAckC,EACnCwE,EAAM,KACNtE,EACApK,EACAqK,CAAA,EAEFqE,EAAM,cAAgBpE,EACtBoE,EAAM,UAAY1G,CACpB,CAGA,OAAI0G,EAAM,QACRA,EAAM,OAAO,MAAA,EAGRA,CACT,CAcO,SAASiO,GACdjO,EACAkO,EAA0B,GACd,CACZ,GAAI,CAAClO,GAAS,CAACA,EAAM,OACnB,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GAAI,CAACkO,GAAiBA,EAAc,SAAW,EAC7C,OAAOlO,EAIT,MAAMmO,EAAW,IAAI,IAAID,EAAc,IAAIjX,GAAQA,EAAK,YAAA,CAAa,CAAC,EAGtE+I,EAAM,KAAOA,EAAM,KAAK,OAAOvO,GAAQ,CAAC0c,EAAS,IAAI1c,EAAK,YAAA,CAAa,CAAC,EAGxE,SAAW,CAAC0K,EAASiS,CAAS,IAAKpO,EAAM,cAAc,UAAW,CAChE,MAAM6C,EAAW,IAAI,IAAI,MAAM,KAAKuL,CAAS,EAAE,OAAQ3c,GAAiB,CAAC0c,EAAS,IAAI1c,EAAK,YAAA,CAAa,CAAC,CAAC,EACtGoR,EAAS,OAAS,EACpB7C,EAAM,cAAc,OAAO7D,CAAO,EAElC6D,EAAM,cAAc,IAAI7D,EAAS0G,CAAQ,CAE7C,CAGA,SAAW,CAACwL,EAAUD,CAAS,IAAKpO,EAAM,eAAe,UAAW,CAClE,MAAM6C,EAAW,IAAI,IAAI,MAAM,KAAKuL,CAAS,EAAE,OAAQ3c,GAAiB,CAAC0c,EAAS,IAAI1c,EAAK,YAAA,CAAa,CAAC,CAAC,EACtGoR,EAAS,OAAS,EACpB7C,EAAM,eAAe,OAAOqO,CAAQ,EAEpCrO,EAAM,eAAe,IAAIqO,EAAUxL,CAAQ,CAE/C,CAGA,SAAW,CAACzG,EAAOgS,CAAS,IAAKpO,EAAM,WAAW,UAAW,CAC3D,MAAM6C,EAAW,IAAI,IAAI,MAAM,KAAKuL,CAAS,EAAE,OAAQ3c,GAAiB,CAAC0c,EAAS,IAAI1c,EAAK,YAAA,CAAa,CAAC,CAAC,EACtGoR,EAAS,OAAS,EACpB7C,EAAM,WAAW,OAAO5D,CAAK,EAE7B4D,EAAM,WAAW,IAAI5D,EAAOyG,CAAQ,CAExC,CAGA,SAAW,CAACvG,EAAS8R,CAAS,IAAKpO,EAAM,WAAW,UAAW,CAC7D,MAAM6C,EAAW,IAAI,IAAI,MAAM,KAAKuL,CAAS,EAAE,OAAQ3c,GAAiB,CAAC0c,EAAS,IAAI1c,EAAK,YAAA,CAAa,CAAC,CAAC,EACtGoR,EAAS,OAAS,EACpB7C,EAAM,WAAW,OAAO1D,CAAO,EAE/B0D,EAAM,WAAW,IAAI1D,EAASuG,CAAQ,CAE1C,CAGA,GAAI7C,EAAM,UACR,UAAW/I,KAAQiX,EACjBlO,EAAM,UAAU,OAAO/I,CAAI,EAK/B,GAAI+I,EAAM,eAAiBA,EAAM,UAAW,CAC1C,MAAM1O,EAAS0O,EAAM,OACfrE,EAAa,IAAI,IAAIrK,EAAO,QAAQ,EACpCoK,EAAqB,MAAM,KAAKsE,EAAM,mBAAmB,QAAQ,EAEjE,CAAE,cAAApE,EAAe,UAAAtC,CAAA,EAAckC,EACnCwE,EAAM,KACNtE,EACApK,EACAqK,CAAA,EAEFqE,EAAM,cAAgBpE,EACtBoE,EAAM,UAAY1G,CACpB,CAGA,OAAI0G,EAAM,QACRA,EAAM,OAAO,MAAA,EAGRA,CACT,CC7tCO,SAASsO,EAAetO,EAA2B,CACxD,MAAMuO,EAA8B,CAClC,QAAS,MACT,KAAMvO,EAAM,KACZ,cAAe,MAAM,KAAKA,EAAM,cAAc,QAAA,CAAS,EAAE,IAAI,CAAC,CAAC9E,EAAGsM,CAAC,IAAM,CAACtM,EAAG,MAAM,KAAKsM,CAAC,CAAC,CAAC,EAC3F,eAAgB,MAAM,KAAKxH,EAAM,eAAe,QAAA,CAAS,EAAE,IAAI,CAAC,CAAC9E,EAAGsM,CAAC,IAAM,CAACtM,EAAG,MAAM,KAAKsM,CAAC,CAAC,CAAC,EAC7F,WAAY,MAAM,KAAKxH,EAAM,WAAW,QAAA,CAAS,EAAE,IAAI,CAAC,CAAC9E,EAAGsM,CAAC,IAAM,CAACtM,EAAG,MAAM,KAAKsM,CAAC,CAAC,CAAC,EACrF,WAAY,MAAM,KAAKxH,EAAM,WAAW,QAAA,CAAS,EAAE,IAAI,CAAC,CAAC9E,EAAGsM,CAAC,IAAM,CAACtM,EAAG,MAAM,KAAKsM,CAAC,CAAC,CAAC,EACrF,OAAQxH,EAAM,OACd,uBAAwB,MAAM,KAAKA,EAAM,mBAAmB,MAAM,CAAA,EAIpE,OAAIA,EAAM,gBACRuO,EAAW,cAAgB,CACzB,eAAgB,MAAM,KAAKvO,EAAM,cAAc,eAAe,SAAS,EACvE,mBAAoB,MAAM,KAAKA,EAAM,cAAc,mBAAmB,SAAS,EAC/E,gBAAiB,MAAM,KAAKA,EAAM,cAAc,gBAAgB,SAAS,EACzE,kBAAmB,MAAM,KAAKA,EAAM,cAAc,kBAAkB,SAAS,EAC7E,UAAWA,EAAM,cAAc,UAC/B,aAAcA,EAAM,cAAc,YAAA,GAKlCA,EAAM,YACRuO,EAAW,UAAYvO,EAAM,WAGxB,KAAK,UAAUuO,CAAU,CAClC,CAKA,eAAsBC,GAAiBC,EAAmC,CACxE,MAAMvW,EAAwB,KAAK,MAAMuW,CAAI,EAGvCC,EAAgB,IAAI,IAAIxW,EAAK,cAAc,IAAI,CAAC,CAACgD,EAAGsM,CAAC,IAAM,CAACtM,EAAG,IAAI,IAAIsM,CAAC,CAAC,CAAC,CAAC,EAC3EmH,EAAiB,IAAI,IAAIzW,EAAK,eAAe,IAAI,CAAC,CAACgD,EAAGsM,CAAC,IAAM,CAACtM,EAAG,IAAI,IAAIsM,CAAC,CAAC,CAAC,CAAC,EAC7EoH,EAAa,IAAI,IAAI1W,EAAK,WAAW,IAAI,CAAC,CAACgD,EAAGsM,CAAC,IAAM,CAACtM,EAAG,IAAI,IAAIsM,CAAC,CAAC,CAAC,CAAC,EACrE3T,EAAa,IAAI,IAAIqE,EAAK,WAAW,IAAI,CAAC,CAACgD,EAAGsM,CAAC,IAAM,CAACtM,EAAG,IAAI,IAAIsM,CAAC,CAAC,CAAC,CAAC,EAGrE,CAAE,iBAAAjT,CAAA,EAAqB,MAAM,QAAA,QAAA,EAAA,KAAA,IAAAyL,EAAA,EAC7BtE,MAAyB,IAC/B,UAAWmT,KAAY3W,EAAK,uBAAwB,CAClD,MAAMxD,EAAYH,EAAiB,aAAasa,CAAQ,EACpDna,GACFgH,EAAmB,IAAImT,EAAUna,CAAS,CAE9C,CAEA,MAAMsL,EAAoB,CACxB,KAAM9H,EAAK,KACX,cAAAwW,EACA,eAAAC,EACA,WAAAC,EACA,WAAA/a,EACA,mBAAA6H,EACA,OAAQxD,EAAK,MAAA,EAqBf,GAjBIA,EAAK,gBACP8H,EAAM,cAAgB,CACpB,eAAgB,IAAI,IAAI9H,EAAK,cAAc,cAAc,EACzD,mBAAoB,IAAI,IAAIA,EAAK,cAAc,kBAAkB,EACjE,gBAAiB,IAAI,IAAIA,EAAK,cAAc,eAAe,EAC3D,kBAAmB,IAAI,IAAIA,EAAK,cAAc,iBAAiB,EAC/D,UAAWA,EAAK,cAAc,UAC9B,aAAcA,EAAK,cAAc,YAAA,GAKjCA,EAAK,YACP8H,EAAM,UAAY9H,EAAK,WAIrBA,EAAK,OAAO,cAAgB,GAAO,CACrC,MAAMuT,EAAYvT,EAAK,OAAO,WAAa,IAC3C8H,EAAM,OAAS,IAAIkB,EAAYuK,CAAS,CAC1C,CAEA,OAAOzL,CACT,CAKO,SAAS8O,GAAwB9O,EAAmBe,EAAc,qBAA4B,CACnG,GAAI,OAAO,aAAiB,IAC1B,MAAM,IAAI,MAAM,+BAA+B,EAEjD,MAAMwN,EAAaD,EAAetO,CAAK,EACvC,aAAa,QAAQe,EAAKwN,CAAU,CACtC,CAKA,eAAsBQ,GAA0BhO,EAAc,qBAAkD,CAC9G,GAAI,OAAO,aAAiB,IAC1B,MAAM,IAAI,MAAM,+BAA+B,EAEjD,MAAMwN,EAAa,aAAa,QAAQxN,CAAG,EAC3C,OAAKwN,EAGE,MAAMC,GAAiBD,CAAU,EAF/B,IAGX,CAKO,SAASS,GAAkBhP,EAA2B,CAC3D,MAAMuO,EAAaD,EAAetO,CAAK,EACvC,OAAO,IAAI,KAAK,CAACuO,CAAU,CAAC,EAAE,IAChC,CClGO,SAASU,EAEdC,EACA9N,EAA8B,GACpB,CACV,KAAM,CAEJ,UAAA+N,EAAY,EACZ,WAAAC,EAAa,GACb,UAAA1M,EAAY,GACZ,QAAA2M,EAAU,EACV,UAAAC,EAAY,EACZ,QAAAC,EAAU,OACV,OAAAC,EAAS,SACT,cAAAC,EAAgB,GAChB,cAAA7L,EAAgB,EAAA,EACdxC,EAEJ,IAAI5P,EAAO0d,EAGX,OAAQM,EAAA,CACN,IAAK,SACH,GAAI,CACFhe,EAAO,KAAK0d,CAAO,CACrB,OAASQ,EAAG,CACV,eAAQ,MAAM,2BAA4BA,CAAC,EACpC,CAAA,CACT,CACA,MAEF,IAAK,OACHle,EAAOme,GAAUT,CAAO,EACxB,MAEF,IAAK,OACH1d,EAAOoe,GAAgBV,CAAO,EAC9B,MAEF,IAAK,MAEH,MAAM,IAAI,MAAM,4DAA4D,CAK5E,CAIAI,EAAY,IAEd9d,EADeqe,GAAUre,EAAM8d,EAAWD,EAASE,CAAO,EAC5C,KAAK,GAAG,GAIxB,IAAI9T,EAAkB,CAAA,EAiCtB,GA/BI2T,EAEF3T,EAAQjK,EAAK,MAAM,6BAA6B,EAAE,OAAQC,GAASA,EAAK,OAAS,CAAC,EAElFgK,EAAQ,CAACjK,CAAI,EAIfiK,EAAQA,EACL,IAAKhK,IAEJA,EAAOA,EAAK,QAAQ,oCAAqC,EAAE,EAGtDmS,IACHnS,EAAOA,EAAK,YAAA,GAGPA,EACR,EACA,OAAQA,GAEH,EAAAA,EAAK,OAAS0d,GAGdM,GAAiB,QAAQ,KAAKhe,CAAI,EAGvC,EAGCiR,GAAa,MAAM,QAAQA,CAAS,EAAG,CACzC,MAAMC,EAAe,IAAI,IAAID,EAAU,IAAKE,GAAMA,EAAE,YAAA,CAAa,CAAC,EAClEnH,EAAQA,EAAM,OAAQhK,GAAS,CAACkR,EAAa,IAAIlR,EAAK,YAAA,CAAa,CAAC,CACtE,CAGA,OAAO,MAAM,KAAK,IAAI,IAAIgK,CAAK,CAAC,CAClC,CAKA,SAASkU,GAAUG,EAAsB,CAEvC,IAAIte,EAAOse,EAAK,QAAQ,sDAAuD,GAAG,EAClF,OAAAte,EAAOA,EAAK,QAAQ,mDAAoD,GAAG,EAG3EA,EAAOA,EAAK,QAAQ,mBAAoB,GAAG,EAG3CA,EAAOA,EAAK,QAAQ,WAAY,GAAG,EAGnCA,EAAOA,EACJ,QAAQ,UAAW,GAAG,EACtB,QAAQ,SAAU,GAAG,EACrB,QAAQ,QAAS,GAAG,EACpB,QAAQ,QAAS,GAAG,EACpB,QAAQ,UAAW,GAAG,EACtB,QAAQ,SAAU,GAAG,EACrB,QAAQ,UAAW,GAAG,EAGzBA,EAAOA,EAAK,QAAQ,OAAQ,GAAG,EAAE,KAAA,EAE1BA,CACT,CAKA,SAASoe,GAAgBG,EAA4B,CACnD,GAAI,CAIF,IAASC,EAAT,SAAuBjb,EAAUkb,EAAgB,EAAS,CAEpDA,EAAQ,KAER,OAAOlb,GAAQ,SACjBmb,EAAO,KAAKnb,CAAG,EACN,MAAM,QAAQA,CAAG,EAC1BA,EAAI,QAASkC,GAAS+Y,EAAc/Y,EAAMgZ,EAAQ,CAAC,CAAC,EAC3C,OAAOlb,GAAQ,UAAYA,IAAQ,MAC5C,OAAO,OAAOA,CAAG,EAAE,QAASiM,GAAUgP,EAAchP,EAAOiP,EAAQ,CAAC,CAAC,EAEzE,EAdA,MAAM/X,EAAO,KAAK,MAAM6X,CAAU,EAC5BG,EAAmB,CAAA,EAezB,OAAAF,EAAc9X,CAAI,EACXgY,EAAO,KAAK,GAAG,CACxB,OAAS,EAAG,CACV,eAAQ,MAAM,wBAAyB,CAAC,EACjC,EACT,CACF,CAKA,SAASL,GAEPre,EACA8d,EACAD,EACAE,EACU,CACV,MAAMY,EAAmB,CAAA,EAEzB,GAAIZ,IAAY,YAAa,CAE3B,MAAMa,EAAa5e,EAAK,MAAM,OAAO,EACrC,IAAI6e,EAAe,GAEnB,UAAWC,KAAQF,GACZC,EAAeC,GAAM,QAAUhB,EAClCe,IAAiBA,EAAe;AAAA;AAAA,EAAS,IAAMC,GAE3CD,GAAcF,EAAO,KAAKE,CAAY,EAC1CA,EAAeC,GAGfD,GAAcF,EAAO,KAAKE,CAAY,CAC5C,SAAWd,IAAY,WAAY,CAEjC,MAAMgB,EAAY/e,EAAK,MAAM,WAAW,EACxC,IAAI6e,EAAe,GAEnB,UAAWG,KAAYD,GAChBF,EAAeG,GAAU,QAAUlB,EACtCe,IAAiBA,EAAe,IAAM,IAAMG,GAExCH,GAAcF,EAAO,KAAKE,CAAY,EAC1CA,EAAeG,GAGfH,GAAcF,EAAO,KAAKE,CAAY,CAC5C,KAAO,CAEL,MAAM5U,EAAQjK,EAAK,MAAM,KAAK,EAC9B,IAAI6e,EAAe,GAEnB,UAAW5e,KAAQgK,GACZ4U,EAAe,IAAM5e,GAAM,QAAU6d,EACxCe,IAAiBA,EAAe,IAAM,IAAM5e,GAExC4e,GAAcF,EAAO,KAAKE,CAAY,EAGtChB,EAAU,GAAKgB,EAEjBA,EADqBA,EAAa,MAAM,KAAK,EAAE,MAAM,CAAC,KAAK,KAAKhB,EAAU,EAAE,CAAC,EACjD,KAAK,GAAG,EAAI,IAAM5d,EAE9C4e,EAAe5e,GAIjB4e,GAAcF,EAAO,KAAKE,CAAY,CAC5C,CAEA,OAAOF,CACT,CAQA,eAAsBM,GAEpBvB,EACA9N,EAA8B,GACX,CACnB,KAAM,CAAE,OAAAoO,EAAS,QAAA,EAAapO,EAE9B,GAAIoO,IAAW,MACb,GAAI,CAEF,MAAMM,EAAO,MADI,MAAM,MAAMZ,CAAO,GACR,KAAA,EAC5B,OAAOD,EAAYa,EAAM,CAAE,GAAG1O,EAAS,OAAQ,OAAQ,CACzD,OAASsO,EAAG,CACV,eAAQ,MAAM,uBAAwBA,CAAC,EAChC,CAAA,CACT,CAGF,OAAOT,EAAYC,EAAS9N,CAAO,CACrC,CC1DO,SAASsP,GAEdC,EACAvP,EAII,GACJ,CACA,MAAMpB,EAAQ0K,GAAgBiG,EAAY,CACxC,OAAQ,CACN,UAAWvP,EAAQ,WAAa,CAAC,SAAS,EAC1C,YAAaA,EAAQ,aAAe,WACpC,WAAYA,EAAQ,YAAc,CAAA,CACpC,CACD,EAED,MAAO,CACL,OAAQ,CAACxE,EAAeuE,IAAwB6I,EAAehK,EAAOpD,EAAOuE,CAAU,EACvF,MAAAnB,CAAA,CAEJ,CAKO,MAAM4Q,GAAU"}