{"version":3,"file":"fuzzyfindjs.min.js","sources":["../../src/core/config.ts","../../src/languages/base/LanguageProcessor.ts","../../src/languages/german/GermanProcessor.ts","../../src/languages/english/EnglishProcessor.ts","../../src/languages/spanish/SpanishProcessor.ts","../../src/languages/french/FrenchProcessor.ts","../../src/languages/index.ts","../../src/utils/memory-pool.ts","../../src/algorithms/levenshtein.ts","../../src/core/trie.ts","../../src/algorithms/bm25.ts","../../src/algorithms/bloom-filter.ts","../../src/utils/tokenizer.ts","../../src/core/inverted-index.ts","../../src/core/highlighting.ts","../../src/core/cache.ts","../../src/utils/accent-normalization.ts","../../src/core/field-weighting.ts","../../src/utils/stop-words.ts","../../src/utils/word-boundaries.ts","../../src/utils/phrase-parser.ts","../../src/core/phrase-matching.ts","../../src/utils/language-detection.ts","../../src/fql/lexer.ts","../../src/fql/parser.ts","../../src/fql/ast.ts","../../src/fql/executor.ts","../../src/fql/index.ts","../../src/utils/alphanumeric-segmenter.ts","../../src/core/filters.ts","../../src/core/sorting.ts","../../src/core/index.ts","../../src/core/serialization.ts","../../src/utils/data-indexer.ts","../../src/index.ts"],"sourcesContent":["import type {\n  //\n  FuzzyConfig,\n  FuzzyFeature,\n  MatchTypeScores,\n  ScoringModifiers,\n} from \"./types.js\";\n\n/**\n * Default match type scores\n * These values determine the base score for each match type\n * Updated to provide more granular scoring like Fuse.js\n */\nexport const DEFAULT_MATCH_TYPE_SCORES: MatchTypeScores = {\n  exact: 1.0,\n  prefix: 0.7,        // Reduced from 0.9 for better granularity\n  substring: 0.75,    // Boosted from 0.6 - exact substrings should rank high\n  phonetic: 0.5,      // Reduced from 0.8\n  fuzzy: 0.6,         // Reduced from 0.9, will be penalized by distance\n  fuzzyMin: 0.1,      // Reduced from 0.3 for wider range\n  synonym: 0.4,       // Reduced from 0.75\n  compound: 0.6,      // Reduced from 0.9\n  ngram: 0.5,         // Reduced from 0.8\n};\n\n/**\n * Default scoring modifiers\n * These values control additional scoring behavior\n */\nexport const DEFAULT_SCORING_MODIFIERS: ScoringModifiers = {\n  baseScore: 0.6,\n  shortWordBoost: 0.1,\n  shortWordMaxDiff: 3,\n  prefixLengthPenalty: false,\n};\n\n/**\n * Default configuration for FuzzyFindJS\n * Provides sensible defaults that work out of the box\n */\nexport const DEFAULT_CONFIG: FuzzyConfig = {\n  languages: [\"english\"],\n  features: [\"phonetic\", \"compound\", \"synonyms\", \"keyboard-neighbors\", \"partial-words\", \"missing-letters\", \"extra-letters\", \"transpositions\"],\n  performance: \"balanced\",\n  maxResults: 10,\n  minQueryLength: 2,\n  fuzzyThreshold: 0.3,      // Reduced from 0.75 for better recall\n  maxEditDistance: 2,\n  ngramSize: 3,\n  enableAlphanumericSegmentation: true, // Enabled by default - opt-out for performance if needed\n  alphanumericAlphaWeight: 0.7,\n  alphanumericNumericWeight: 0.3,\n  alphanumericNumericEditDistanceMultiplier: 1.5,\n  matchTypeScores: DEFAULT_MATCH_TYPE_SCORES,\n  scoringModifiers: DEFAULT_SCORING_MODIFIERS,\n};\n\n/**\n * Performance-optimized configurations\n */\nexport const PERFORMANCE_CONFIGS: Record<string, Partial<FuzzyConfig>> = {\n  fast: {\n    performance: \"fast\",\n    features: [\"partial-words\", \"missing-letters\"],\n    maxEditDistance: 1,\n    fuzzyThreshold: 0.4,      // Reduced from 0.9 for better recall\n    maxResults: 3,\n    enableAlphanumericSegmentation: true, // Enabled in fast mode\n    matchTypeScores: {\n      exact: 1.0,\n      prefix: 0.8,      // Higher than default but still granular\n      substring: 0.5,    // Lower - less important\n      fuzzy: 0.7,\n      fuzzyMin: 0.2,     // Higher minimum than default but still low\n    },\n  },\n  balanced: {\n    performance: \"balanced\",\n    features: [\"phonetic\", \"compound\", \"synonyms\", \"keyboard-neighbors\", \"partial-words\", \"missing-letters\", \"extra-letters\", \"transpositions\"],\n    maxEditDistance: 2,\n    fuzzyThreshold: 0.3,      // Reduced from 0.75 for better recall\n    maxResults: 10,\n    enableAlphanumericSegmentation: true,\n    // Uses default scoring for balanced performance\n  },\n  comprehensive: {\n    performance: \"comprehensive\",\n    features: [\"phonetic\", \"compound\", \"synonyms\", \"keyboard-neighbors\", \"partial-words\", \"missing-letters\", \"extra-letters\", \"transpositions\"],\n    maxEditDistance: 3,\n    fuzzyThreshold: 0.2,      // Reduced from default for maximum recall\n    maxResults: 20,\n    enableAlphanumericSegmentation: true,\n    matchTypeScores: {\n      exact: 1.0,\n      prefix: 0.6,      // Lower for more comprehensive results\n      substring: 0.7,    // Higher than prefix - prioritize substring matching\n      fuzzy: 0.5,\n      fuzzyMin: 0.05,    // Very low for maximum recall\n      phonetic: 0.6,     // Higher for comprehensive matching\n      synonym: 0.5,\n      compound: 0.7,\n      ngram: 0.6,\n    },\n  },\n};\n\n/**\n * Language-specific feature recommendations\n */\nexport const LANGUAGE_FEATURES: Record<string, FuzzyFeature[]> = {\n  german: [\n    //\n    \"phonetic\",\n    \"compound\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n    \"extra-letters\",\n  ],\n  english: [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n    \"transpositions\",\n  ],\n  spanish: [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n  ],\n  french: [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n  ],\n};\n\n/**\n * Merge user configuration with defaults\n */\nexport function mergeConfig(userConfig: Partial<FuzzyConfig> = {}): FuzzyConfig {\n  const baseConfig = { ...DEFAULT_CONFIG };\n\n  // Apply performance preset if specified\n  if (userConfig.performance && userConfig.performance !== \"balanced\") {\n    const performanceConfig = PERFORMANCE_CONFIGS[userConfig.performance];\n    Object.assign(baseConfig, performanceConfig);\n    \n    // Deep merge scoring configs from performance preset\n    if (performanceConfig.matchTypeScores) {\n      baseConfig.matchTypeScores = {\n        ...DEFAULT_MATCH_TYPE_SCORES,\n        ...performanceConfig.matchTypeScores,\n      };\n    }\n    if (performanceConfig.scoringModifiers) {\n      baseConfig.scoringModifiers = {\n        ...DEFAULT_SCORING_MODIFIERS,\n        ...performanceConfig.scoringModifiers,\n      };\n    }\n  }\n\n  // Apply user overrides\n  const mergedConfig = { ...baseConfig, ...userConfig };\n\n  // Deep merge user scoring configs\n  if (userConfig.matchTypeScores) {\n    mergedConfig.matchTypeScores = {\n      ...baseConfig.matchTypeScores,\n      ...userConfig.matchTypeScores,\n    };\n  }\n  if (userConfig.scoringModifiers) {\n    mergedConfig.scoringModifiers = {\n      ...baseConfig.scoringModifiers,\n      ...userConfig.scoringModifiers,\n    };\n  }\n\n  // Auto-adjust features based on languages if not explicitly set\n  if (!userConfig.features && userConfig.languages) {\n    const recommendedFeatures = new Set<FuzzyFeature>();\n\n    for (const lang of userConfig.languages) {\n      const langFeatures = LANGUAGE_FEATURES[lang] || LANGUAGE_FEATURES.english;\n      langFeatures.forEach((feature) => recommendedFeatures.add(feature));\n    }\n\n    mergedConfig.features = Array.from(recommendedFeatures);\n  }\n\n  return mergedConfig;\n}\n\n/**\n * Validate configuration\n */\nexport function validateConfig(config: FuzzyConfig): void {\n  if (config.maxResults < 1) {\n    throw new Error(\"maxResults must be at least 1\");\n  }\n\n  if (config.minQueryLength < 1) {\n    throw new Error(\"minQueryLength must be at least 1\");\n  }\n\n  if (config.fuzzyThreshold < 0 || config.fuzzyThreshold > 1) {\n    throw new Error(\"fuzzyThreshold must be between 0 and 1\");\n  }\n\n  if (config.maxEditDistance < 0) {\n    throw new Error(\"maxEditDistance must be non-negative\");\n  }\n\n  if (config.ngramSize < 2) {\n    throw new Error(\"ngramSize must be at least 2\");\n  }\n\n  if (config.languages.length === 0) {\n    throw new Error(\"At least one language must be specified\");\n  }\n}\n","import type { LanguageProcessor, FuzzyFeature } from \"../../core/types.js\";\n\n/**\n * Abstract base class for language processors\n * Provides common functionality and enforces interface\n */\nexport abstract class BaseLanguageProcessor implements LanguageProcessor {\n  abstract readonly language: string;\n  abstract readonly displayName: string;\n  abstract readonly supportedFeatures: FuzzyFeature[];\n\n  /**\n   * Basic text normalization (override for language-specific behavior)\n   */\n  normalize(text: string): string {\n    return text.toLowerCase().trim().replace(/\\s+/g, \" \");\n  }\n\n  /**\n   * Default phonetic implementation (override for language-specific algorithms)\n   */\n  getPhoneticCode(word: string): string {\n    // Simple soundex-like algorithm as fallback\n    const normalized = this.normalize(word);\n    if (normalized.length === 0) return \"\";\n\n    let code = normalized[0].toUpperCase();\n    const consonantMap: Record<string, string> = {\n      b: \"1\",\n      f: \"1\",\n      p: \"1\",\n      v: \"1\",\n      c: \"2\",\n      g: \"2\",\n      j: \"2\",\n      k: \"2\",\n      q: \"2\",\n      s: \"2\",\n      x: \"2\",\n      z: \"2\",\n      d: \"3\",\n      t: \"3\",\n      l: \"4\",\n      m: \"5\",\n      n: \"5\",\n      r: \"6\",\n    };\n\n    for (let i = 1; i < normalized.length && code.length < 4; i++) {\n      const char = normalized[i];\n      const digit = consonantMap[char];\n      if (digit && digit !== code[code.length - 1]) {\n        code += digit;\n      }\n    }\n\n    return code.padEnd(4, \"0\");\n  }\n\n  /**\n   * Default compound word splitting (override for languages that support it)\n   */\n  splitCompoundWords(word: string): string[] {\n    return [word]; // No splitting by default\n  }\n\n  /**\n   * Generate common word variants\n   * OPTIMIZATION 2: In fast mode, generate fewer prefixes to reduce index size\n   */\n  getWordVariants(word: string, performanceMode?: string): string[] {\n    const variants = new Set<string>();\n    const normalized = this.normalize(word);\n\n    variants.add(normalized);\n    variants.add(word); // Original form\n\n    // Add variants without common endings\n    const commonEndings = this.getCommonEndings();\n    for (const ending of commonEndings) {\n      if (normalized.endsWith(ending) && normalized.length > ending.length + 2) {\n        variants.add(normalized.slice(0, -ending.length));\n      }\n    }\n\n    // Add partial variants for longer words\n    if (normalized.length > 4) {\n      // OPTIMIZATION: In fast mode, generate every 2nd prefix to reduce index size by ~50%\n      const step = performanceMode === 'fast' ? 2 : 1;\n      for (let i = 3; i < normalized.length; i += step) {\n        variants.add(normalized.slice(0, i));\n      }\n    }\n\n    return Array.from(variants);\n  }\n\n  /**\n   * Get common word endings for this language (override for language-specific endings)\n   */\n  protected getCommonEndings(): string[] {\n    return [\n      //\n      \"s\",\n      \"es\",\n      \"ed\",\n      \"ing\",\n      \"er\",\n      \"est\",\n    ];\n  }\n\n  /**\n   * Default synonym lookup (override to provide language-specific synonyms)\n   */\n  getSynonyms(_word: string): string[] {\n    return []; // No built-in synonyms by default\n  }\n\n  /**\n   * Check if two characters are keyboard neighbors\n   */\n  isValidSubstitution(char1: string, char2: string): boolean {\n    const keyboardNeighbors = this.getKeyboardNeighbors();\n    const neighbors = keyboardNeighbors[char1.toLowerCase()];\n    return neighbors ? neighbors.includes(char2.toLowerCase()) : false;\n  }\n\n  /**\n   * Get keyboard neighbor mappings (QWERTY layout by default)\n   */\n  protected getKeyboardNeighbors(): Record<string, string[]> {\n    return {\n      q: [\"w\", \"a\", \"s\"],\n      w: [\"q\", \"e\", \"a\", \"s\", \"d\"],\n      e: [\"w\", \"r\", \"s\", \"d\", \"f\"],\n      r: [\"e\", \"t\", \"d\", \"f\", \"g\"],\n      t: [\"r\", \"y\", \"f\", \"g\", \"h\"],\n      y: [\"t\", \"u\", \"g\", \"h\", \"j\"],\n      u: [\"y\", \"i\", \"h\", \"j\", \"k\"],\n      i: [\"u\", \"o\", \"j\", \"k\", \"l\"],\n      o: [\"i\", \"p\", \"k\", \"l\"],\n      p: [\"o\", \"l\"],\n      a: [\"q\", \"w\", \"s\", \"z\", \"x\"],\n      s: [\"q\", \"w\", \"e\", \"a\", \"d\", \"z\", \"x\", \"c\"],\n      d: [\"w\", \"e\", \"r\", \"s\", \"f\", \"x\", \"c\", \"v\"],\n      f: [\"e\", \"r\", \"t\", \"d\", \"g\", \"c\", \"v\", \"b\"],\n      g: [\"r\", \"t\", \"y\", \"f\", \"h\", \"v\", \"b\", \"n\"],\n      h: [\"t\", \"y\", \"u\", \"g\", \"j\", \"b\", \"n\", \"m\"],\n      j: [\"y\", \"u\", \"i\", \"h\", \"k\", \"n\", \"m\"],\n      k: [\"u\", \"i\", \"o\", \"j\", \"l\", \"m\"],\n      l: [\"i\", \"o\", \"p\", \"k\"],\n      z: [\"a\", \"s\", \"x\"],\n      x: [\"a\", \"s\", \"d\", \"z\", \"c\"],\n      c: [\"s\", \"d\", \"f\", \"x\", \"v\"],\n      v: [\"d\", \"f\", \"g\", \"c\", \"b\"],\n      b: [\"f\", \"g\", \"h\", \"v\", \"n\"],\n      n: [\"g\", \"h\", \"j\", \"b\", \"m\"],\n      m: [\"h\", \"j\", \"k\", \"n\"],\n    };\n  }\n\n  /**\n   * Generate n-grams for partial matching\n   */\n  generateNgrams(word: string, n: number = 3): string[] {\n    const normalized = this.normalize(word);\n    if (normalized.length < n) return [normalized];\n\n    const ngrams: string[] = [];\n    for (let i = 0; i <= normalized.length - n; i++) {\n      ngrams.push(normalized.slice(i, i + n));\n    }\n    return ngrams;\n  }\n\n  /**\n   * Calculate basic edit distance (Levenshtein)\n   */\n  calculateEditDistance(str1: string, str2: string): number {\n    const matrix: number[][] = [];\n    const len1 = str1.length;\n    const len2 = str2.length;\n\n    // Initialize matrix\n    for (let i = 0; i <= len1; i++) {\n      matrix[i] = [i];\n    }\n    for (let j = 0; j <= len2; j++) {\n      matrix[0][j] = j;\n    }\n\n    // Fill matrix\n    for (let i = 1; i <= len1; i++) {\n      for (let j = 1; j <= len2; j++) {\n        const cost = str1[i - 1] === str2[j - 1] ? 0 : 1;\n        matrix[i][j] = Math.min(\n          matrix[i - 1][j] + 1, // deletion\n          matrix[i][j - 1] + 1, // insertion\n          matrix[i - 1][j - 1] + cost // substitution\n        );\n      }\n    }\n\n    return matrix[len1][len2];\n  }\n}\n","import { BaseLanguageProcessor } from \"../base/LanguageProcessor.js\";\nimport type { FuzzyFeature } from \"../../core/types.js\";\n\n/**\n * German language processor with specialized features:\n * - Umlaut normalization (ä, ö, ü, ß)\n * - Compound word splitting\n * - German-specific phonetic matching (Kölner Phonetik)\n * - Common German word endings\n */\nexport class GermanProcessor extends BaseLanguageProcessor {\n  readonly language = \"german\";\n  readonly displayName = \"Deutsch\";\n  readonly supportedFeatures: FuzzyFeature[] = [\"phonetic\", \"compound\", \"synonyms\", \"keyboard-neighbors\", \"partial-words\", \"missing-letters\", \"extra-letters\"];\n\n  /**\n   * German text normalization with umlaut handling\n   */\n  normalize(text: string): string {\n    return (\n      text\n        .toLowerCase()\n        .trim()\n        .replace(/\\s+/g, \" \")\n        // Normalize umlauts\n        .replace(/ä/g, \"ae\")\n        .replace(/ö/g, \"oe\")\n        .replace(/ü/g, \"ue\")\n        .replace(/ß/g, \"ss\")\n    );\n  }\n\n  /**\n   * Kölner Phonetik algorithm for German phonetic matching\n   */\n  getPhoneticCode(word: string): string {\n    const normalized = this.normalize(word);\n    if (normalized.length === 0) return \"\";\n\n    let code = \"\";\n    let prev = \"\";\n\n    for (let i = 0; i < normalized.length; i++) {\n      const char = normalized[i];\n      const next = i < normalized.length - 1 ? normalized[i + 1] : \"\";\n      let digit = \"\";\n\n      switch (char) {\n        case \"a\":\n        case \"e\":\n        case \"i\":\n        case \"j\":\n        case \"o\":\n        case \"u\":\n        case \"y\":\n          digit = \"0\";\n          break;\n        case \"h\":\n          // H is ignored\n          continue;\n        case \"b\":\n        case \"p\":\n          digit = \"1\";\n          break;\n        case \"d\":\n        case \"t\":\n          if (next === \"c\" || next === \"s\" || next === \"z\") {\n            digit = \"8\";\n          } else {\n            digit = \"2\";\n          }\n          break;\n        case \"f\":\n        case \"v\":\n        case \"w\":\n          digit = \"3\";\n          break;\n        case \"g\":\n        case \"k\":\n        case \"q\":\n          digit = \"4\";\n          break;\n        case \"c\":\n          if (i === 0) {\n            if (next === \"a\" || next === \"h\" || next === \"k\" || next === \"l\" || next === \"o\" || next === \"q\" || next === \"r\" || next === \"u\" || next === \"x\") {\n              digit = \"4\";\n            } else {\n              digit = \"8\";\n            }\n          } else {\n            if (prev === \"s\" || prev === \"z\") {\n              digit = \"8\";\n            } else if (next === \"h\") {\n              digit = \"4\";\n            } else if (next === \"k\" || next === \"q\") {\n              digit = \"4\";\n            } else {\n              digit = \"8\";\n            }\n          }\n          break;\n        case \"x\":\n          if (prev === \"c\" || prev === \"k\" || prev === \"q\") {\n            digit = \"8\";\n          } else {\n            digit = \"48\";\n          }\n          break;\n        case \"l\":\n          digit = \"5\";\n          break;\n        case \"m\":\n        case \"n\":\n          digit = \"6\";\n          break;\n        case \"r\":\n          digit = \"7\";\n          break;\n        case \"s\":\n        case \"z\":\n          digit = \"8\";\n          break;\n        default:\n          continue;\n      }\n\n      // Don't add consecutive identical digits\n      if (digit && digit !== prev) {\n        code += digit;\n      }\n      prev = digit;\n    }\n\n    return code || \"0\";\n  }\n\n  /**\n   * German compound word splitting\n   * Uses common German compound patterns and a dictionary approach\n   */\n  splitCompoundWords(word: string): string[] {\n    const normalized = this.normalize(word);\n    if (normalized.length < 6) return [word]; // Too short to be compound\n\n    const parts: string[] = [];\n    const commonPrefixes = this.getCommonPrefixes();\n    const commonSuffixes = this.getCommonSuffixes();\n    const commonWords = this.getCommonWords();\n\n    // Try to find known prefixes\n    for (const prefix of commonPrefixes) {\n      if (normalized.startsWith(prefix) && normalized.length > prefix.length + 3) {\n        const remainder = normalized.slice(prefix.length);\n        parts.push(prefix);\n        parts.push(...this.splitCompoundWords(remainder));\n        break;\n      }\n    }\n\n    if (parts.length === 0) {\n      // Try to find known suffixes\n      for (const suffix of commonSuffixes) {\n        if (normalized.endsWith(suffix) && normalized.length > suffix.length + 3) {\n          const remainder = normalized.slice(0, -suffix.length);\n          parts.push(...this.splitCompoundWords(remainder));\n          parts.push(suffix);\n          break;\n        }\n      }\n    }\n\n    if (parts.length === 0) {\n      // Try to find known words within the compound\n      for (let i = 3; i <= normalized.length - 3; i++) {\n        const leftPart = normalized.slice(0, i);\n        const rightPart = normalized.slice(i);\n\n        if (commonWords.has(leftPart) && rightPart.length >= 3) {\n          parts.push(leftPart);\n          parts.push(...this.splitCompoundWords(rightPart));\n          break;\n        }\n      }\n    }\n\n    return parts.length > 0 ? parts : [word];\n  }\n\n  /**\n   * German word variants including common endings\n   * Uses optimized base implementation with German-specific additions\n   */\n  getWordVariants(word: string, performanceMode?: string): string[] {\n    // Use optimized base implementation\n    const variants = new Set(super.getWordVariants(word, performanceMode));\n\n    // Add German-specific compound word parts\n    const compoundParts = this.splitCompoundWords(word);\n    if (compoundParts.length > 1) {\n      compoundParts.forEach((part) => {\n        if (part.length >= 3) {\n          variants.add(this.normalize(part));\n        }\n      });\n    }\n\n    return Array.from(variants);\n  }\n\n  /**\n   * German word endings\n   */\n  protected getCommonEndings(): string[] {\n    return [\n      //\n      \"en\",\n      \"e\",\n      \"er\",\n      \"n\",\n      \"r\",\n      \"s\",\n      \"es\",\n      \"t\",\n      \"ung\",\n      \"heit\",\n      \"keit\",\n      \"schaft\",\n      \"chen\",\n      \"lein\",\n      \"lich\",\n      \"ig\",\n      \"isch\",\n      \"bar\",\n      \"los\",\n      \"voll\",\n    ];\n  }\n\n  /**\n   * German synonyms for common words\n   */\n  getSynonyms(word: string): string[] {\n    const synonymMap: Record<string, string[]> = {\n      arzt: [\n        //\n        \"doktor\",\n        \"mediziner\",\n        \"doc\",\n      ],\n      krankenhaus: [\n        //\n        \"spital\",\n        \"klinik\",\n        \"hospital\",\n      ],\n      schule: [\n        //\n        \"bildungseinrichtung\",\n        \"lehranstalt\",\n      ],\n      auto: [\n        //\n        \"wagen\",\n        \"fahrzeug\",\n        \"pkw\",\n      ],\n      haus: [\n        //\n        \"gebaeude\",\n        \"heim\",\n        \"wohnhaus\",\n      ],\n      strasse: [\n        //\n        \"weg\",\n        \"gasse\",\n        \"allee\",\n      ],\n      stadt: [\n        //\n        \"ort\",\n        \"gemeinde\",\n        \"ortschaft\",\n      ],\n      arbeit: [\n        //\n        \"job\",\n        \"beruf\",\n        \"taetigkeit\",\n      ],\n      geld: [\n        //\n        \"waehrung\",\n        \"kapital\",\n        \"finanzen\",\n      ],\n      zeit: [\n        //\n        \"dauer\",\n        \"periode\",\n        \"zeitraum\",\n      ],\n    };\n\n    const normalized = this.normalize(word);\n    return synonymMap[normalized] || [];\n  }\n\n  /**\n   * German keyboard layout (QWERTZ)\n   */\n  protected getKeyboardNeighbors(): Record<string, string[]> {\n    return {\n      q: [\n        //\n        \"w\",\n        \"a\",\n        \"s\",\n      ],\n      w: [\n        //\n        \"q\",\n        \"e\",\n        \"a\",\n        \"s\",\n        \"d\",\n      ],\n      e: [\n        //\n        \"w\",\n        \"r\",\n        \"s\",\n        \"d\",\n        \"f\",\n      ],\n      r: [\n        //\n        \"e\",\n        \"t\",\n        \"d\",\n        \"f\",\n        \"g\",\n      ],\n      t: [\n        //\n        \"r\",\n        \"z\",\n        \"f\",\n        \"g\",\n        \"h\",\n      ],\n      z: [\n        //\n        \"t\",\n        \"u\",\n        \"g\",\n        \"h\",\n        \"j\",\n      ], // QWERTZ difference\n      u: [\n        //\n        \"z\",\n        \"i\",\n        \"h\",\n        \"j\",\n        \"k\",\n      ],\n      i: [\n        //\n        \"u\",\n        \"o\",\n        \"j\",\n        \"k\",\n        \"l\",\n      ],\n      o: [\n        //\n        \"i\",\n        \"p\",\n        \"k\",\n        \"l\",\n        \"oe\",\n      ],\n      p: [\n        //\n        \"o\",\n        \"ue\",\n        \"l\",\n        \"oe\",\n      ],\n      ue: [\n        //\n        \"p\",\n        \"ae\",\n      ], // German umlaut\n      a: [\n        //\n        \"q\",\n        \"w\",\n        \"s\",\n        \"y\",\n        \"x\",\n      ],\n      s: [\n        //\n        \"q\",\n        \"w\",\n        \"e\",\n        \"a\",\n        \"d\",\n        \"y\",\n        \"x\",\n        \"c\",\n      ],\n      d: [\n        //\n        \"w\",\n        \"e\",\n        \"r\",\n        \"s\",\n        \"f\",\n        \"x\",\n        \"c\",\n        \"v\",\n      ],\n      f: [\n        //\n        \"e\",\n        \"r\",\n        \"t\",\n        \"d\",\n        \"g\",\n        \"c\",\n        \"v\",\n        \"b\",\n      ],\n      g: [\n        //\n        \"r\",\n        \"t\",\n        \"z\",\n        \"f\",\n        \"h\",\n        \"v\",\n        \"b\",\n        \"n\",\n      ],\n      h: [\n        //\n        \"t\",\n        \"z\",\n        \"u\",\n        \"g\",\n        \"j\",\n        \"b\",\n        \"n\",\n        \"m\",\n      ],\n      j: [\n        //\n        \"z\",\n        \"u\",\n        \"i\",\n        \"h\",\n        \"k\",\n        \"n\",\n        \"m\",\n      ],\n      k: [\n        //\n        \"u\",\n        \"i\",\n        \"o\",\n        \"j\",\n        \"l\",\n        \"m\",\n      ],\n      l: [\n        //\n        \"i\",\n        \"o\",\n        \"p\",\n        \"k\",\n        \"oe\",\n      ],\n      oe: [\n        //\n        \"o\",\n        \"p\",\n        \"ue\",\n        \"l\",\n        \"ae\",\n      ], // German umlaut\n      ae: [\n        //\n        \"ue\",\n        \"oe\",\n      ], // German umlaut\n      y: [\n        //\n        \"a\",\n        \"s\",\n        \"x\",\n      ], // QWERTZ difference\n      x: [\n        //\n        \"a\",\n        \"s\",\n        \"d\",\n        \"y\",\n        \"c\",\n      ],\n      c: [\n        //\n        \"s\",\n        \"d\",\n        \"f\",\n        \"x\",\n        \"v\",\n      ],\n      v: [\n        //\n        \"d\",\n        \"f\",\n        \"g\",\n        \"c\",\n        \"b\",\n      ],\n      b: [\n        //\n        \"f\",\n        \"g\",\n        \"h\",\n        \"v\",\n        \"n\",\n      ],\n      n: [\n        //\n        \"g\",\n        \"h\",\n        \"j\",\n        \"b\",\n        \"m\",\n      ],\n      m: [\n        //\n        \"h\",\n        \"j\",\n        \"k\",\n        \"n\",\n      ],\n    };\n  }\n\n  /**\n   * Common German prefixes for compound word splitting\n   */\n  private getCommonPrefixes(): string[] {\n    return [\"un\", \"vor\", \"nach\", \"bei\", \"mit\", \"ab\", \"an\", \"auf\", \"aus\", \"ein\", \"gegen\", \"hinter\", \"neben\", \"ueber\", \"unter\", \"zwischen\", \"selbst\"];\n  }\n\n  /**\n   * Common German suffixes for compound word splitting\n   */\n  private getCommonSuffixes(): string[] {\n    return [\"haus\", \"platz\", \"strasse\", \"weg\", \"hof\", \"berg\", \"tal\", \"feld\", \"stadt\", \"dorf\", \"heim\", \"werk\", \"bau\", \"anlage\", \"zentrum\"];\n  }\n\n  /**\n   * Common German words for compound splitting\n   */\n  private getCommonWords(): Set<string> {\n    return new Set([\"kranken\", \"kinder\", \"frauen\", \"maenner\", \"alt\", \"neu\", \"gross\", \"klein\", \"hoch\", \"tief\", \"lang\", \"kurz\", \"breit\", \"schmal\", \"dick\", \"duenn\", \"stark\", \"schwach\", \"schnell\", \"langsam\", \"heiss\", \"kalt\", \"warm\", \"auto\", \"bahn\", \"bus\", \"zug\", \"flug\", \"schiff\", \"rad\", \"motor\", \"wasser\", \"feuer\", \"erde\", \"luft\", \"licht\", \"schatten\", \"sonne\", \"mond\", \"tag\", \"nacht\", \"morgen\", \"abend\", \"mittag\", \"zeit\", \"jahr\", \"monat\"]);\n  }\n}\n","import { BaseLanguageProcessor } from \"../base/LanguageProcessor.js\";\nimport type { FuzzyFeature } from \"../../core/types.js\";\n\n/**\n * English language processor with specialized features:\n * - Metaphone phonetic algorithm\n * - Common English contractions\n * - English-specific word endings\n * - Comprehensive synonym support\n */\nexport class EnglishProcessor extends BaseLanguageProcessor {\n  readonly language = \"english\";\n  readonly displayName = \"English\";\n  readonly supportedFeatures: FuzzyFeature[] = [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n    \"extra-letters\",\n    \"transpositions\",\n  ];\n\n  /**\n   * English text normalization with contraction handling\n   */\n  normalize(text: string): string {\n    return (\n      text\n        .toLowerCase()\n        .trim()\n        .replace(/\\s+/g, \" \")\n        // Handle common contractions\n        .replace(/won't/g, \"will not\")\n        .replace(/can't/g, \"cannot\")\n        .replace(/n't/g, \" not\")\n        .replace(/'re/g, \" are\")\n        .replace(/'ve/g, \" have\")\n        .replace(/'ll/g, \" will\")\n        .replace(/'d/g, \" would\")\n        .replace(/'m/g, \" am\")\n        .replace(/'/g, \"\")\n    ); // Remove remaining apostrophes\n  }\n\n  /**\n   * Simplified Metaphone algorithm for English phonetic matching\n   */\n  getPhoneticCode(word: string): string {\n    const normalized = this.normalize(word).replace(/[^a-z]/g, \"\");\n    if (normalized.length === 0) return \"\";\n\n    let metaphone = \"\";\n    let current = 0;\n    const length = normalized.length;\n\n    // Handle initial letters\n    if (normalized.startsWith(\"gn\") || normalized.startsWith(\"kn\") || normalized.startsWith(\"pn\") || normalized.startsWith(\"wr\")) {\n      current = 1;\n    }\n\n    while (current < length && metaphone.length < 4) {\n      const char = normalized[current];\n      const next = current + 1 < length ? normalized[current + 1] : \"\";\n      const prev = current > 0 ? normalized[current - 1] : \"\";\n\n      switch (char) {\n        case \"a\":\n        case \"e\":\n        case \"i\":\n        case \"o\":\n        case \"u\":\n          if (current === 0) metaphone += char.toUpperCase();\n          break;\n        case \"b\":\n          if (current === length - 1 && prev === \"m\") {\n            // Silent B at end after M\n          } else {\n            metaphone += \"B\";\n          }\n          break;\n        case \"c\":\n          if (next === \"h\") {\n            metaphone += \"X\";\n            current++;\n          } else if (next === \"i\" || next === \"e\" || next === \"y\") {\n            metaphone += \"S\";\n          } else {\n            metaphone += \"K\";\n          }\n          break;\n        case \"d\":\n          if (next === \"g\") {\n            metaphone += \"J\";\n            current++;\n          } else {\n            metaphone += \"T\";\n          }\n          break;\n        case \"f\":\n          metaphone += \"F\";\n          break;\n        case \"g\":\n          if (next === \"h\" && current !== 0) {\n            // Silent GH\n          } else if (next === \"n\") {\n            metaphone += \"N\";\n            current++;\n          } else if (next === \"i\" || next === \"e\" || next === \"y\") {\n            metaphone += \"J\";\n          } else {\n            metaphone += \"K\";\n          }\n          break;\n        case \"h\":\n          if (current === 0 || \"aeiou\".includes(prev) || \"aeiou\".includes(next)) {\n            metaphone += \"H\";\n          }\n          break;\n        case \"j\":\n          metaphone += \"J\";\n          break;\n        case \"k\":\n          if (prev !== \"c\") {\n            metaphone += \"K\";\n          }\n          break;\n        case \"l\":\n          metaphone += \"L\";\n          break;\n        case \"m\":\n          metaphone += \"M\";\n          break;\n        case \"n\":\n          metaphone += \"N\";\n          break;\n        case \"p\":\n          if (next === \"h\") {\n            metaphone += \"F\";\n            current++;\n          } else {\n            metaphone += \"P\";\n          }\n          break;\n        case \"q\":\n          metaphone += \"K\";\n          break;\n        case \"r\":\n          metaphone += \"R\";\n          break;\n        case \"s\":\n          if (next === \"h\") {\n            metaphone += \"X\";\n            current++;\n          } else {\n            metaphone += \"S\";\n          }\n          break;\n        case \"t\":\n          if (next === \"h\") {\n            metaphone += \"0\";\n            current++;\n          } else if (next === \"i\" && current + 2 < length && (normalized[current + 2] === \"a\" || normalized[current + 2] === \"o\")) {\n            metaphone += \"X\";\n          } else {\n            metaphone += \"T\";\n          }\n          break;\n        case \"v\":\n          metaphone += \"F\";\n          break;\n        case \"w\":\n          if (\"aeiou\".includes(next)) {\n            metaphone += \"W\";\n          }\n          break;\n        case \"x\":\n          metaphone += \"KS\";\n          break;\n        case \"y\":\n          if (\"aeiou\".includes(next)) {\n            metaphone += \"Y\";\n          }\n          break;\n        case \"z\":\n          metaphone += \"S\";\n          break;\n      }\n      current++;\n    }\n\n    return metaphone || \"A\";\n  }\n\n  /**\n   * English word variants\n   * Uses optimized base implementation with English-specific additions\n   */\n  getWordVariants(word: string, performanceMode?: string): string[] {\n    // Use optimized base implementation\n    const variants = new Set(super.getWordVariants(word, performanceMode));\n    \n    const normalized = this.normalize(word);\n\n    // Add English-specific morphological variants\n    // Add plural/singular variants\n    if (normalized.endsWith(\"s\") && normalized.length > 3) {\n      variants.add(normalized.slice(0, -1));\n    }\n    if (!normalized.endsWith(\"s\")) {\n      variants.add(normalized + \"s\");\n    }\n\n    // Add -ing/-ed variants\n    if (normalized.endsWith(\"ing\") && normalized.length > 5) {\n      const base = normalized.slice(0, -3);\n      variants.add(base);\n      variants.add(base + \"e\"); // handle dropped 'e'\n    }\n    if (normalized.endsWith(\"ed\") && normalized.length > 4) {\n      const base = normalized.slice(0, -2);\n      variants.add(base);\n      variants.add(base + \"e\"); // handle dropped 'e'\n    }\n\n    return Array.from(variants);\n  }\n\n  /**\n   * English word endings\n   */\n  protected getCommonEndings(): string[] {\n    return [\n      //\n      \"s\",\n      \"es\",\n      \"ed\",\n      \"ing\",\n      \"er\",\n      \"est\",\n      \"ly\",\n      \"tion\",\n      \"sion\",\n      \"ness\",\n      \"ment\",\n      \"able\",\n      \"ible\",\n      \"ful\",\n      \"less\",\n      \"ous\",\n      \"ious\",\n      \"al\",\n      \"ial\",\n      \"ic\",\n      \"ive\",\n      \"ary\",\n      \"ery\",\n      \"ory\",\n    ];\n  }\n\n  /**\n   * English synonyms for common words\n   */\n  getSynonyms(word: string): string[] {\n    const synonymMap: Record<string, string[]> = {\n      doctor: [\n        //\n        \"physician\",\n        \"medic\",\n        \"doc\",\n        \"md\",\n      ],\n      hospital: [\n        //\n        \"clinic\",\n        \"medical center\",\n        \"infirmary\",\n      ],\n      school: [\n        //\n        \"academy\",\n        \"institution\",\n        \"college\",\n        \"university\",\n      ],\n      car: [\n        //\n        \"vehicle\",\n        \"automobile\",\n        \"auto\",\n      ],\n      house: [\n        //\n        \"home\",\n        \"residence\",\n        \"dwelling\",\n        \"building\",\n      ],\n      street: [\n        //\n        \"road\",\n        \"avenue\",\n        \"lane\",\n        \"boulevard\",\n      ],\n      city: [\n        //\n        \"town\",\n        \"municipality\",\n        \"urban area\",\n      ],\n      work: [\n        //\n        \"job\",\n        \"employment\",\n        \"occupation\",\n        \"career\",\n      ],\n      money: [\n        //\n        \"cash\",\n        \"currency\",\n        \"funds\",\n        \"capital\",\n      ],\n      time: [\n        //\n        \"duration\",\n        \"period\",\n        \"moment\",\n        \"hour\",\n      ],\n      big: [\n        //\n        \"large\",\n        \"huge\",\n        \"enormous\",\n        \"massive\",\n        \"giant\",\n      ],\n      small: [\n        //\n        \"little\",\n        \"tiny\",\n        \"miniature\",\n        \"petite\",\n      ],\n      fast: [\n        //\n        \"quick\",\n        \"rapid\",\n        \"speedy\",\n        \"swift\",\n      ],\n      slow: [\n        //\n        \"sluggish\",\n        \"gradual\",\n        \"leisurely\",\n      ],\n      good: [\n        //\n        \"excellent\",\n        \"great\",\n        \"wonderful\",\n        \"fine\",\n      ],\n      bad: [\n        //\n        \"poor\",\n        \"terrible\",\n        \"awful\",\n        \"horrible\",\n      ],\n      happy: [\n        //\n        \"joyful\",\n        \"cheerful\",\n        \"glad\",\n        \"pleased\",\n      ],\n      sad: [\n        //\n        \"unhappy\",\n        \"depressed\",\n        \"melancholy\",\n        \"sorrowful\",\n      ],\n    };\n\n    const normalized = this.normalize(word);\n    return synonymMap[normalized] || [];\n  }\n}\n","import { BaseLanguageProcessor } from \"../base/LanguageProcessor.js\";\nimport type { FuzzyFeature } from \"../../core/types.js\";\n\n/**\n * Spanish language processor with specialized features:\n * - Accent normalization (á, é, í, ó, ú, ñ)\n * - Spanish phonetic patterns\n * - Common Spanish word endings\n * - Spanish synonym support\n */\nexport class SpanishProcessor extends BaseLanguageProcessor {\n  readonly language = \"spanish\";\n  readonly displayName = \"Español\";\n  readonly supportedFeatures: FuzzyFeature[] = [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n    \"extra-letters\",\n  ];\n\n  /**\n   * Spanish text normalization with accent handling\n   */\n  normalize(text: string): string {\n    return (\n      text\n        .toLowerCase()\n        .trim()\n        .replace(/\\s+/g, \" \")\n        // Normalize accented characters\n        .replace(/á/g, \"a\")\n        .replace(/é/g, \"e\")\n        .replace(/í/g, \"i\")\n        .replace(/ó/g, \"o\")\n        .replace(/ú/g, \"u\")\n        .replace(/ñ/g, \"n\")\n        .replace(/ü/g, \"u\")\n    );\n  }\n\n  /**\n   * Spanish phonetic matching\n   */\n  getPhoneticCode(word: string): string {\n    const normalized = this.normalize(word);\n    if (normalized.length === 0) return \"\";\n\n    let code = \"\";\n    let prev = \"\";\n\n    for (let i = 0; i < normalized.length; i++) {\n      const char = normalized[i];\n      const next = i < normalized.length - 1 ? normalized[i + 1] : \"\";\n      let digit = \"\";\n\n      switch (char) {\n        case \"a\":\n        case \"e\":\n        case \"i\":\n        case \"o\":\n        case \"u\":\n          digit = \"0\";\n          break;\n        case \"b\":\n        case \"v\": // B and V sound similar in Spanish\n          digit = \"1\";\n          break;\n        case \"c\":\n          if (next === \"h\") {\n            digit = \"2\"; // CH sound\n          } else if (next === \"e\" || next === \"i\") {\n            digit = \"8\"; // CE, CI sounds like S\n          } else {\n            digit = \"4\";\n          }\n          break;\n        case \"d\":\n          digit = \"3\";\n          break;\n        case \"f\":\n          digit = \"5\";\n          break;\n        case \"g\":\n          if (next === \"u\" && i + 2 < normalized.length && (normalized[i + 2] === \"e\" || normalized[i + 2] === \"i\")) {\n            digit = \"4\"; // GUE, GUI\n          } else if (next === \"e\" || next === \"i\") {\n            digit = \"6\"; // GE, GI sound like J\n          } else {\n            digit = \"4\";\n          }\n          break;\n        case \"h\":\n          // H is silent in Spanish\n          continue;\n        case \"j\":\n          digit = \"6\";\n          break;\n        case \"k\":\n          digit = \"4\";\n          break;\n        case \"l\":\n          if (next === \"l\") {\n            digit = \"7\"; // LL sound\n          } else {\n            digit = \"5\";\n          }\n          break;\n        case \"m\":\n          digit = \"6\";\n          break;\n        case \"n\":\n          if (next === \"n\") {\n            digit = \"7\"; // NN sound (rare)\n          } else {\n            digit = \"6\";\n          }\n          break;\n        case \"ñ\":\n          digit = \"7\"; // Ñ sound\n          break;\n        case \"p\":\n          digit = \"1\";\n          break;\n        case \"q\":\n          digit = \"4\";\n          break;\n        case \"r\":\n          if (next === \"r\" || i === 0) {\n            digit = \"8\"; // RR or initial R\n          } else {\n            digit = \"7\";\n          }\n          break;\n        case \"s\":\n          digit = \"8\";\n          break;\n        case \"t\":\n          digit = \"3\";\n          break;\n        case \"w\":\n          digit = \"1\"; // Rare in Spanish\n          break;\n        case \"x\":\n          digit = \"48\";\n          break;\n        case \"y\":\n          digit = \"7\";\n          break;\n        case \"z\":\n          digit = \"8\";\n          break;\n        default:\n          continue;\n      }\n\n      if (digit && digit !== prev) {\n        code += digit;\n      }\n      prev = digit;\n    }\n\n    return code || \"0\";\n  }\n\n  /**\n   * Spanish word endings\n   */\n  protected getCommonEndings(): string[] {\n    return [\n      //\n      \"o\",\n      \"a\",\n      \"os\",\n      \"as\",\n      \"e\",\n      \"es\",\n      \"ar\",\n      \"er\",\n      \"ir\",\n      \"ado\",\n      \"ada\",\n      \"idos\",\n      \"idas\",\n      \"ando\",\n      \"endo\",\n      \"iendo\",\n      \"cion\",\n      \"sion\",\n      \"dad\",\n      \"tad\",\n      \"mente\",\n      \"oso\",\n      \"osa\",\n      \"ito\",\n      \"ita\",\n      \"illo\",\n      \"illa\",\n    ];\n  }\n\n  /**\n   * Spanish synonyms\n   */\n  getSynonyms(word: string): string[] {\n    const synonymMap: Record<string, string[]> = {\n      medico: [\n        //\n        \"doctor\",\n        \"facultativo\",\n      ],\n      hospital: [\n        //\n        \"clinica\",\n        \"sanatorio\",\n      ],\n      escuela: [\n        //\n        \"colegio\",\n        \"instituto\",\n      ],\n      coche: [\n        //\n        \"auto\",\n        \"automovil\",\n        \"vehiculo\",\n      ],\n      casa: [\n        //\n        \"hogar\",\n        \"vivienda\",\n        \"domicilio\",\n      ],\n      calle: [\n        //\n        \"via\",\n        \"avenida\",\n        \"carretera\",\n      ],\n      ciudad: [\n        //\n        \"urbe\",\n        \"poblacion\",\n        \"municipio\",\n      ],\n      trabajo: [\n        //\n        \"empleo\",\n        \"ocupacion\",\n        \"labor\",\n      ],\n      dinero: [\n        //\n        \"plata\",\n        \"efectivo\",\n        \"capital\",\n      ],\n      tiempo: [\n        //\n        \"momento\",\n        \"periodo\",\n        \"duracion\",\n      ],\n      grande: [\n        //\n        \"enorme\",\n        \"gigante\",\n        \"inmenso\",\n      ],\n      pequeno: [\n        //\n        \"chico\",\n        \"diminuto\",\n        \"minusculo\",\n      ],\n      rapido: [\n        //\n        \"veloz\",\n        \"ligero\",\n        \"acelerado\",\n      ],\n      lento: [\n        //\n        \"despacio\",\n        \"pausado\",\n      ],\n      bueno: [\n        //\n        \"excelente\",\n        \"magnifico\",\n        \"estupendo\",\n      ],\n      malo: [\n        //\n        \"pesimo\",\n        \"terrible\",\n        \"horrible\",\n      ],\n    };\n\n    const normalized = this.normalize(word);\n    return synonymMap[normalized] || [];\n  }\n}\n","import { BaseLanguageProcessor } from \"../base/LanguageProcessor.js\";\nimport type { FuzzyFeature } from \"../../core/types.js\";\n\n/**\n * French language processor with specialized features:\n * - Accent normalization (à, é, è, ê, ç, etc.)\n * - French phonetic patterns\n * - Common French word endings\n * - French synonym support\n */\nexport class FrenchProcessor extends BaseLanguageProcessor {\n  readonly language = \"french\";\n  readonly displayName = \"Français\";\n  readonly supportedFeatures: FuzzyFeature[] = [\n    //\n    \"phonetic\",\n    \"synonyms\",\n    \"keyboard-neighbors\",\n    \"partial-words\",\n    \"missing-letters\",\n    \"extra-letters\",\n  ];\n\n  /**\n   * French text normalization with accent handling\n   */\n  normalize(text: string): string {\n    return (\n      text\n        .toLowerCase()\n        .trim()\n        .replace(/\\s+/g, \" \")\n        // Normalize accented characters\n        .replace(/[àáâãä]/g, \"a\")\n        .replace(/[èéêë]/g, \"e\")\n        .replace(/[ìíîï]/g, \"i\")\n        .replace(/[òóôõö]/g, \"o\")\n        .replace(/[ùúûü]/g, \"u\")\n        .replace(/ç/g, \"c\")\n        .replace(/ñ/g, \"n\")\n        .replace(/ÿ/g, \"y\")\n    );\n  }\n\n  /**\n   * French phonetic matching\n   */\n  getPhoneticCode(word: string): string {\n    const normalized = this.normalize(word);\n    if (normalized.length === 0) return \"\";\n\n    let code = \"\";\n    let prev = \"\";\n\n    for (let i = 0; i < normalized.length; i++) {\n      const char = normalized[i];\n      const next = i < normalized.length - 1 ? normalized[i + 1] : \"\";\n      const next2 = i < normalized.length - 2 ? normalized[i + 2] : \"\";\n      let digit = \"\";\n\n      switch (char) {\n        case \"a\":\n        case \"e\":\n        case \"i\":\n        case \"o\":\n        case \"u\":\n        case \"y\":\n          digit = \"0\";\n          break;\n        case \"b\":\n          digit = \"1\";\n          break;\n        case \"c\":\n          if (next === \"h\") {\n            digit = \"2\"; // CH sound\n          } else if (next === \"e\" || next === \"i\") {\n            digit = \"8\"; // CE, CI sounds like S\n          } else {\n            digit = \"4\";\n          }\n          break;\n        case \"d\":\n          digit = \"3\";\n          break;\n        case \"f\":\n          digit = \"5\";\n          break;\n        case \"g\":\n          if (next === \"n\") {\n            digit = \"6\"; // GN sound\n          } else if (next === \"u\" && (next2 === \"e\" || next2 === \"i\")) {\n            digit = \"4\"; // GUE, GUI\n          } else if (next === \"e\" || next === \"i\") {\n            digit = \"6\"; // GE, GI sound like J\n          } else {\n            digit = \"4\";\n          }\n          break;\n        case \"h\":\n          // H is often silent in French\n          if (i === 0) {\n            digit = \"0\"; // Initial H\n          }\n          break;\n        case \"j\":\n          digit = \"6\";\n          break;\n        case \"k\":\n          digit = \"4\";\n          break;\n        case \"l\":\n          digit = \"5\";\n          break;\n        case \"m\":\n          digit = \"6\";\n          break;\n        case \"n\":\n          digit = \"6\";\n          break;\n        case \"p\":\n          if (next === \"h\") {\n            digit = \"5\"; // PH sounds like F\n          } else {\n            digit = \"1\";\n          }\n          break;\n        case \"q\":\n          digit = \"4\";\n          break;\n        case \"r\":\n          digit = \"7\";\n          break;\n        case \"s\":\n          digit = \"8\";\n          break;\n        case \"t\":\n          if (next === \"h\") {\n            digit = \"3\"; // TH sound\n          } else {\n            digit = \"3\";\n          }\n          break;\n        case \"v\":\n          digit = \"5\";\n          break;\n        case \"w\":\n          digit = \"5\"; // Rare in French\n          break;\n        case \"x\":\n          digit = \"48\";\n          break;\n        case \"z\":\n          digit = \"8\";\n          break;\n        default:\n          continue;\n      }\n\n      if (digit && digit !== prev) {\n        code += digit;\n      }\n      prev = digit;\n    }\n\n    return code || \"0\";\n  }\n\n  /**\n   * French word endings\n   */\n  protected getCommonEndings(): string[] {\n    return [\"e\", \"es\", \"s\", \"x\", \"ent\", \"ant\", \"ment\", \"tion\", \"sion\", \"eur\", \"euse\", \"teur\", \"trice\", \"able\", \"ible\", \"ique\", \"aire\", \"oire\", \"ette\", \"elle\", \"esse\", \"asse\", \"isse\", \"age\", \"isme\", \"iste\", \"ite\", \"ude\", \"ade\"];\n  }\n\n  /**\n   * French synonyms\n   */\n  getSynonyms(word: string): string[] {\n    const synonymMap: Record<string, string[]> = {\n      medecin: [\n        //\n        \"docteur\",\n        \"praticien\",\n      ],\n      hopital: [\n        //\n        \"clinique\",\n        \"centre medical\",\n      ],\n      ecole: [\n        //\n        \"etablissement\",\n        \"institution\",\n      ],\n      voiture: [\n        //\n        \"automobile\",\n        \"vehicule\",\n        \"auto\",\n      ],\n      maison: [\n        //\n        \"domicile\",\n        \"residence\",\n        \"habitation\",\n      ],\n      rue: [\n        //\n        \"avenue\",\n        \"boulevard\",\n        \"voie\",\n      ],\n      ville: [\n        //\n        \"cite\",\n        \"commune\",\n        \"agglomeration\",\n      ],\n      travail: [\n        //\n        \"emploi\",\n        \"occupation\",\n        \"metier\",\n      ],\n      argent: [\n        //\n        \"monnaie\",\n        \"especes\",\n        \"capital\",\n      ],\n      temps: [\n        //\n        \"duree\",\n        \"periode\",\n        \"moment\",\n      ],\n      grand: [\n        //\n        \"enorme\",\n        \"immense\",\n        \"gigantesque\",\n      ],\n      petit: [\n        //\n        \"minuscule\",\n        \"minime\",\n        \"reduit\",\n      ],\n      rapide: [\n        //\n        \"vite\",\n        \"accelere\",\n        \"prompt\",\n      ],\n      lent: [\n        //\n        \"lentement\",\n        \"doucement\",\n      ],\n      bon: [\n        //\n        \"excellent\",\n        \"parfait\",\n        \"formidable\",\n      ],\n      mauvais: [\n        //\n        \"terrible\",\n        \"affreux\",\n        \"horrible\",\n      ],\n      heureux: [\n        //\n        \"joyeux\",\n        \"content\",\n        \"ravi\",\n      ],\n      triste: [\n        //\n        \"malheureux\",\n        \"chagrine\",\n        \"melancolique\",\n      ],\n    };\n\n    const normalized = this.normalize(word);\n    return synonymMap[normalized] || [];\n  }\n\n  /**\n   * French keyboard layout (AZERTY)\n   */\n  protected getKeyboardNeighbors(): Record<string, string[]> {\n    return {\n      a: [\n        //\n        \"z\",\n        \"e\",\n        \"r\",\n        \"q\",\n        \"s\",\n      ],\n      z: [\n        //\n        \"a\",\n        \"e\",\n        \"r\",\n        \"q\",\n        \"s\",\n        \"d\",\n      ],\n      e: [\n        //\n        \"z\",\n        \"r\",\n        \"t\",\n        \"s\",\n        \"d\",\n        \"f\",\n      ],\n      r: [\n        //\n        \"e\",\n        \"t\",\n        \"y\",\n        \"d\",\n        \"f\",\n        \"g\",\n      ],\n      t: [\n        //\n        \"r\",\n        \"y\",\n        \"u\",\n        \"f\",\n        \"g\",\n        \"h\",\n      ],\n      y: [\n        //\n        \"t\",\n        \"u\",\n        \"i\",\n        \"g\",\n        \"h\",\n        \"j\",\n      ],\n      u: [\n        //\n        \"y\",\n        \"i\",\n        \"o\",\n        \"h\",\n        \"j\",\n        \"k\",\n      ],\n      i: [\n        //\n        \"u\",\n        \"o\",\n        \"p\",\n        \"j\",\n        \"k\",\n        \"l\",\n      ],\n      o: [\n        //\n        \"i\",\n        \"p\",\n        \"k\",\n        \"l\",\n        \"m\",\n      ],\n      p: [\n        //\n        \"o\",\n        \"l\",\n        \"m\",\n      ],\n      q: [\n        //\n        \"a\",\n        \"z\",\n        \"s\",\n        \"w\",\n        \"x\",\n      ],\n      s: [\n        //\n        \"a\",\n        \"z\",\n        \"e\",\n        \"q\",\n        \"d\",\n        \"w\",\n        \"x\",\n        \"c\",\n      ],\n      d: [\n        //\n        \"z\",\n        \"e\",\n        \"r\",\n        \"s\",\n        \"f\",\n        \"x\",\n        \"c\",\n        \"v\",\n      ],\n      f: [\n        //\n        \"e\",\n        \"r\",\n        \"t\",\n        \"d\",\n        \"g\",\n        \"c\",\n        \"v\",\n        \"b\",\n      ],\n      g: [\n        //\n        \"r\",\n        \"t\",\n        \"y\",\n        \"f\",\n        \"h\",\n        \"v\",\n        \"b\",\n        \"n\",\n      ],\n      h: [\n        //\n        \"t\",\n        \"y\",\n        \"u\",\n        \"g\",\n        \"j\",\n        \"b\",\n        \"n\",\n      ],\n      j: [\n        //\n        \"y\",\n        \"u\",\n        \"i\",\n        \"h\",\n        \"k\",\n        \"n\",\n      ],\n      k: [\n        //\n        \"u\",\n        \"i\",\n        \"o\",\n        \"j\",\n        \"l\",\n      ],\n      l: [\n        //\n        \"i\",\n        \"o\",\n        \"p\",\n        \"k\",\n        \"m\",\n      ],\n      m: [\n        //\n        \"o\",\n        \"p\",\n        \"l\",\n      ],\n      w: [\n        //\n        \"q\",\n        \"s\",\n        \"x\",\n      ],\n      x: [\n        //\n        \"q\",\n        \"s\",\n        \"d\",\n        \"w\",\n        \"c\",\n      ],\n      c: [\n        //\n        \"s\",\n        \"d\",\n        \"f\",\n        \"x\",\n        \"v\",\n      ],\n      v: [\n        //\n        \"d\",\n        \"f\",\n        \"g\",\n        \"c\",\n        \"b\",\n      ],\n      b: [\n        //\n        \"f\",\n        \"g\",\n        \"h\",\n        \"v\",\n        \"n\",\n      ],\n      n: [\n        //\n        \"g\",\n        \"h\",\n        \"j\",\n        \"b\",\n      ],\n    };\n  }\n}\n","import type { LanguageProcessor } from \"../core/types.js\";\nimport { GermanProcessor } from \"./german/GermanProcessor.js\";\nimport { EnglishProcessor } from \"./english/EnglishProcessor.js\";\nimport { SpanishProcessor } from \"./spanish/SpanishProcessor.js\";\nimport { FrenchProcessor } from \"./french/FrenchProcessor.js\";\n\n/**\n * Registry of all available language processors\n */\nexport class LanguageRegistry {\n  private static processors = new Map<string, LanguageProcessor>([\n    [\"german\", new GermanProcessor()],\n    [\"english\", new EnglishProcessor()],\n    [\"spanish\", new SpanishProcessor()],\n    [\"french\", new FrenchProcessor()],\n  ]);\n\n  /**\n   * Get a language processor by name\n   */\n  static getProcessor(language: string): LanguageProcessor | undefined {\n    return this.processors.get(language.toLowerCase());\n  }\n\n  /**\n   * Get multiple language processors\n   */\n  static getProcessors(languages: string[]): LanguageProcessor[] {\n    return languages.map((lang) => this.getProcessor(lang)).filter((processor): processor is LanguageProcessor => processor !== undefined);\n  }\n\n  /**\n   * Get all available language names\n   */\n  static getAvailableLanguages(): string[] {\n    return Array.from(this.processors.keys());\n  }\n\n  /**\n   * Register a custom language processor\n   */\n  static registerProcessor(processor: LanguageProcessor): void {\n    this.processors.set(processor.language.toLowerCase(), processor);\n  }\n\n  /**\n   * Check if a language is supported\n   */\n  static isSupported(language: string): boolean {\n    return this.processors.has(language.toLowerCase());\n  }\n\n  /**\n   * Get processor info for all languages\n   */\n  static getProcessorInfo(): Array<{\n    language: string;\n    displayName: string;\n    supportedFeatures: string[];\n  }> {\n    return Array.from(this.processors.values()).map((processor) => ({\n      language: processor.language,\n      displayName: processor.displayName,\n      supportedFeatures: processor.supportedFeatures,\n    }));\n  }\n}\n\n// Export individual processors for direct use\nexport { GermanProcessor } from \"./german/GermanProcessor.js\";\nexport { EnglishProcessor } from \"./english/EnglishProcessor.js\";\nexport { SpanishProcessor } from \"./spanish/SpanishProcessor.js\";\nexport { FrenchProcessor } from \"./french/FrenchProcessor.js\";\nexport { BaseLanguageProcessor } from \"./base/LanguageProcessor.js\";\n","/**\n * Memory Pooling Utilities\n * Reuse objects and arrays to reduce GC pressure and improve performance\n * How does this work?\n */\n\n/**\n * Generic object pool for reusing objects\n * Reduces garbage collection overhead by 30-50%\n */\nexport class ObjectPool<T> {\n  private pool: T[] = [];\n  private factory: () => T;\n  private reset?: (obj: T) => void;\n  private maxSize: number;\n\n  constructor(factory: () => T, maxSize: number = 1000, reset?: (obj: T) => void) {\n    this.factory = factory;\n    this.maxSize = maxSize;\n    this.reset = reset;\n  }\n\n  /**\n   * Get an object from the pool or create a new one\n   */\n  acquire(): T {\n    const obj = this.pool.pop();\n    if (obj !== undefined) {\n      return obj;\n    }\n    return this.factory();\n  }\n\n  /**\n   * Return an object to the pool for reuse\n   */\n  release(obj: T): void {\n    if (this.pool.length < this.maxSize) {\n      if (this.reset) {\n        this.reset(obj);\n      }\n      this.pool.push(obj);\n    }\n  }\n\n  /**\n   * Clear the pool\n   */\n  clear(): void {\n    this.pool = [];\n  }\n\n  /**\n   * Get current pool size\n   */\n  size(): number {\n    return this.pool.length;\n  }\n}\n\n/**\n * Array pool for reusing arrays\n * Particularly useful for temporary arrays in hot paths\n * Note: size parameter is just a hint for pool organization\n */\nexport class ArrayPool<T> {\n  private pool: T[][] = [];\n  private maxSize: number;\n\n  constructor(maxSize: number = 1000) {\n    this.maxSize = maxSize;\n  }\n\n  /**\n   * Get an array from the pool (size is just a hint for organization)\n   */\n  acquire(_size?: number): T[] {\n    if (this.pool.length > 0) {\n      return this.pool.pop()!;\n    }\n    return [];\n  }\n\n  /**\n   * Return an array to the pool for reuse\n   */\n  release(arr: T[]): void {\n    if (this.pool.length < this.maxSize) {\n      // Clear array contents\n      arr.length = 0;\n      this.pool.push(arr);\n    }\n  }\n\n  /**\n   * Clear the pool\n   */\n  clear(): void {\n    this.pool = [];\n  }\n\n  /**\n   * Get total number of pooled arrays\n   */\n  size(): number {\n    return this.pool.length;\n  }\n}\n\n/**\n * Global array pool for common operations\n */\nexport const globalArrayPool = new ArrayPool<any>(500);\n\n/**\n * Helper to use pooled array with automatic cleanup\n */\nexport function withPooledArray<T, R>(\n  size: number,\n  fn: (arr: T[]) => R\n): R {\n  const arr = globalArrayPool.acquire(size) as T[];\n  try {\n    return fn(arr);\n  } finally {\n    globalArrayPool.release(arr);\n  }\n}\n\n/**\n * Map pool for reusing Map objects\n */\nexport class MapPool<K, V> {\n  private pool: Map<K, V>[] = [];\n  private maxSize: number;\n\n  constructor(maxSize: number = 100) {\n    this.maxSize = maxSize;\n  }\n\n  /**\n   * Get a Map from the pool\n   */\n  acquire(): Map<K, V> {\n    const map = this.pool.pop();\n    if (map !== undefined) {\n      return map;\n    }\n    return new Map<K, V>();\n  }\n\n  /**\n   * Return a Map to the pool for reuse\n   */\n  release(map: Map<K, V>): void {\n    if (this.pool.length < this.maxSize) {\n      map.clear();\n      this.pool.push(map);\n    }\n  }\n\n  /**\n   * Clear the pool\n   */\n  clear(): void {\n    this.pool = [];\n  }\n\n  /**\n   * Get current pool size\n   */\n  size(): number {\n    return this.pool.length;\n  }\n}\n\n/**\n * Set pool for reusing Set objects\n */\nexport class SetPool<T> {\n  private pool: Set<T>[] = [];\n  private maxSize: number;\n\n  constructor(maxSize: number = 100) {\n    this.maxSize = maxSize;\n  }\n\n  /**\n   * Get a Set from the pool\n   */\n  acquire(): Set<T> {\n    const set = this.pool.pop();\n    if (set !== undefined) {\n      return set;\n    }\n    return new Set<T>();\n  }\n\n  /**\n   * Return a Set to the pool for reuse\n   */\n  release(set: Set<T>): void {\n    if (this.pool.length < this.maxSize) {\n      set.clear();\n      this.pool.push(set);\n    }\n  }\n\n  /**\n   * Clear the pool\n   */\n  clear(): void {\n    this.pool = [];\n  }\n\n  /**\n   * Get current pool size\n   */\n  size(): number {\n    return this.pool.length;\n  }\n}\n\n/**\n * Global pools for common use cases\n */\nexport const globalMapPool = new MapPool<any, any>(100);\nexport const globalSetPool = new SetPool<any>(100);\n","/**\n * Optimized Levenshtein distance calculation with early termination\n * Performance-focused implementation for fuzzy matching\n * Uses memory pooling to reduce GC pressure by 30-50%\n */\n\nimport { globalArrayPool } from \"../utils/memory-pool.js\";\n\n/**\n * Calculate Levenshtein distance with maximum threshold\n * Returns early if distance exceeds maxDistance for performance\n * \n * @param str1 - First string to compare\n * @param str2 - Second string to compare\n * @param maxDistance - Maximum allowed distance (default: Infinity)\n * @returns Edit distance between strings, or maxDistance + 1 if exceeded\n * \n * @example\n * ```typescript\n * calculateLevenshteinDistance('kitten', 'sitting'); // 3\n * calculateLevenshteinDistance('hello', 'helo', 2); // 1\n * calculateLevenshteinDistance('abc', 'xyz', 1); // 2 (exceeds max)\n * ```\n */\nexport function calculateLevenshteinDistance(\n  //\n  str1: string,\n  str2: string,\n  maxDistance: number = Infinity\n): number {\n  const len1 = str1.length;\n  const len2 = str2.length;\n\n  // Quick checks for performance\n  if (Math.abs(len1 - len2) > maxDistance) {\n    return maxDistance + 1;\n  }\n\n  if (len1 === 0) return len2;\n  if (len2 === 0) return len1;\n  if (str1 === str2) return 0;\n\n  // Use memory pool for arrays to reduce GC pressure\n  const previousRow = globalArrayPool.acquire(len2 + 1) as number[];\n  const currentRow = globalArrayPool.acquire(len2 + 1) as number[];\n\n  try {\n    // Initialize first row\n    for (let j = 0; j <= len2; j++) {\n      previousRow[j] = j;\n    }\n\n    for (let i = 1; i <= len1; i++) {\n      currentRow[0] = i;\n      let minInRow = i;\n\n      for (let j = 1; j <= len2; j++) {\n        const cost = str1[i - 1] === str2[j - 1] ? 0 : 1;\n\n        currentRow[j] = Math.min(\n          currentRow[j - 1] + 1, // insertion\n          previousRow[j] + 1, // deletion\n          previousRow[j - 1] + cost // substitution\n        );\n\n        minInRow = Math.min(minInRow, currentRow[j]);\n      }\n\n      // Early termination if minimum in row exceeds threshold\n      if (minInRow > maxDistance) {\n        return maxDistance + 1;\n      }\n\n      // Copy current to previous for next iteration\n      for (let j = 0; j <= len2; j++) {\n        previousRow[j] = currentRow[j];\n      }\n    }\n\n    return previousRow[len2];\n  } finally {\n    // Always release arrays back to pool\n    globalArrayPool.release(previousRow);\n    globalArrayPool.release(currentRow);\n  }\n}\n\n/**\n * Calculate Damerau-Levenshtein distance (includes transpositions)\n * More expensive but handles character swaps\n */\nexport function calculateDamerauLevenshteinDistance(str1: string, str2: string, maxDistance: number = Infinity): number {\n  const len1 = str1.length;\n  const len2 = str2.length;\n\n  if (Math.abs(len1 - len2) > maxDistance) {\n    return maxDistance + 1;\n  }\n\n  if (len1 === 0) return len2;\n  if (len2 === 0) return len1;\n  if (str1 === str2) return 0;\n\n  const maxLen = Math.max(len1, len2);\n  const H: number[][] = [];\n  const INF = maxLen + 1;\n\n  // Initialize H matrix\n  for (let i = 0; i <= len1 + 1; i++) {\n    H[i] = new Array(len2 + 2).fill(INF);\n  }\n\n  H[0][0] = INF;\n  for (let i = 0; i <= len1; i++) {\n    H[i + 1][0] = INF;\n    H[i + 1][1] = i;\n  }\n  for (let j = 0; j <= len2; j++) {\n    H[0][j + 1] = INF;\n    H[1][j + 1] = j;\n  }\n\n  const charMap = new Map<string, number>();\n\n  for (let i = 1; i <= len1; i++) {\n    let lastMatchCol = 0;\n\n    for (let j = 1; j <= len2; j++) {\n      const char1 = str1[i - 1];\n      const char2 = str2[j - 1];\n      const lastMatchRow = charMap.get(char2) || 0;\n\n      let cost = 1;\n      if (char1 === char2) {\n        cost = 0;\n        lastMatchCol = j;\n      }\n\n      H[i + 1][j + 1] = Math.min(\n        H[i][j] + cost, // substitution\n        H[i + 1][j] + 1, // insertion\n        H[i][j + 1] + 1, // deletion\n        H[lastMatchRow][lastMatchCol] + (i - lastMatchRow - 1) + 1 + (j - lastMatchCol - 1) // transposition\n      );\n    }\n\n    charMap.set(str1[i - 1], i);\n  }\n\n  const result = H[len1 + 1][len2 + 1];\n  return result > maxDistance ? maxDistance + 1 : result;\n}\n\n/**\n * Fast approximate string matching using n-gram similarity\n * Much faster than edit distance for initial filtering\n * Uses memory pooling for Set objects to reduce GC pressure\n * \n * @param str1 - First string to compare\n * @param str2 - Second string to compare\n * @param n - N-gram size (default: 3)\n * @returns Similarity score between 0 and 1\n * \n * @example\n * ```typescript\n * calculateNgramSimilarity('hello', 'hallo'); // ~0.6\n * calculateNgramSimilarity('test', 'test'); // 1.0\n * ```\n */\nexport function calculateNgramSimilarity(str1: string, str2: string, n: number = 3): number {\n  if (str1 === str2) return 1.0;\n  if (str1.length === 0 || str2.length === 0) return 0.0;\n\n  const ngrams1 = generateNgrams(str1, n);\n  const ngrams2 = generateNgrams(str2, n);\n\n  if (ngrams1.length === 0 && ngrams2.length === 0) return 1.0;\n  if (ngrams1.length === 0 || ngrams2.length === 0) return 0.0;\n\n  const set1 = new Set(ngrams1);\n  const set2 = new Set(ngrams2);\n\n  // Calculate intersection size without creating new Set\n  let intersectionSize = 0;\n  for (const item of set1) {\n    if (set2.has(item)) {\n      intersectionSize++;\n    }\n  }\n\n  // Union size = size1 + size2 - intersection\n  const unionSize = set1.size + set2.size - intersectionSize;\n\n  return unionSize > 0 ? intersectionSize / unionSize : 0;\n}\n\n/**\n * Generate n-grams from a string\n * Pre-allocates array for better performance\n * \n * @param str - Input string\n * @param n - N-gram size\n * @returns Array of n-grams\n * \n * @example\n * ```typescript\n * generateNgrams('hello', 3); // ['hel', 'ell', 'llo']\n * generateNgrams('hi', 3); // ['hi']\n * ```\n */\nexport function generateNgrams(str: string, n: number): string[] {\n  if (str.length < n) return [str];\n\n  // Pre-allocate array with exact size needed\n  const count = str.length - n + 1;\n  const ngrams: string[] = new Array(count);\n  \n  for (let i = 0; i < count; i++) {\n    ngrams[i] = str.slice(i, i + n);\n  }\n  \n  return ngrams;\n}\n\n/**\n * Calculate similarity score (0-1) from edit distance\n * \n * @param distance - Edit distance between strings\n * @param maxLength - Maximum length of the two strings\n * @returns Similarity score from 0 to 1 (1 = identical)\n * \n * @example\n * ```typescript\n * distanceToSimilarity(0, 5); // 1.0 (no edits)\n * distanceToSimilarity(2, 10); // 0.8 (2 edits in 10 chars)\n * ```\n */\nexport function distanceToSimilarity(distance: number, maxLength: number): number {\n  if (maxLength === 0) return distance === 0 ? 1.0 : 0.0;\n  return Math.max(0, 1 - distance / maxLength);\n}\n\n/**\n * Check if strings are similar within threshold using fast approximation\n * Uses n-gram pre-filtering before expensive Levenshtein calculation\n * \n * @param str1 - First string to compare\n * @param str2 - Second string to compare\n * @param threshold - Similarity threshold (0-1, default: 0.8)\n * @param maxDistance - Maximum edit distance allowed (default: 2)\n * @returns True if strings are similar enough\n * \n * @example\n * ```typescript\n * areStringsSimilar('hello', 'helo'); // true\n * areStringsSimilar('hello', 'world'); // false\n * ```\n */\nexport function areStringsSimilar(str1: string, str2: string, threshold: number = 0.8, maxDistance: number = 2): boolean {\n  // Quick exact match\n  if (str1 === str2) return true;\n\n  // Quick length check\n  const maxLen = Math.max(str1.length, str2.length);\n  if (Math.abs(str1.length - str2.length) > maxDistance) return false;\n\n  // Use n-gram similarity for fast approximation\n  const ngramSim = calculateNgramSimilarity(str1, str2);\n  if (ngramSim < threshold - 0.2) return false; // Early rejection\n\n  // Calculate actual edit distance only if n-gram similarity is promising\n  const distance = calculateLevenshteinDistance(str1, str2, maxDistance);\n  const similarity = distanceToSimilarity(distance, maxLen);\n\n  return similarity >= threshold;\n}\n","/**\n * Trie (Prefix Tree) for fast prefix matching\n * Provides O(k) lookup where k is the query length, instead of O(n) where n is the number of terms\n */\n\nexport interface TrieNode {\n  children: Map<string, TrieNode>;\n  isEndOfWord: boolean;\n  docIds: Set<number>;\n  term?: string; // Store the full term at leaf nodes\n}\n\nexport class Trie {\n  private root: TrieNode;\n  private size: number;\n\n  constructor() {\n    this.root = this.createNode();\n    this.size = 0;\n  }\n\n  private createNode(): TrieNode {\n    return {\n      children: new Map(),\n      isEndOfWord: false,\n      docIds: new Set(),\n    };\n  }\n\n  /**\n   * Insert a term with associated document IDs\n   */\n  insert(term: string, docIds: number[]): void {\n    if (!term) return;\n\n    let node = this.root;\n\n    for (const char of term) {\n      if (!node.children.has(char)) {\n        node.children.set(char, this.createNode());\n      }\n      node = node.children.get(char)!;\n    }\n\n    node.isEndOfWord = true;\n    node.term = term;\n    docIds.forEach(id => node.docIds.add(id));\n    this.size++;\n  }\n\n  /**\n   * Find all terms that start with the given prefix\n   * Returns array of [term, docIds[]] tuples\n   */\n  findWithPrefix(prefix: string): Array<[string, number[]]> {\n    if (!prefix) return [];\n\n    // Navigate to the prefix node\n    let node = this.root;\n    for (const char of prefix) {\n      if (!node.children.has(char)) {\n        return []; // Prefix not found\n      }\n      node = node.children.get(char)!;\n    }\n\n    // Collect all terms from this node downwards\n    const results: Array<[string, number[]]> = [];\n    this.collectTerms(node, results);\n    return results;\n  }\n\n  /**\n   * Check if exact term exists\n   */\n  has(term: string): boolean {\n    let node = this.root;\n    for (const char of term) {\n      if (!node.children.has(char)) {\n        return false;\n      }\n      node = node.children.get(char)!;\n    }\n    return node.isEndOfWord;\n  }\n\n  /**\n   * Get document IDs for exact term\n   */\n  get(term: string): number[] | null {\n    let node = this.root;\n    for (const char of term) {\n      if (!node.children.has(char)) {\n        return null;\n      }\n      node = node.children.get(char)!;\n    }\n    return node.isEndOfWord ? Array.from(node.docIds) : null;\n  }\n\n  /**\n   * Recursively collect all terms from a node\n   */\n  private collectTerms(node: TrieNode, results: Array<[string, number[]]>): void {\n    if (node.isEndOfWord && node.term) {\n      results.push([node.term, Array.from(node.docIds)]);\n    }\n\n    for (const child of node.children.values()) {\n      this.collectTerms(child, results);\n    }\n  }\n\n  /**\n   * Get the number of terms in the trie\n   */\n  getSize(): number {\n    return this.size;\n  }\n\n  /**\n   * Clear the trie\n   */\n  clear(): void {\n    this.root = this.createNode();\n    this.size = 0;\n  }\n\n  /**\n   * Serialize trie to JSON-compatible format\n   */\n  toJSON(): any {\n    return {\n      root: this.serializeNode(this.root),\n      size: this.size,\n    };\n  }\n\n  /**\n   * Deserialize trie from JSON\n   */\n  static fromJSON(data: any): Trie {\n    const trie = new Trie();\n    trie.root = Trie.deserializeNode(data.root);\n    trie.size = data.size;\n    return trie;\n  }\n\n  private serializeNode(node: TrieNode): any {\n    return {\n      children: Array.from(node.children.entries()).map(([char, child]) => [\n        char,\n        this.serializeNode(child),\n      ]),\n      isEndOfWord: node.isEndOfWord,\n      docIds: Array.from(node.docIds),\n      term: node.term,\n    };\n  }\n\n  private static deserializeNode(data: any): TrieNode {\n    const node: TrieNode = {\n      children: new Map(),\n      isEndOfWord: data.isEndOfWord,\n      docIds: new Set(data.docIds),\n      term: data.term,\n    };\n\n    for (const [char, childData] of data.children) {\n      node.children.set(char, Trie.deserializeNode(childData));\n    }\n\n    return node;\n  }\n}\n","/**\n * BM25 (Best Matching 25) Scoring Algorithm\n * Industry-standard probabilistic ranking function used by search engines\n *\n * BM25 considers:\n * - Term frequency (TF): How often does the term appear?\n * - Inverse document frequency (IDF): How rare is the term?\n * - Document length normalization: Penalize very long documents\n *\n * Formula: BM25(D, Q) = Σ IDF(qi) * (f(qi, D) * (k1 + 1)) / (f(qi, D) + k1 * (1 - b + b * |D| / avgdl))\n *\n * Where:\n * - D = document\n * - Q = query\n * - qi = query term i\n * - f(qi, D) = frequency of qi in D\n * - |D| = length of document D\n * - avgdl = average document length\n * - k1 = term frequency saturation parameter (default: 1.2)\n * - b = length normalization parameter (default: 0.75)\n */\n\nexport interface BM25Config {\n  /** Term frequency saturation parameter (typical: 1.2-2.0) */\n  k1: number;\n  /** Length normalization parameter (typical: 0.5-0.8) */\n  b: number;\n  /** Minimum IDF value to prevent negative scores */\n  minIDF: number;\n}\n\nexport const DEFAULT_BM25_CONFIG: BM25Config = {\n  k1: 1.2,\n  b: 0.75,\n  minIDF: 0.1,\n};\n\n/**\n * Document statistics for BM25 calculation\n */\nexport interface DocumentStats {\n  /** Document ID */\n  docId: number;\n  /** Document length (number of terms) */\n  length: number;\n  /** Term frequencies in this document */\n  termFrequencies: Map<string, number>;\n}\n\n/**\n * Corpus statistics for BM25 calculation\n */\nexport interface CorpusStats {\n  /** Total number of documents */\n  totalDocs: number;\n  /** Average document length */\n  avgDocLength: number;\n  /** Document frequency for each term (how many docs contain the term) */\n  documentFrequencies: Map<string, number>;\n}\n\n/**\n * Calculate IDF (Inverse Document Frequency) for a term\n * IDF = log((N - df + 0.5) / (df + 0.5) + 1)\n *\n * Where:\n * - N = total number of documents\n * - df = document frequency (number of documents containing the term)\n */\nexport function calculateIDF(term: string, corpusStats: CorpusStats, config: BM25Config = DEFAULT_BM25_CONFIG): number {\n  const df = corpusStats.documentFrequencies.get(term) || 0;\n  const N = corpusStats.totalDocs;\n\n  // Prevent division by zero and negative IDF\n  if (df === 0 || N === 0) {\n    return config.minIDF;\n  }\n\n  // BM25 IDF formula with smoothing\n  const idf = Math.log((N - df + 0.5) / (df + 0.5) + 1);\n\n  // Ensure minimum IDF\n  return Math.max(idf, config.minIDF);\n}\n\n/**\n * Calculate BM25 score for a single term in a document\n */\nexport function calculateTermScore(term: string, docStats: DocumentStats, corpusStats: CorpusStats, config: BM25Config = DEFAULT_BM25_CONFIG): number {\n  const tf = docStats.termFrequencies.get(term) || 0;\n\n  // If term not in document, score is 0\n  if (tf === 0) {\n    return 0;\n  }\n\n  const idf = calculateIDF(term, corpusStats, config);\n  const docLength = docStats.length;\n  const avgDocLength = corpusStats.avgDocLength;\n\n  // BM25 formula\n  const numerator = tf * (config.k1 + 1);\n  const denominator = tf + config.k1 * (1 - config.b + config.b * (docLength / avgDocLength));\n\n  return idf * (numerator / denominator);\n}\n\n/**\n * Calculate BM25 score for a query against a document\n * Returns the sum of BM25 scores for all query terms\n */\nexport function calculateBM25Score(queryTerms: string[], docStats: DocumentStats, corpusStats: CorpusStats, config: BM25Config = DEFAULT_BM25_CONFIG): number {\n  let totalScore = 0;\n\n  for (const term of queryTerms) {\n    totalScore += calculateTermScore(term, docStats, corpusStats, config);\n  }\n\n  return totalScore;\n}\n\n/**\n * Build corpus statistics from documents\n * This should be called once during index building\n */\nexport function buildCorpusStats(documents: DocumentStats[]): CorpusStats {\n  const totalDocs = documents.length;\n  let totalLength = 0;\n  const documentFrequencies = new Map<string, number>();\n\n  for (const doc of documents) {\n    totalLength += doc.length;\n\n    // Count unique terms per document (for document frequency)\n    const uniqueTerms = new Set(doc.termFrequencies.keys());\n    for (const term of uniqueTerms) {\n      documentFrequencies.set(term, (documentFrequencies.get(term) || 0) + 1);\n    }\n  }\n\n  const avgDocLength = totalDocs > 0 ? totalLength / totalDocs : 0;\n\n  return {\n    totalDocs,\n    avgDocLength,\n    documentFrequencies,\n  };\n}\n\n/**\n * Normalize BM25 score to 0-1 range for consistency with existing scoring\n * Uses sigmoid function for smooth normalization\n */\nexport function normalizeBM25Score(score: number, maxScore: number = 10): number {\n  if (maxScore === 0) return 0;\n\n  // Sigmoid normalization: 1 / (1 + e^(-x))\n  // Scale score to reasonable range first\n  const scaledScore = (score / maxScore) * 6 - 3; // Map to [-3, 3] range\n  return 1 / (1 + Math.exp(-scaledScore));\n}\n\n/**\n * Combine BM25 score with fuzzy match score\n * Provides a hybrid scoring approach\n */\nexport function combineScores(bm25Score: number, fuzzyScore: number, bm25Weight: number = 0.6, fuzzyWeight: number = 0.4): number {\n  // Normalize weights\n  const totalWeight = bm25Weight + fuzzyWeight;\n  const normalizedBM25Weight = bm25Weight / totalWeight;\n  const normalizedFuzzyWeight = fuzzyWeight / totalWeight;\n\n  // Weighted combination\n  return normalizedBM25Weight * bm25Score + normalizedFuzzyWeight * fuzzyScore;\n}\n","/**\n * Bloom Filter Implementation\n * Probabilistic data structure for fast membership testing\n *\n * Benefits:\n * - O(1) lookup time\n * - Space-efficient (much smaller than Set/Map)\n * - No false negatives (if it says \"no\", it's definitely not there)\n * - Small false positive rate (configurable)\n *\n * Use case: Quickly check if a term exists before expensive lookups\n * Saves 50-70% of lookup time for non-existent terms\n */\n\nexport interface BloomFilterConfig {\n  /** Expected number of elements */\n  expectedElements: number;\n  /** Desired false positive rate (0-1, e.g., 0.01 = 1%) */\n  falsePositiveRate: number;\n}\n\nexport class BloomFilter {\n  private bitArray: Uint8Array;\n  private size: number;\n  private numHashFunctions: number;\n  private numElements: number = 0;\n\n  constructor(config: BloomFilterConfig) {\n    // Calculate optimal bit array size\n    // m = -(n * ln(p)) / (ln(2)^2)\n    // where n = expected elements, p = false positive rate\n    const n = config.expectedElements;\n    const p = config.falsePositiveRate;\n\n    this.size = Math.ceil(-(n * Math.log(p)) / Math.log(2) ** 2);\n\n    // Calculate optimal number of hash functions\n    // k = (m / n) * ln(2)\n    this.numHashFunctions = Math.ceil((this.size / n) * Math.log(2));\n\n    // Use Uint8Array for efficient bit storage (8 bits per byte)\n    this.bitArray = new Uint8Array(Math.ceil(this.size / 8));\n  }\n\n  /**\n   * Add an element to the bloom filter\n   */\n  add(item: string): void {\n    const hashes = this.getHashes(item);\n\n    for (const hash of hashes) {\n      const byteIndex = Math.floor(hash / 8);\n      const bitIndex = hash % 8;\n      this.bitArray[byteIndex] |= 1 << bitIndex;\n    }\n\n    this.numElements++;\n  }\n\n  /**\n   * Check if an element might be in the set\n   * Returns:\n   * - true: element MIGHT be in the set (could be false positive)\n   * - false: element is DEFINITELY NOT in the set (no false negatives)\n   */\n  mightContain(item: string): boolean {\n    const hashes = this.getHashes(item);\n\n    for (const hash of hashes) {\n      const byteIndex = Math.floor(hash / 8);\n      const bitIndex = hash % 8;\n\n      if ((this.bitArray[byteIndex] & (1 << bitIndex)) === 0) {\n        return false; // Definitely not in set\n      }\n    }\n\n    return true; // Might be in set\n  }\n\n  /**\n   * Generate multiple hash values for an item\n   * Uses double hashing technique for efficiency\n   */\n  private getHashes(item: string): number[] {\n    const hash1 = this.hash(item, 0);\n    const hash2 = this.hash(item, 1);\n\n    const hashes: number[] = [];\n\n    for (let i = 0; i < this.numHashFunctions; i++) {\n      // Double hashing: h(i) = (hash1 + i * hash2) mod m\n      const combinedHash = (hash1 + i * hash2) % this.size;\n      hashes.push(Math.abs(combinedHash));\n    }\n\n    return hashes;\n  }\n\n  /**\n   * Simple hash function (FNV-1a variant)\n   */\n  private hash(str: string, seed: number): number {\n    let hash = 2166136261 ^ seed; // FNV offset basis\n\n    for (let i = 0; i < str.length; i++) {\n      hash ^= str.charCodeAt(i);\n      hash += (hash << 1) + (hash << 4) + (hash << 7) + (hash << 8) + (hash << 24);\n    }\n\n    return hash >>> 0; // Convert to unsigned 32-bit integer\n  }\n\n  /**\n   * Get current false positive probability\n   * Actual rate may differ from configured rate as elements are added\n   */\n  getFalsePositiveRate(): number {\n    if (this.numElements === 0) return 0;\n\n    // p = (1 - e^(-kn/m))^k\n    // where k = num hash functions, n = num elements, m = bit array size\n    const k = this.numHashFunctions;\n    const n = this.numElements;\n    const m = this.size;\n\n    return Math.pow(1 - Math.exp((-k * n) / m), k);\n  }\n\n  /**\n   * Get statistics about the bloom filter\n   */\n  getStats(): {\n    size: number;\n    numHashFunctions: number;\n    numElements: number;\n    falsePositiveRate: number;\n    memoryUsage: number;\n  } {\n    return {\n      size: this.size,\n      numHashFunctions: this.numHashFunctions,\n      numElements: this.numElements,\n      falsePositiveRate: this.getFalsePositiveRate(),\n      memoryUsage: this.bitArray.byteLength,\n    };\n  }\n\n  /**\n   * Clear all elements from the filter\n   */\n  clear(): void {\n    this.bitArray.fill(0);\n    this.numElements = 0;\n  }\n\n  /**\n   * Serialize bloom filter to JSON\n   */\n  toJSON(): {\n    bitArray: number[];\n    size: number;\n    numHashFunctions: number;\n    numElements: number;\n  } {\n    return {\n      bitArray: Array.from(this.bitArray),\n      size: this.size,\n      numHashFunctions: this.numHashFunctions,\n      numElements: this.numElements,\n    };\n  }\n\n  /**\n   * Deserialize bloom filter from JSON\n   */\n  static fromJSON(data: { bitArray: number[]; size: number; numHashFunctions: number; numElements: number }): BloomFilter {\n    // Create a dummy filter with minimal config\n    const filter = new BloomFilter({\n      expectedElements: 100,\n      falsePositiveRate: 0.01,\n    });\n\n    // Override with saved data\n    filter.bitArray = new Uint8Array(data.bitArray);\n    filter.size = data.size;\n    filter.numHashFunctions = data.numHashFunctions;\n    filter.numElements = data.numElements;\n\n    return filter;\n  }\n}\n\n/**\n * Create a bloom filter with sensible defaults\n */\nexport function createBloomFilter(expectedElements: number, falsePositiveRate: number = 0.01): BloomFilter {\n  return new BloomFilter({\n    expectedElements,\n    falsePositiveRate,\n  });\n}\n","/**\n * Centralized tokenization utilities for consistent word boundary handling\n * \n * This module provides a single source of truth for how text is split into tokens,\n * ensuring consistent behavior across indexing, search, and phrase matching.\n */\n\n/**\n * Word boundary characters - these separate tokens\n * Includes: whitespace, hyphens, underscores, punctuation, brackets, quotes, slashes\n */\nexport const WORD_BOUNDARY_CHARS = /[\\s\\-_.,;:!?()[\\]{}'\"\\/\\\\#@$%^&*+=<>|~`]/;\n\n/**\n * Word boundary pattern for splitting text into tokens\n */\nexport const WORD_BOUNDARY_PATTERN = /[\\s\\-_.,;:!?()[\\]{}'\"\\/\\\\#@$%^&*+=<>|~`]+/;\n\n/**\n * Tokenize text into words by splitting on word boundaries\n * \n * This is the core tokenization function used throughout the library.\n * It splits on common delimiters while preserving alphanumeric content.\n * \n * @param text - Text to tokenize\n * @param options - Tokenization options\n * @returns Array of tokens\n * \n * @example\n * ```typescript\n * tokenize(\"api_manager_3254\") // [\"api\", \"manager\", \"3254\"]\n * tokenize(\"hello-world\") // [\"hello\", \"world\"]\n * tokenize(\"user@email.com\") // [\"user\", \"email\", \"com\"]\n * tokenize(\"snake_case_var\") // [\"snake\", \"case\", \"var\"]\n * ```\n */\nexport function tokenize(\n  text: string,\n  options: {\n    /** Keep empty tokens (default: false) */\n    keepEmpty?: boolean;\n    /** Minimum token length (default: 0) */\n    minLength?: number;\n    /** Convert to lowercase (default: false) */\n    lowercase?: boolean;\n  } = {}\n): string[] {\n  const { keepEmpty = false, minLength = 0, lowercase = false } = options;\n\n  // Split on word boundaries\n  let tokens = text.split(WORD_BOUNDARY_PATTERN);\n\n  // Filter empty tokens unless explicitly kept\n  if (!keepEmpty) {\n    tokens = tokens.filter((token) => token.length > 0);\n  }\n\n  // Apply minimum length filter\n  if (minLength > 0) {\n    tokens = tokens.filter((token) => token.length >= minLength);\n  }\n\n  // Apply lowercase transformation\n  if (lowercase) {\n    tokens = tokens.map((token) => token.toLowerCase());\n  }\n\n  return tokens;\n}\n\n/**\n * Check if a character is a word boundary\n * \n * @param char - Character to check\n * @returns True if the character is a word boundary\n */\nexport function isWordBoundaryChar(char: string): boolean {\n  return WORD_BOUNDARY_CHARS.test(char);\n}\n\n/**\n * Tokenize and also return the original text with tokens\n * Useful for highlighting and position tracking\n * \n * @param text - Text to tokenize\n * @returns Object with tokens and original text\n */\nexport function tokenizeWithPositions(text: string): {\n  tokens: string[];\n  positions: { token: string; start: number; end: number }[];\n} {\n  const tokens: string[] = [];\n  const positions: { token: string; start: number; end: number }[] = [];\n\n  let currentToken = \"\";\n  let tokenStart = 0;\n\n  for (let i = 0; i < text.length; i++) {\n    const char = text[i];\n\n    if (isWordBoundaryChar(char)) {\n      // End of token\n      if (currentToken.length > 0) {\n        tokens.push(currentToken);\n        positions.push({\n          token: currentToken,\n          start: tokenStart,\n          end: i,\n        });\n        currentToken = \"\";\n      }\n      tokenStart = i + 1;\n    } else {\n      // Part of token\n      if (currentToken.length === 0) {\n        tokenStart = i;\n      }\n      currentToken += char;\n    }\n  }\n\n  // Add final token if exists\n  if (currentToken.length > 0) {\n    tokens.push(currentToken);\n    positions.push({\n      token: currentToken,\n      start: tokenStart,\n      end: text.length,\n    });\n  }\n\n  return { tokens, positions };\n}\n\n/**\n * Join tokens back into text with a separator\n * \n * @param tokens - Tokens to join\n * @param separator - Separator to use (default: space)\n * @returns Joined text\n */\nexport function joinTokens(tokens: string[], separator: string = \" \"): string {\n  return tokens.join(separator);\n}\n\n/**\n * Normalize text for search by tokenizing and rejoining\n * This ensures consistent handling of special characters\n * \n * @param text - Text to normalize\n * @param options - Normalization options\n * @returns Normalized text\n */\nexport function normalizeForSearch(\n  text: string,\n  options: {\n    lowercase?: boolean;\n    separator?: string;\n  } = {}\n): string {\n  const { lowercase = true, separator = \" \" } = options;\n  const tokens = tokenize(text, { lowercase });\n  return joinTokens(tokens, separator);\n}\n","/**\n * Inverted Index Implementation\n * Optimized for large datasets (1M+ words)\n *\n * Architecture:\n * - Token → [docId1, docId2, ...] (posting lists)\n * - Fast intersection/union operations\n * - BM25-like scoring for relevance\n * - Parallel to existing hash-based index (backwards compatible)\n */\n\nimport type { InvertedIndex, DocumentMetadata, PostingList, FuzzyConfig, LanguageProcessor, SearchMatch } from \"./types.js\";\nimport { generateNgrams, calculateLevenshteinDistance, calculateDamerauLevenshteinDistance } from \"../algorithms/levenshtein.js\";\nimport { Trie } from \"./trie.js\";\nimport { calculateBM25Score, normalizeBM25Score, DEFAULT_BM25_CONFIG, type DocumentStats, type CorpusStats } from \"../algorithms/bm25.js\";\nimport { BloomFilter } from \"../algorithms/bloom-filter.js\";\nimport { tokenize } from \"../utils/tokenizer.js\";\n\n/**\n * Build inverted index from documents\n * This runs ALONGSIDE the existing index building\n */\nexport function buildInvertedIndex(\n  //\n  words: string[],\n  languageProcessors: LanguageProcessor[],\n  config: FuzzyConfig,\n  featureSet: Set<string>\n): { invertedIndex: InvertedIndex; documents: DocumentMetadata[] } {\n  const documents: DocumentMetadata[] = [];\n  const invertedIndex: InvertedIndex = {\n    termToPostings: new Map(),\n    termTrie: new Trie(), // Initialize Trie for fast prefix matching\n    phoneticToPostings: new Map(),\n    ngramToPostings: new Map(),\n    synonymToPostings: new Map(),\n    fieldIndices: new Map(),\n    totalDocs: 0,\n    avgDocLength: 0,\n  };\n\n  let totalLength = 0;\n  let docId = 0;\n\n  // Build documents and posting lists\n  for (const word of words) {\n    if (!word || word.trim().length < config.minQueryLength) continue;\n\n    const trimmedWord = word.trim();\n\n    // Process with each language processor\n    for (const processor of languageProcessors) {\n      const normalized = processor.normalize(trimmedWord);\n      const phoneticCode = featureSet.has(\"phonetic\") && processor.supportedFeatures.includes(\"phonetic\") ? processor.getPhoneticCode(trimmedWord) : undefined;\n\n      const compoundParts = featureSet.has(\"compound\") && processor.supportedFeatures.includes(\"compound\") ? processor.splitCompoundWords(trimmedWord) : undefined;\n\n      // Create document metadata\n      const doc: DocumentMetadata = {\n        id: docId,\n        word: trimmedWord,\n        normalized,\n        phoneticCode,\n        language: processor.language,\n        compoundParts: compoundParts && compoundParts.length > 1 ? compoundParts : undefined,\n      };\n\n      documents.push(doc);\n      totalLength += normalized.length;\n\n      // Index the normalized term\n      addToPostingList(invertedIndex.termToPostings, normalized, docId);\n      invertedIndex.termTrie!.insert(normalized, [docId]);\n\n      // Index original word (for exact matching)\n      const lowerWord = trimmedWord.toLowerCase();\n      addToPostingList(invertedIndex.termToPostings, lowerWord, docId);\n      invertedIndex.termTrie!.insert(lowerWord, [docId]);\n\n      // TOKENIZATION: Index individual tokens from words with special characters\n      // This allows \"api_\" to match \"api_manager_3254\" by indexing [\"api\", \"manager\", \"3254\"]\n      const tokens = tokenize(trimmedWord, { lowercase: true, minLength: 1 });\n      if (tokens.length > 1) {\n        // Only tokenize if there are multiple tokens (word contains special chars)\n        tokens.forEach((token) => {\n          if (token.length >= config.minQueryLength) {\n            addToPostingList(invertedIndex.termToPostings, token, docId);\n            invertedIndex.termTrie!.insert(token, [docId]);\n          }\n        });\n      }\n\n      // Index word variants (prefixes)\n      if (featureSet.has(\"partial-words\")) {\n        const variants = processor.getWordVariants(trimmedWord, config.performance);\n        variants.forEach((variant) => {\n          addToPostingList(invertedIndex.termToPostings, variant, docId);\n          invertedIndex.termTrie!.insert(variant, [docId]);\n        });\n      }\n\n      // Index phonetic code\n      if (phoneticCode) {\n        addToPostingList(invertedIndex.phoneticToPostings, phoneticCode, docId);\n      }\n\n      // Index n-grams\n      const ngrams = generateNgrams(normalized, config.ngramSize);\n      ngrams.forEach((ngram) => {\n        addToPostingList(invertedIndex.ngramToPostings, ngram, docId);\n      });\n\n      // Index compound parts\n      if (compoundParts && compoundParts.length > 1) {\n        compoundParts.forEach((part) => {\n          const normalizedPart = processor.normalize(part);\n          addToPostingList(invertedIndex.termToPostings, normalizedPart, docId);\n          invertedIndex.termTrie!.insert(normalizedPart, [docId]);\n        });\n      }\n\n      // Index synonyms\n      if (featureSet.has(\"synonyms\")) {\n        const synonyms = processor.getSynonyms(normalized);\n        synonyms.forEach((synonym) => {\n          addToPostingList(invertedIndex.synonymToPostings, synonym, docId);\n        });\n\n        // Custom synonyms\n        if (config.customSynonyms) {\n          const customSynonyms = config.customSynonyms[normalized];\n          if (customSynonyms) {\n            customSynonyms.forEach((synonym) => {\n              addToPostingList(invertedIndex.synonymToPostings, synonym, docId);\n            });\n          }\n        }\n      }\n\n      docId++;\n    }\n  }\n\n  invertedIndex.totalDocs = docId;\n  invertedIndex.avgDocLength = totalLength / Math.max(1, docId);\n\n  // Build BM25 statistics if enabled\n  if (config.useBM25) {\n    const documentFrequencies = new Map<string, number>();\n    const documentLengths = new Map<number, number>();\n\n    // Calculate document frequencies (how many docs contain each term)\n    for (const [term, posting] of invertedIndex.termToPostings.entries()) {\n      documentFrequencies.set(term, posting.docIds.length);\n    }\n\n    // Store document lengths\n    documents.forEach((doc) => {\n      documentLengths.set(doc.id, doc.normalized.length);\n    });\n\n    invertedIndex.bm25Stats = {\n      documentFrequencies,\n      documentLengths,\n    };\n  }\n\n  // Build Bloom Filter if enabled or auto-enable for large datasets\n  const shouldUseBloomFilter = config.useBloomFilter || words.length >= 10000;\n\n  if (shouldUseBloomFilter) {\n    const falsePositiveRate = config.bloomFilterFalsePositiveRate || 0.01;\n    const bloomFilter = new BloomFilter({\n      expectedElements: invertedIndex.termToPostings.size,\n      falsePositiveRate,\n    });\n\n    // Add all terms to bloom filter\n    for (const term of invertedIndex.termToPostings.keys()) {\n      bloomFilter.add(term);\n    }\n\n    invertedIndex.bloomFilter = bloomFilter;\n  }\n\n  return { invertedIndex, documents };\n}\n\n/**\n * Search using inverted index\n * Much faster than hash-based approach for large datasets\n */\nexport function searchInvertedIndex(\n  //\n  invertedIndex: InvertedIndex,\n  documents: DocumentMetadata[],\n  query: string,\n  processors: LanguageProcessor[],\n  config: FuzzyConfig\n): SearchMatch[] {\n  const matches = new Map<number, SearchMatch>();\n  const featureSet = new Set(config.features);\n\n  // Process query with each language processor\n  for (const processor of processors) {\n    const normalizedQuery = processor.normalize(query.trim());\n\n    // 1. Exact term lookup (fastest)\n    findExactMatchesInverted(normalizedQuery, invertedIndex, documents, matches, processor.language);\n\n    // 2. Prefix matches\n    findPrefixMatchesInverted(normalizedQuery, invertedIndex, documents, matches, processor.language);\n\n    // 3. Phonetic matches\n    if (featureSet.has(\"phonetic\") && processor.supportedFeatures.includes(\"phonetic\")) {\n      findPhoneticMatchesInverted(normalizedQuery, processor, invertedIndex, documents, matches);\n    }\n\n    // 4. Synonym matches\n    if (featureSet.has(\"synonyms\")) {\n      findSynonymMatchesInverted(normalizedQuery, invertedIndex, documents, matches);\n    }\n\n    // 5. N-gram matches\n    findNgramMatchesInverted(normalizedQuery, invertedIndex, documents, matches, processor.language, config.ngramSize);\n\n    // 6. Fuzzy matches (most expensive, do last)\n    // OPTIMIZATION: Skip fuzzy matching for very large datasets in fast mode if we have enough good matches\n    const shouldSkipFuzzy = config.performance === \"fast\" && invertedIndex.termToPostings.size > 100000 && matches.size >= config.maxResults * 2;\n\n    if (!shouldSkipFuzzy && (featureSet.has(\"missing-letters\") || featureSet.has(\"extra-letters\") || featureSet.has(\"transpositions\"))) {\n      findFuzzyMatchesInverted(normalizedQuery, invertedIndex, documents, matches, processor, config.maxEditDistance, config);\n    }\n  }\n\n  // Convert to array and return\n  return Array.from(matches.values());\n}\n\n/**\n * Helper: Add document to posting list\n */\nfunction addToPostingList(\n  //\n  postings: Map<string, PostingList>,\n  term: string,\n  docId: number\n): void {\n  let posting = postings.get(term);\n  if (!posting) {\n    posting = { term, docIds: [], docIdSet: new Set() };\n    postings.set(term, posting);\n  }\n\n  // Initialize docIdSet if not present (for backward compatibility)\n  if (!posting.docIdSet) {\n    posting.docIdSet = new Set(posting.docIds);\n  }\n\n  // Avoid duplicates using O(1) Set lookup\n  if (!posting.docIdSet.has(docId)) {\n    posting.docIds.push(docId);\n    posting.docIdSet.add(docId);\n  }\n}\n\n/**\n * Find exact matches in inverted index\n */\nfunction findExactMatchesInverted(\n  //\n  query: string,\n  invertedIndex: InvertedIndex,\n  documents: DocumentMetadata[],\n  matches: Map<number, SearchMatch>,\n  language: string\n): void {\n  // BLOOM FILTER: Fast negative lookup\n  if (invertedIndex.bloomFilter && !invertedIndex.bloomFilter.mightContain(query)) {\n    return; // Definitely not in index, skip expensive lookup\n  }\n\n  const posting = invertedIndex.termToPostings.get(query);\n  if (!posting) return;\n\n  posting.docIds.forEach((docId) => {\n    const doc = documents[docId];\n    if (!doc) return;\n\n    if (!matches.has(docId)) {\n      matches.set(docId, {\n        word: doc.word,\n        normalized: query,\n        matchType: \"exact\",\n        editDistance: 0,\n        language,\n        docId,\n      });\n    }\n  });\n}\n\n/**\n * Find prefix matches in inverted index\n * Now uses Trie for O(k) lookup instead of O(n) iteration!\n */\nfunction findPrefixMatchesInverted(\n  //\n  query: string,\n  invertedIndex: InvertedIndex,\n  documents: DocumentMetadata[],\n  matches: Map<number, SearchMatch>,\n  language: string\n): void {\n  // Use Trie for fast prefix matching (100-1000x faster!)\n  if (invertedIndex.termTrie) {\n    const prefixMatches = invertedIndex.termTrie.findWithPrefix(query);\n\n    for (const [term, docIds] of prefixMatches) {\n      if (term !== query) {\n        // Exclude exact matches (handled separately)\n        docIds.forEach((docId: number) => {\n          const doc = documents[docId];\n          if (!doc) return;\n\n          if (!matches.has(docId)) {\n            matches.set(docId, {\n              word: doc.word,\n              normalized: term,\n              matchType: \"prefix\",\n              language,\n              docId,\n            });\n          }\n        });\n      }\n    }\n  } else {\n    // Fallback to old O(n) method if Trie not available\n    for (const [term, posting] of invertedIndex.termToPostings.entries()) {\n      if (term.startsWith(query) && term !== query) {\n        posting.docIds.forEach((docId) => {\n          const doc = documents[docId];\n          if (!doc) return;\n\n          if (!matches.has(docId)) {\n            matches.set(docId, {\n              word: doc.word,\n              normalized: term,\n              matchType: \"prefix\",\n              language,\n              docId,\n            });\n          }\n        });\n      }\n    }\n  }\n}\n\n/**\n * Find phonetic matches in inverted index\n */\nfunction findPhoneticMatchesInverted(\n  //\n  query: string,\n  processor: LanguageProcessor,\n  invertedIndex: InvertedIndex,\n  documents: DocumentMetadata[],\n  matches: Map<number, SearchMatch>\n): void {\n  const phoneticCode = processor.getPhoneticCode(query);\n  if (!phoneticCode) return;\n\n  const posting = invertedIndex.phoneticToPostings.get(phoneticCode);\n  if (!posting) return;\n\n  posting.docIds.forEach((docId) => {\n    const doc = documents[docId];\n    if (!doc) return;\n\n    if (!matches.has(docId)) {\n      matches.set(docId, {\n        word: doc.word,\n        normalized: query,\n        matchType: \"phonetic\",\n        phoneticCode,\n        language: processor.language,\n        docId,\n      });\n    }\n  });\n}\n\n/**\n * Find synonym matches in inverted index\n */\nfunction findSynonymMatchesInverted(\n  //\n  query: string,\n  invertedIndex: InvertedIndex,\n  documents: DocumentMetadata[],\n  matches: Map<number, SearchMatch>\n): void {\n  const posting = invertedIndex.synonymToPostings.get(query);\n  if (!posting) return;\n\n  posting.docIds.forEach((docId) => {\n    const doc = documents[docId];\n    if (!doc) return;\n\n    if (!matches.has(docId)) {\n      matches.set(docId, {\n        word: doc.word,\n        normalized: query,\n        matchType: \"synonym\",\n        language: \"synonym\",\n        docId,\n      });\n    }\n  });\n}\n\n/**\n * Find n-gram matches in inverted index\n */\nfunction findNgramMatchesInverted(\n  //\n  query: string,\n  invertedIndex: InvertedIndex,\n  documents: DocumentMetadata[],\n  matches: Map<number, SearchMatch>,\n  language: string,\n  ngramSize: number\n): void {\n  if (query.length < ngramSize) return;\n\n  const queryNgrams = generateNgrams(query, ngramSize);\n  const candidateDocs = new Set<number>();\n\n  // Collect all documents that contain at least one n-gram\n  queryNgrams.forEach((ngram) => {\n    const posting = invertedIndex.ngramToPostings.get(ngram);\n    if (posting) {\n      posting.docIds.forEach((docId) => candidateDocs.add(docId));\n    }\n  });\n\n  // Add to matches\n  candidateDocs.forEach((docId) => {\n    const doc = documents[docId];\n    if (!doc) return;\n\n    if (!matches.has(docId)) {\n      matches.set(docId, {\n        word: doc.word,\n        normalized: query,\n        matchType: \"ngram\",\n        language,\n        docId,\n      });\n    }\n  });\n}\n\n/**\n * Find fuzzy matches in inverted index\n * Optimized with length-based pre-filtering (5-10x faster)\n */\nfunction findFuzzyMatchesInverted(\n  //\n  query: string,\n  invertedIndex: InvertedIndex,\n  documents: DocumentMetadata[],\n  matches: Map<number, SearchMatch>,\n  processor: LanguageProcessor,\n  maxDistance: number,\n  config: FuzzyConfig\n): void {\n  const queryLen = query.length;\n  const minLen = queryLen - maxDistance;\n  const maxLen = queryLen + maxDistance;\n\n  // Pre-compute for performance\n  const useTranspositions = config.features?.includes(\"transpositions\");\n\n  // OPTIMIZATION: Dynamic candidate limit based on dataset size\n  // Smaller limit for larger datasets to maintain sub-10ms performance\n  const datasetSize = invertedIndex.termToPostings.size;\n  const MAX_FUZZY_CANDIDATES = datasetSize > 100000 ? 1000 : datasetSize > 50000 ? 1500 : datasetSize > 20000 ? 3000 : datasetSize > 10000 ? 5000 : 8000;\n  let candidatesChecked = 0;\n\n  // OPTIMIZATION: For very large datasets (50K+), use Trie prefix filtering first\n  let termsArray: [string, PostingList][];\n\n  if (datasetSize > 50000 && query.length >= 2 && invertedIndex.termTrie) {\n    // Get prefix matches from Trie (much faster than iterating all terms)\n    // Use longer prefix for 100K+ datasets for better filtering\n    const prefixLength = datasetSize > 100000 ? Math.min(3, query.length) : Math.min(2, query.length);\n    const prefix = query.substring(0, prefixLength);\n    const prefixMatches = invertedIndex.termTrie.findWithPrefix(prefix);\n\n    // Only check terms that share a prefix with the query\n    termsArray = prefixMatches.map(([term, _docIds]: [string, number[]]) => [term, invertedIndex.termToPostings.get(term)] as [string, PostingList | undefined]).filter((entry: [string, PostingList | undefined]): entry is [string, PostingList] => entry[1] !== undefined);\n\n    // If prefix filtering gives us too few candidates, fall back to full search\n    if (termsArray.length < 100) {\n      termsArray = Array.from(invertedIndex.termToPostings.entries());\n    }\n  } else {\n    termsArray = Array.from(invertedIndex.termToPostings.entries());\n  }\n\n  // Sort by length similarity for better early termination\n  termsArray.sort((a, b) => {\n    const aDiff = Math.abs(a[0].length - queryLen);\n    const bDiff = Math.abs(b[0].length - queryLen);\n    return aDiff - bDiff;\n  });\n\n  // Iterate through sorted terms with optimized filtering\n  for (const [term, posting] of termsArray) {\n    // OPTIMIZATION 1: Length-based pre-filter (O(1) check)\n    // This eliminates 80-90% of candidates before expensive Levenshtein\n    const termLen = term.length;\n    if (termLen < minLen || termLen > maxLen) {\n      continue;\n    }\n\n    // OPTIMIZATION 2: Limit candidates in large datasets\n    if (candidatesChecked >= MAX_FUZZY_CANDIDATES) {\n      break;\n    }\n    candidatesChecked++;\n\n    // OPTIMIZATION 3: Enhanced early termination based on match quality and quantity\n    // Less aggressive to ensure better search quality\n    const currentMatches = matches.size;\n    const earlyTerminationThreshold = datasetSize > 50000 ? config.maxResults * 3 : config.maxResults * 5;\n    \n    // Only consider early termination if we have significantly more matches than needed\n    if (currentMatches >= earlyTerminationThreshold) {\n      // Calculate minimum edit distance in current matches\n      let minEditDistance = maxDistance;\n      let hasPerfectMatches = false;\n      \n      for (const match of matches.values()) {\n        if (match.editDistance !== undefined) {\n          if (match.editDistance === 0) {\n            // Perfect match found - we can terminate early but still need more results\n            hasPerfectMatches = true;\n            minEditDistance = 0;\n            break;\n          } else if (match.editDistance <= 1) {\n            minEditDistance = Math.min(minEditDistance, match.editDistance);\n          }\n        }\n      }\n      \n      // Only terminate early if we have many perfect matches\n      // Much more conservative than before\n      if (hasPerfectMatches && currentMatches >= config.maxResults * 10) {\n        break;\n      }\n    }\n\n    // OPTIMIZATION 4: Skip if first character is too different (cheap check)\n    if (query.length > 0 && term.length > 0) {\n      const firstCharDiff = Math.abs(query.charCodeAt(0) - term.charCodeAt(0));\n      if (firstCharDiff > 10 && maxDistance < 2) {\n        // Allow more variance for higher edit distance\n        continue;\n      }\n    }\n\n    // Now do expensive edit distance calculation\n    const distance = useTranspositions ? calculateDamerauLevenshteinDistance(query, term, maxDistance) : calculateLevenshteinDistance(query, term, maxDistance);\n\n    if (distance <= maxDistance) {\n      posting.docIds.forEach((docId) => {\n        const doc = documents[docId];\n        if (!doc) return;\n\n        const existingMatch = matches.get(docId);\n        // Only update if this is a better match (lower edit distance)\n        if (!existingMatch || (existingMatch.editDistance || Infinity) > distance) {\n          matches.set(docId, {\n            word: doc.word,\n            normalized: term,\n            matchType: \"fuzzy\",\n            editDistance: distance,\n            language: processor.language,\n            docId,\n          });\n        }\n      });\n    }\n  }\n}\n\n/**\n * Calculate BM25 scores for search matches\n * Enhances relevance ranking with statistical scoring\n */\nexport function calculateBM25Scores(matches: SearchMatch[], queryTerms: string[], invertedIndex: InvertedIndex, documents: DocumentMetadata[], config: FuzzyConfig): SearchMatch[] {\n  if (!config.useBM25 || !invertedIndex.bm25Stats) {\n    return matches;\n  }\n\n  const bm25Config = {\n    ...DEFAULT_BM25_CONFIG,\n    ...config.bm25Config,\n  };\n\n  // Build corpus stats from inverted index\n  const corpusStats: CorpusStats = {\n    totalDocs: invertedIndex.totalDocs,\n    avgDocLength: invertedIndex.avgDocLength,\n    documentFrequencies: invertedIndex.bm25Stats.documentFrequencies,\n  };\n\n  // Calculate BM25 score for each match\n  return matches.map((match) => {\n    if (match.docId === undefined) {\n      return match;\n    }\n\n    const doc = documents[match.docId];\n    if (!doc) {\n      return match;\n    }\n\n    // Build document stats\n    const termFrequencies = new Map<string, number>();\n    const normalizedTerms = doc.normalized.toLowerCase().split(/\\s+/);\n\n    for (const term of normalizedTerms) {\n      termFrequencies.set(term, (termFrequencies.get(term) || 0) + 1);\n    }\n\n    const docStats: DocumentStats = {\n      docId: doc.id,\n      length: normalizedTerms.length,\n      termFrequencies,\n    };\n\n    // Calculate BM25 score\n    const bm25Score = calculateBM25Score(queryTerms, docStats, corpusStats, bm25Config);\n    const normalizedBM25 = normalizeBM25Score(bm25Score);\n\n    return {\n      ...match,\n      bm25Score: normalizedBM25,\n    };\n  });\n}\n","/**\n * Match Highlighting Utilities\n * Calculates positions of matched characters for UI highlighting\n */\n\nimport type { MatchHighlight, MatchType, SearchMatch } from \"./types.js\";\n\n/**\n * Calculate highlights for a search match\n */\nexport function calculateHighlights(match: SearchMatch, query: string, displayText: string): MatchHighlight[] {\n  const highlights: MatchHighlight[] = [];\n  const normalizedDisplay = displayText.toLowerCase();\n  const normalizedQuery = query.toLowerCase();\n\n  switch (match.matchType) {\n    case \"exact\":\n      // Highlight the entire word\n      highlights.push({\n        start: 0,\n        end: displayText.length,\n        type: \"exact\",\n      });\n      break;\n\n    case \"prefix\":\n      // Highlight the matching prefix\n      const prefixEnd = Math.min(normalizedQuery.length, displayText.length);\n      highlights.push({\n        start: 0,\n        end: prefixEnd,\n        type: \"prefix\",\n      });\n      break;\n\n    case \"substring\":\n      // Find where the query appears in the display text\n      const substringIndex = normalizedDisplay.indexOf(normalizedQuery);\n      if (substringIndex !== -1) {\n        highlights.push({\n          start: substringIndex,\n          end: substringIndex + normalizedQuery.length,\n          type: \"substring\",\n        });\n      }\n      break;\n\n    case \"fuzzy\":\n      // For fuzzy matches, highlight matching characters\n      highlights.push(...calculateFuzzyHighlights(normalizedQuery, normalizedDisplay, \"fuzzy\"));\n      break;\n\n    case \"ngram\":\n      // Highlight n-gram matches\n      highlights.push(...calculateNgramHighlights(normalizedQuery, normalizedDisplay));\n      break;\n\n    case \"phonetic\":\n    case \"synonym\":\n    case \"compound\":\n      // For phonetic/synonym/compound, highlight the whole word\n      highlights.push({\n        start: 0,\n        end: displayText.length,\n        type: match.matchType,\n      });\n      break;\n  }\n\n  return mergeOverlappingHighlights(highlights);\n}\n\n/**\n * Calculate highlights for fuzzy matches using edit distance alignment\n */\nfunction calculateFuzzyHighlights(query: string, text: string, type: MatchType): MatchHighlight[] {\n  const highlights: MatchHighlight[] = [];\n  let queryIdx = 0;\n  let textIdx = 0;\n\n  // Simple greedy matching - find matching characters\n  while (queryIdx < query.length && textIdx < text.length) {\n    if (query[queryIdx] === text[textIdx]) {\n      // Found a match\n      const start = textIdx;\n      let end = textIdx + 1;\n\n      // Extend the match as far as possible\n      queryIdx++;\n      textIdx++;\n      while (queryIdx < query.length && textIdx < text.length && query[queryIdx] === text[textIdx]) {\n        end++;\n        queryIdx++;\n        textIdx++;\n      }\n\n      highlights.push({ start, end, type });\n    } else {\n      textIdx++;\n    }\n  }\n\n  return highlights;\n}\n\n/**\n * Calculate highlights for n-gram matches\n */\nfunction calculateNgramHighlights(query: string, text: string): MatchHighlight[] {\n  const highlights: MatchHighlight[] = [];\n  const ngramSize = 3;\n\n  // Find all n-grams from query that appear in text\n  for (let i = 0; i <= query.length - ngramSize; i++) {\n    const ngram = query.slice(i, i + ngramSize);\n    let searchStart = 0;\n\n    // Find all occurrences of this n-gram\n    while (true) {\n      const index = text.indexOf(ngram, searchStart);\n      if (index === -1) break;\n\n      highlights.push({\n        start: index,\n        end: index + ngramSize,\n        type: \"ngram\",\n      });\n\n      searchStart = index + 1;\n    }\n  }\n\n  return highlights;\n}\n\n/**\n * Merge overlapping highlights to avoid duplicate highlighting\n */\nfunction mergeOverlappingHighlights(highlights: MatchHighlight[]): MatchHighlight[] {\n  if (highlights.length === 0) return [];\n\n  // Sort by start position\n  const sorted = [...highlights].sort((a, b) => a.start - b.start);\n  const merged: MatchHighlight[] = [sorted[0]];\n\n  for (let i = 1; i < sorted.length; i++) {\n    const current = sorted[i];\n    const last = merged[merged.length - 1];\n\n    if (current.start <= last.end) {\n      // Overlapping - merge them\n      last.end = Math.max(last.end, current.end);\n      // Keep the more specific match type\n      if (getMatchTypePriority(current.type) > getMatchTypePriority(last.type)) {\n        last.type = current.type;\n      }\n    } else {\n      // No overlap - add as new highlight\n      merged.push(current);\n    }\n  }\n\n  return merged;\n}\n\n/**\n * Get priority for match types (higher = more specific)\n */\nfunction getMatchTypePriority(type: MatchType): number {\n  const priorities: Record<MatchType, number> = {\n    exact: 10,\n    prefix: 9,\n    substring: 8,\n    fuzzy: 7,\n    ngram: 6,\n    phonetic: 5,\n    compound: 4,\n    synonym: 3,\n  };\n  return priorities[type] || 0;\n}\n\n/**\n * Format highlighted text for HTML rendering\n */\nexport function formatHighlightedHTML(\n  //\n  text: string,\n  highlights: MatchHighlight[],\n  className: string = \"highlight\"\n): string {\n  if (!highlights || highlights.length === 0) {\n    return escapeHTML(text);\n  }\n\n  let result = \"\";\n  let lastEnd = 0;\n\n  for (const highlight of highlights) {\n    // Add text before highlight\n    if (highlight.start > lastEnd) {\n      result += escapeHTML(text.slice(lastEnd, highlight.start));\n    }\n\n    // Add highlighted text\n    const highlightedText = text.slice(highlight.start, highlight.end);\n    result += `<mark ${highlight.type === \"exact\" ? 'data-type=\"exact\"' : \"\"} class=\"${className} ${className}--${highlight.type}\">${escapeHTML(highlightedText)}</mark>`;\n\n    lastEnd = highlight.end;\n  }\n\n  // Add remaining text\n  if (lastEnd < text.length) {\n    result += escapeHTML(text.slice(lastEnd));\n  }\n\n  return result;\n}\n\n/**\n * Escape HTML special characters\n */\nfunction escapeHTML(text: string): string {\n  const div = typeof document !== \"undefined\" ? document.createElement(\"div\") : null;\n  if (div) {\n    div.textContent = text;\n    return div.innerHTML;\n  }\n  // Fallback for Node.js\n  return text.replace(/&/g, \"&amp;\").replace(/</g, \"&lt;\").replace(/>/g, \"&gt;\").replace(/\"/g, \"&quot;\").replace(/'/g, \"&#039;\");\n}\n","/**\n * LRU Cache for Search Results\n * Provides 10-100x speedup for repeated queries (e.g., autocomplete)\n */\n\nimport type { SuggestionResult } from \"./types.js\";\n\n/**\n * LRU (Least Recently Used) Cache\n * Automatically evicts oldest entries when capacity is reached\n */\nexport class LRUCache<K, V> {\n  private cache: Map<K, V>;\n  private capacity: number;\n\n  constructor(capacity: number = 100) {\n    this.cache = new Map();\n    this.capacity = capacity;\n  }\n\n  /**\n   * Get value from cache\n   * Moves item to end (most recently used)\n   */\n  get(key: K): V | undefined {\n    if (!this.cache.has(key)) {\n      return undefined;\n    }\n\n    // Move to end (most recently used)\n    const value = this.cache.get(key)!;\n    this.cache.delete(key);\n    this.cache.set(key, value);\n\n    return value;\n  }\n\n  /**\n   * Set value in cache\n   * Evicts oldest entry if capacity exceeded\n   */\n  set(\n    //\n    key: K,\n    value: V\n  ): void {\n    // Remove if exists (to update position)\n    if (this.cache.has(key)) {\n      this.cache.delete(key);\n    }\n\n    // Add to end (most recently used)\n    this.cache.set(key, value);\n\n    // Evict oldest if over capacity\n    if (this.cache.size > this.capacity) {\n      const firstKey = this.cache.keys().next().value as K;\n      if (firstKey !== undefined) {\n        this.cache.delete(firstKey);\n      }\n    }\n  }\n\n  /**\n   * Check if key exists in cache\n   */\n  has(key: K): boolean {\n    return this.cache.has(key);\n  }\n\n  /**\n   * Clear all cached entries\n   */\n  clear(): void {\n    this.cache.clear();\n  }\n\n  /**\n   * Get current cache size\n   */\n  get size(): number {\n    return this.cache.size;\n  }\n\n  /**\n   * Get cache statistics\n   */\n  getStats(): {\n    //\n    size: number;\n    capacity: number;\n    utilization: number;\n  } {\n    return {\n      size: this.cache.size,\n      capacity: this.capacity,\n      utilization: this.cache.size / this.capacity,\n    };\n  }\n}\n\n/**\n * Search Result Cache\n * Caches search results with automatic invalidation\n */\nexport class SearchCache {\n  private cache: LRUCache<string, SuggestionResult[]>;\n  private hits: number = 0;\n  private misses: number = 0;\n\n  constructor(capacity: number = 100) {\n    this.cache = new LRUCache(capacity);\n  }\n\n  /**\n   * Generate cache key from query and options\n   */\n  private getCacheKey(query: string, maxResults?: number, options?: any): string {\n    const optionsKey = options ? JSON.stringify(options) : \"\";\n    return `${query}|${maxResults || \"default\"}|${optionsKey}`;\n  }\n\n  /**\n   * Get cached results\n   */\n  get(query: string, maxResults?: number, options?: any): SuggestionResult[] | undefined {\n    const key = this.getCacheKey(query, maxResults, options);\n    const result = this.cache.get(key);\n\n    if (result) {\n      this.hits++;\n    } else {\n      this.misses++;\n    }\n\n    return result;\n  }\n\n  /**\n   * Set cached results\n   */\n  set(query: string, results: SuggestionResult[], maxResults?: number, options?: any): void {\n    const key = this.getCacheKey(query, maxResults, options);\n    this.cache.set(key, results);\n  }\n\n  /**\n   * Clear cache\n   */\n  clear(): void {\n    this.cache.clear();\n    this.hits = 0;\n    this.misses = 0;\n  }\n\n  /**\n   * Get cache statistics\n   */\n  getStats(): {\n    //\n    size: number;\n    capacity: number;\n    hits: number;\n    misses: number;\n    hitRate: number;\n  } {\n    const cacheStats = this.cache.getStats();\n    const total = this.hits + this.misses;\n    const hitRate = total > 0 ? this.hits / total : 0;\n\n    return {\n      ...cacheStats,\n      hits: this.hits,\n      misses: this.misses,\n      hitRate,\n    };\n  }\n}\n","/**\n * Accent Normalization Utilities\n * Removes diacritics and accents from text for better matching\n */\n\n/**\n * Comprehensive accent/diacritic mapping\n * Maps accented characters to their base forms\n */\nconst ACCENT_MAP: Record<string, string> = {\n  // Latin Extended-A\n  à: \"a\",\n  á: \"a\",\n  â: \"a\",\n  ã: \"a\",\n  ä: \"a\",\n  å: \"a\",\n  ā: \"a\",\n  ă: \"a\",\n  ą: \"a\",\n  À: \"A\",\n  Á: \"A\",\n  Â: \"A\",\n  Ã: \"A\",\n  Ä: \"A\",\n  Å: \"A\",\n  Ā: \"A\",\n  Ă: \"A\",\n  Ą: \"A\",\n\n  è: \"e\",\n  é: \"e\",\n  ê: \"e\",\n  ë: \"e\",\n  ē: \"e\",\n  ĕ: \"e\",\n  ė: \"e\",\n  ę: \"e\",\n  ě: \"e\",\n  È: \"E\",\n  É: \"E\",\n  Ê: \"E\",\n  Ë: \"E\",\n  Ē: \"E\",\n  Ĕ: \"E\",\n  Ė: \"E\",\n  Ę: \"E\",\n  Ě: \"E\",\n\n  ì: \"i\",\n  í: \"i\",\n  î: \"i\",\n  ï: \"i\",\n  ĩ: \"i\",\n  ī: \"i\",\n  ĭ: \"i\",\n  į: \"i\",\n  Ì: \"I\",\n  Í: \"I\",\n  Î: \"I\",\n  Ï: \"I\",\n  Ĩ: \"I\",\n  Ī: \"I\",\n  Ĭ: \"I\",\n  Į: \"I\",\n\n  'ò': 'o', 'ó': 'o', 'ô': 'o', 'õ': 'o', 'ö': 'o', 'ø': 'o', 'ō': 'o', 'ŏ': 'o', 'ő': 'o',\n  'Ò': 'O', 'Ó': 'O', 'Ô': 'O', 'Õ': 'O', 'Ö': 'O', 'Ø': 'O', 'Ō': 'O', 'Ŏ': 'O', 'Ő': 'O',\n\n  'ù': 'u', 'ú': 'u', 'û': 'u', 'ü': 'u', 'ũ': 'u', 'ū': 'u', 'ŭ': 'u', 'ů': 'u', 'ű': 'u', 'ų': 'u',\n  'Ù': 'U', 'Ú': 'U', 'Û': 'U', 'Ü': 'U', 'Ũ': 'U', 'Ū': 'U', 'Ŭ': 'U', 'Ů': 'U', 'Ű': 'U', 'Ų': 'U',\n\n  ý: \"y\",\n  ÿ: \"y\",\n  ŷ: \"y\",\n  Ý: \"Y\",\n  Ÿ: \"Y\",\n  Ŷ: \"Y\",\n\n  ñ: \"n\",\n  ń: \"n\",\n  ņ: \"n\",\n  ň: \"n\",\n  Ñ: \"N\",\n  Ń: \"N\",\n  Ņ: \"N\",\n  Ň: \"N\",\n\n  ç: \"c\",\n  ć: \"c\",\n  ĉ: \"c\",\n  ċ: \"c\",\n  č: \"c\",\n  Ç: \"C\",\n  Ć: \"C\",\n  Ĉ: \"C\",\n  Ċ: \"C\",\n  Č: \"C\",\n\n  ß: \"ss\", // German sharp s\n\n  ð: \"d\",\n  đ: \"d\",\n  Ð: \"D\",\n  Đ: \"D\",\n\n  ĝ: \"g\",\n  ğ: \"g\",\n  ġ: \"g\",\n  ģ: \"g\",\n  Ĝ: \"G\",\n  Ğ: \"G\",\n  Ġ: \"G\",\n  Ģ: \"G\",\n\n  ĥ: \"h\",\n  ħ: \"h\",\n  Ĥ: \"H\",\n  Ħ: \"H\",\n\n  ĵ: \"j\",\n  Ĵ: \"J\",\n\n  ķ: \"k\",\n  Ķ: \"K\",\n\n  ĺ: \"l\",\n  ļ: \"l\",\n  ľ: \"l\",\n  ŀ: \"l\",\n  ł: \"l\",\n  Ĺ: \"L\",\n  Ļ: \"L\",\n  Ľ: \"L\",\n  Ŀ: \"L\",\n  Ł: \"L\",\n\n  ŕ: \"r\",\n  ŗ: \"r\",\n  ř: \"r\",\n  Ŕ: \"R\",\n  Ŗ: \"R\",\n  Ř: \"R\",\n\n  ś: \"s\",\n  ŝ: \"s\",\n  ş: \"s\",\n  š: \"s\",\n  Ś: \"S\",\n  Ŝ: \"S\",\n  Ş: \"S\",\n  Š: \"S\",\n\n  ţ: \"t\",\n  ť: \"t\",\n  ŧ: \"t\",\n  Ţ: \"T\",\n  Ť: \"T\",\n  Ŧ: \"T\",\n\n  ŵ: \"w\",\n  Ŵ: \"W\",\n\n  ź: \"z\",\n  ż: \"z\",\n  ž: \"z\",\n  Ź: \"Z\",\n  Ż: \"Z\",\n  Ž: \"Z\",\n\n  æ: \"ae\",\n  œ: \"oe\",\n  Æ: \"AE\",\n  Œ: \"OE\",\n\n  þ: \"th\",\n  Þ: \"TH\",\n};\n\n/**\n * Cache for accent removal results\n * Dramatically speeds up repeated accent normalization\n */\nconst accentCache = new Map<string, string>();\nconst MAX_CACHE_SIZE = 10000; // TODO: Adjust based on memory constraints\n\n/**\n * Remove accents and diacritics from a string\n * Uses both custom mapping and Unicode normalization with caching\n */\nexport function removeAccents(text: string): string {\n  if (!text) return text;\n\n  // Check cache first (massive speedup for repeated words)\n  const cached = accentCache.get(text);\n  if (cached !== undefined) {\n    return cached;\n  }\n\n  // OPTIMIZATION: Use array join instead of string concatenation\n  const chars: string[] = [];\n  for (let i = 0; i < text.length; i++) {\n    const char = text[i];\n    chars.push(ACCENT_MAP[char] || char);\n  }\n  let result = chars.join('');\n\n  // Second pass: Use Unicode normalization for any remaining accents\n  // NFD = Canonical Decomposition (separates base char from combining marks)\n  // Then remove combining diacritical marks (Unicode range \\u0300-\\u036f)\n  result = result.normalize(\"NFD\").replace(/[\\u0300-\\u036f]/g, \"\");\n\n  // Cache the result (with size limit)\n  if (accentCache.size < MAX_CACHE_SIZE) {\n    accentCache.set(text, result);\n  } else if (accentCache.size === MAX_CACHE_SIZE) {\n    // Clear cache when it gets too large (keep most recent)\n    accentCache.clear();\n    accentCache.set(text, result);\n  }\n\n  return result;\n}\n\n/**\n * Check if a string contains any accented characters\n * Optimized with early return\n */\nexport function hasAccents(text: string): boolean {\n  if (!text) return false;\n\n  // OPTIMIZATION: Check custom map first (fast path)\n  for (let i = 0; i < text.length; i++) {\n    if (ACCENT_MAP[text[i]]) {\n      return true;\n    }\n  }\n\n  // OPTIMIZATION: Only normalize if we didn't find accents in map\n  // Check for combining diacritical marks\n  return /[\\u0300-\\u036f]/.test(text.normalize(\"NFD\"));\n}\n\n/**\n * Normalize text for accent-insensitive comparison\n * Converts to lowercase and removes accents\n */\nexport function normalizeForComparison(text: string): string {\n  return removeAccents(text.toLowerCase());\n}\n\n/**\n * Create accent-insensitive variants of a word\n * Returns both original and accent-free version\n */\nexport function getAccentVariants(word: string): string[] {\n  const normalized = removeAccents(word);\n\n  // If word has accents, return both versions\n  if (normalized !== word) {\n    return [word, normalized];\n  }\n\n  // Otherwise just return original\n  return [word];\n}\n","/**\n * Field Weighting Utilities\n * Support for multi-field search with weighted scoring\n */\n\n/**\n * Extract field values from an object or string\n */\nexport function extractFieldValues(\n  //\n  item: any,\n  fields?: string[]\n): Record<string, string> | null {\n  // If no fields specified, treat item as simple string\n  if (!fields || fields.length === 0) {\n    return null;\n  }\n\n  // If item is a string, can't extract fields\n  if (typeof item === \"string\") {\n    return null;\n  }\n\n  // If item is an object, extract field values\n  if (typeof item === \"object\" && item !== null) {\n    const fieldValues: Record<string, string> = {};\n\n    for (const field of fields) {\n      const value = item[field];\n      if (value !== undefined && value !== null) {\n        fieldValues[field] = String(value);\n      }\n    }\n\n    return Object.keys(fieldValues).length > 0 ? fieldValues : null;\n  }\n\n  return null;\n}\n\n/**\n * Get all searchable text from field values\n */\nexport function getSearchableText(\n  //\n  fieldValues: Record<string, string>\n): string[] {\n  return Object.values(fieldValues).filter((v) => v && v.trim().length > 0);\n}\n\n/**\n * Normalize field weights (ensure all fields have a weight)\n */\nexport function normalizeFieldWeights(\n  //\n  fields: string[],\n  fieldWeights?: Record<string, number>\n): Record<string, number> {\n  const normalized: Record<string, number> = {};\n\n  for (const field of fields) {\n    normalized[field] = fieldWeights?.[field] ?? 1.0;\n  }\n\n  return normalized;\n}\n\n/**\n * Apply field weight to a score\n */\nexport function applyFieldWeight(\n  //\n  baseScore: number,\n  fieldWeight: number\n): number {\n  return Math.min(1.0, baseScore * fieldWeight);\n}\n","/**\n * Stop Words Filtering\n * Common words that should be ignored in search queries\n */\n\n/**\n * Default stop words by language\n */\nexport const DEFAULT_STOP_WORDS: Record<string, string[]> = {\n  english: [\n    //\n    \"a\",\n    \"an\",\n    \"and\",\n    \"are\",\n    \"as\",\n    \"at\",\n    \"be\",\n    \"by\",\n    \"for\",\n    \"from\",\n    \"has\",\n    \"he\",\n    \"in\",\n    \"is\",\n    \"it\",\n    \"its\",\n    \"of\",\n    \"on\",\n    \"that\",\n    \"the\",\n    \"to\",\n    \"was\",\n    \"will\",\n    \"with\",\n    \"the\",\n    \"this\",\n    \"but\",\n    \"they\",\n    \"have\",\n    \"had\",\n    \"what\",\n    \"when\",\n    \"where\",\n    \"who\",\n    \"which\",\n    \"why\",\n    \"how\",\n  ],\n  german: [\n    //\n    \"der\",\n    \"die\",\n    \"das\",\n    \"den\",\n    \"dem\",\n    \"des\",\n    \"ein\",\n    \"eine\",\n    \"einer\",\n    \"eines\",\n    \"einem\",\n    \"einen\",\n    \"und\",\n    \"oder\",\n    \"aber\",\n    \"ist\",\n    \"sind\",\n    \"war\",\n    \"waren\",\n    \"hat\",\n    \"haben\",\n    \"wird\",\n    \"werden\",\n    \"von\",\n    \"zu\",\n    \"im\",\n    \"am\",\n    \"um\",\n    \"auf\",\n    \"für\",\n    \"mit\",\n    \"nach\",\n    \"bei\",\n    \"aus\",\n  ],\n  spanish: [\n    //\n    \"el\",\n    \"la\",\n    \"los\",\n    \"las\",\n    \"un\",\n    \"una\",\n    \"unos\",\n    \"unas\",\n    \"de\",\n    \"del\",\n    \"y\",\n    \"o\",\n    \"pero\",\n    \"es\",\n    \"son\",\n    \"era\",\n    \"fueron\",\n    \"ha\",\n    \"han\",\n    \"en\",\n    \"a\",\n    \"al\",\n    \"con\",\n    \"por\",\n    \"para\",\n    \"sin\",\n    \"sobre\",\n    \"entre\",\n  ],\n  french: [\n    //\n    \"le\",\n    \"la\",\n    \"les\",\n    \"un\",\n    \"une\",\n    \"des\",\n    \"du\",\n    \"de\",\n    \"et\",\n    \"ou\",\n    \"mais\",\n    \"est\",\n    \"sont\",\n    \"était\",\n    \"étaient\",\n    \"a\",\n    \"ont\",\n    \"à\",\n    \"au\",\n    \"aux\",\n    \"avec\",\n    \"pour\",\n    \"par\",\n    \"dans\",\n    \"sur\",\n    \"sous\",\n    \"entre\",\n  ],\n};\n\n/**\n * Filter stop words from a query\n */\nexport function filterStopWords(\n  query: string,\n  stopWords: string[] | Set<string>\n): string {\n  const stopWordsSet = stopWords instanceof Set ? stopWords : new Set(stopWords.map(w => w.toLowerCase()));\n  \n  // Split query into words, preserving original case\n  const words = query.split(/\\s+/);\n  const filtered = words.filter(word => !stopWordsSet.has(word.toLowerCase()));\n  \n  // If all words are stop words, return original query to avoid empty search\n  if (filtered.length === 0) {\n    return query;\n  }\n  \n  return filtered.join(' ');\n}\n\n/**\n * Get stop words for specific languages\n */\nexport function getStopWordsForLanguages(languages: string[]): Set<string> {\n  const stopWords = new Set<string>();\n\n  for (const lang of languages) {\n    const langStopWords = DEFAULT_STOP_WORDS[lang.toLowerCase()];\n    if (langStopWords) {\n      langStopWords.forEach((word) => stopWords.add(word));\n    }\n  }\n\n  return stopWords;\n}\n\n/**\n * Check if a word is a stop word\n */\nexport function isStopWord(word: string, stopWords: string[] | Set<string>): boolean {\n  const stopWordsSet = stopWords instanceof Set ? stopWords : new Set(stopWords.map((w) => w.toLowerCase()));\n  return stopWordsSet.has(word.toLowerCase());\n}\n","/**\n * Word Boundary Utilities\n * Check if matches occur at word boundaries for more precise results\n */\n\n/**\n * Check if a match is at a word boundary\n * A word boundary is:\n * - Start of string\n * - After whitespace\n * - After punctuation\n */\nexport function isWordBoundary(text: string, position: number): boolean {\n  // Start of string is always a word boundary\n  if (position === 0) {\n    return true;\n  }\n\n  // Check the character before the position\n  const charBefore = text[position - 1];\n  \n  // Word boundary if previous character is whitespace or punctuation\n  return /[\\s\\-_.,;:!?()[\\]{}'\"\\/\\\\]/.test(charBefore);\n}\n\n/**\n * Check if a match occurs at word boundaries (both start and end)\n */\nexport function matchesAtWordBoundary(\n  text: string,\n  matchStart: number,\n  matchLength: number\n): boolean {\n  const matchEnd = matchStart + matchLength;\n  \n  // Check start boundary\n  const startBoundary = isWordBoundary(text, matchStart);\n  \n  // Check end boundary (either end of string or followed by boundary character)\n  const endBoundary = matchEnd >= text.length || /[\\s\\-_.,;:!?()[\\]{}'\"\\/\\\\]/.test(text[matchEnd]);\n  \n  return startBoundary && endBoundary;\n}\n\n/**\n * Find all word boundary matches of a pattern in text\n */\nexport function findWordBoundaryMatches(\n  text: string,\n  pattern: string,\n  caseSensitive: boolean = false\n): number[] {\n  const positions: number[] = [];\n  const searchText = caseSensitive ? text : text.toLowerCase();\n  const searchPattern = caseSensitive ? pattern : pattern.toLowerCase();\n  \n  let index = 0;\n  while (index < searchText.length) {\n    const found = searchText.indexOf(searchPattern, index);\n    \n    if (found === -1) {\n      break;\n    }\n    \n    // Check if this match is at a word boundary\n    if (matchesAtWordBoundary(text, found, searchPattern.length)) {\n      positions.push(found);\n    }\n    \n    index = found + 1;\n  }\n  \n  return positions;\n}\n\n/**\n * Check if query matches word with word boundaries\n */\nexport function matchesWord(word: string, query: string, wordBoundaries: boolean): boolean {\n  if (!wordBoundaries) {\n    // No word boundary checking - substring match is fine\n    return word.toLowerCase().includes(query.toLowerCase());\n  }\n  \n  // With word boundaries - must match at word boundary\n  const positions = findWordBoundaryMatches(word, query, false);\n  return positions.length > 0;\n}\n\n/**\n * Check if a word starts with query (prefix match with word boundaries)\n */\nexport function startsWithWord(word: string, query: string, wordBoundaries: boolean): boolean {\n  const wordLower = word.toLowerCase();\n  const queryLower = query.toLowerCase();\n  \n  if (!wordBoundaries) {\n    return wordLower.startsWith(queryLower);\n  }\n  \n  // With word boundaries - check if it starts at position 0 (which is always a boundary)\n  return wordLower.startsWith(queryLower);\n}\n\n/**\n * Parse wildcard pattern (supports * for any characters)\n */\nexport function parseWildcard(pattern: string): RegExp {\n  // Escape special regex characters except *\n  const escaped = pattern.replace(/[.+?^${}()|[\\]\\\\]/g, '\\\\$&');\n  \n  // Replace * with .*\n  const regexPattern = escaped.replace(/\\*/g, '.*');\n  \n  // Create regex with word boundaries if no wildcards\n  return new RegExp(`^${regexPattern}$`, 'i');\n}\n\n/**\n * Check if word matches wildcard pattern\n */\nexport function matchesWildcard(word: string, pattern: string): boolean {\n  const regex = parseWildcard(pattern);\n  return regex.test(word);\n}\n","/**\n * Phrase parser for multi-word query support\n * Extracts quoted phrases and regular terms from search queries\n */\n\nexport interface ParsedQuery {\n  /** Quoted phrases to search as units */\n  phrases: string[];\n  /** Individual search terms */\n  terms: string[];\n  /** Original query string */\n  original: string;\n  /** Whether query contains any phrases */\n  hasPhrases: boolean;\n}\n\n/**\n * Parse a search query to extract phrases and terms\n * Supports both double quotes (\") and single quotes (')\n * \n * @example\n * parseQuery('\"new york\" city')\n * // → { phrases: ['new york'], terms: ['city'], hasPhrases: true }\n * \n * parseQuery('hello world')\n * // → { phrases: [], terms: ['hello', 'world'], hasPhrases: false }\n */\nexport function parseQuery(query: string): ParsedQuery {\n  if (!query || typeof query !== 'string') {\n    return {\n      phrases: [],\n      terms: [],\n      original: query || '',\n      hasPhrases: false,\n    };\n  }\n\n  const phrases: string[] = [];\n  let remaining = query;\n\n  // Extract phrases with double quotes\n  const doubleQuoteRegex = /\"([^\"]+)\"/g;\n  let match;\n  \n  while ((match = doubleQuoteRegex.exec(query)) !== null) {\n    const phrase = match[1].trim();\n    if (phrase) {\n      // Validate phrase length (max 10 words)\n      const wordCount = phrase.split(/\\s+/).length;\n      if (wordCount <= 10) {\n        phrases.push(phrase);\n      }\n    }\n  }\n\n  // Remove double-quoted phrases from remaining text (including empty ones)\n  remaining = remaining.replace(/\"[^\"]*\"/g, ' ');\n\n  // Extract phrases with single quotes\n  const singleQuoteRegex = /'([^']+)'/g;\n  \n  while ((match = singleQuoteRegex.exec(query)) !== null) {\n    const phrase = match[1].trim();\n    if (phrase) {\n      // Validate phrase length (max 10 words)\n      const wordCount = phrase.split(/\\s+/).length;\n      if (wordCount <= 10) {\n        phrases.push(phrase);\n      }\n    }\n  }\n\n  // Remove single-quoted phrases from remaining text (including empty ones)\n  remaining = remaining.replace(/'[^']*'/g, ' ');\n\n  // Extract remaining terms (non-phrase words)\n  const terms = remaining\n    .split(/\\s+/)\n    .map(t => t.trim())\n    .filter(t => t.length > 0);\n\n  return {\n    phrases,\n    terms,\n    original: query,\n    hasPhrases: phrases.length > 0,\n  };\n}\n\n/**\n * Check if a query contains phrase syntax (quotes)\n */\nexport function hasPhraseSyntax(query: string): boolean {\n  if (!query) return false;\n  return /\"[^\"]*\"/.test(query) || /'[^']*'/.test(query);\n}\n\n/**\n * Normalize a phrase for matching (lowercase, trim)\n */\nexport function normalizePhrase(phrase: string): string {\n  return phrase.toLowerCase().trim().replace(/\\s+/g, ' ');\n}\n\n/**\n * Split a phrase into words\n */\nexport function splitPhraseWords(phrase: string): string[] {\n  return phrase\n    .toLowerCase()\n    .trim()\n    .split(/\\s+/)\n    .filter(w => w.length > 0);\n}\n","/**\n * Phrase matching algorithms for multi-word query support\n */\n\nimport { calculateLevenshteinDistance, calculateDamerauLevenshteinDistance } from \"../algorithms/levenshtein.js\";\nimport { tokenize } from \"../utils/tokenizer.js\";\n\nexport interface PhraseMatchOptions {\n  /** Require exact phrase match (no typos) */\n  exactMatch?: boolean;\n  /** Maximum edit distance per word in phrase */\n  maxEditDistance?: number;\n  /** Score multiplier for phrase matches */\n  proximityBonus?: number;\n  /** Maximum words between phrase words for proximity match */\n  maxProximityDistance?: number;\n  /** Use Damerau-Levenshtein (transpositions) */\n  useTranspositions?: boolean;\n}\n\nexport interface PhraseMatchResult {\n  /** Whether phrase was found */\n  matched: boolean;\n  /** Match score (0-1) */\n  score: number;\n  /** Type of match */\n  matchType: \"exact\" | \"fuzzy\" | \"proximity\" | \"none\";\n  /** Start position in text */\n  startPos?: number;\n  /** End position in text */\n  endPos?: number;\n  /** Words that matched */\n  matchedWords?: string[];\n}\n\nconst DEFAULT_OPTIONS: Required<PhraseMatchOptions> = {\n  exactMatch: false,\n  maxEditDistance: 1,\n  proximityBonus: 1.5,\n  maxProximityDistance: 3,\n  useTranspositions: false,\n};\n\n/**\n * Match a phrase in text with various strategies\n */\nexport function matchPhrase(\n  //\n  text: string,\n  phrase: string,\n  options: PhraseMatchOptions = {}\n): PhraseMatchResult {\n  const opts = { ...DEFAULT_OPTIONS, ...options };\n\n  if (!text || !phrase) {\n    return { matched: false, score: 0, matchType: \"none\" };\n  }\n\n  const normalizedText = text.toLowerCase();\n  const normalizedPhrase = phrase.toLowerCase();\n\n  // Strategy 1: Exact phrase match (highest score)\n  const exactMatch = findExactPhrase(normalizedText, normalizedPhrase);\n  if (exactMatch.matched) {\n    return { ...exactMatch, score: 1.0, matchType: \"exact\" };\n  }\n\n  // If exact match required, stop here\n  if (opts.exactMatch) {\n    return { matched: false, score: 0, matchType: \"none\" };\n  }\n\n  // Strategy 2: Fuzzy phrase match (allow typos)\n  const fuzzyMatch = findFuzzyPhrase(normalizedText, normalizedPhrase, opts.maxEditDistance, opts.useTranspositions);\n  if (fuzzyMatch.matched) {\n    return { ...fuzzyMatch, matchType: \"fuzzy\" };\n  }\n\n  // Strategy 3: Proximity match (words nearby)\n  const proximityMatch = findProximityMatch(normalizedText, normalizedPhrase, opts.maxProximityDistance);\n  if (proximityMatch.matched) {\n    return { ...proximityMatch, matchType: \"proximity\" };\n  }\n\n  return { matched: false, score: 0, matchType: \"none\" };\n}\n\n/**\n * Find exact phrase in text\n */\nfunction findExactPhrase(\n  //\n  text: string,\n  phrase: string\n): PhraseMatchResult {\n  const index = text.indexOf(phrase);\n\n  if (index !== -1) {\n    return {\n      matched: true,\n      score: 1.0,\n      matchType: \"exact\",\n      startPos: index,\n      endPos: index + phrase.length,\n    };\n  }\n\n  return { matched: false, score: 0, matchType: \"none\" };\n}\n\n/**\n * Find phrase with fuzzy matching (allow typos)\n */\nfunction findFuzzyPhrase(\n  //\n  text: string,\n  phrase: string,\n  maxEditDistance: number,\n  useTranspositions: boolean\n): PhraseMatchResult {\n  // Use centralized tokenizer for consistent word boundary handling\n  const phraseWords = tokenize(phrase, { lowercase: true });\n  const textWords = tokenize(text, { lowercase: true });\n\n  // Try to find consecutive words that match the phrase\n  for (let i = 0; i <= textWords.length - phraseWords.length; i++) {\n    const segment = textWords.slice(i, i + phraseWords.length);\n\n    // Check if this segment matches the phrase with fuzzy matching\n    let totalDistance = 0;\n    let allMatch = true;\n\n    for (let j = 0; j < phraseWords.length; j++) {\n      const distance = useTranspositions ? calculateDamerauLevenshteinDistance(phraseWords[j], segment[j], maxEditDistance) : calculateLevenshteinDistance(phraseWords[j], segment[j], maxEditDistance);\n\n      if (distance > maxEditDistance) {\n        allMatch = false;\n        break;\n      }\n      totalDistance += distance;\n    }\n\n    if (allMatch) {\n      // Calculate score based on edit distance\n      const maxPossibleDistance = phraseWords.length * maxEditDistance;\n      const score = maxPossibleDistance > 0 ? 0.7 + 0.2 * (1 - totalDistance / maxPossibleDistance) : 0.9;\n\n      return {\n        matched: true,\n        score,\n        matchType: \"fuzzy\",\n        matchedWords: segment,\n      };\n    }\n  }\n\n  return { matched: false, score: 0, matchType: \"none\" };\n}\n\n/**\n * Find words in proximity (nearby but not necessarily consecutive)\n */\nfunction findProximityMatch(\n  //\n  text: string,\n  phrase: string,\n  maxDistance: number\n): PhraseMatchResult {\n  // Use centralized tokenizer for consistent word boundary handling\n  const phraseWords = tokenize(phrase, { lowercase: true });\n  const textWords = tokenize(text, { lowercase: true });\n\n  // Find positions of each phrase word in text\n  const positions: number[][] = phraseWords.map(() => []);\n\n  textWords.forEach((word, index) => {\n    phraseWords.forEach((phraseWord, phraseIndex) => {\n      if (word === phraseWord || word.includes(phraseWord) || phraseWord.includes(word)) {\n        positions[phraseIndex].push(index);\n      }\n    });\n  });\n\n  // Check if all words were found\n  if (positions.some((p) => p.length === 0)) {\n    return { matched: false, score: 0, matchType: \"none\" };\n  }\n\n  // Find the best combination where words are close together\n  let bestDistance = Infinity;\n  let bestPositions: number[] = [];\n\n  function findBestCombination(wordIndex: number, currentPositions: number[]): void {\n    if (wordIndex === phraseWords.length) {\n      // Calculate total distance\n      const sorted = [...currentPositions].sort((a, b) => a - b);\n      const distance = sorted[sorted.length - 1] - sorted[0];\n\n      if (distance < bestDistance) {\n        bestDistance = distance;\n        bestPositions = [...currentPositions];\n      }\n      return;\n    }\n\n    for (const pos of positions[wordIndex]) {\n      findBestCombination(wordIndex + 1, [...currentPositions, pos]);\n    }\n  }\n\n  findBestCombination(0, []);\n\n  // Check if words are within max distance\n  if (bestDistance <= maxDistance) {\n    // Score based on proximity (closer = higher score)\n    const score = 0.5 + 0.2 * (1 - bestDistance / maxDistance);\n\n    return {\n      matched: true,\n      score,\n      matchType: \"proximity\",\n      matchedWords: bestPositions.map((i) => textWords[i]),\n    };\n  }\n\n  return { matched: false, score: 0, matchType: \"none\" };\n}\n\n/**\n * Calculate phrase match score for a text\n * Returns 0 if no match, or a boosted score if phrase matches\n */\nexport function calculatePhraseScore(\n  //\n  text: string,\n  phrase: string,\n  baseScore: number,\n  options: PhraseMatchOptions = {}\n): number {\n  const match = matchPhrase(text, phrase, options);\n\n  if (!match.matched) {\n    return 0;\n  }\n\n  // Apply proximity bonus\n  const bonus = options.proximityBonus || 1.5;\n  return Math.min(1.0, baseScore * match.score * bonus);\n}\n","/**\n * Language auto-detection utility\n * Uses character-based heuristics to detect languages in text\n */\n\nexport interface LanguageDetectionResult {\n  /** Detected languages */\n  languages: string[];\n  /** Confidence scores for each language (0-1) */\n  confidence: Record<string, number>;\n  /** Primary language (highest confidence) */\n  primary: string;\n}\n\n/**\n * Detect languages from text using character-based heuristics\n * Detects multiple languages if present in the same text\n * \n * @param text - Text to analyze\n * @returns Array of detected language codes\n * \n * @example\n * detectLanguages('Müller café hello')\n * // → ['english', 'german', 'french']\n */\nexport function detectLanguages(text: string): string[] {\n  if (!text || text.trim().length === 0) {\n    return ['english']; // Default fallback\n  }\n\n  const detected = new Set<string>();\n\n  // Always include English as base language\n  detected.add('english');\n\n  // German indicators: ä, ö, ü, ß\n  if (/[äöüßÄÖÜ]/.test(text)) {\n    detected.add('german');\n  }\n\n  // French indicators: é, è, ê, à, ç, œ, etc.\n  if (/[àâäæçéèêëïîôùûüÿœÀÂÄÆÇÉÈÊËÏÎÔÙÛÜŸŒ]/.test(text)) {\n    detected.add('french');\n  }\n\n  // Spanish indicators: ñ, á, é, í, ó, ú, ¿, ¡\n  if (/[áéíóúñüÁÉÍÓÚÑÜ¿¡]/.test(text)) {\n    detected.add('spanish');\n  }\n\n  return Array.from(detected);\n}\n\n/**\n * Detect languages with confidence scores\n * Provides more detailed information about language detection\n * \n * @param text - Text to analyze\n * @returns Detection result with confidence scores\n */\nexport function detectLanguagesWithConfidence(text: string): LanguageDetectionResult {\n  if (!text || text.trim().length === 0) {\n    return {\n      languages: ['english'],\n      confidence: { english: 1.0 },\n      primary: 'english',\n    };\n  }\n\n  const confidence: Record<string, number> = {\n    english: 0.5, // Base confidence for English\n  };\n\n  const textLength = text.length;\n\n  // Count German characters\n  const germanChars = (text.match(/[äöüßÄÖÜ]/g) || []).length;\n  if (germanChars > 0) {\n    confidence.german = Math.min(1.0, 0.5 + (germanChars / textLength) * 10);\n  }\n\n  // Count French characters\n  const frenchChars = (text.match(/[àâäæçéèêëïîôùûüÿœÀÂÄÆÇÉÈÊËÏÎÔÙÛÜŸŒ]/g) || []).length;\n  if (frenchChars > 0) {\n    confidence.french = Math.min(1.0, 0.5 + (frenchChars / textLength) * 10);\n  }\n\n  // Count Spanish characters\n  const spanishChars = (text.match(/[áéíóúñüÁÉÍÓÚÑÜ¿¡]/g) || []).length;\n  if (spanishChars > 0) {\n    confidence.spanish = Math.min(1.0, 0.5 + (spanishChars / textLength) * 10);\n  }\n\n  // Determine languages (confidence > 0.5)\n  const languages = Object.entries(confidence)\n    .filter(([_, conf]) => conf >= 0.5)\n    .map(([lang]) => lang);\n\n  // Find primary language (highest confidence)\n  const primary = Object.entries(confidence)\n    .sort(([, a], [, b]) => b - a)[0][0];\n\n  return {\n    languages,\n    confidence,\n    primary,\n  };\n}\n\n/**\n * Sample text from a dataset for language detection\n * Takes first N items to avoid processing entire large datasets\n * \n * @param words - Array of words or objects\n * @param sampleSize - Number of items to sample (default: 100)\n * @returns Combined sample text\n */\nexport function sampleTextForDetection(\n  //\n  words: (string | any)[], sampleSize: number = 100): string {\n  const sample = words.slice(0, Math.min(sampleSize, words.length));\n  \n  return sample\n    .map(item => {\n      if (typeof item === 'string') {\n        return item;\n      } else if (typeof item === 'object' && item !== null) {\n        // Extract text from object fields\n        return Object.values(item)\n          .filter(v => typeof v === 'string')\n          .join(' ');\n      }\n      return '';\n    })\n    .join(' ');\n}\n\n/**\n * Check if a language code is valid\n */\nexport function isValidLanguage(lang: string): boolean {\n  const validLanguages = ['english', 'german', 'french', 'spanish', 'auto'];\n  return validLanguages.includes(lang.toLowerCase());\n}\n\n/**\n * Normalize language codes\n * Handles common variations and aliases\n */\nexport function normalizeLanguageCode(lang: string): string {\n  const normalized = lang.toLowerCase().trim();\n  \n  // Handle aliases\n  const aliases: Record<string, string> = {\n    'en': 'english',\n    'de': 'german',\n    'fr': 'french',\n    'es': 'spanish',\n    'eng': 'english',\n    'deu': 'german',\n    'fra': 'french',\n    'esp': 'spanish',\n  };\n  \n  return aliases[normalized] || normalized;\n}\n","/**\n * FQL Lexer (Tokenizer)\n * Converts FQL query strings into tokens for parsing\n */\n\nexport const TokenType = {\n  TERM: \"TERM\",\n  QUOTED: \"QUOTED\",\n  AND: \"AND\",\n  OR: \"OR\",\n  NOT: \"NOT\",\n  LPAREN: \"LPAREN\",\n  RPAREN: \"RPAREN\",\n  COLON: \"COLON\",\n  EXACT: \"EXACT\",\n  FUZZY: \"FUZZY\",\n  PHONETIC: \"PHONETIC\",\n  PREFIX: \"PREFIX\",\n  REGEX: \"REGEX\",\n  COMPOUND: \"COMPOUND\",\n  LANG: \"LANG\",\n  SCORE: \"SCORE\",\n  SCORE_OP: \"SCORE_OP\",\n  NUMBER: \"NUMBER\",\n  EOF: \"EOF\",\n} as const;\n\nexport type TokenType = (typeof TokenType)[keyof typeof TokenType];\n\nexport interface Token {\n  type: TokenType;\n  value: string;\n  position: number;\n}\n\nexport class FQLLexer {\n  private input: string = \"\";\n  private position: number = 0;\n  private tokens: Token[] = [];\n\n  /**\n   * Tokenize an FQL query string\n   */\n  tokenize(input: string): Token[] {\n    this.input = input.trim();\n    this.position = 0;\n    this.tokens = [];\n\n    while (this.position < this.input.length) {\n      this.skipWhitespace();\n\n      if (this.position >= this.input.length) break;\n\n      const char = this.input[this.position];\n\n      // Parentheses\n      if (char === \"(\") {\n        this.tokens.push({ type: TokenType.LPAREN, value: \"(\", position: this.position });\n        this.position++;\n        continue;\n      }\n\n      if (char === \")\") {\n        this.tokens.push({ type: TokenType.RPAREN, value: \")\", position: this.position });\n        this.position++;\n        continue;\n      }\n\n      // Colon\n      if (char === \":\") {\n        this.tokens.push({ type: TokenType.COLON, value: \":\", position: this.position });\n        this.position++;\n        continue;\n      }\n\n      // Quoted strings\n      if (char === '\"' || char === \"'\") {\n        this.tokenizeQuotedString(char);\n        continue;\n      }\n\n      // Numbers (for score thresholds)\n      if (this.isDigit(char)) {\n        this.tokenizeNumber();\n        continue;\n      }\n\n      // Keywords and terms\n      if (this.isAlpha(char)) {\n        this.tokenizeKeywordOrTerm();\n        continue;\n      }\n\n      // Score operators (>, <, >=, <=)\n      if (char === \">\" || char === \"<\") {\n        this.tokenizeScoreOperator();\n        continue;\n      }\n\n      // Unknown character - skip it\n      this.position++;\n    }\n\n    // Add EOF token\n    this.tokens.push({ type: TokenType.EOF, value: \"\", position: this.position });\n\n    return this.tokens;\n  }\n\n  private skipWhitespace(): void {\n    while (this.position < this.input.length && /\\s/.test(this.input[this.position])) {\n      this.position++;\n    }\n  }\n\n  private isAlpha(char: string): boolean {\n    return /[a-zA-ZäöüßÄÖÜàâäæçéèêëïîôùûüÿœÀÂÄÆÇÉÈÊËÏÎÔÙÛÜŸŒáéíóúñüÁÉÍÓÚÑÜ_]/.test(char);\n  }\n\n  private isDigit(char: string): boolean {\n    return /[0-9.]/.test(char);\n  }\n\n  private isAlphaNumeric(char: string): boolean {\n    return this.isAlpha(char) || this.isDigit(char);\n  }\n\n  private tokenizeQuotedString(quote: string): void {\n    const start = this.position;\n    this.position++; // Skip opening quote\n\n    let value = \"\";\n    while (this.position < this.input.length && this.input[this.position] !== quote) {\n      value += this.input[this.position];\n      this.position++;\n    }\n\n    if (this.position >= this.input.length) {\n      throw new Error(`Unclosed quote at position ${start}`);\n    }\n\n    this.position++; // Skip closing quote\n\n    this.tokens.push({ type: TokenType.QUOTED, value, position: start });\n  }\n\n  private tokenizeNumber(): void {\n    const start = this.position;\n    let value = \"\";\n\n    while (this.position < this.input.length && this.isDigit(this.input[this.position])) {\n      value += this.input[this.position];\n      this.position++;\n    }\n\n    this.tokens.push({ type: TokenType.NUMBER, value, position: start });\n  }\n\n  private tokenizeKeywordOrTerm(): void {\n    const start = this.position;\n    let value = \"\";\n\n    while (this.position < this.input.length && this.isAlphaNumeric(this.input[this.position])) {\n      value += this.input[this.position];\n      this.position++;\n    }\n\n    const upperValue = value.toUpperCase();\n\n    // Check for keywords\n    switch (upperValue) {\n      case \"AND\":\n        this.tokens.push({ type: TokenType.AND, value: upperValue, position: start });\n        break;\n      case \"OR\":\n        this.tokens.push({ type: TokenType.OR, value: upperValue, position: start });\n        break;\n      case \"NOT\":\n        this.tokens.push({ type: TokenType.NOT, value: upperValue, position: start });\n        break;\n      case \"EXACT\":\n        this.tokens.push({ type: TokenType.EXACT, value: upperValue, position: start });\n        break;\n      case \"FUZZY\":\n        this.tokens.push({ type: TokenType.FUZZY, value: upperValue, position: start });\n        break;\n      case \"PHONETIC\":\n        this.tokens.push({ type: TokenType.PHONETIC, value: upperValue, position: start });\n        break;\n      case \"PREFIX\":\n        this.tokens.push({ type: TokenType.PREFIX, value: upperValue, position: start });\n        break;\n      case \"REGEX\":\n        this.tokens.push({ type: TokenType.REGEX, value: upperValue, position: start });\n        break;\n      case \"COMPOUND\":\n        this.tokens.push({ type: TokenType.COMPOUND, value: upperValue, position: start });\n        break;\n      case \"LANG\":\n        this.tokens.push({ type: TokenType.LANG, value: upperValue, position: start });\n        break;\n      case \"SCORE\":\n        this.tokens.push({ type: TokenType.SCORE, value: upperValue, position: start });\n        break;\n      default:\n        // Regular term (preserve original case)\n        this.tokens.push({ type: TokenType.TERM, value, position: start });\n        break;\n    }\n  }\n\n  private tokenizeScoreOperator(): void {\n    const start = this.position;\n    let value = this.input[this.position];\n    this.position++;\n\n    // Check for >= or <=\n    if (this.position < this.input.length && this.input[this.position] === \"=\") {\n      value += \"=\";\n      this.position++;\n    }\n\n    this.tokens.push({ type: TokenType.SCORE_OP, value, position: start });\n  }\n}\n","/**\n * FQL Parser\n * Converts tokens into an Abstract Syntax Tree (AST)\n */\n\nimport type { Token } from \"./lexer.js\";\nimport { TokenType } from \"./lexer.js\";\nimport type { FQLNode, TermNode, PhraseNode, AndNode, OrNode, NotNode, FilterNode, FieldNode, ScoreNode, LangNode } from \"./ast.js\";\n\nexport class FQLSyntaxError extends Error {\n  public position: number;\n  \n  constructor(message: string, position: number) {\n    super(message);\n    this.name = \"FQLSyntaxError\";\n    this.position = position;\n  }\n}\n\nexport class FQLParser {\n  private tokens: Token[] = [];\n  private current: number = 0;\n\n  /**\n   * Parse tokens into an AST\n   */\n  parse(tokens: Token[]): FQLNode {\n    this.tokens = tokens;\n    this.current = 0;\n\n    if (this.tokens.length === 0 || this.tokens[0].type === TokenType.EOF) {\n      throw new FQLSyntaxError(\"Empty query\", 0);\n    }\n\n    const ast = this.parseExpression();\n\n    // Ensure we consumed all tokens\n    if (!this.isAtEnd()) {\n      throw new FQLSyntaxError(`Unexpected token '${this.peek().value}' at position ${this.peek().position}`, this.peek().position);\n    }\n\n    return ast;\n  }\n\n  /**\n   * expression → or_expr\n   */\n  private parseExpression(): FQLNode {\n    return this.parseOrExpression();\n  }\n\n  /**\n   * or_expr → and_expr ( OR and_expr )*\n   */\n  private parseOrExpression(): FQLNode {\n    let left = this.parseAndExpression();\n\n    while (this.match(TokenType.OR)) {\n      const right = this.parseAndExpression();\n      left = {\n        type: \"or\",\n        left,\n        right,\n      } as OrNode;\n    }\n\n    return left;\n  }\n\n  /**\n   * and_expr → not_expr ( AND not_expr )*\n   */\n  private parseAndExpression(): FQLNode {\n    let left = this.parseNotExpression();\n\n    while (this.match(TokenType.AND)) {\n      const right = this.parseNotExpression();\n      left = {\n        type: \"and\",\n        left,\n        right,\n      } as AndNode;\n    }\n\n    return left;\n  }\n\n  /**\n   * not_expr → NOT? primary\n   */\n  private parseNotExpression(): FQLNode {\n    if (this.match(TokenType.NOT)) {\n      const child = this.parsePrimary();\n      return {\n        type: \"not\",\n        child,\n      } as NotNode;\n    }\n\n    return this.parsePrimary();\n  }\n\n  /**\n   * primary → filter | field | lang | score | term | phrase | grouped\n   */\n  private parsePrimary(): FQLNode {\n    // Grouped expression: ( expression )\n    if (this.match(TokenType.LPAREN)) {\n      const expr = this.parseExpression();\n      if (!this.match(TokenType.RPAREN)) {\n        throw new FQLSyntaxError(`Expected ')' at position ${this.peek().position}`, this.peek().position);\n      }\n      return expr;\n    }\n\n    // Filter: EXACT:value, FUZZY:value, etc.\n    if (this.check(TokenType.EXACT) || this.check(TokenType.FUZZY) || this.check(TokenType.PHONETIC) || this.check(TokenType.PREFIX) || this.check(TokenType.REGEX) || this.check(TokenType.COMPOUND)) {\n      return this.parseFilter();\n    }\n\n    // Language: LANG:german term\n    if (this.check(TokenType.LANG)) {\n      return this.parseLang();\n    }\n\n    // Quoted phrase\n    if (this.check(TokenType.QUOTED)) {\n      const token = this.advance();\n      const phrase: PhraseNode = {\n        type: \"phrase\",\n        value: token.value,\n      };\n\n      // Check for SCORE filter after phrase\n      if (this.check(TokenType.SCORE)) {\n        return this.parseScore(phrase);\n      }\n\n      return phrase;\n    }\n\n    // Term (could be field:value or just term)\n    if (this.check(TokenType.TERM)) {\n      const token = this.advance();\n\n      // Check if it's a field selector: term:expression\n      if (this.match(TokenType.COLON)) {\n        const child = this.parsePrimary();\n        const field: FieldNode = {\n          type: \"field\",\n          field: token.value,\n          child,\n        };\n        return field;\n      }\n\n      // Just a regular term\n      const term: TermNode = {\n        type: \"term\",\n        value: token.value,\n      };\n\n      // Check for SCORE filter after term\n      if (this.check(TokenType.SCORE)) {\n        return this.parseScore(term);\n      }\n\n      return term;\n    }\n\n    throw new FQLSyntaxError(`Unexpected token '${this.peek().value}' at position ${this.peek().position}`, this.peek().position);\n  }\n\n  /**\n   * filter → (EXACT|FUZZY|PHONETIC|PREFIX|REGEX|COMPOUND) COLON value\n   */\n  private parseFilter(): FQLNode {\n    const filterToken = this.advance();\n    const filterType = filterToken.value.toLowerCase() as \"exact\" | \"fuzzy\" | \"phonetic\" | \"prefix\" | \"regex\" | \"compound\";\n\n    if (!this.match(TokenType.COLON)) {\n      throw new FQLSyntaxError(`Expected ':' after ${filterToken.value} at position ${this.peek().position}`, this.peek().position);\n    }\n\n    let value: string;\n\n    if (this.check(TokenType.QUOTED)) {\n      value = this.advance().value;\n    } else if (this.check(TokenType.TERM)) {\n      value = this.advance().value;\n    } else {\n      throw new FQLSyntaxError(`Expected value after ${filterToken.value}: at position ${this.peek().position}`, this.peek().position);\n    }\n\n    const filter: FilterNode = {\n      type: \"filter\",\n      filterType,\n      value,\n    };\n\n    // Check for SCORE filter after filter\n    if (this.check(TokenType.SCORE)) {\n      return this.parseScore(filter);\n    }\n\n    return filter;\n  }\n\n  /**\n   * lang → LANG COLON TERM expression\n   */\n  private parseLang(): LangNode {\n    this.advance(); // Consume LANG\n\n    if (!this.match(TokenType.COLON)) {\n      throw new FQLSyntaxError(`Expected ':' after LANG at position ${this.peek().position}`, this.peek().position);\n    }\n\n    if (!this.check(TokenType.TERM)) {\n      throw new FQLSyntaxError(`Expected language name after LANG: at position ${this.peek().position}`, this.peek().position);\n    }\n\n    const language = this.advance().value;\n    const child = this.parsePrimary();\n\n    return {\n      type: \"lang\",\n      language,\n      child,\n    };\n  }\n\n  /**\n   * score → expression SCORE (>|<|>=|<=) NUMBER\n   */\n  private parseScore(child: FQLNode): ScoreNode {\n    this.advance(); // Consume SCORE\n\n    if (!this.check(TokenType.SCORE_OP)) {\n      throw new FQLSyntaxError(`Expected score operator (>, <, >=, <=) at position ${this.peek().position}`, this.peek().position);\n    }\n\n    const operator = this.advance().value as \">\" | \"<\" | \">=\" | \"<=\";\n\n    if (!this.check(TokenType.NUMBER)) {\n      throw new FQLSyntaxError(`Expected number after ${operator} at position ${this.peek().position}`, this.peek().position);\n    }\n\n    const threshold = parseFloat(this.advance().value);\n\n    if (isNaN(threshold) || threshold < 0 || threshold > 1) {\n      throw new FQLSyntaxError(`Score threshold must be between 0 and 1`, this.previous().position);\n    }\n\n    return {\n      type: \"score\",\n      operator,\n      threshold,\n      child,\n    };\n  }\n\n  // Helper methods\n\n  private match(...types: TokenType[]): boolean {\n    for (const type of types) {\n      if (this.check(type)) {\n        this.advance();\n        return true;\n      }\n    }\n    return false;\n  }\n\n  private check(type: TokenType): boolean {\n    if (this.isAtEnd()) return false;\n    return this.peek().type === type;\n  }\n\n  private advance(): Token {\n    if (!this.isAtEnd()) this.current++;\n    return this.previous();\n  }\n\n  private isAtEnd(): boolean {\n    return this.peek().type === TokenType.EOF;\n  }\n\n  private peek(): Token {\n    return this.tokens[this.current];\n  }\n\n  private previous(): Token {\n    return this.tokens[this.current - 1];\n  }\n}\n","/**\n * FQL Abstract Syntax Tree (AST) Node Types\n */\n\nexport type FQLNode = TermNode | PhraseNode | AndNode | OrNode | NotNode | FilterNode | FieldNode | ScoreNode | LangNode;\n\n/**\n * Simple term node\n */\nexport interface TermNode {\n  type: \"term\";\n  value: string;\n}\n\n/**\n * Quoted phrase node\n */\nexport interface PhraseNode {\n  type: \"phrase\";\n  value: string;\n}\n\n/**\n * AND operator node (intersection)\n */\nexport interface AndNode {\n  type: \"and\";\n  left: FQLNode;\n  right: FQLNode;\n}\n\n/**\n * OR operator node (union)\n */\nexport interface OrNode {\n  type: \"or\";\n  left: FQLNode;\n  right: FQLNode;\n}\n\n/**\n * NOT operator node (exclusion)\n */\nexport interface NotNode {\n  type: \"not\";\n  child: FQLNode;\n}\n\n/**\n * Match type filter node\n */\nexport interface FilterNode {\n  type: \"filter\";\n  filterType: \"exact\" | \"fuzzy\" | \"phonetic\" | \"prefix\" | \"regex\" | \"compound\";\n  value: string;\n}\n\n/**\n * Field selector node\n */\nexport interface FieldNode {\n  type: \"field\";\n  field: string;\n  child: FQLNode;\n}\n\n/**\n * Score filter node\n */\nexport interface ScoreNode {\n  type: \"score\";\n  operator: \">\" | \"<\" | \">=\" | \"<=\";\n  threshold: number;\n  child: FQLNode;\n}\n\n/**\n * Language filter node\n */\nexport interface LangNode {\n  type: \"lang\";\n  language: string;\n  child: FQLNode;\n}\n\n/**\n * Helper to check node type\n */\nexport function isTermNode(node: FQLNode): node is TermNode {\n  return node.type === \"term\";\n}\n\nexport function isPhraseNode(node: FQLNode): node is PhraseNode {\n  return node.type === \"phrase\";\n}\n\nexport function isAndNode(node: FQLNode): node is AndNode {\n  return node.type === \"and\";\n}\n\nexport function isOrNode(node: FQLNode): node is OrNode {\n  return node.type === \"or\";\n}\n\nexport function isNotNode(node: FQLNode): node is NotNode {\n  return node.type === \"not\";\n}\n\nexport function isFilterNode(node: FQLNode): node is FilterNode {\n  return node.type === \"filter\";\n}\n\nexport function isFieldNode(node: FQLNode): node is FieldNode {\n  return node.type === \"field\";\n}\n\nexport function isScoreNode(node: FQLNode): node is ScoreNode {\n  return node.type === \"score\";\n}\n\nexport function isLangNode(node: FQLNode): node is LangNode {\n  return node.type === \"lang\";\n}\n","/**\n * FQL Executor\n * Executes FQL AST against a fuzzy index\n */\n\nimport type { FuzzyIndex, SuggestionResult, SearchOptions } from \"../core/types.js\";\nimport type { FQLNode } from \"./ast.js\";\nimport { isAndNode, isOrNode, isNotNode, isTermNode, isPhraseNode, isFilterNode, isFieldNode, isScoreNode, isLangNode } from \"./ast.js\";\nimport { getSuggestions } from \"../core/index.js\";\n\nexport class FQLTimeoutError extends Error {\n  constructor(message: string) {\n    super(message);\n    this.name = \"FQLTimeoutError\";\n  }\n}\n\nexport class FQLExecutor {\n  private index: FuzzyIndex;\n  private options: SearchOptions;\n  private startTime: number = 0;\n  private timeout: number = 5000; // Default 5 seconds\n\n  constructor(index: FuzzyIndex, options: SearchOptions = {}) {\n    this.index = index;\n    this.options = options;\n    this.timeout = options.fqlOptions?.timeout || 5000;\n  }\n\n  /**\n   * Execute an FQL AST and return results\n   */\n  execute(ast: FQLNode): SuggestionResult[] {\n    this.startTime = Date.now();\n    return this.executeNode(ast);\n  }\n\n  private checkTimeout(): void {\n    if (Date.now() - this.startTime > this.timeout) {\n      throw new FQLTimeoutError(`Query execution timeout after ${this.timeout}ms`);\n    }\n  }\n\n  private executeNode(node: FQLNode): SuggestionResult[] {\n    this.checkTimeout();\n\n    if (isAndNode(node)) {\n      return this.executeAnd(node);\n    }\n\n    if (isOrNode(node)) {\n      return this.executeOr(node);\n    }\n\n    if (isNotNode(node)) {\n      return this.executeNot(node);\n    }\n\n    if (isTermNode(node)) {\n      return this.executeTerm(node.value);\n    }\n\n    if (isPhraseNode(node)) {\n      return this.executePhrase(node.value);\n    }\n\n    if (isFilterNode(node)) {\n      return this.executeFilter(node);\n    }\n\n    if (isFieldNode(node)) {\n      return this.executeField(node);\n    }\n\n    if (isScoreNode(node)) {\n      return this.executeScore(node);\n    }\n\n    if (isLangNode(node)) {\n      return this.executeLang(node);\n    }\n\n    return [];\n  }\n\n  /**\n   * Execute AND - intersection of results\n   */\n  private executeAnd(node: { left: FQLNode; right: FQLNode }): SuggestionResult[] {\n    const leftResults = this.executeNode(node.left);\n    const rightResults = this.executeNode(node.right);\n\n    // Intersection: items that appear in both\n    const rightDisplays = new Set(rightResults.map((r) => r.display));\n    const intersection = leftResults.filter((r) => rightDisplays.has(r.display));\n\n    // Sort by score\n    return intersection.sort((a, b) => b.score - a.score);\n  }\n\n  /**\n   * Execute OR - union of results\n   */\n  private executeOr(node: { left: FQLNode; right: FQLNode }): SuggestionResult[] {\n    const leftResults = this.executeNode(node.left);\n    const rightResults = this.executeNode(node.right);\n\n    // Union: combine and deduplicate\n    const resultMap = new Map<string, SuggestionResult>();\n\n    for (const result of leftResults) {\n      resultMap.set(result.display, result);\n    }\n\n    for (const result of rightResults) {\n      const existing = resultMap.get(result.display);\n      // Keep higher score\n      if (!existing || result.score > existing.score) {\n        resultMap.set(result.display, result);\n      }\n    }\n\n    // Sort by score\n    return Array.from(resultMap.values()).sort((a, b) => b.score - a.score);\n  }\n\n  /**\n   * Execute NOT - exclusion of results\n   */\n  private executeNot(node: { child: FQLNode }): SuggestionResult[] {\n    const childResults = this.executeNode(node.child);\n    const excludeDisplays = new Set(childResults.map((r) => r.display));\n\n    // Get all results and exclude\n    const allResults = getSuggestions(this.index, \"\", this.index.base.length, this.options);\n    return allResults.filter((r) => !excludeDisplays.has(r.display)).sort((a, b) => b.score - a.score);\n  }\n\n  /**\n   * Execute simple term search\n   */\n  private executeTerm(term: string): SuggestionResult[] {\n    return getSuggestions(this.index, term, this.index.base.length, this.options);\n  }\n\n  /**\n   * Execute phrase search\n   */\n  private executePhrase(phrase: string): SuggestionResult[] {\n    // Use existing phrase search with quotes\n    return getSuggestions(this.index, `\"${phrase}\"`, this.index.base.length, this.options);\n  }\n\n  /**\n   * Execute filter (EXACT, FUZZY, PHONETIC, etc.)\n   */\n  private executeFilter(node: { filterType: string; value: string }): SuggestionResult[] {\n    const { filterType, value } = node;\n\n    // Get all results for the value\n    const results = getSuggestions(this.index, value, this.index.base.length, this.options);\n\n    // Filter by match type\n    switch (filterType) {\n      case \"exact\":\n        return results.filter((r) => (r as any)._debug_matchType === \"exact\");\n\n      case \"fuzzy\":\n        return results.filter((r) => (r as any)._debug_matchType === \"fuzzy\");\n\n      case \"phonetic\":\n        return results.filter((r) => (r as any)._debug_matchType === \"phonetic\");\n\n      case \"prefix\":\n        return results.filter((r) => (r as any)._debug_matchType === \"prefix\");\n\n      case \"compound\":\n        return results.filter((r) => (r as any)._debug_matchType === \"compound\");\n\n      case \"regex\":\n        return this.executeRegex(value);\n\n      default:\n        return results;\n    }\n  }\n\n  /**\n   * Execute regex pattern\n   */\n  private executeRegex(pattern: string): SuggestionResult[] {\n    // Check if regex is allowed\n    if (!this.options.fqlOptions?.allowRegex) {\n      throw new Error(\"Regex not enabled. Set fqlOptions.allowRegex = true\");\n    }\n\n    try {\n      const regex = new RegExp(pattern);\n      const results: SuggestionResult[] = [];\n\n      for (const word of this.index.base) {\n        if (regex.test(word)) {\n          results.push({\n            display: word,\n            baseWord: word,\n            score: 1.0,\n            isSynonym: false,\n            language: \"unknown\",\n            _debug_matchType: \"regex\",\n          } as any);\n        }\n      }\n\n      return results;\n    } catch (error) {\n      throw new Error(`Invalid regex pattern: ${pattern}`);\n    }\n  }\n\n  /**\n   * Execute field selector\n   */\n  private executeField(node: { field: string; child: FQLNode }): SuggestionResult[] {\n    // Execute child query\n    const childResults = this.executeNode(node.child);\n\n    // Filter by field if multi-field index\n    if (!this.index.fieldData) {\n      // No field data, return all results\n      return childResults;\n    }\n\n    // Filter results that match the field\n    return childResults.filter((result) => {\n      if (result.field === node.field) {\n        return true;\n      }\n      return false;\n    });\n  }\n\n  /**\n   * Execute score filter\n   */\n  private executeScore(node: { operator: string; threshold: number; child: FQLNode }): SuggestionResult[] {\n    const childResults = this.executeNode(node.child);\n    const { operator, threshold } = node;\n\n    return childResults.filter((result) => {\n      switch (operator) {\n        case \">\":\n          return result.score > threshold;\n        case \"<\":\n          return result.score < threshold;\n        case \">=\":\n          return result.score >= threshold;\n        case \"<=\":\n          return result.score <= threshold;\n        default:\n          return true;\n      }\n    });\n  }\n\n  /**\n   * Execute language filter\n   */\n  private executeLang(node: { language: string; child: FQLNode }): SuggestionResult[] {\n    const childResults = this.executeNode(node.child);\n    const targetLang = node.language.toLowerCase();\n\n    return childResults.filter((result) => {\n      return result.language?.toLowerCase() === targetLang;\n    });\n  }\n}\n","/**\n * FQL (Fuzzy Query Language) - Main entry point\n */\n\nimport type { FuzzyIndex, SuggestionResult, SearchOptions } from \"../core/types.js\";\nimport { FQLLexer } from \"./lexer.js\";\nimport { FQLParser, FQLSyntaxError } from \"./parser.js\";\nimport { FQLExecutor, FQLTimeoutError } from \"./executor.js\";\n\n/**\n * Check if a query is an FQL query\n */\nexport function isFQLQuery(query: string): boolean {\n  const trimmed = query.trim();\n  return trimmed.startsWith(\"fql(\") && trimmed.endsWith(\")\");\n}\n\n/**\n * Extract FQL query from fql(...) wrapper\n */\nexport function extractFQLQuery(query: string): string {\n  const trimmed = query.trim();\n  if (!isFQLQuery(trimmed)) {\n    throw new Error(\"Not a valid FQL query. Must be wrapped in fql(...)\");\n  }\n  \n  // Remove fql( and )\n  return trimmed.slice(4, -1).trim();\n}\n\n/**\n * Execute an FQL query\n */\nexport function executeFQLQuery(\n  index: FuzzyIndex,\n  query: string,\n  maxResults?: number,\n  options: SearchOptions = {}\n): SuggestionResult[] {\n  try {\n    // Extract query from fql(...)\n    const fqlQuery = extractFQLQuery(query);\n    \n    // Lexer: tokenize\n    const lexer = new FQLLexer();\n    const tokens = lexer.tokenize(fqlQuery);\n    \n    // Parser: build AST\n    const parser = new FQLParser();\n    const ast = parser.parse(tokens);\n    \n    // Executor: run query\n    const executor = new FQLExecutor(index, options);\n    const results = executor.execute(ast);\n    \n    // Apply maxResults limit\n    const limit = maxResults || options.maxResults || 10;\n    return results.slice(0, limit);\n  } catch (error) {\n    // Re-throw FQL-specific errors\n    if (error instanceof FQLSyntaxError || error instanceof FQLTimeoutError) {\n      throw error;\n    }\n    \n    // Wrap other errors\n    throw new Error(`FQL execution error: ${(error as Error).message}`);\n  }\n}\n\n// Export all FQL components\nexport { FQLLexer } from \"./lexer.js\";\nexport { FQLParser, FQLSyntaxError } from \"./parser.js\";\nexport { FQLExecutor, FQLTimeoutError } from \"./executor.js\";\nexport type { FQLNode } from \"./ast.js\";\nexport { TokenType } from \"./lexer.js\";\n","/**\n * Alphanumeric Segmentation Utilities\n * \n * Segments strings into alphabetic and numeric parts for better fuzzy matching\n * of identifiers like \"servicehandler14568\" or \"api_manager_3254\"\n */\n\nexport type SegmentType = 'alpha' | 'numeric' | 'other';\n\nexport interface Segment {\n  /** Type of segment */\n  type: SegmentType;\n  /** The actual text content */\n  value: string;\n  /** Start position in original string */\n  start: number;\n  /** End position in original string */\n  end: number;\n}\n\n/**\n * Check if a string contains both letters and numbers\n * \n * @param str - String to check\n * @returns True if string is alphanumeric (contains both letters and numbers)\n */\nexport function isAlphanumeric(str: string): boolean {\n  const hasLetters = /[a-zA-Z]/.test(str);\n  const hasNumbers = /[0-9]/.test(str);\n  return hasLetters && hasNumbers;\n}\n\n/**\n * Segment a string into alphabetic, numeric, and other parts\n * \n * @param str - String to segment\n * @returns Array of segments\n * \n * @example\n * ```typescript\n * segmentString(\"servicehandler14568\")\n * // [\n * //   { type: 'alpha', value: 'servicehandler', start: 0, end: 14 },\n * //   { type: 'numeric', value: '14568', start: 14, end: 19 }\n * // ]\n * \n * segmentString(\"api_manager_3254\")\n * // [\n * //   { type: 'alpha', value: 'api', start: 0, end: 3 },\n * //   { type: 'other', value: '_', start: 3, end: 4 },\n * //   { type: 'alpha', value: 'manager', start: 4, end: 11 },\n * //   { type: 'other', value: '_', start: 11, end: 12 },\n * //   { type: 'numeric', value: '3254', start: 12, end: 16 }\n * // ]\n * ```\n */\nexport function segmentString(str: string): Segment[] {\n  const segments: Segment[] = [];\n  let currentType: SegmentType | null = null;\n  let currentValue = '';\n  let currentStart = 0;\n\n  for (let i = 0; i < str.length; i++) {\n    const char = str[i];\n    let charType: SegmentType;\n\n    if (/[a-zA-Z]/.test(char)) {\n      charType = 'alpha';\n    } else if (/[0-9]/.test(char)) {\n      charType = 'numeric';\n    } else {\n      charType = 'other';\n    }\n\n    if (currentType === null) {\n      // Start first segment\n      currentType = charType;\n      currentValue = char;\n      currentStart = i;\n    } else if (currentType === charType) {\n      // Continue current segment\n      currentValue += char;\n    } else {\n      // End current segment and start new one\n      segments.push({\n        type: currentType,\n        value: currentValue,\n        start: currentStart,\n        end: i,\n      });\n      currentType = charType;\n      currentValue = char;\n      currentStart = i;\n    }\n  }\n\n  // Add final segment\n  if (currentType !== null && currentValue.length > 0) {\n    segments.push({\n      type: currentType,\n      value: currentValue,\n      start: currentStart,\n      end: str.length,\n    });\n  }\n\n  return segments;\n}\n\n/**\n * Get only alphabetic segments from a string\n * \n * @param str - String to segment\n * @returns Array of alphabetic segments\n */\nexport function getAlphaSegments(str: string): Segment[] {\n  return segmentString(str).filter(s => s.type === 'alpha');\n}\n\n/**\n * Get only numeric segments from a string\n * \n * @param str - String to segment\n * @returns Array of numeric segments\n */\nexport function getNumericSegments(str: string): Segment[] {\n  return segmentString(str).filter(s => s.type === 'numeric');\n}\n\n/**\n * Extract just the alphabetic parts of a string\n * \n * @param str - String to process\n * @returns Concatenated alphabetic parts\n * \n * @example\n * ```typescript\n * extractAlphaPart(\"servicehandler14568\") // \"servicehandler\"\n * extractAlphaPart(\"api_manager_3254\") // \"apimanager\"\n * ```\n */\nexport function extractAlphaPart(str: string): string {\n  return getAlphaSegments(str).map(s => s.value).join('');\n}\n\n/**\n * Extract just the numeric parts of a string\n * \n * @param str - String to process\n * @returns Concatenated numeric parts\n * \n * @example\n * ```typescript\n * extractNumericPart(\"servicehandler14568\") // \"14568\"\n * extractNumericPart(\"api_manager_3254\") // \"3254\"\n * ```\n */\nexport function extractNumericPart(str: string): string {\n  return getNumericSegments(str).map(s => s.value).join('');\n}\n\n/**\n * Compare two strings segment by segment\n * Returns similarity scores for alpha and numeric parts separately\n * \n * @param str1 - First string\n * @param str2 - Second string\n * @returns Object with alpha and numeric similarity scores (0-1)\n */\nexport function compareSegments(\n  str1: string,\n  str2: string\n): {\n  alphaSimilarity: number;\n  numericSimilarity: number;\n  hasAlpha: boolean;\n  hasNumeric: boolean;\n} {\n  const alpha1 = extractAlphaPart(str1);\n  const alpha2 = extractAlphaPart(str2);\n  const numeric1 = extractNumericPart(str1);\n  const numeric2 = extractNumericPart(str2);\n\n  const hasAlpha = alpha1.length > 0 || alpha2.length > 0;\n  const hasNumeric = numeric1.length > 0 || numeric2.length > 0;\n\n  // Calculate alpha similarity (exact match for now, can be enhanced with edit distance)\n  let alphaSimilarity = 0;\n  if (hasAlpha) {\n    if (alpha1 === alpha2) {\n      alphaSimilarity = 1.0;\n    } else if (alpha1.length === 0 || alpha2.length === 0) {\n      alphaSimilarity = 0;\n    } else {\n      // Basic similarity based on common prefix\n      let commonLength = 0;\n      const minLen = Math.min(alpha1.length, alpha2.length);\n      for (let i = 0; i < minLen; i++) {\n        if (alpha1[i].toLowerCase() === alpha2[i].toLowerCase()) {\n          commonLength++;\n        } else {\n          break;\n        }\n      }\n      const maxLen = Math.max(alpha1.length, alpha2.length);\n      alphaSimilarity = commonLength / maxLen;\n    }\n  }\n\n  // Calculate numeric similarity\n  let numericSimilarity = 0;\n  if (hasNumeric) {\n    if (numeric1 === numeric2) {\n      numericSimilarity = 1.0;\n    } else if (numeric1.length === 0 || numeric2.length === 0) {\n      numericSimilarity = 0;\n    } else {\n      // For numbers, we're more lenient - partial match is ok\n      const longer = numeric1.length > numeric2.length ? numeric1 : numeric2;\n      const shorter = numeric1.length > numeric2.length ? numeric2 : numeric1;\n      if (longer.includes(shorter)) {\n        numericSimilarity = shorter.length / longer.length;\n      } else {\n        // Count matching digits\n        let matchingDigits = 0;\n        const minLen = Math.min(numeric1.length, numeric2.length);\n        for (let i = 0; i < minLen; i++) {\n          if (numeric1[i] === numeric2[i]) {\n            matchingDigits++;\n          }\n        }\n        numericSimilarity = matchingDigits / Math.max(numeric1.length, numeric2.length);\n      }\n    }\n  }\n\n  return {\n    alphaSimilarity,\n    numericSimilarity,\n    hasAlpha,\n    hasNumeric,\n  };\n}\n","/**\n * E-Commerce Filtering System\n * Works with multi-field search results to filter by ranges, terms, and booleans\n */\n\nimport type { SuggestionResult } from \"./types.js\";\n\n/**\n * Range filter for numeric fields\n */\nexport interface RangeFilter {\n  field: string;\n  min?: number;\n  max?: number;\n}\n\n/**\n * Term filter for categorical fields\n */\nexport interface TermFilter {\n  field: string;\n  values: any[];\n  operator?: \"AND\" | \"OR\";\n}\n\n/**\n * Boolean filter\n */\nexport interface BooleanFilter {\n  field: string;\n  value: boolean;\n}\n\n/**\n * Combined filter options\n */\nexport interface FilterOptions {\n  ranges?: RangeFilter[];\n  terms?: TermFilter[];\n  booleans?: BooleanFilter[];\n}\n\n/**\n * Apply filters to search results\n * Works with result.fields property populated by multi-field search\n */\nexport function applyFilters(results: SuggestionResult[], filters: FilterOptions): SuggestionResult[] {\n  let filtered = results;\n\n  if (filters.ranges && filters.ranges.length > 0) {\n    filtered = filtered.filter((result) => {\n      if (!result.fields) return true;\n      \n      return filters.ranges!.every((range) => {\n        const value = result.fields![range.field];\n        if (value === undefined) return true;\n        \n        const numValue = Number(value);\n        if (isNaN(numValue)) return true;\n        \n        if (range.min !== undefined && numValue < range.min) return false;\n        if (range.max !== undefined && numValue > range.max) return false;\n        \n        return true;\n      });\n    });\n  }\n\n  if (filters.terms && filters.terms.length > 0) {\n    filtered = filtered.filter((result) => {\n      if (!result.fields) return true;\n      \n      return filters.terms!.every((term) => {\n        const value = result.fields![term.field];\n        if (value === undefined) return true;\n        \n        const operator = term.operator || \"OR\";\n        \n        if (operator === \"OR\") {\n          return term.values.some((filterValue) => matchValue(value, filterValue));\n        } else {\n          // AND for array fields\n          if (Array.isArray(value)) {\n            return term.values.every((filterValue) =>\n              value.some((v) => matchValue(v, filterValue))\n            );\n          }\n          return term.values.some((filterValue) => matchValue(value, filterValue));\n        }\n      });\n    });\n  }\n\n  if (filters.booleans && filters.booleans.length > 0) {\n    filtered = filtered.filter((result) => {\n      if (!result.fields) return true;\n      \n      return filters.booleans!.every((boolFilter) => {\n        const value = result.fields![boolFilter.field];\n        if (value === undefined) return true;\n        \n        const boolValue = typeof value === \"boolean\" ? value : String(value) === \"true\" || Number(value) === 1;\n        \n        return boolValue === boolFilter.value;\n      });\n    });\n  }\n\n  return filtered;\n}\n\nfunction matchValue(value: any, filterValue: any): boolean {\n  if (value === filterValue) return true;\n  \n  if (typeof value === \"string\" && typeof filterValue === \"string\") {\n    return value.toLowerCase() === filterValue.toLowerCase();\n  }\n  \n  const numValue = Number(value);\n  const numFilterValue = Number(filterValue);\n  if (!isNaN(numValue) && !isNaN(numFilterValue)) {\n    return numValue === numFilterValue;\n  }\n  \n  return false;\n}\n","/**\n * E-Commerce Custom Sorting System\n * Works with multi-field search results to sort by any field\n */\n\nimport type { SuggestionResult } from \"./types.js\";\n\n/**\n * Sort option for a field\n */\nexport interface SortOption {\n  field: string;\n  order: \"asc\" | \"desc\";\n  type?: \"number\" | \"string\" | \"date\";\n}\n\n/**\n * Sort configuration\n */\nexport interface SortConfig {\n  primary: SortOption;\n  secondary?: SortOption;\n  keepRelevance?: boolean;\n}\n\n/**\n * Apply custom sorting to search results\n * Works with result.fields property populated by multi-field search\n */\nexport function applySorting(results: SuggestionResult[], sortConfig: SortConfig): SuggestionResult[] {\n  const sorted = [...results];\n\n  sorted.sort((a, b) => {\n    // Primary sort\n    const primaryCompare = compareResults(a, b, sortConfig.primary);\n    if (primaryCompare !== 0) return primaryCompare;\n\n    // Secondary sort\n    if (sortConfig.secondary) {\n      const secondaryCompare = compareResults(a, b, sortConfig.secondary);\n      if (secondaryCompare !== 0) return secondaryCompare;\n    }\n\n    // Final tie-breaker: relevance score\n    if (sortConfig.keepRelevance !== false) {\n      return b.score - a.score;\n    }\n\n    return 0;\n  });\n\n  return sorted;\n}\n\nfunction compareResults(a: SuggestionResult, b: SuggestionResult, sort: SortOption): number {\n  const aValue = a.fields?.[sort.field];\n  const bValue = b.fields?.[sort.field];\n\n  if (aValue === undefined && bValue === undefined) return 0;\n  if (aValue === undefined) return 1;\n  if (bValue === undefined) return -1;\n\n  const type = sort.type || detectType(aValue);\n\n  let comparison = 0;\n\n  switch (type) {\n    case \"number\":\n      comparison = compareNumbers(aValue, bValue);\n      break;\n    case \"date\":\n      comparison = compareDates(aValue, bValue);\n      break;\n    case \"string\":\n    default:\n      comparison = compareStrings(aValue, bValue);\n  }\n\n  return sort.order === \"desc\" ? -comparison : comparison;\n}\n\nfunction compareNumbers(a: any, b: any): number {\n  const numA = Number(a);\n  const numB = Number(b);\n\n  if (isNaN(numA) && isNaN(numB)) return 0;\n  if (isNaN(numA)) return 1;\n  if (isNaN(numB)) return -1;\n\n  return numA - numB;\n}\n\nfunction compareDates(a: any, b: any): number {\n  const dateA = new Date(a);\n  const dateB = new Date(b);\n\n  const timeA = dateA.getTime();\n  const timeB = dateB.getTime();\n\n  if (isNaN(timeA) && isNaN(timeB)) return 0;\n  if (isNaN(timeA)) return 1;\n  if (isNaN(timeB)) return -1;\n\n  return timeA - timeB;\n}\n\nfunction compareStrings(a: any, b: any): number {\n  return String(a).localeCompare(String(b));\n}\n\nfunction detectType(value: any): \"number\" | \"string\" | \"date\" {\n  if (typeof value === \"number\") return \"number\";\n  \n  if (typeof value === \"string\" && !isNaN(parseFloat(value)) && isFinite(Number(value))) {\n    return \"number\";\n  }\n  \n  if (value instanceof Date) return \"date\";\n  \n  if (typeof value === \"string\") {\n    const date = new Date(value);\n    if (!isNaN(date.getTime()) && /\\d{4}-\\d{2}-\\d{2}|\\d{2}\\/\\d{2}\\/\\d{4}/.test(value)) {\n      return \"date\";\n    }\n  }\n  \n  return \"string\";\n}\n","import type {\n  //\n  FuzzyIndex,\n  FuzzyConfig,\n  SuggestionResult,\n  SearchMatch,\n  BuildIndexOptions,\n  SearchOptions,\n  LanguageProcessor,\n} from \"./types.js\";\nimport {\n  //\n  mergeConfig,\n  validateConfig,\n  DEFAULT_MATCH_TYPE_SCORES,\n  DEFAULT_SCORING_MODIFIERS,\n} from \"./config.js\";\nimport {\n  //\n  LanguageRegistry,\n} from \"../languages/index.js\";\nimport {\n  //\n  calculateLevenshteinDistance,\n  calculateDamerauLevenshteinDistance,\n  calculateNgramSimilarity,\n} from \"../algorithms/levenshtein.js\";\nimport {\n  //\n  buildInvertedIndex,\n  searchInvertedIndex,\n  calculateBM25Scores,\n} from \"./inverted-index.js\";\nimport {\n  //\n  calculateHighlights,\n} from \"./highlighting.js\";\nimport {\n  //\n  SearchCache,\n} from \"./cache.js\";\nimport { removeAccents } from \"../utils/accent-normalization.js\";\nimport { extractFieldValues, normalizeFieldWeights } from \"./field-weighting.js\";\nimport { filterStopWords } from \"../utils/stop-words.js\";\nimport { matchesWord, matchesWildcard } from \"../utils/word-boundaries.js\";\nimport { parseQuery } from \"../utils/phrase-parser.js\";\nimport { matchPhrase } from \"./phrase-matching.js\";\nimport { detectLanguages, sampleTextForDetection } from \"../utils/language-detection.js\";\nimport { isFQLQuery, executeFQLQuery } from \"../fql/index.js\";\nimport { isAlphanumeric, extractAlphaPart, extractNumericPart } from \"../utils/alphanumeric-segmenter.js\";\nimport { applyFilters } from \"./filters.js\";\nimport { applySorting } from \"./sorting.js\";\n\n/**\n * Builds a fuzzy search index from an array of words or objects.\n * \n * This is the primary function for creating a searchable index. It processes each word/object\n * through language-specific processors, builds various indices (phonetic, n-gram, synonym),\n * and automatically enables optimizations like inverted index for large datasets (10k+ items).\n * \n * @param words - Array of strings to index, or objects with fields to search across\n * @param options - Configuration options for index building\n * @param options.config - Fuzzy search configuration (languages, features, thresholds)\n * @param options.languageProcessors - Custom language processors (overrides default)\n * @param options.onProgress - Callback for tracking indexing progress (processed, total)\n * @param options.useInvertedIndex - Force inverted index usage (auto-enabled for 10k+ words)\n * @param options.fields - Field names for multi-field search (required when indexing objects)\n * @param options.fieldWeights - Weight multipliers for field scoring (e.g., {title: 2.0, description: 1.0})\n * \n * @returns A searchable fuzzy index containing all processed data and metadata\n * \n * @throws {Error} If no language processors found for specified languages\n * @throws {Error} If objects are provided without specifying fields via options.fields\n * \n * @example\n * ```typescript\n * // Simple string array\n * const index = buildFuzzyIndex(['apple', 'banana', 'cherry'], {\n *   config: { languages: ['english'], performance: 'fast' }\n * });\n * \n * // Multi-field objects\n * const products = [\n *   { name: 'iPhone', description: 'Smartphone', price: 999 },\n *   { name: 'MacBook', description: 'Laptop', price: 1999 }\n * ];\n * const index = buildFuzzyIndex(products, {\n *   fields: ['name', 'description'],\n *   fieldWeights: { name: 2.0, description: 1.0 }\n * });\n * \n * // With progress tracking\n * const index = buildFuzzyIndex(largeDataset, {\n *   onProgress: (processed, total) => {\n *     console.log(`Indexing: ${(processed/total*100).toFixed(1)}%`);\n *   }\n * });\n * ```\n * \n * @see {@link getSuggestions} for searching the index\n * @see {@link BuildIndexOptions} for all configuration options\n * @see {@link FuzzyConfig} for fuzzy search settings\n */\nexport function buildFuzzyIndex(words: (string | any)[] = [], options: BuildIndexOptions = {}): FuzzyIndex {\n  // AUTO-DETECTION: Detect languages if not explicitly specified\n  const userSpecifiedLanguages = options.config?.languages;\n  const shouldAutoDetect = !userSpecifiedLanguages || userSpecifiedLanguages.includes('auto');\n  \n  const config = mergeConfig(options.config);\n  \n  if (shouldAutoDetect) {\n    const sampleText = sampleTextForDetection(words, 100);\n    const detectedLanguages = detectLanguages(sampleText);\n    config.languages = detectedLanguages;\n  }\n  \n  validateConfig(config);\n\n  // Convert features array to Set for O(1) lookup performance\n  const featureSet = new Set(config.features);\n\n  const languageProcessors = options.languageProcessors || LanguageRegistry.getProcessors(config.languages);\n\n  if (languageProcessors.length === 0) {\n    throw new Error(`No language processors found for: ${config.languages.join(\", \")}`);\n  }\n\n  // Check if we're doing multi-field search\n  const hasFields = options.fields && options.fields.length > 0;\n  const isObjectArray = words.length > 0 && typeof words[0] === \"object\" && words[0] !== null;\n\n  // Validate: if objects are provided, fields must be specified\n  if (isObjectArray && !hasFields) {\n    throw new Error(\"When indexing objects, you must specify which fields to index via options.fields\");\n  }\n\n  const index: FuzzyIndex = {\n    base: [],\n    variantToBase: new Map(),\n    phoneticToBase: new Map(),\n    ngramIndex: new Map(),\n    synonymMap: new Map(),\n    languageProcessors: new Map(),\n    config,\n  };\n\n  // Store field configuration if provided\n  if (hasFields) {\n    index.fields = options.fields;\n    index.fieldWeights = normalizeFieldWeights(options.fields!, options.fieldWeights);\n    index.fieldData = new Map();\n  }\n\n  // Store language processors\n  languageProcessors.forEach((processor) => {\n    index.languageProcessors.set(processor.language, processor);\n  });\n\n  // OPTIMIZATION 2: Decide early whether to use inverted index to avoid building redundant structures\n  // Use inverted index for large datasets (10k+) or when explicitly requested\n  const shouldUseInvertedIndex = options.useInvertedIndex || config.useInvertedIndex || config.useBM25 || config.useBloomFilter || words.length >= 10000;\n\n  const processedWords = new Set<string>();\n  let processed = 0;\n\n  // OPTIMIZATION 2: Only build hash maps if NOT using inverted index\n  // This avoids storing the same data twice in different structures\n  if (!shouldUseInvertedIndex) {\n    for (const item of words) {\n      if (!item) continue;\n\n      // Handle multi-field objects\n      if (hasFields && isObjectArray) {\n        const fieldValues = extractFieldValues(item, options.fields);\n        if (!fieldValues) continue;\n\n        // Generate a unique ID for this object (use first field value as base)\n        const baseId = Object.values(fieldValues)[0] || `item_${processed}`;\n\n        // Store field data\n        index.fieldData!.set(baseId, fieldValues);\n\n        // Index each field separately\n        for (const [fieldName, fieldValue] of Object.entries(fieldValues)) {\n          if (!fieldValue || fieldValue.trim().length < config.minQueryLength) continue;\n\n          const trimmedValue = fieldValue.trim();\n\n          // Add to base if not already there\n          if (!processedWords.has(baseId.toLowerCase())) {\n            processedWords.add(baseId.toLowerCase());\n            index.base.push(baseId);\n          }\n\n          // Process this field value with each language processor\n          for (const processor of languageProcessors) {\n            processWordWithProcessorAndField(trimmedValue, baseId, fieldName, processor, index, config, featureSet);\n          }\n        }\n      } else {\n        // Handle simple string array (backwards compatible)\n        const word = typeof item === \"string\" ? item : String(item);\n        if (word.trim().length < config.minQueryLength) continue;\n\n        const trimmedWord = word.trim();\n        if (processedWords.has(trimmedWord.toLowerCase())) continue;\n\n        processedWords.add(trimmedWord.toLowerCase());\n        index.base.push(trimmedWord);\n\n        // Process with each language processor\n        for (const processor of languageProcessors) {\n          processWordWithProcessor(trimmedWord, processor, index, config, featureSet);\n        }\n      }\n\n      processed++;\n      if (options.onProgress) {\n        options.onProgress(processed, words.length);\n      }\n    }\n  }\n\n  // INVERTED INDEX: Build for large datasets (contains all the data we need)\n  if (shouldUseInvertedIndex) {\n    const { invertedIndex, documents } = buildInvertedIndex(words, languageProcessors, config, featureSet);\n    index.invertedIndex = invertedIndex;\n    index.documents = documents;\n    \n    // Populate base array from documents for compatibility\n    index.base = documents.map(doc => doc.word);\n  }\n\n  // CACHE: Initialize search result cache if enabled (default: true)\n  const enableCache = config.enableCache !== false; // Default to true\n  if (enableCache) {\n    const cacheSize = config.cacheSize || 100;\n    index._cache = new SearchCache(cacheSize);\n  }\n\n  return index;\n}\n\n/**\n * Process a word with a specific language processor\n */\nfunction processWordWithProcessor(word: string, processor: LanguageProcessor, index: FuzzyIndex, config: FuzzyConfig, featureSet: Set<string>): void {\n  const normalized = processor.normalize(word);\n\n  // OPTIMIZATION: Store only lowercase normalized form to eliminate duplicates\n  // All case variations (apple, Apple, APPLE) map to same lowercase key\n  addToVariantMap(index.variantToBase, normalized.toLowerCase(), word);\n\n  // Add accent-insensitive variants (also normalized to lowercase)\n  const accentFreeWord = removeAccents(word);\n  if (accentFreeWord !== word) {\n    const normalizedAccentFree = processor.normalize(accentFreeWord).toLowerCase();\n    // Only add if different from the already-stored normalized form\n    if (normalizedAccentFree !== normalized.toLowerCase()) {\n      addToVariantMap(index.variantToBase, normalizedAccentFree, word);\n    }\n  }\n\n  // Generate and index variants (normalized to lowercase)\n  if (featureSet.has(\"partial-words\")) {\n    const variants = processor.getWordVariants(word, config.performance);\n    variants.forEach((variant) => {\n      addToVariantMap(index.variantToBase, variant.toLowerCase(), word);\n    });\n  }\n\n  // Generate phonetic codes\n  if (featureSet.has(\"phonetic\") && processor.supportedFeatures.includes(\"phonetic\")) {\n    const phoneticCode = processor.getPhoneticCode(word);\n    if (phoneticCode) {\n      addToVariantMap(index.phoneticToBase, phoneticCode, word);\n    }\n  }\n\n  // Generate n-grams for partial matching (normalized to lowercase)\n  // OPTIMIZATION 3: Limit n-gram generation in fast mode to reduce index size\n  const shouldLimitNgrams = config.performance === 'fast' && normalized.length > 10;\n  const ngramSource = shouldLimitNgrams ? normalized.substring(0, 15) : normalized;\n  const ngrams = generateNgrams(ngramSource.toLowerCase(), config.ngramSize);\n  ngrams.forEach((ngram: string) => {\n    addToVariantMap(index.ngramIndex, ngram, word);\n  });\n\n  // Handle compound words (normalized to lowercase)\n  if (featureSet.has(\"compound\") && processor.supportedFeatures.includes(\"compound\")) {\n    const compoundParts = processor.splitCompoundWords(word);\n    compoundParts.forEach((part) => {\n      if (part !== word) {\n        addToVariantMap(index.variantToBase, processor.normalize(part).toLowerCase(), word);\n      }\n    });\n  }\n\n  // Add synonyms (normalized to lowercase)\n  if (featureSet.has(\"synonyms\")) {\n    const synonyms = processor.getSynonyms(normalized);\n    synonyms.forEach((synonym) => {\n      addToVariantMap(index.synonymMap, synonym.toLowerCase(), word);\n    });\n\n    // Add custom synonyms\n    if (config.customSynonyms) {\n      const customSynonyms = config.customSynonyms[normalized.toLowerCase()];\n      if (customSynonyms) {\n        customSynonyms.forEach((synonym) => {\n          addToVariantMap(index.synonymMap, synonym.toLowerCase(), word);\n        });\n      }\n    }\n  }\n}\n\n/**\n * Process a word with field information for multi-field search\n */\nfunction processWordWithProcessorAndField(fieldValue: string, baseId: string, fieldName: string, processor: LanguageProcessor, index: FuzzyIndex, config: FuzzyConfig, featureSet: Set<string>): void {\n  const normalized = processor.normalize(fieldValue);\n\n  // OPTIMIZATION: Store only lowercase normalized form to eliminate duplicates\n  addToVariantMapWithField(index.variantToBase, normalized.toLowerCase(), baseId, fieldName);\n\n  // Add accent-insensitive variants (normalized to lowercase)\n  const accentFreeWord = removeAccents(fieldValue);\n  if (accentFreeWord !== fieldValue) {\n    const normalizedAccentFree = processor.normalize(accentFreeWord).toLowerCase();\n    if (normalizedAccentFree !== normalized.toLowerCase()) {\n      addToVariantMapWithField(index.variantToBase, normalizedAccentFree, baseId, fieldName);\n    }\n  }\n\n  // Generate and index variants (normalized to lowercase)\n  if (featureSet.has(\"partial-words\")) {\n    const variants = processor.getWordVariants(fieldValue, config.performance);\n    variants.forEach((variant) => {\n      addToVariantMapWithField(index.variantToBase, variant.toLowerCase(), baseId, fieldName);\n    });\n  }\n\n  // Generate phonetic codes\n  if (featureSet.has(\"phonetic\") && processor.supportedFeatures.includes(\"phonetic\")) {\n    const phoneticCode = processor.getPhoneticCode(fieldValue);\n    if (phoneticCode) {\n      addToVariantMapWithField(index.phoneticToBase, phoneticCode, baseId, fieldName);\n    }\n  }\n\n  // Generate n-grams for partial matching (normalized to lowercase)\n  // OPTIMIZATION 3: Limit n-gram generation in fast mode to reduce index size\n  const shouldLimitNgrams = config.performance === 'fast' && normalized.length > 15;\n  const ngramSource = shouldLimitNgrams ? normalized.substring(0, 15) : normalized;\n  const ngrams = generateNgrams(ngramSource.toLowerCase(), config.ngramSize);\n  ngrams.forEach((ngram: string) => {\n    addToVariantMapWithField(index.ngramIndex, ngram, baseId, fieldName);\n  });\n\n  // Handle compound words (normalized to lowercase)\n  if (featureSet.has(\"compound\") && processor.supportedFeatures.includes(\"compound\")) {\n    const parts = processor.splitCompoundWords(fieldValue);\n    parts.forEach((part) => {\n      if (part.length >= config.minQueryLength) {\n        addToVariantMapWithField(index.variantToBase, processor.normalize(part).toLowerCase(), baseId, fieldName);\n      }\n    });\n  }\n\n  // Add synonyms (normalized to lowercase)\n  if (featureSet.has(\"synonyms\")) {\n    const synonyms = processor.getSynonyms(normalized);\n    synonyms.forEach((synonym) => {\n      addToVariantMapWithField(index.synonymMap, synonym.toLowerCase(), baseId, fieldName);\n    });\n\n    // Add custom synonyms\n    if (config.customSynonyms) {\n      const customSynonyms = config.customSynonyms[normalized.toLowerCase()];\n      if (customSynonyms) {\n        customSynonyms.forEach((synonym) => {\n          addToVariantMapWithField(index.synonymMap, synonym.toLowerCase(), baseId, fieldName);\n        });\n      }\n    }\n  }\n}\n\n/**\n * Helper function to add mappings to variant maps with field information\n */\nfunction addToVariantMapWithField(map: Map<string, Set<string>>, key: string, value: string, _fieldName: string): void {\n  // For now, we'll use a simple approach: store the value with field metadata\n  // The field information will be tracked separately in the index\n  // _fieldName is prefixed with _ to indicate it's reserved for future use\n  if (!map.has(key)) {\n    map.set(key, new Set());\n  }\n  map.get(key)!.add(value);\n}\n\n/**\n * Helper function to add mappings to variant maps\n */\nfunction addToVariantMap(map: Map<string, Set<string>>, key: string, value: string): void {\n  if (!map.has(key)) {\n    map.set(key, new Set());\n  }\n  map.get(key)!.add(value);\n}\n\n/**\n * Searches multiple queries at once with automatic deduplication.\n * \n * This function efficiently processes multiple search queries by deduplicating identical\n * queries and leveraging the search cache. Perfect for batch processing or multi-field forms.\n * \n * @param index - The fuzzy search index to search against\n * @param queries - Array of search query strings\n * @param maxResults - Maximum results per query (optional, defaults to index config)\n * @param options - Search options to apply to all queries\n * \n * @returns Object mapping each unique query to its search results\n * \n * @example\n * ```typescript\n * const results = batchSearch(index, ['apple', 'banana', 'apple', 'cherry']);\n * // Returns: { apple: [...], banana: [...], cherry: [...] }\n * // Note: 'apple' only searched once despite appearing twice\n * \n * // With options\n * const results = batchSearch(index, ['app', 'ban'], 5, {\n *   includeHighlights: true,\n *   fuzzyThreshold: 0.8\n * });\n * ```\n * \n * @see {@link getSuggestions} for single query search\n */\nexport function batchSearch(index: FuzzyIndex, queries: string[], maxResults?: number, options: SearchOptions = {}): Record<string, SuggestionResult[]> {\n  const results: Record<string, SuggestionResult[]> = {};\n  const uniqueQueries = [...new Set(queries)]; // Deduplicate\n\n  for (const query of uniqueQueries) {\n    results[query] = getSuggestions(index, query, maxResults, options);\n  }\n\n  return results;\n}\n\n/**\n * Searches the index for fuzzy matches to the query string.\n * \n * This is the primary search function. It automatically selects the optimal search strategy\n * (inverted index for large datasets, hash-based for smaller ones), handles phrase search,\n * FQL queries, stop word filtering, and caching for performance.\n * \n * @param index - The fuzzy search index to search against\n * @param query - The search query string (supports phrases in quotes, FQL with fql() wrapper)\n * @param maxResults - Maximum number of results to return (optional, defaults to index config)\n * @param options - Search options to customize behavior\n * @param options.fuzzyThreshold - Override fuzzy matching threshold (0-1, higher = stricter)\n * @param options.languages - Filter to specific languages\n * @param options.matchTypes - Filter to specific match types (exact, fuzzy, phonetic, etc.)\n * @param options.debug - Include debug information in results\n * @param options.includeHighlights - Include match position highlights for UI rendering\n * @param options.enableFQL - Enable Fuzzy Query Language support (AND, OR, NOT operators)\n * \n * @returns Array of suggestion results sorted by relevance score (highest first)\n * \n * @example\n * ```typescript\n * // Basic search\n * const results = getSuggestions(index, 'hospitl', 5);\n * // Returns: [{ display: 'Hospital', score: 0.92, ... }]\n * \n * // With highlights for UI\n * const results = getSuggestions(index, 'app', 10, {\n *   includeHighlights: true\n * });\n * // Results include highlight positions for rendering\n * \n * // Phrase search\n * const results = getSuggestions(index, '\"new york\"');\n * // Finds multi-word phrases\n * \n * // FQL query\n * const results = getSuggestions(index, 'fql(doctor AND berlin)', 10, {\n *   enableFQL: true\n * });\n * \n * // With debug info\n * const results = getSuggestions(index, 'query', 5, { debug: true });\n * // Results include timing and match details\n * ```\n * \n * @see {@link buildFuzzyIndex} for creating the index\n * @see {@link batchSearch} for searching multiple queries\n */\nexport function getSuggestions(index: FuzzyIndex, query: string, maxResults?: number, options: SearchOptions = {}): SuggestionResult[] {\n  const config = index.config;\n  const limit = maxResults || options.maxResults || config.maxResults;\n  const threshold = options.fuzzyThreshold || config.fuzzyThreshold;\n\n  if (!query || query.trim().length < config.minQueryLength) {\n    return [];\n  }\n\n  // FQL: Check if FQL is enabled and query is FQL\n  if (options.enableFQL && isFQLQuery(query)) {\n    return executeFQLQuery(index, query, limit, options);\n  }\n\n  // PHRASE SEARCH: Check if query contains phrases\n  const parsedQuery = parseQuery(query);\n  \n  // If query has phrases, use phrase search\n  if (parsedQuery.hasPhrases) {\n    return searchWithPhrases(index, parsedQuery, limit, threshold, options);\n  }\n\n  // STOP WORDS: Filter stop words from query if enabled\n  let processedQuery = query;\n  if (config.enableStopWords && config.stopWords && config.stopWords.length > 0) {\n    processedQuery = filterStopWords(query, config.stopWords);\n  }\n\n  // Early return if processed query is empty after filtering\n  if (!processedQuery || processedQuery.trim().length === 0) {\n    return [];\n  }\n\n  // CACHE: Check cache first (use processed query for cache key)\n  if (index._cache) {\n    const cached = index._cache.get(processedQuery, limit, options);\n    if (cached) {\n      return cached; // Cache hit - return immediately!\n    }\n  }\n\n  // Get active language processors\n  const activeLanguages = options.languages || config.languages;\n  const processors = activeLanguages.map((lang) => index.languageProcessors.get(lang)).filter((p): p is LanguageProcessor => p !== undefined);\n\n  if (processors.length === 0) {\n    return [];\n  }\n\n  // AUTO-DETECTION: Use inverted index if available\n  if (index.invertedIndex && index.documents) {\n    const results = getSuggestionsInverted(index, processedQuery, limit, threshold, processors, options);\n    // Cache the results\n    if (index._cache) {\n      index._cache.set(processedQuery, results, limit, options);\n    }\n    return results;\n  }\n\n  // CLASSIC: Use hash-based approach (existing implementation)\n  const matches = new Map<string, SearchMatch>();\n\n  // Process query with each language processor\n  for (const processor of processors) {\n    const normalizedQuery = processor.normalize(processedQuery.trim());\n\n    // Find matches using different strategies\n    findExactMatches(normalizedQuery, index, matches, processor.language);\n    \n    // Early termination: If we found perfect exact matches and have enough results\n    const exactMatches = Array.from(matches.values()).filter(m => m.matchType === 'exact');\n    if (exactMatches.length >= limit && exactMatches.some(m => m.word === normalizedQuery)) {\n      break; // Perfect match found, no need for other strategies\n    }\n    \n    findPrefixMatches(normalizedQuery, index, matches, processor.language);\n    findSubstringMatches(normalizedQuery, index, matches, processor.language);\n    \n    // Early termination: If we have enough high-quality matches (exact + prefix + substring)\n    const highQualityMatches = Array.from(matches.values()).filter(m => \n      m.matchType === 'exact' || m.matchType === 'prefix' || m.matchType === 'substring'\n    );\n    if (highQualityMatches.length >= limit * 2) {\n      // Continue with other strategies but be more selective\n      findPhoneticMatches(normalizedQuery, processor, index, matches);\n      findSynonymMatches(normalizedQuery, index, matches);\n      \n      // Only add n-gram and fuzzy if we still need more results\n      if (matches.size < limit * 3) {\n        findNgramMatches(normalizedQuery, index, matches, processor.language, config.ngramSize);\n\n        if (config.features.includes(\"missing-letters\") || config.features.includes(\"extra-letters\") || config.features.includes(\"transpositions\")) {\n          findFuzzyMatches(normalizedQuery, index, matches, processor, config);\n        }\n      }\n    } else {\n      // Normal flow when we don't have enough matches yet\n      findPhoneticMatches(normalizedQuery, processor, index, matches);\n      findSynonymMatches(normalizedQuery, index, matches);\n      findNgramMatches(normalizedQuery, index, matches, processor.language, config.ngramSize);\n\n      if (config.features.includes(\"missing-letters\") || config.features.includes(\"extra-letters\") || config.features.includes(\"transpositions\")) {\n        findFuzzyMatches(normalizedQuery, index, matches, processor, config);\n      }\n    }\n  }\n\n  // Convert matches to results and rank them\n  let results = Array.from(matches.values())\n    .map((match) => createSuggestionResult(match, processedQuery, threshold, index, options))\n    .filter((result): result is SuggestionResult => result !== null);\n\n  // Apply filters if provided\n  if (options.filters) {\n    results = applyFilters(results, options.filters);\n  }\n\n  // Apply custom sorting if provided\n  if (options.sort) {\n    results = applySorting(results, options.sort);\n  } else {\n    // Default: sort by relevance\n    results = results.sort((a, b) => b.score - a.score);\n  }\n\n  // Limit results\n  results = results.slice(0, limit);\n\n  // Cache the results\n  if (index._cache) {\n    index._cache.set(processedQuery, results, limit, options);\n  }\n\n  return results;\n}\n\n/**\n * Find exact matches\n */\nfunction findExactMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>, language: string): void {\n  const wordBoundaries = index.config.wordBoundaries || false;\n\n  // Check for wildcard pattern\n  if (query.includes(\"*\")) {\n    // Wildcard search\n    for (const baseWord of index.base) {\n      if (matchesWildcard(baseWord, query)) {\n        if (!matches.has(baseWord)) {\n          matches.set(baseWord, {\n            word: baseWord,\n            normalized: query,\n            matchType: \"exact\",\n            editDistance: 0,\n            language,\n          });\n        }\n      }\n    }\n    return;\n  }\n\n  // Check for exact matches in the variant map (normalize to lowercase)\n  const exactMatches = index.variantToBase.get(query.toLowerCase());\n  if (exactMatches) {\n    exactMatches.forEach((word) => {\n      // With word boundaries, verify the match\n      if (wordBoundaries && !matchesWord(word, query, wordBoundaries)) {\n        return;\n      }\n\n      // Always add exact matches, even if already found with lower score\n      const existing = matches.get(word);\n      if (!existing || existing.matchType !== \"exact\") {\n        matches.set(word, {\n          word,\n          normalized: query,\n          matchType: \"exact\",\n          editDistance: 0,\n          language,\n        });\n      }\n    });\n  }\n\n  // Also check if the query exactly matches any base word (case-insensitive)\n  const queryLower = query.toLowerCase();\n  for (const baseWord of index.base) {\n    if (baseWord.toLowerCase() === queryLower) {\n      if (!matches.has(baseWord)) {\n        matches.set(baseWord, {\n          word: baseWord,\n          normalized: query,\n          matchType: \"exact\",\n          editDistance: 0,\n          language,\n        });\n      }\n    }\n  }\n}\n\n/**\n * Find prefix matches\n */\nfunction findPrefixMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>, language: string): void {\n  const wordBoundaries = index.config.wordBoundaries || false;\n  const queryLower = query.toLowerCase();\n\n  for (const [variant, words] of index.variantToBase.entries()) {\n    if (variant.startsWith(queryLower) && variant !== queryLower) {\n      words.forEach((word) => {\n        // With word boundaries, verify the match\n        if (wordBoundaries && !matchesWord(word, query, wordBoundaries)) {\n          return;\n        }\n\n        if (!matches.has(word)) {\n          matches.set(word, {\n            word,\n            normalized: variant,\n            matchType: \"prefix\",\n            language,\n          });\n        }\n      });\n    }\n  }\n}\n\n/**\n * Find substring matches (exact substring within the word)\n */\nfunction findSubstringMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>, language: string): void {\n  const queryLower = query.toLowerCase();\n  \n  // Skip very short queries to avoid too many matches\n  if (queryLower.length < 2) return;\n\n  for (const [variant, words] of index.variantToBase.entries()) {\n    // Check if query is a substring (but not prefix or exact match)\n    if (variant.includes(queryLower) && !variant.startsWith(queryLower) && variant !== queryLower) {\n      words.forEach((word) => {\n        const existingMatch = matches.get(word);\n        // Don't replace exact or prefix matches with substring matches\n        if (!existingMatch || (existingMatch.matchType !== \"exact\" && existingMatch.matchType !== \"prefix\")) {\n          matches.set(word, {\n            word,\n            normalized: variant,\n            matchType: \"substring\",\n            language,\n          });\n        }\n      });\n    }\n  }\n}\n\n/**\n * Find phonetic matches\n */\nfunction findPhoneticMatches(query: string, processor: LanguageProcessor, index: FuzzyIndex, matches: Map<string, SearchMatch>): void {\n  if (!processor.supportedFeatures.includes(\"phonetic\")) return;\n\n  const phoneticCode = processor.getPhoneticCode(query);\n  if (phoneticCode) {\n    const phoneticMatches = index.phoneticToBase.get(phoneticCode);\n    if (phoneticMatches) {\n      phoneticMatches.forEach((word) => {\n        if (!matches.has(word)) {\n          matches.set(word, {\n            word,\n            normalized: query,\n            matchType: \"phonetic\",\n            phoneticCode,\n            language: processor.language,\n          });\n        }\n      });\n    }\n  }\n}\n\n/**\n * Find synonym matches\n */\nfunction findSynonymMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>): void {\n  const synonymMatches = index.synonymMap.get(query.toLowerCase());\n  if (synonymMatches) {\n    synonymMatches.forEach((word) => {\n      if (!matches.has(word)) {\n        matches.set(word, {\n          word,\n          normalized: query,\n          matchType: \"synonym\",\n          language: \"synonym\",\n        });\n      }\n    });\n  }\n}\n\n/**\n * Find n-gram matches\n */\nfunction findNgramMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>, language: string, ngramSize: number): void {\n  if (query.length < ngramSize) return;\n\n  const queryNgrams = generateNgrams(query, ngramSize);\n  const candidateWords = new Set<string>();\n\n  queryNgrams.forEach((ngram) => {\n    const ngramMatches = index.ngramIndex.get(ngram);\n    if (ngramMatches) {\n      ngramMatches.forEach((word) => candidateWords.add(word));\n    }\n  });\n\n  candidateWords.forEach((word) => {\n    if (!matches.has(word)) {\n      matches.set(word, {\n        word,\n        normalized: query,\n        matchType: \"ngram\",\n        language,\n      });\n    }\n  });\n}\n\n/**\n * Find fuzzy matches using edit distance\n */\nfunction findFuzzyMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>, processor: LanguageProcessor, config: FuzzyConfig): void {\n  // Adaptive max distance for short queries\n  let maxDistance = config.maxEditDistance;\n  \n  // For very short queries (3-4 chars), be more lenient\n  if (query.length <= 3) {\n    maxDistance = Math.max(maxDistance, 2);\n  } else if (query.length <= 4) {\n    maxDistance = Math.max(maxDistance, 2);\n  }\n\n  for (const [variant, words] of index.variantToBase.entries()) {\n    // Improved length check for short queries - be more lenient\n    const lengthDiff = Math.abs(variant.length - query.length);\n    const maxLengthDiff = query.length <= 3 ? 5 : (query.length <= 4 ? 4 : maxDistance);\n    \n    if (lengthDiff <= maxLengthDiff) {\n      // Use Damerau-Levenshtein if transpositions feature is enabled\n      const useTranspositions = index.config.features?.includes(\"transpositions\");\n      const distance = useTranspositions ? calculateDamerauLevenshteinDistance(query, variant, maxDistance) : calculateLevenshteinDistance(query, variant, maxDistance);\n\n      // Adaptive distance threshold for short queries\n      const distanceThreshold = query.length <= 3 ? 2 : maxDistance;\n      \n      if (distance <= distanceThreshold) {\n        words.forEach((word) => {\n          const existingMatch = matches.get(word);\n          // Don't replace exact or prefix matches with fuzzy matches\n          if (!existingMatch || (existingMatch.matchType !== \"exact\" && existingMatch.matchType !== \"prefix\" && (existingMatch.editDistance || Infinity) > distance)) {\n            matches.set(word, {\n              word,\n              normalized: variant,\n              matchType: \"fuzzy\",\n              editDistance: distance,\n              language: processor.language,\n            });\n          }\n        });\n      }\n    }\n  }\n}\n\n/**\n * Create a suggestion result from a search match\n */\nfunction createSuggestionResult(match: SearchMatch, originalQuery: string, threshold: number, index: FuzzyIndex, options?: SearchOptions): SuggestionResult | null {\n  let score = calculateMatchScore(match, originalQuery, index.config);\n\n  // Combine with BM25 score if available\n  if (match.bm25Score !== undefined && index.config.useBM25) {\n    const bm25Weight = index.config.bm25Weight || 0.6;\n    const fuzzyWeight = 1 - bm25Weight;\n    score = bm25Weight * match.bm25Score + fuzzyWeight * score;\n  }\n\n  // Apply field weight if present\n  if (match.fieldWeight) {\n    score = Math.min(1.0, score * match.fieldWeight);\n  }\n\n  if (score < threshold) {\n    return null;\n  }\n\n  const result: SuggestionResult = {\n    display: match.word,\n    baseWord: match.word,\n    isSynonym: match.matchType === \"synonym\",\n    score,\n    language: match.language,\n    // @ts-ignore - temporary debug property\n    _debug_matchType: match.matchType,\n  };\n\n  // Add field information if this is a multi-field search\n  if (index.fieldData && index.fieldData.has(match.word)) {\n    result.fields = index.fieldData.get(match.word);\n    result.field = match.field;\n  }\n\n  // Add highlights if requested\n  if (options?.includeHighlights) {\n    result.highlights = calculateHighlights(match, originalQuery, match.word);\n  }\n\n  return result;\n}\n\n/**\n * Calculate match score (0-1, higher is better)\n */\nfunction calculateMatchScore(\n  //\n  match: SearchMatch,\n  query: string,\n  config?: FuzzyConfig\n): number {\n  // Get scoring configuration with defaults - merge with defaults to ensure all values are present\n  const scores = {\n    ...DEFAULT_MATCH_TYPE_SCORES,\n    ...(config?.matchTypeScores || {}),\n  };\n  const modifiers = {\n    ...DEFAULT_SCORING_MODIFIERS,\n    ...(config?.scoringModifiers || {}),\n  };\n  \n  const queryLen = query.length;\n  const wordLen = match.word.length;\n  const maxLen = Math.max(queryLen, wordLen);\n\n  let score = modifiers.baseScore;\n\n  switch (match.matchType) {\n    case \"exact\":\n      score = scores.exact;\n      break;\n    case \"prefix\":\n      score = scores.prefix;\n      // Apply length penalty if enabled\n      if (modifiers.prefixLengthPenalty) {\n        score -= (wordLen - queryLen) / (maxLen * 2);\n      }\n      break;\n    case \"substring\":\n      score = scores.substring;\n      // Boost substring matches that appear earlier in the word\n      const substringPos = match.normalized.toLowerCase().indexOf(query.toLowerCase());\n      if (substringPos !== -1) {\n        // Earlier positions get a small boost (up to +0.1)\n        const positionBoost = Math.max(0, 0.1 * (1 - substringPos / match.normalized.length));\n        score += positionBoost;\n      }\n      break;\n    case \"phonetic\":\n      score = scores.phonetic;\n      break;\n    case \"fuzzy\":\n      if (match.editDistance !== undefined) {\n        // Use segment-aware scoring for alphanumeric strings if enabled\n        if (config?.enableAlphanumericSegmentation && isAlphanumeric(query) && isAlphanumeric(match.word)) {\n          score = calculateAlphanumericScore(query, match.word, config);\n        } else {\n          // Simple linear penalty for edit distance\n          score = Math.max(scores.fuzzyMin, scores.fuzzy - (match.editDistance / maxLen) * 0.3);\n        }\n      }\n      break;\n    case \"synonym\":\n      score = scores.synonym;\n      break;\n    case \"compound\":\n      score = scores.compound;\n      break;\n    case \"ngram\":\n      score = calculateNgramSimilarity(query.toLowerCase(), match.normalized, 3) * scores.ngram;\n      break;\n  }\n\n  // Apply short word boost if configured\n  // Boost words that are close in length to the query (prefer concise matches)\n  // Don't boost exact matches (already at 1.0) or words much longer than query\n  if (wordLen <= queryLen + modifiers.shortWordMaxDiff && match.matchType !== \"exact\") {\n    score += modifiers.shortWordBoost;\n  }\n\n  // Exact matches should use the configured score, defaulting to 1.0\n  if (match.matchType === \"exact\") {\n    return Math.min(1.0, Math.max(0.0, scores.exact)); // Clamp to [0, 1] range\n  }\n\n  return Math.min(1.0, Math.max(0.0, score));\n}\n\n/**\n * Calculate score for alphanumeric strings using segment-aware matching\n * Prioritizes alphabetic accuracy over numeric accuracy\n */\nfunction calculateAlphanumericScore(\n  query: string,\n  target: string,\n  config: FuzzyConfig\n): number {\n  // Extract alphabetic and numeric parts\n  const queryAlpha = extractAlphaPart(query).toLowerCase();\n  const targetAlpha = extractAlphaPart(target).toLowerCase();\n  const queryNumeric = extractNumericPart(query);\n  const targetNumeric = extractNumericPart(target);\n\n  const alphaWeight = config.alphanumericAlphaWeight || 0.7;\n  const numericWeight = config.alphanumericNumericWeight || 0.3;\n\n  let alphaScore = 0;\n  let numericScore = 0;\n\n  // Calculate alphabetic score\n  if (queryAlpha.length > 0 && targetAlpha.length > 0) {\n    const alphaMaxLen = Math.max(queryAlpha.length, targetAlpha.length);\n    const alphaDistance = calculateLevenshteinDistance(queryAlpha, targetAlpha, config.maxEditDistance);\n    alphaScore = Math.max(0, 1.0 - alphaDistance / alphaMaxLen);\n  } else if (queryAlpha.length === 0 && targetAlpha.length === 0) {\n    alphaScore = 1.0; // Both have no alpha parts\n  }\n\n  // Calculate numeric score (more lenient)\n  if (queryNumeric.length > 0 && targetNumeric.length > 0) {\n    if (queryNumeric === targetNumeric) {\n      numericScore = 1.0;\n    } else {\n      // Check if one contains the other\n      if (targetNumeric.includes(queryNumeric) || queryNumeric.includes(targetNumeric)) {\n        const shorter = queryNumeric.length < targetNumeric.length ? queryNumeric : targetNumeric;\n        const longer = queryNumeric.length < targetNumeric.length ? targetNumeric : queryNumeric;\n        numericScore = shorter.length / longer.length;\n      } else {\n        // Use edit distance with multiplier (more lenient for numbers)\n        const numericMaxLen = Math.max(queryNumeric.length, targetNumeric.length);\n        const multiplier = config.alphanumericNumericEditDistanceMultiplier || 1.5;\n        const numericDistance = calculateLevenshteinDistance(queryNumeric, targetNumeric, Math.ceil(config.maxEditDistance * multiplier));\n        numericScore = Math.max(0, 1.0 - numericDistance / numericMaxLen);\n      }\n    }\n  } else if (queryNumeric.length === 0 && targetNumeric.length === 0) {\n    numericScore = 1.0; // Both have no numeric parts\n  } else {\n    // One has numbers, one doesn't - partial penalty\n    numericScore = 0.3;\n  }\n\n  // Weighted combination\n  const combinedScore = alphaScore * alphaWeight + numericScore * numericWeight;\n\n  // Ensure minimum score of 0.3 for fuzzy matches\n  return Math.max(0.3, combinedScore);\n}\n\n/**\n * Generate n-grams from a string\n */\nfunction generateNgrams(\n  //\n  str: string,\n  n: number\n): string[] {\n  if (str.length < n) return [str];\n\n  const ngrams: string[] = [];\n  for (let i = 0; i <= str.length - n; i++) {\n    ngrams.push(str.slice(i, i + n));\n  }\n  return ngrams;\n}\n\n/**\n * Get suggestions using inverted index (for large datasets)\n * This is a wrapper that converts inverted index results to the same format\n */\nfunction getSuggestionsInverted(\n  //\n  index: FuzzyIndex,\n  query: string,\n  limit: number,\n  threshold: number,\n  processors: LanguageProcessor[],\n  options?: SearchOptions\n): SuggestionResult[] {\n  if (!index.invertedIndex || !index.documents) {\n    throw new Error(\"Inverted index not available\");\n  }\n\n  // Use inverted index search\n  let matches = searchInvertedIndex(index.invertedIndex, index.documents, query, processors, index.config);\n\n  // Calculate BM25 scores if enabled\n  if (index.config.useBM25) {\n    const queryTerms = query.toLowerCase().split(/\\s+/).filter(t => t.length > 0);\n    matches = calculateBM25Scores(matches, queryTerms, index.invertedIndex, index.documents, index.config);\n  }\n\n  // Convert to suggestion results (same as classic approach)\n  let results = matches\n    .map((match) => createSuggestionResult(match, query, threshold, index, options))\n    .filter((result): result is SuggestionResult => result !== null);\n\n  // Apply filters if provided\n  if (options?.filters) {\n    results = applyFilters(results, options.filters);\n  }\n\n  // Apply custom sorting if provided\n  if (options?.sort) {\n    results = applySorting(results, options.sort);\n  } else {\n    // Default: sort by relevance\n    results = results.sort((a, b) => b.score - a.score);\n  }\n\n  // Limit results\n  results = results.slice(0, limit);\n\n  return results;\n}\n\n/**\n * Search with phrase support\n * Handles queries containing quoted phrases\n */\nfunction searchWithPhrases(\n  index: FuzzyIndex,\n  parsedQuery: ReturnType<typeof parseQuery>,\n  limit: number,\n  threshold: number,\n  options: SearchOptions\n): SuggestionResult[] {\n  const config = index.config;\n  const useTranspositions = config.features.includes('transpositions');\n  \n  // Get phrase match options\n  const phraseOptions = {\n    exactMatch: false,\n    maxEditDistance: 1,\n    proximityBonus: 1.5,\n    maxProximityDistance: 3,\n    useTranspositions,\n  };\n\n  // Search all base words for phrase matches\n  const phraseMatches = new Map<string, { score: number; phraseCount: number }>();\n\n  // For each phrase, find matching words\n  for (const phrase of parsedQuery.phrases) {\n    for (const word of index.base) {\n      const match = matchPhrase(word, phrase, phraseOptions);\n      \n      if (match.matched) {\n        const existing = phraseMatches.get(word);\n        const newScore = match.score * phraseOptions.proximityBonus;\n        \n        if (existing) {\n          // Multiple phrases matched - boost even more\n          phraseMatches.set(word, {\n            score: Math.max(existing.score, newScore),\n            phraseCount: existing.phraseCount + 1,\n          });\n        } else {\n          phraseMatches.set(word, { score: newScore, phraseCount: 1 });\n        }\n      }\n    }\n  }\n\n  // If we have regular terms too, search for them\n  let termMatches = new Map<string, SearchMatch>();\n  \n  if (parsedQuery.terms.length > 0) {\n    const termQuery = parsedQuery.terms.join(' ');\n    const processors = config.languages\n      .map((lang) => index.languageProcessors.get(lang))\n      .filter((p): p is LanguageProcessor => p !== undefined);\n\n    for (const processor of processors) {\n      const normalizedQuery = processor.normalize(termQuery);\n      \n      // Use existing search strategies for terms\n      findExactMatches(normalizedQuery, index, termMatches, processor.language);\n      findPrefixMatches(normalizedQuery, index, termMatches, processor.language);\n      findPhoneticMatches(normalizedQuery, processor, index, termMatches);\n      findNgramMatches(normalizedQuery, index, termMatches, processor.language, config.ngramSize);\n      \n      if (config.features.includes(\"missing-letters\") || config.features.includes(\"extra-letters\") || config.features.includes(\"transpositions\")) {\n        findFuzzyMatches(normalizedQuery, index, termMatches, processor, config);\n      }\n    }\n  }\n\n  // Combine phrase and term matches\n  const combinedResults = new Map<string, SuggestionResult>();\n\n  // Add phrase matches\n  for (const [word, phraseData] of phraseMatches.entries()) {\n    const result: SuggestionResult = {\n      display: word,\n      baseWord: word,\n      isSynonym: false,\n      score: phraseData.score,\n    };\n    \n    // If word also matched terms, boost score even more\n    const termMatch = termMatches.get(word);\n    if (termMatch) {\n      result.score = Math.min(1.0, result.score * 1.2);\n    }\n    \n    combinedResults.set(word, result);\n  }\n\n  // Add term matches that didn't match phrases (with lower priority)\n  for (const [word, match] of termMatches.entries()) {\n    if (!combinedResults.has(word)) {\n      const result = createSuggestionResult(match, parsedQuery.terms.join(' '), threshold, index, options);\n      if (result) {\n        // Reduce score slightly since it didn't match the phrase\n        result.score *= 0.8;\n        combinedResults.set(word, result);\n      }\n    }\n  }\n\n  // Sort and limit results\n  const results = Array.from(combinedResults.values())\n    .filter(r => r.score >= threshold)\n    .sort((a, b) => b.score - a.score)\n    .slice(0, limit);\n\n  // Cache the results\n  if (index._cache) {\n    index._cache.set(parsedQuery.original, results, limit, options);\n  }\n\n  return results;\n}\n\n/**\n * Update an existing index by adding new items\n * Much faster than rebuilding the entire index\n * \n * @param index - Existing fuzzy index to update\n * @param newItems - New items to add (strings or objects)\n * @param options - Optional configuration (uses index's existing config by default)\n * @returns Updated index (mutates the original)\n * \n * @example\n * const index = buildFuzzyIndex(['apple', 'banana']);\n * updateIndex(index, ['cherry', 'date']);\n * // Index now contains: apple, banana, cherry, date\n */\nexport function updateIndex(\n  index: FuzzyIndex,\n  newItems: (string | any)[] = [],\n  options: Partial<BuildIndexOptions> = {}\n): FuzzyIndex {\n  if (!index || !index.config) {\n    throw new Error('Invalid index provided');\n  }\n\n  if (!newItems || newItems.length === 0) {\n    return index;\n  }\n\n  // Use existing index configuration\n  const config = index.config;\n  const featureSet = new Set(config.features);\n  \n  // Get language processors from index\n  const languageProcessors = Array.from(index.languageProcessors.values());\n  \n  if (languageProcessors.length === 0) {\n    throw new Error('No language processors found in index');\n  }\n\n  // Check if we're doing multi-field search\n  const hasFields = index.fields && index.fields.length > 0;\n  const isObjectArray = newItems.length > 0 && typeof newItems[0] === 'object' && newItems[0] !== null;\n\n  // Validate: if objects are provided, fields must be specified\n  if (isObjectArray && !hasFields) {\n    throw new Error('Index was not built with fields, cannot add objects');\n  }\n\n  // Track existing words to avoid duplicates\n  const existingWords = new Set(index.base.map(w => w.toLowerCase()));\n  let processed = 0;\n\n  for (const item of newItems) {\n    if (!item) continue;\n\n    // Handle multi-field objects\n    if (hasFields && isObjectArray) {\n      const fieldValues = extractFieldValues(item, index.fields);\n      if (!fieldValues) continue;\n\n      // Generate a unique ID for this object\n      const baseId = Object.values(fieldValues)[0] || `item_${index.base.length + processed}`;\n\n      // Skip if already exists\n      if (existingWords.has(baseId.toLowerCase())) continue;\n\n      // Store field data\n      if (index.fieldData) {\n        index.fieldData.set(baseId, fieldValues);\n      }\n\n      // Add to base\n      existingWords.add(baseId.toLowerCase());\n      index.base.push(baseId);\n\n      // Index each field separately\n      for (const [fieldName, fieldValue] of Object.entries(fieldValues)) {\n        if (!fieldValue || fieldValue.trim().length < config.minQueryLength) continue;\n\n        const trimmedValue = fieldValue.trim();\n\n        // Process this field value with each language processor\n        for (const processor of languageProcessors) {\n          processWordWithProcessorAndField(trimmedValue, baseId, fieldName, processor, index, config, featureSet);\n        }\n      }\n    } else {\n      // Handle simple string array\n      const word = typeof item === 'string' ? item : String(item);\n      if (word.trim().length < config.minQueryLength) continue;\n\n      const trimmedWord = word.trim();\n      \n      // Skip if already exists\n      if (existingWords.has(trimmedWord.toLowerCase())) continue;\n\n      existingWords.add(trimmedWord.toLowerCase());\n      index.base.push(trimmedWord);\n\n      // Process with each language processor\n      for (const processor of languageProcessors) {\n        processWordWithProcessor(trimmedWord, processor, index, config, featureSet);\n      }\n    }\n\n    processed++;\n    if (options.onProgress) {\n      options.onProgress(processed, newItems.length);\n    }\n  }\n\n  // Update inverted index if it exists\n  if (index.invertedIndex && index.documents) {\n    const { invertedIndex, documents } = buildInvertedIndex(\n      index.base,\n      languageProcessors,\n      config,\n      featureSet\n    );\n    index.invertedIndex = invertedIndex;\n    index.documents = documents;\n  }\n\n  // Clear cache since index has changed\n  if (index._cache) {\n    index._cache.clear();\n  }\n\n  return index;\n}\n\n/**\n * Remove items from an existing index\n * \n * @param index - Existing fuzzy index to update\n * @param itemsToRemove - Items to remove (exact matches)\n * @returns Updated index (mutates the original)\n * \n * @example\n * const index = buildFuzzyIndex(['apple', 'banana', 'cherry']);\n * removeFromIndex(index, ['banana']);\n * // Index now contains: apple, cherry\n */\nexport function removeFromIndex(\n  index: FuzzyIndex,\n  itemsToRemove: string[] = []\n): FuzzyIndex {\n  if (!index || !index.config) {\n    throw new Error('Invalid index provided');\n  }\n\n  if (!itemsToRemove || itemsToRemove.length === 0) {\n    return index;\n  }\n\n  // Create set of items to remove (case-insensitive)\n  const toRemove = new Set(itemsToRemove.map(item => item.toLowerCase()));\n\n  // Remove from base array\n  index.base = index.base.filter(word => !toRemove.has(word.toLowerCase()));\n\n  // Remove from variant maps\n  for (const [variant, baseWords] of index.variantToBase.entries()) {\n    const filtered = new Set(Array.from(baseWords).filter((word: string) => !toRemove.has(word.toLowerCase())));\n    if (filtered.size === 0) {\n      index.variantToBase.delete(variant);\n    } else {\n      index.variantToBase.set(variant, filtered);\n    }\n  }\n\n  // Remove from phonetic map\n  for (const [phonetic, baseWords] of index.phoneticToBase.entries()) {\n    const filtered = new Set(Array.from(baseWords).filter((word: string) => !toRemove.has(word.toLowerCase())));\n    if (filtered.size === 0) {\n      index.phoneticToBase.delete(phonetic);\n    } else {\n      index.phoneticToBase.set(phonetic, filtered);\n    }\n  }\n\n  // Remove from ngram index\n  for (const [ngram, baseWords] of index.ngramIndex.entries()) {\n    const filtered = new Set(Array.from(baseWords).filter((word: string) => !toRemove.has(word.toLowerCase())));\n    if (filtered.size === 0) {\n      index.ngramIndex.delete(ngram);\n    } else {\n      index.ngramIndex.set(ngram, filtered);\n    }\n  }\n\n  // Remove from synonym map\n  for (const [synonym, baseWords] of index.synonymMap.entries()) {\n    const filtered = new Set(Array.from(baseWords).filter((word: string) => !toRemove.has(word.toLowerCase())));\n    if (filtered.size === 0) {\n      index.synonymMap.delete(synonym);\n    } else {\n      index.synonymMap.set(synonym, filtered);\n    }\n  }\n\n  // Remove from field data if exists\n  if (index.fieldData) {\n    for (const item of itemsToRemove) {\n      index.fieldData.delete(item);\n    }\n  }\n\n  // Rebuild inverted index if it exists\n  if (index.invertedIndex && index.documents) {\n    const config = index.config;\n    const featureSet = new Set(config.features);\n    const languageProcessors = Array.from(index.languageProcessors.values());\n    \n    const { invertedIndex, documents } = buildInvertedIndex(\n      index.base,\n      languageProcessors,\n      config,\n      featureSet\n    );\n    index.invertedIndex = invertedIndex;\n    index.documents = documents;\n  }\n\n  // Clear cache since index has changed\n  if (index._cache) {\n    index._cache.clear();\n  }\n\n  return index;\n}\n","/**\n * Index Serialization\n * Save and load fuzzy search indices for 100x faster startup\n */\n\nimport type { FuzzyIndex } from \"./types.js\";\nimport { SearchCache } from \"./cache.js\";\n\n/**\n * Serializable index format (JSON-compatible)\n */\ninterface SerializedIndex {\n  version: string;\n  base: string[];\n  variantToBase: [string, string[]][];\n  phoneticToBase: [string, string[]][];\n  ngramIndex: [string, string[]][];\n  synonymMap: [string, string[]][];\n  config: any;\n  languageProcessorNames: string[];\n  invertedIndex?: any;\n  documents?: any[];\n}\n\n/**\n * Serialize a FuzzyIndex to JSON string\n */\nexport function serializeIndex(index: FuzzyIndex): string {\n  const serialized: SerializedIndex = {\n    version: \"1.0\",\n    base: index.base,\n    variantToBase: Array.from(index.variantToBase.entries()).map(([k, v]) => [k, Array.from(v)]),\n    phoneticToBase: Array.from(index.phoneticToBase.entries()).map(([k, v]) => [k, Array.from(v)]),\n    ngramIndex: Array.from(index.ngramIndex.entries()).map(([k, v]) => [k, Array.from(v)]),\n    synonymMap: Array.from(index.synonymMap.entries()).map(([k, v]) => [k, Array.from(v)]),\n    config: index.config,\n    languageProcessorNames: Array.from(index.languageProcessors.keys()),\n  };\n\n  // Serialize inverted index if present\n  if (index.invertedIndex) {\n    serialized.invertedIndex = {\n      termToPostings: Array.from(index.invertedIndex.termToPostings.entries()),\n      phoneticToPostings: Array.from(index.invertedIndex.phoneticToPostings.entries()),\n      ngramToPostings: Array.from(index.invertedIndex.ngramToPostings.entries()),\n      synonymToPostings: Array.from(index.invertedIndex.synonymToPostings.entries()),\n      totalDocs: index.invertedIndex.totalDocs,\n      avgDocLength: index.invertedIndex.avgDocLength,\n    };\n  }\n\n  // Serialize documents if present\n  if (index.documents) {\n    serialized.documents = index.documents;\n  }\n\n  return JSON.stringify(serialized);\n}\n\n/**\n * Deserialize a FuzzyIndex from JSON string\n */\nexport async function deserializeIndex(json: string): Promise<FuzzyIndex> {\n  const data: SerializedIndex = JSON.parse(json);\n\n  // Reconstruct Maps from arrays\n  const variantToBase = new Map(data.variantToBase.map(([k, v]) => [k, new Set(v)]));\n  const phoneticToBase = new Map(data.phoneticToBase.map(([k, v]) => [k, new Set(v)]));\n  const ngramIndex = new Map(data.ngramIndex.map(([k, v]) => [k, new Set(v)]));\n  const synonymMap = new Map(data.synonymMap.map(([k, v]) => [k, new Set(v)]));\n\n  // Reconstruct language processors (need to import them)\n  const { LanguageRegistry } = await import(\"../languages/index.js\");\n  const languageProcessors = new Map();\n  for (const langName of data.languageProcessorNames) {\n    const processor = LanguageRegistry.getProcessor(langName);\n    if (processor) {\n      languageProcessors.set(langName, processor);\n    }\n  }\n\n  const index: FuzzyIndex = {\n    base: data.base,\n    variantToBase,\n    phoneticToBase,\n    ngramIndex,\n    synonymMap,\n    languageProcessors,\n    config: data.config,\n  };\n\n  // Reconstruct inverted index if present\n  if (data.invertedIndex) {\n    index.invertedIndex = {\n      termToPostings: new Map(data.invertedIndex.termToPostings),\n      phoneticToPostings: new Map(data.invertedIndex.phoneticToPostings),\n      ngramToPostings: new Map(data.invertedIndex.ngramToPostings),\n      synonymToPostings: new Map(data.invertedIndex.synonymToPostings),\n      totalDocs: data.invertedIndex.totalDocs,\n      avgDocLength: data.invertedIndex.avgDocLength,\n    };\n  }\n\n  // Reconstruct documents if present\n  if (data.documents) {\n    index.documents = data.documents;\n  }\n\n  // Reconstruct cache if enabled in config\n  if (data.config.enableCache !== false) {\n    const cacheSize = data.config.cacheSize || 100;\n    index._cache = new SearchCache(cacheSize);\n  }\n\n  return index;\n}\n\n/**\n * Save index to localStorage (browser)\n */\nexport function saveIndexToLocalStorage(index: FuzzyIndex, key: string = \"fuzzy-search-index\"): void {\n  if (typeof localStorage === \"undefined\") {\n    throw new Error(\"localStorage is not available\");\n  }\n  const serialized = serializeIndex(index);\n  localStorage.setItem(key, serialized);\n}\n\n/**\n * Load index from localStorage (browser)\n */\nexport async function loadIndexFromLocalStorage(key: string = \"fuzzy-search-index\"): Promise<FuzzyIndex | null> {\n  if (typeof localStorage === \"undefined\") {\n    throw new Error(\"localStorage is not available\");\n  }\n  const serialized = localStorage.getItem(key);\n  if (!serialized) {\n    return null;\n  }\n  return await deserializeIndex(serialized);\n}\n\n/**\n * Get serialized index size in bytes\n */\nexport function getSerializedSize(index: FuzzyIndex): number {\n  const serialized = serializeIndex(index);\n  return new Blob([serialized]).size;\n}\n","/**\n * Data Indexer Utility\n * Extract unique words from various data formats for fuzzy search indexing\n */\n\nimport { tokenize } from \"./tokenizer.js\";\n\nexport interface DataToIndexOptions {\n  /** Minimum word length to include (default: 2) */\n  minLength?: number;\n  /** Split text into words (default: true) */\n  splitWords?: boolean;\n  /** Remove stop words (default: false) */\n  stopWords?: string[] | false;\n  /** Overlap between chunks in characters (default: 0) */\n  overlap?: number;\n  /** Size of each chunk in characters (default: 0 = no chunking) */\n  chunkSize?: number;\n  /** Split strategy for chunking (default: 'word') */\n  splitOn?: \"word\" | \"sentence\" | \"paragraph\";\n  /** Data format (default: 'string') */\n  format?: \"string\" | \"html\" | \"json\" | \"base64\" | \"url\";\n  /** Remove numbers (default: false) */\n  removeNumbers?: boolean;\n  /** Case sensitive (default: false) */\n  caseSensitive?: boolean;\n}\n\n/**\n * Extract unique words from various data formats\n * Returns an array of unique words that can be used as a dictionary for fuzzy search\n *\n * @param content - The content to extract words from\n * @param options - Configuration options\n * @returns Array of unique words (no duplicates)\n *\n * @example\n * // Simple text\n * const words = dataToIndex(\"Hello world! Hello again.\");\n * // → ['hello', 'world', 'again']\n *\n * @example\n * // HTML content\n * const words = dataToIndex(\"<h1>Title</h1><p>Content here</p>\", { format: 'html' });\n * // → ['title', 'content', 'here']\n *\n * @example\n * // JSON data\n * const data = [{ name: \"John\", city: \"NYC\" }, { name: \"Jane\", city: \"LA\" }];\n * const words = dataToIndex(JSON.stringify(data), { format: 'json' });\n * // → ['john', 'nyc', 'jane', 'la']\n */\nexport function dataToIndex(\n  //\n  content: string,\n  options: DataToIndexOptions = {}\n): string[] {\n  const {\n    //\n    minLength = 2,\n    splitWords = true,\n    stopWords = false,\n    overlap = 0,\n    chunkSize = 0,\n    splitOn = \"word\",\n    format = \"string\",\n    removeNumbers = false,\n    caseSensitive = false,\n  } = options;\n\n  let text = content;\n\n  // Step 1: Handle different formats\n  switch (format) {\n    case \"base64\":\n      try {\n        text = atob(content);\n      } catch (e) {\n        console.error(\"Failed to decode base64:\", e);\n        return [];\n      }\n      break;\n\n    case \"html\":\n      text = stripHTML(content);\n      break;\n\n    case \"json\":\n      text = extractFromJSON(content);\n      break;\n\n    case \"url\":\n      // URL format requires async, so we'll throw an error\n      throw new Error(\"URL format requires async. Use dataToIndexAsync() instead.\");\n\n    case \"string\":\n    default:\n      // Already a string, no conversion needed\n      break;\n  }\n\n  // Step 2: Apply chunking if specified\n  if (chunkSize > 0) {\n    const chunks = chunkText(text, chunkSize, overlap, splitOn);\n    text = chunks.join(\" \");\n  }\n\n  // Step 3: Extract words\n  let words: string[] = [];\n\n  if (splitWords) {\n    // Use centralized tokenizer for consistent word boundary handling\n    words = tokenize(text, { keepEmpty: false });\n  } else {\n    words = [text];\n  }\n\n  // Step 4: Clean and filter words\n  words = words\n    .map((word) => {\n      // Remove leading/trailing punctuation (but preserve unicode letters)\n      word = word.replace(/^[^\\p{L}\\p{N}]+|[^\\p{L}\\p{N}]+$/gu, \"\");\n\n      // Convert case\n      if (!caseSensitive) {\n        word = word.toLowerCase();\n      }\n\n      return word;\n    })\n    .filter((word) => {\n      // Filter by minimum length\n      if (word.length < minLength) return false;\n\n      // Filter numbers if requested\n      if (removeNumbers && /^\\d+$/.test(word)) return false;\n\n      return true;\n    });\n\n  // Step 5: Remove stop words if specified\n  if (stopWords && Array.isArray(stopWords)) {\n    const stopWordsSet = new Set(stopWords.map((w) => w.toLowerCase()));\n    words = words.filter((word) => !stopWordsSet.has(word.toLowerCase()));\n  }\n\n  // Step 6: Remove duplicates and return\n  return Array.from(new Set(words));\n}\n\n/**\n * Strip HTML tags and extract text content\n */\nfunction stripHTML(html: string): string {\n  // Remove script and style tags with their content\n  let text = html.replace(/<script\\b[^<]*(?:(?!<\\/script>)<[^<]*)*<\\/script>/gi, \" \");\n  text = text.replace(/<style\\b[^<]*(?:(?!<\\/style>)<[^<]*)*<\\/style>/gi, \" \");\n\n  // Remove HTML comments\n  text = text.replace(/<!--[\\s\\S]*?-->/g, \" \");\n\n  // Remove all HTML tags\n  text = text.replace(/<[^>]+>/g, \" \");\n\n  // Decode common HTML entities\n  text = text\n    .replace(/&nbsp;/g, \" \")\n    .replace(/&amp;/g, \"&\")\n    .replace(/&lt;/g, \"<\")\n    .replace(/&gt;/g, \">\")\n    .replace(/&quot;/g, '\"')\n    .replace(/&#39;/g, \"'\")\n    .replace(/&apos;/g, \"'\");\n\n  // Normalize whitespace\n  text = text.replace(/\\s+/g, \" \").trim();\n\n  return text;\n}\n\n/**\n * Extract string values from JSON\n */\nfunction extractFromJSON(jsonString: string): string {\n  try {\n    const data = JSON.parse(jsonString);\n    const values: string[] = [];\n\n    function extractValues(obj: any, depth: number = 0): void {\n      // Limit recursion depth to prevent stack overflow\n      if (depth > 10) return;\n\n      if (typeof obj === \"string\") {\n        values.push(obj);\n      } else if (Array.isArray(obj)) {\n        obj.forEach((item) => extractValues(item, depth + 1));\n      } else if (typeof obj === \"object\" && obj !== null) {\n        Object.values(obj).forEach((value) => extractValues(value, depth + 1));\n      }\n    }\n\n    extractValues(data);\n    return values.join(\" \");\n  } catch (e) {\n    console.error(\"Failed to parse JSON:\", e);\n    return \"\";\n  }\n}\n\n/**\n * Chunk text into smaller pieces\n */\nfunction chunkText(\n  //\n  text: string,\n  chunkSize: number,\n  overlap: number,\n  splitOn: \"word\" | \"sentence\" | \"paragraph\"\n): string[] {\n  const chunks: string[] = [];\n\n  if (splitOn === \"paragraph\") {\n    // Split on double newlines\n    const paragraphs = text.split(/\\n\\n+/);\n    let currentChunk = \"\";\n\n    for (const para of paragraphs) {\n      if ((currentChunk + para).length <= chunkSize) {\n        currentChunk += (currentChunk ? \"\\n\\n\" : \"\") + para;\n      } else {\n        if (currentChunk) chunks.push(currentChunk);\n        currentChunk = para;\n      }\n    }\n    if (currentChunk) chunks.push(currentChunk);\n  } else if (splitOn === \"sentence\") {\n    // Split on sentence boundaries\n    const sentences = text.split(/[.!?]+\\s+/);\n    let currentChunk = \"\";\n\n    for (const sentence of sentences) {\n      if ((currentChunk + sentence).length <= chunkSize) {\n        currentChunk += (currentChunk ? \" \" : \"\") + sentence;\n      } else {\n        if (currentChunk) chunks.push(currentChunk);\n        currentChunk = sentence;\n      }\n    }\n    if (currentChunk) chunks.push(currentChunk);\n  } else {\n    // Split on words (default)\n    const words = text.split(/\\s+/);\n    let currentChunk = \"\";\n\n    for (const word of words) {\n      if ((currentChunk + \" \" + word).length <= chunkSize) {\n        currentChunk += (currentChunk ? \" \" : \"\") + word;\n      } else {\n        if (currentChunk) chunks.push(currentChunk);\n\n        // Add overlap\n        if (overlap > 0 && currentChunk) {\n          const overlapWords = currentChunk.split(/\\s+/).slice(-Math.ceil(overlap / 10));\n          currentChunk = overlapWords.join(\" \") + \" \" + word;\n        } else {\n          currentChunk = word;\n        }\n      }\n    }\n    if (currentChunk) chunks.push(currentChunk);\n  }\n\n  return chunks;\n}\n\n/**\n * Async version for URL fetching\n * @param content - URL or content string\n * @param options - Configuration options\n * @returns Promise<string[]> Array of unique words\n */\nexport async function dataToIndexAsync(\n  //\n  content: string,\n  options: DataToIndexOptions = {}\n): Promise<string[]> {\n  const { format = \"string\" } = options;\n\n  if (format === \"url\") {\n    try {\n      const response = await fetch(content);\n      const html = await response.text();\n      return dataToIndex(html, { ...options, format: \"html\" });\n    } catch (e) {\n      console.error(\"Failed to fetch URL:\", e);\n      return [];\n    }\n  }\n\n  return dataToIndex(content, options);\n}\n","/**\n * FuzzyFindJS - A powerful, multi-language optimized fuzzy search library\n *\n * @example\n * ```typescript\n * import { buildFuzzyIndex, getSuggestions } from 'fuzzyfindjs';\n *\n * const dictionary = ['Krankenhaus', 'Schule', 'Kindergarten'];\n * const index = buildFuzzyIndex(dictionary);\n * const results = getSuggestions(index, 'krankenh', 5);\n * ```\n */\n\n// Core functionality\nexport {\n  //\n  buildFuzzyIndex,\n  getSuggestions,\n  batchSearch,\n  updateIndex,\n  removeFromIndex,\n} from \"./core/index.js\";\n\nimport {\n  //\n  buildFuzzyIndex,\n  getSuggestions,\n} from \"./core/index.js\";\n\n// Highlighting utilities (for UI rendering)\nexport {\n  //\n  calculateHighlights,\n  formatHighlightedHTML,\n} from \"./core/highlighting.js\";\n\n// Cache utilities (for advanced users)\nexport {\n  //\n  SearchCache,\n  LRUCache,\n} from \"./core/cache.js\";\n\n// Serialization utilities (save/load indices)\nexport {\n  //\n  serializeIndex,\n  deserializeIndex,\n  saveIndexToLocalStorage,\n  loadIndexFromLocalStorage,\n  getSerializedSize,\n} from \"./core/serialization.js\";\n\n// E-Commerce: Filtering\nexport { applyFilters } from \"./core/filters.js\";\nexport type { RangeFilter, TermFilter, BooleanFilter, FilterOptions } from \"./core/filters.js\";\n\n// E-Commerce: Sorting\nexport { applySorting } from \"./core/sorting.js\";\nexport type { SortOption, SortConfig } from \"./core/sorting.js\";\n\n// Accent normalization utilities\nexport {\n  //\n  removeAccents,\n  hasAccents,\n  normalizeForComparison,\n  getAccentVariants,\n} from \"./utils/accent-normalization.js\";\n\n// Stop words utilities\nexport {\n  //\n  filterStopWords,\n  getStopWordsForLanguages,\n  isStopWord,\n  DEFAULT_STOP_WORDS,\n} from \"./utils/stop-words.js\";\n\n// Word boundary utilities\nexport {\n  //\n  isWordBoundary,\n  matchesAtWordBoundary,\n  findWordBoundaryMatches,\n  matchesWord,\n  matchesWildcard,\n} from \"./utils/word-boundaries.js\";\n\n// Data indexing utilities\nexport {\n  //\n  dataToIndex,\n  dataToIndexAsync,\n} from \"./utils/data-indexer.js\";\nexport type {\n  //\n  DataToIndexOptions,\n} from \"./utils/data-indexer.js\";\n\n// Phrase parsing utilities\nexport {\n  //\n  parseQuery,\n  hasPhraseSyntax,\n  normalizePhrase,\n  splitPhraseWords,\n} from \"./utils/phrase-parser.js\";\nexport type {\n  //\n  ParsedQuery,\n} from \"./utils/phrase-parser.js\";\n\n// Language detection utilities\nexport {\n  //\n  detectLanguages,\n  detectLanguagesWithConfidence,\n  sampleTextForDetection,\n  isValidLanguage,\n  normalizeLanguageCode,\n} from \"./utils/language-detection.js\";\nexport type {\n  //\n  LanguageDetectionResult,\n} from \"./utils/language-detection.js\";\n\n// Configuration\nexport {\n  //\n  DEFAULT_CONFIG,\n  PERFORMANCE_CONFIGS,\n  mergeConfig,\n  DEFAULT_MATCH_TYPE_SCORES,\n  DEFAULT_SCORING_MODIFIERS,\n} from \"./core/config.js\";\n\n// Types\nexport type {\n  //\n  FuzzyIndex,\n  FuzzyConfig,\n  SuggestionResult,\n  SearchMatch,\n  MatchType,\n  FuzzyFeature,\n  LanguageProcessor,\n  BuildIndexOptions,\n  SearchOptions,\n  DebugInfo,\n  SuggestionResultWithDebug,\n  MatchTypeScores,\n  ScoringModifiers,\n} from \"./core/types.js\";\n\n// Language processors\nexport {\n  //\n  LanguageRegistry,\n  GermanProcessor,\n  EnglishProcessor,\n  SpanishProcessor,\n  FrenchProcessor,\n  BaseLanguageProcessor,\n} from \"./languages/index.js\";\n\n// Algorithms (for advanced users)\nexport {\n  //\n  calculateLevenshteinDistance,\n  calculateDamerauLevenshteinDistance,\n  calculateNgramSimilarity,\n  distanceToSimilarity,\n  areStringsSimilar,\n} from \"./algorithms/levenshtein.js\";\nexport {\n  //\n  calculateBM25Score,\n  calculateIDF,\n  normalizeBM25Score,\n  combineScores,\n  buildCorpusStats,\n  DEFAULT_BM25_CONFIG,\n} from \"./algorithms/bm25.js\";\nexport type {\n  //\n  BM25Config,\n  DocumentStats,\n  CorpusStats,\n} from \"./algorithms/bm25.js\";\nexport {\n  //\n  BloomFilter,\n  createBloomFilter,\n} from \"./algorithms/bloom-filter.js\";\nexport type {\n  //\n  BloomFilterConfig,\n} from \"./algorithms/bloom-filter.js\";\n\n// Memory pooling utilities (for performance optimization)\nexport {\n  //\n  ObjectPool,\n  ArrayPool,\n  MapPool,\n  SetPool,\n  withPooledArray,\n  globalArrayPool,\n  globalMapPool,\n  globalSetPool,\n} from \"./utils/memory-pool.js\";\n\n// Alphanumeric segmentation utilities\nexport {\n  //\n  isAlphanumeric,\n  segmentString,\n  getAlphaSegments,\n  getNumericSegments,\n  extractAlphaPart,\n  extractNumericPart,\n  compareSegments,\n} from \"./utils/alphanumeric-segmenter.js\";\nexport type {\n  //\n  Segment,\n  SegmentType,\n} from \"./utils/alphanumeric-segmenter.js\";\n\n/**\n * Creates a fuzzy search instance with sensible defaults - the easiest way to get started.\n * \n * This convenience function combines index building and searching into a simple API.\n * It's perfect for quick prototyping and simple use cases. For advanced features,\n * use {@link buildFuzzyIndex} and {@link getSuggestions} directly.\n * \n * @param dictionary - Array of strings to make searchable\n * @param options - Simple configuration options\n * @param options.languages - Languages to enable (default: ['english'])\n * @param options.performance - Performance mode: 'fast', 'balanced', or 'comprehensive' (default: 'balanced')\n * @param options.maxResults - Maximum results to return per search (default: 5)\n * \n * @returns Object with search() method and the underlying index\n * @returns {Function} search - Function to search the index: (query: string, maxResults?: number) => SuggestionResult[]\n * @returns {FuzzyIndex} index - The underlying fuzzy index (for advanced usage)\n * \n * @example\n * ```typescript\n * // Quick start - one line setup\n * const search = createFuzzySearch(['apple', 'banana', 'cherry']);\n * const results = search.search('aple');\n * // Returns: [{ display: 'apple', score: 0.9, ... }]\n * \n * // With options\n * const search = createFuzzySearch(['Krankenhaus', 'Apotheke'], {\n *   languages: ['german'],\n *   performance: 'comprehensive',\n *   maxResults: 10\n * });\n * \n * // Access underlying index for advanced features\n * const { search: searchFn, index } = createFuzzySearch(['hello', 'world']);\n * console.log(index.base); // ['hello', 'world']\n * ```\n * \n * @see {@link buildFuzzyIndex} for advanced index building\n * @see {@link getSuggestions} for advanced search options\n */\nexport function createFuzzySearch(\n  //\n  dictionary: string[],\n  options: {\n    languages?: string[];\n    performance?: \"fast\" | \"balanced\" | \"comprehensive\";\n    maxResults?: number;\n  } = {}\n) {\n  const index = buildFuzzyIndex(dictionary, {\n    config: {\n      languages: options.languages || [\"english\"],\n      performance: options.performance || \"balanced\",\n      maxResults: options.maxResults || 5,\n    },\n  });\n\n  return {\n    search: (query: string, maxResults?: number) => getSuggestions(index, query, maxResults),\n    index,\n  };\n}\n\n/**\n * Version information\n */\nexport const VERSION = \"1.0.13\";\n"],"names":["DEFAULT_MATCH_TYPE_SCORES","DEFAULT_SCORING_MODIFIERS","DEFAULT_CONFIG","PERFORMANCE_CONFIGS","LANGUAGE_FEATURES","mergeConfig","userConfig","baseConfig","performanceConfig","mergedConfig","recommendedFeatures","lang","feature","validateConfig","config","BaseLanguageProcessor","text","word","normalized","code","consonantMap","i","char","digit","performanceMode","variants","commonEndings","ending","step","_word","char1","char2","neighbors","ngrams","str1","str2","matrix","len1","len2","j","cost","GermanProcessor","prev","next","parts","commonPrefixes","commonSuffixes","commonWords","prefix","remainder","suffix","leftPart","rightPart","compoundParts","part","synonymMap","EnglishProcessor","metaphone","current","length","base","SpanishProcessor","FrenchProcessor","next2","LanguageRegistry","language","languages","processor","ObjectPool","factory","maxSize","reset","obj","ArrayPool","_size","arr","globalArrayPool","withPooledArray","size","fn","MapPool","map","SetPool","set","globalMapPool","globalSetPool","calculateLevenshteinDistance","maxDistance","previousRow","currentRow","minInRow","calculateDamerauLevenshteinDistance","maxLen","H","INF","charMap","lastMatchCol","lastMatchRow","result","calculateNgramSimilarity","ngrams1","generateNgrams","ngrams2","set1","set2","intersectionSize","item","unionSize","str","n","count","distanceToSimilarity","distance","maxLength","areStringsSimilar","threshold","Trie","term","docIds","node","id","results","child","data","trie","childData","DEFAULT_BM25_CONFIG","calculateIDF","corpusStats","df","N","idf","calculateTermScore","docStats","tf","docLength","avgDocLength","numerator","denominator","calculateBM25Score","queryTerms","totalScore","buildCorpusStats","documents","totalDocs","totalLength","documentFrequencies","doc","uniqueTerms","normalizeBM25Score","score","maxScore","scaledScore","combineScores","bm25Score","fuzzyScore","bm25Weight","fuzzyWeight","totalWeight","normalizedBM25Weight","normalizedFuzzyWeight","BloomFilter","p","hashes","hash","byteIndex","bitIndex","hash1","hash2","combinedHash","seed","k","m","filter","createBloomFilter","expectedElements","falsePositiveRate","WORD_BOUNDARY_PATTERN","tokenize","options","keepEmpty","minLength","lowercase","tokens","token","buildInvertedIndex","words","languageProcessors","featureSet","invertedIndex","docId","trimmedWord","phoneticCode","addToPostingList","lowerWord","variant","ngram","normalizedPart","synonym","customSynonyms","documentLengths","posting","bloomFilter","searchInvertedIndex","query","processors","matches","normalizedQuery","findExactMatchesInverted","findPrefixMatchesInverted","findPhoneticMatchesInverted","findSynonymMatchesInverted","findNgramMatchesInverted","findFuzzyMatchesInverted","postings","prefixMatches","ngramSize","queryNgrams","candidateDocs","queryLen","minLen","useTranspositions","datasetSize","MAX_FUZZY_CANDIDATES","candidatesChecked","termsArray","prefixLength","_docIds","entry","a","aDiff","bDiff","termLen","currentMatches","earlyTerminationThreshold","minEditDistance","hasPerfectMatches","match","existingMatch","calculateBM25Scores","bm25Config","termFrequencies","normalizedTerms","normalizedBM25","calculateHighlights","displayText","highlights","normalizedDisplay","prefixEnd","substringIndex","calculateFuzzyHighlights","calculateNgramHighlights","mergeOverlappingHighlights","type","queryIdx","textIdx","start","end","searchStart","index","sorted","b","merged","last","getMatchTypePriority","formatHighlightedHTML","className","escapeHTML","lastEnd","highlight","highlightedText","div","LRUCache","capacity","key","value","firstKey","SearchCache","maxResults","optionsKey","cacheStats","total","hitRate","ACCENT_MAP","accentCache","MAX_CACHE_SIZE","removeAccents","cached","chars","hasAccents","normalizeForComparison","getAccentVariants","extractFieldValues","fields","fieldValues","field","normalizeFieldWeights","fieldWeights","DEFAULT_STOP_WORDS","filterStopWords","stopWords","stopWordsSet","w","filtered","getStopWordsForLanguages","langStopWords","isStopWord","isWordBoundary","position","charBefore","matchesAtWordBoundary","matchStart","matchLength","matchEnd","startBoundary","endBoundary","findWordBoundaryMatches","pattern","caseSensitive","positions","searchText","searchPattern","found","matchesWord","wordBoundaries","parseWildcard","regexPattern","matchesWildcard","parseQuery","phrases","remaining","doubleQuoteRegex","phrase","singleQuoteRegex","terms","t","hasPhraseSyntax","normalizePhrase","splitPhraseWords","DEFAULT_OPTIONS","matchPhrase","opts","normalizedText","normalizedPhrase","exactMatch","findExactPhrase","fuzzyMatch","findFuzzyPhrase","proximityMatch","findProximityMatch","maxEditDistance","phraseWords","textWords","segment","totalDistance","allMatch","maxPossibleDistance","phraseWord","phraseIndex","bestDistance","bestPositions","findBestCombination","wordIndex","currentPositions","pos","detectLanguages","detected","detectLanguagesWithConfidence","confidence","textLength","germanChars","frenchChars","spanishChars","_","conf","primary","sampleTextForDetection","sampleSize","v","isValidLanguage","normalizeLanguageCode","TokenType","FQLLexer","input","quote","upperValue","FQLSyntaxError","message","FQLParser","ast","left","right","expr","filterToken","filterType","operator","types","isTermNode","isPhraseNode","isAndNode","isOrNode","isNotNode","isFilterNode","isFieldNode","isScoreNode","isLangNode","FQLTimeoutError","FQLExecutor","leftResults","rightResults","rightDisplays","r","resultMap","existing","childResults","excludeDisplays","getSuggestions","regex","targetLang","isFQLQuery","trimmed","extractFQLQuery","executeFQLQuery","fqlQuery","limit","error","isAlphanumeric","hasLetters","hasNumbers","segmentString","segments","currentType","currentValue","currentStart","charType","getAlphaSegments","s","getNumericSegments","extractAlphaPart","extractNumericPart","compareSegments","alpha1","alpha2","numeric1","numeric2","hasAlpha","hasNumeric","alphaSimilarity","commonLength","numericSimilarity","longer","shorter","matchingDigits","applyFilters","filters","range","numValue","filterValue","matchValue","boolFilter","numFilterValue","applySorting","sortConfig","primaryCompare","compareResults","secondaryCompare","sort","aValue","bValue","detectType","comparison","compareNumbers","compareDates","compareStrings","numA","numB","dateA","dateB","timeA","timeB","date","buildFuzzyIndex","userSpecifiedLanguages","shouldAutoDetect","sampleText","detectedLanguages","hasFields","isObjectArray","shouldUseInvertedIndex","processedWords","processed","baseId","fieldName","fieldValue","trimmedValue","processWordWithProcessorAndField","processWordWithProcessor","cacheSize","addToVariantMap","accentFreeWord","normalizedAccentFree","ngramSource","addToVariantMapWithField","_fieldName","batchSearch","queries","uniqueQueries","parsedQuery","searchWithPhrases","processedQuery","getSuggestionsInverted","findExactMatches","exactMatches","findPrefixMatches","findSubstringMatches","findPhoneticMatches","findSynonymMatches","findNgramMatches","findFuzzyMatches","createSuggestionResult","baseWord","queryLower","phoneticMatches","synonymMatches","candidateWords","ngramMatches","lengthDiff","maxLengthDiff","distanceThreshold","originalQuery","calculateMatchScore","scores","modifiers","wordLen","substringPos","positionBoost","calculateAlphanumericScore","target","queryAlpha","targetAlpha","queryNumeric","targetNumeric","alphaWeight","numericWeight","alphaScore","numericScore","alphaMaxLen","alphaDistance","numericMaxLen","multiplier","numericDistance","combinedScore","phraseOptions","phraseMatches","newScore","termMatches","termQuery","combinedResults","phraseData","updateIndex","newItems","existingWords","removeFromIndex","itemsToRemove","toRemove","baseWords","phonetic","serializeIndex","serialized","deserializeIndex","json","variantToBase","phoneticToBase","ngramIndex","langName","saveIndexToLocalStorage","loadIndexFromLocalStorage","getSerializedSize","dataToIndex","content","splitWords","overlap","chunkSize","splitOn","format","removeNumbers","e","stripHTML","extractFromJSON","chunkText","html","jsonString","extractValues","depth","values","chunks","paragraphs","currentChunk","para","sentences","sentence","dataToIndexAsync","createFuzzySearch","dictionary","VERSION"],"mappings":"oOAaO,MAAMA,EAA6C,CACxD,MAAO,EACP,OAAQ,GACR,UAAW,IACX,SAAU,GACV,MAAO,GACP,SAAU,GACV,QAAS,GACT,SAAU,GACV,MAAO,EACT,EAMaC,EAA8C,CACzD,UAAW,GACX,eAAgB,GAChB,iBAAkB,EAClB,oBAAqB,EACvB,EAMaC,GAA8B,CACzC,UAAW,CAAC,SAAS,EACrB,SAAU,CAAC,WAAY,WAAY,WAAY,qBAAsB,gBAAiB,kBAAmB,gBAAiB,gBAAgB,EAC1I,YAAa,WACb,WAAY,GACZ,eAAgB,EAChB,eAAgB,GAChB,gBAAiB,EACjB,UAAW,EACX,+BAAgC,GAChC,wBAAyB,GACzB,0BAA2B,GAC3B,0CAA2C,IAC3C,gBAAiBF,EACjB,iBAAkBC,CACpB,EAKaE,GAA4D,CACvE,KAAM,CACJ,YAAa,OACb,SAAU,CAAC,gBAAiB,iBAAiB,EAC7C,gBAAiB,EACjB,eAAgB,GAChB,WAAY,EACZ,+BAAgC,GAChC,gBAAiB,CACf,MAAO,EACP,OAAQ,GACR,UAAW,GACX,MAAO,GACP,SAAU,EAAA,CACZ,EAEF,SAAU,CACR,YAAa,WACb,SAAU,CAAC,WAAY,WAAY,WAAY,qBAAsB,gBAAiB,kBAAmB,gBAAiB,gBAAgB,EAC1I,gBAAiB,EACjB,eAAgB,GAChB,WAAY,GACZ,+BAAgC,EAAA,EAGlC,cAAe,CACb,YAAa,gBACb,SAAU,CAAC,WAAY,WAAY,WAAY,qBAAsB,gBAAiB,kBAAmB,gBAAiB,gBAAgB,EAC1I,gBAAiB,EACjB,eAAgB,GAChB,WAAY,GACZ,+BAAgC,GAChC,gBAAiB,CACf,MAAO,EACP,OAAQ,GACR,UAAW,GACX,MAAO,GACP,SAAU,IACV,SAAU,GACV,QAAS,GACT,SAAU,GACV,MAAO,EAAA,CACT,CAEJ,EAKaC,GAAoD,CAC/D,OAAQ,CAEN,WACA,WACA,WACA,qBACA,gBACA,kBACA,eAAA,EAEF,QAAS,CAEP,WACA,WACA,qBACA,gBACA,kBACA,gBAAA,EAEF,QAAS,CAEP,WACA,WACA,qBACA,gBACA,iBAAA,EAEF,OAAQ,CAEN,WACA,WACA,qBACA,gBACA,iBAAA,CAEJ,EAKO,SAASC,GAAYC,EAAmC,GAAiB,CAC9E,MAAMC,EAAa,CAAE,GAAGL,EAAA,EAGxB,GAAII,EAAW,aAAeA,EAAW,cAAgB,WAAY,CACnE,MAAME,EAAoBL,GAAoBG,EAAW,WAAW,EACpE,OAAO,OAAOC,EAAYC,CAAiB,EAGvCA,EAAkB,kBACpBD,EAAW,gBAAkB,CAC3B,GAAGP,EACH,GAAGQ,EAAkB,eAAA,GAGrBA,EAAkB,mBACpBD,EAAW,iBAAmB,CAC5B,GAAGN,EACH,GAAGO,EAAkB,gBAAA,EAG3B,CAGA,MAAMC,EAAe,CAAE,GAAGF,EAAY,GAAGD,CAAA,EAiBzC,GAdIA,EAAW,kBACbG,EAAa,gBAAkB,CAC7B,GAAGF,EAAW,gBACd,GAAGD,EAAW,eAAA,GAGdA,EAAW,mBACbG,EAAa,iBAAmB,CAC9B,GAAGF,EAAW,iBACd,GAAGD,EAAW,gBAAA,GAKd,CAACA,EAAW,UAAYA,EAAW,UAAW,CAChD,MAAMI,MAA0B,IAEhC,UAAWC,KAAQL,EAAW,WACPF,GAAkBO,CAAI,GAAKP,GAAkB,SACrD,QAASQ,GAAYF,EAAoB,IAAIE,CAAO,CAAC,EAGpEH,EAAa,SAAW,MAAM,KAAKC,CAAmB,CACxD,CAEA,OAAOD,CACT,CAKO,SAASI,GAAeC,EAA2B,CACxD,GAAIA,EAAO,WAAa,EACtB,MAAM,IAAI,MAAM,+BAA+B,EAGjD,GAAIA,EAAO,eAAiB,EAC1B,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIA,EAAO,eAAiB,GAAKA,EAAO,eAAiB,EACvD,MAAM,IAAI,MAAM,wCAAwC,EAG1D,GAAIA,EAAO,gBAAkB,EAC3B,MAAM,IAAI,MAAM,sCAAsC,EAGxD,GAAIA,EAAO,UAAY,EACrB,MAAM,IAAI,MAAM,8BAA8B,EAGhD,GAAIA,EAAO,UAAU,SAAW,EAC9B,MAAM,IAAI,MAAM,yCAAyC,CAE7D,CClOO,MAAeC,CAAmD,CAQvE,UAAUC,EAAsB,CAC9B,OAAOA,EAAK,cAAc,OAAO,QAAQ,OAAQ,GAAG,CACtD,CAKA,gBAAgBC,EAAsB,CAEpC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,SAAW,EAAG,MAAO,GAEpC,IAAIC,EAAOD,EAAW,CAAC,EAAE,YAAA,EACzB,MAAME,EAAuC,CAC3C,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,GAAA,EAGL,QAASC,EAAI,EAAGA,EAAIH,EAAW,QAAUC,EAAK,OAAS,EAAGE,IAAK,CAC7D,MAAMC,EAAOJ,EAAWG,CAAC,EACnBE,EAAQH,EAAaE,CAAI,EAC3BC,GAASA,IAAUJ,EAAKA,EAAK,OAAS,CAAC,IACzCA,GAAQI,EAEZ,CAEA,OAAOJ,EAAK,OAAO,EAAG,GAAG,CAC3B,CAKA,mBAAmBF,EAAwB,CACzC,MAAO,CAACA,CAAI,CACd,CAMA,gBAAgBA,EAAcO,EAAoC,CAChE,MAAMC,MAAe,IACfP,EAAa,KAAK,UAAUD,CAAI,EAEtCQ,EAAS,IAAIP,CAAU,EACvBO,EAAS,IAAIR,CAAI,EAGjB,MAAMS,EAAgB,KAAK,iBAAA,EAC3B,UAAWC,KAAUD,EACfR,EAAW,SAASS,CAAM,GAAKT,EAAW,OAASS,EAAO,OAAS,GACrEF,EAAS,IAAIP,EAAW,MAAM,EAAG,CAACS,EAAO,MAAM,CAAC,EAKpD,GAAIT,EAAW,OAAS,EAAG,CAEzB,MAAMU,EAAOJ,IAAoB,OAAS,EAAI,EAC9C,QAAS,EAAI,EAAG,EAAIN,EAAW,OAAQ,GAAKU,EAC1CH,EAAS,IAAIP,EAAW,MAAM,EAAG,CAAC,CAAC,CAEvC,CAEA,OAAO,MAAM,KAAKO,CAAQ,CAC5B,CAKU,kBAA6B,CACrC,MAAO,CAEL,IACA,KACA,KACA,MACA,KACA,KAAA,CAEJ,CAKA,YAAYI,EAAyB,CACnC,MAAO,CAAA,CACT,CAKA,oBAAoBC,EAAeC,EAAwB,CAEzD,MAAMC,EADoB,KAAK,qBAAA,EACKF,EAAM,YAAA,CAAa,EACvD,OAAOE,EAAYA,EAAU,SAASD,EAAM,YAAA,CAAa,EAAI,EAC/D,CAKU,sBAAiD,CACzD,MAAO,CACL,EAAG,CAAC,IAAK,IAAK,GAAG,EACjB,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,GAAG,EACtB,EAAG,CAAC,IAAK,GAAG,EACZ,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAC1C,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAC1C,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAC1C,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAC1C,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAC1C,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EACrC,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,GAAG,EAChC,EAAG,CAAC,IAAK,IAAK,IAAK,GAAG,EACtB,EAAG,CAAC,IAAK,IAAK,GAAG,EACjB,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAC3B,EAAG,CAAC,IAAK,IAAK,IAAK,GAAG,CAAA,CAE1B,CAKA,eAAed,EAAc,EAAY,EAAa,CACpD,MAAMC,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,OAAS,EAAG,MAAO,CAACA,CAAU,EAE7C,MAAMe,EAAmB,CAAA,EACzB,QAASZ,EAAI,EAAGA,GAAKH,EAAW,OAAS,EAAGG,IAC1CY,EAAO,KAAKf,EAAW,MAAMG,EAAGA,EAAI,CAAC,CAAC,EAExC,OAAOY,CACT,CAKA,sBAAsBC,EAAcC,EAAsB,CACxD,MAAMC,EAAqB,CAAA,EACrBC,EAAOH,EAAK,OACZI,EAAOH,EAAK,OAGlB,QAASd,EAAI,EAAGA,GAAKgB,EAAMhB,IACzBe,EAAOf,CAAC,EAAI,CAACA,CAAC,EAEhB,QAASkB,EAAI,EAAGA,GAAKD,EAAMC,IACzBH,EAAO,CAAC,EAAEG,CAAC,EAAIA,EAIjB,QAASlB,EAAI,EAAGA,GAAKgB,EAAMhB,IACzB,QAASkB,EAAI,EAAGA,GAAKD,EAAMC,IAAK,CAC9B,MAAMC,EAAON,EAAKb,EAAI,CAAC,IAAMc,EAAKI,EAAI,CAAC,EAAI,EAAI,EAC/CH,EAAOf,CAAC,EAAEkB,CAAC,EAAI,KAAK,IAClBH,EAAOf,EAAI,CAAC,EAAEkB,CAAC,EAAI,EACnBH,EAAOf,CAAC,EAAEkB,EAAI,CAAC,EAAI,EACnBH,EAAOf,EAAI,CAAC,EAAEkB,EAAI,CAAC,EAAIC,CAAA,CAE3B,CAGF,OAAOJ,EAAOC,CAAI,EAAEC,CAAI,CAC1B,CACF,CCpMO,MAAMG,UAAwB1B,CAAsB,CAChD,SAAW,SACX,YAAc,UACd,kBAAoC,CAAC,WAAY,WAAY,WAAY,qBAAsB,gBAAiB,kBAAmB,eAAe,EAK3J,UAAUC,EAAsB,CAC9B,OACEA,EACG,cACA,KAAA,EACA,QAAQ,OAAQ,GAAG,EAEnB,QAAQ,KAAM,IAAI,EAClB,QAAQ,KAAM,IAAI,EAClB,QAAQ,KAAM,IAAI,EAClB,QAAQ,KAAM,IAAI,CAEzB,CAKA,gBAAgBC,EAAsB,CACpC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,SAAW,EAAG,MAAO,GAEpC,IAAIC,EAAO,GACPuB,EAAO,GAEX,QAASrB,EAAI,EAAGA,EAAIH,EAAW,OAAQG,IAAK,CAC1C,MAAMC,EAAOJ,EAAWG,CAAC,EACnBsB,EAAOtB,EAAIH,EAAW,OAAS,EAAIA,EAAWG,EAAI,CAAC,EAAI,GAC7D,IAAIE,EAAQ,GAEZ,OAAQD,EAAA,CACN,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACHC,EAAQ,IACR,MACF,IAAK,IAEH,SACF,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACL,IAAK,IACCoB,IAAS,KAAOA,IAAS,KAAOA,IAAS,IAC3CpB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACL,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACL,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCF,IAAM,EACJsB,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,KAAOA,IAAS,IAC3IpB,EAAQ,IAERA,EAAQ,IAGNmB,IAAS,KAAOA,IAAS,IAC3BnB,EAAQ,IACCoB,IAAS,KAETA,IAAS,KAAOA,IAAS,IADlCpB,EAAQ,IAIRA,EAAQ,IAGZ,MACF,IAAK,IACCmB,IAAS,KAAOA,IAAS,KAAOA,IAAS,IAC3CnB,EAAQ,IAERA,EAAQ,KAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,QACE,QAAA,CAIAA,GAASA,IAAUmB,IACrBvB,GAAQI,GAEVmB,EAAOnB,CACT,CAEA,OAAOJ,GAAQ,GACjB,CAMA,mBAAmBF,EAAwB,CACzC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,OAAS,EAAG,MAAO,CAACD,CAAI,EAEvC,MAAM2B,EAAkB,CAAA,EAClBC,EAAiB,KAAK,kBAAA,EACtBC,EAAiB,KAAK,kBAAA,EACtBC,EAAc,KAAK,eAAA,EAGzB,UAAWC,KAAUH,EACnB,GAAI3B,EAAW,WAAW8B,CAAM,GAAK9B,EAAW,OAAS8B,EAAO,OAAS,EAAG,CAC1E,MAAMC,EAAY/B,EAAW,MAAM8B,EAAO,MAAM,EAChDJ,EAAM,KAAKI,CAAM,EACjBJ,EAAM,KAAK,GAAG,KAAK,mBAAmBK,CAAS,CAAC,EAChD,KACF,CAGF,GAAIL,EAAM,SAAW,GAEnB,UAAWM,KAAUJ,EACnB,GAAI5B,EAAW,SAASgC,CAAM,GAAKhC,EAAW,OAASgC,EAAO,OAAS,EAAG,CACxE,MAAMD,EAAY/B,EAAW,MAAM,EAAG,CAACgC,EAAO,MAAM,EACpDN,EAAM,KAAK,GAAG,KAAK,mBAAmBK,CAAS,CAAC,EAChDL,EAAM,KAAKM,CAAM,EACjB,KACF,EAIJ,GAAIN,EAAM,SAAW,EAEnB,QAAS,EAAI,EAAG,GAAK1B,EAAW,OAAS,EAAG,IAAK,CAC/C,MAAMiC,EAAWjC,EAAW,MAAM,EAAG,CAAC,EAChCkC,EAAYlC,EAAW,MAAM,CAAC,EAEpC,GAAI6B,EAAY,IAAII,CAAQ,GAAKC,EAAU,QAAU,EAAG,CACtDR,EAAM,KAAKO,CAAQ,EACnBP,EAAM,KAAK,GAAG,KAAK,mBAAmBQ,CAAS,CAAC,EAChD,KACF,CACF,CAGF,OAAOR,EAAM,OAAS,EAAIA,EAAQ,CAAC3B,CAAI,CACzC,CAMA,gBAAgBA,EAAcO,EAAoC,CAEhE,MAAMC,EAAW,IAAI,IAAI,MAAM,gBAAgBR,EAAMO,CAAe,CAAC,EAG/D6B,EAAgB,KAAK,mBAAmBpC,CAAI,EAClD,OAAIoC,EAAc,OAAS,GACzBA,EAAc,QAASC,GAAS,CAC1BA,EAAK,QAAU,GACjB7B,EAAS,IAAI,KAAK,UAAU6B,CAAI,CAAC,CAErC,CAAC,EAGI,MAAM,KAAK7B,CAAQ,CAC5B,CAKU,kBAA6B,CACrC,MAAO,CAEL,KACA,IACA,KACA,IACA,IACA,IACA,KACA,IACA,MACA,OACA,OACA,SACA,OACA,OACA,OACA,KACA,OACA,MACA,MACA,MAAA,CAEJ,CAKA,YAAYR,EAAwB,CAClC,MAAMsC,EAAuC,CAC3C,KAAM,CAEJ,SACA,YACA,KAAA,EAEF,YAAa,CAEX,SACA,SACA,UAAA,EAEF,OAAQ,CAEN,sBACA,aAAA,EAEF,KAAM,CAEJ,QACA,WACA,KAAA,EAEF,KAAM,CAEJ,WACA,OACA,UAAA,EAEF,QAAS,CAEP,MACA,QACA,OAAA,EAEF,MAAO,CAEL,MACA,WACA,WAAA,EAEF,OAAQ,CAEN,MACA,QACA,YAAA,EAEF,KAAM,CAEJ,WACA,UACA,UAAA,EAEF,KAAM,CAEJ,QACA,UACA,UAAA,CACF,EAGIrC,EAAa,KAAK,UAAUD,CAAI,EACtC,OAAOsC,EAAWrC,CAAU,GAAK,CAAA,CACnC,CAKU,sBAAiD,CACzD,MAAO,CACL,EAAG,CAED,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IAAA,EAEF,EAAG,CAED,IACA,KACA,IACA,IAAA,EAEF,GAAI,CAEF,IACA,IAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IAAA,EAEF,GAAI,CAEF,IACA,IACA,KACA,IACA,IAAA,EAEF,GAAI,CAEF,KACA,IAAA,EAEF,EAAG,CAED,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,GAAA,CACF,CAEJ,CAKQ,mBAA8B,CACpC,MAAO,CAAC,KAAM,MAAO,OAAQ,MAAO,MAAO,KAAM,KAAM,MAAO,MAAO,MAAO,QAAS,SAAU,QAAS,QAAS,QAAS,WAAY,QAAQ,CAChJ,CAKQ,mBAA8B,CACpC,MAAO,CAAC,OAAQ,QAAS,UAAW,MAAO,MAAO,OAAQ,MAAO,OAAQ,QAAS,OAAQ,OAAQ,OAAQ,MAAO,SAAU,SAAS,CACtI,CAKQ,gBAA8B,CACpC,OAAO,IAAI,IAAI,CAAC,UAAW,SAAU,SAAU,UAAW,MAAO,MAAO,QAAS,QAAS,OAAQ,OAAQ,OAAQ,OAAQ,QAAS,SAAU,OAAQ,QAAS,QAAS,UAAW,UAAW,UAAW,QAAS,OAAQ,OAAQ,OAAQ,OAAQ,MAAO,MAAO,OAAQ,SAAU,MAAO,QAAS,SAAU,QAAS,OAAQ,OAAQ,QAAS,WAAY,QAAS,OAAQ,MAAO,QAAS,SAAU,QAAS,SAAU,OAAQ,OAAQ,OAAO,CAAC,CACjb,CACF,CCpjBO,MAAMsC,UAAyBzC,CAAsB,CACjD,SAAW,UACX,YAAc,UACd,kBAAoC,CAE3C,WACA,WACA,qBACA,gBACA,kBACA,gBACA,gBAAA,EAMF,UAAUC,EAAsB,CAC9B,OACEA,EACG,YAAA,EACA,OACA,QAAQ,OAAQ,GAAG,EAEnB,QAAQ,SAAU,UAAU,EAC5B,QAAQ,SAAU,QAAQ,EAC1B,QAAQ,OAAQ,MAAM,EACtB,QAAQ,OAAQ,MAAM,EACtB,QAAQ,OAAQ,OAAO,EACvB,QAAQ,OAAQ,OAAO,EACvB,QAAQ,MAAO,QAAQ,EACvB,QAAQ,MAAO,KAAK,EACpB,QAAQ,KAAM,EAAE,CAEvB,CAKA,gBAAgBC,EAAsB,CACpC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EAAE,QAAQ,UAAW,EAAE,EAC7D,GAAIC,EAAW,SAAW,EAAG,MAAO,GAEpC,IAAIuC,EAAY,GACZC,EAAU,EACd,MAAMC,EAASzC,EAAW,OAO1B,KAJIA,EAAW,WAAW,IAAI,GAAKA,EAAW,WAAW,IAAI,GAAKA,EAAW,WAAW,IAAI,GAAKA,EAAW,WAAW,IAAI,KACzHwC,EAAU,GAGLA,EAAUC,GAAUF,EAAU,OAAS,GAAG,CAC/C,MAAMnC,EAAOJ,EAAWwC,CAAO,EACzBf,EAAOe,EAAU,EAAIC,EAASzC,EAAWwC,EAAU,CAAC,EAAI,GACxDhB,EAAOgB,EAAU,EAAIxC,EAAWwC,EAAU,CAAC,EAAI,GAErD,OAAQpC,EAAA,CACN,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACCoC,IAAY,IAAGD,GAAanC,EAAK,YAAA,GACrC,MACF,IAAK,IACCoC,IAAYC,EAAS,GAAKjB,IAAS,MAGrCe,GAAa,KAEf,MACF,IAAK,IACCd,IAAS,KACXc,GAAa,IACbC,KACSf,IAAS,KAAOA,IAAS,KAAOA,IAAS,IAClDc,GAAa,IAEbA,GAAa,IAEf,MACF,IAAK,IACCd,IAAS,KACXc,GAAa,IACbC,KAEAD,GAAa,IAEf,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACCd,IAAS,KAAOe,IAAY,IAErBf,IAAS,KAClBc,GAAa,IACbC,KACSf,IAAS,KAAOA,IAAS,KAAOA,IAAS,IAClDc,GAAa,IAEbA,GAAa,KAEf,MACF,IAAK,KACCC,IAAY,GAAK,QAAQ,SAAShB,CAAI,GAAK,QAAQ,SAASC,CAAI,KAClEc,GAAa,KAEf,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACCf,IAAS,MACXe,GAAa,KAEf,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACCd,IAAS,KACXc,GAAa,IACbC,KAEAD,GAAa,IAEf,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACCd,IAAS,KACXc,GAAa,IACbC,KAEAD,GAAa,IAEf,MACF,IAAK,IACCd,IAAS,KACXc,GAAa,IACbC,KACSf,IAAS,KAAOe,EAAU,EAAIC,IAAWzC,EAAWwC,EAAU,CAAC,IAAM,KAAOxC,EAAWwC,EAAU,CAAC,IAAM,KACjHD,GAAa,IAEbA,GAAa,IAEf,MACF,IAAK,IACHA,GAAa,IACb,MACF,IAAK,IACC,QAAQ,SAASd,CAAI,IACvBc,GAAa,KAEf,MACF,IAAK,IACHA,GAAa,KACb,MACF,IAAK,IACC,QAAQ,SAASd,CAAI,IACvBc,GAAa,KAEf,MACF,IAAK,IACHA,GAAa,IACb,KAAA,CAEJC,GACF,CAEA,OAAOD,GAAa,GACtB,CAMA,gBAAgBxC,EAAcO,EAAoC,CAEhE,MAAMC,EAAW,IAAI,IAAI,MAAM,gBAAgBR,EAAMO,CAAe,CAAC,EAE/DN,EAAa,KAAK,UAAUD,CAAI,EAYtC,GARIC,EAAW,SAAS,GAAG,GAAKA,EAAW,OAAS,GAClDO,EAAS,IAAIP,EAAW,MAAM,EAAG,EAAE,CAAC,EAEjCA,EAAW,SAAS,GAAG,GAC1BO,EAAS,IAAIP,EAAa,GAAG,EAI3BA,EAAW,SAAS,KAAK,GAAKA,EAAW,OAAS,EAAG,CACvD,MAAM0C,EAAO1C,EAAW,MAAM,EAAG,EAAE,EACnCO,EAAS,IAAImC,CAAI,EACjBnC,EAAS,IAAImC,EAAO,GAAG,CACzB,CACA,GAAI1C,EAAW,SAAS,IAAI,GAAKA,EAAW,OAAS,EAAG,CACtD,MAAM0C,EAAO1C,EAAW,MAAM,EAAG,EAAE,EACnCO,EAAS,IAAImC,CAAI,EACjBnC,EAAS,IAAImC,EAAO,GAAG,CACzB,CAEA,OAAO,MAAM,KAAKnC,CAAQ,CAC5B,CAKU,kBAA6B,CACrC,MAAO,CAEL,IACA,KACA,KACA,MACA,KACA,MACA,KACA,OACA,OACA,OACA,OACA,OACA,OACA,MACA,OACA,MACA,OACA,KACA,MACA,KACA,MACA,MACA,MACA,KAAA,CAEJ,CAKA,YAAYR,EAAwB,CAClC,MAAMsC,EAAuC,CAC3C,OAAQ,CAEN,YACA,QACA,MACA,IAAA,EAEF,SAAU,CAER,SACA,iBACA,WAAA,EAEF,OAAQ,CAEN,UACA,cACA,UACA,YAAA,EAEF,IAAK,CAEH,UACA,aACA,MAAA,EAEF,MAAO,CAEL,OACA,YACA,WACA,UAAA,EAEF,OAAQ,CAEN,OACA,SACA,OACA,WAAA,EAEF,KAAM,CAEJ,OACA,eACA,YAAA,EAEF,KAAM,CAEJ,MACA,aACA,aACA,QAAA,EAEF,MAAO,CAEL,OACA,WACA,QACA,SAAA,EAEF,KAAM,CAEJ,WACA,SACA,SACA,MAAA,EAEF,IAAK,CAEH,QACA,OACA,WACA,UACA,OAAA,EAEF,MAAO,CAEL,SACA,OACA,YACA,QAAA,EAEF,KAAM,CAEJ,QACA,QACA,SACA,OAAA,EAEF,KAAM,CAEJ,WACA,UACA,WAAA,EAEF,KAAM,CAEJ,YACA,QACA,YACA,MAAA,EAEF,IAAK,CAEH,OACA,WACA,QACA,UAAA,EAEF,MAAO,CAEL,SACA,WACA,OACA,SAAA,EAEF,IAAK,CAEH,UACA,YACA,aACA,WAAA,CACF,EAGIrC,EAAa,KAAK,UAAUD,CAAI,EACtC,OAAOsC,EAAWrC,CAAU,GAAK,CAAA,CACnC,CACF,CCjYO,MAAM2C,UAAyB9C,CAAsB,CACjD,SAAW,UACX,YAAc,UACd,kBAAoC,CAE3C,WACA,WACA,qBACA,gBACA,kBACA,eAAA,EAMF,UAAUC,EAAsB,CAC9B,OACEA,EACG,YAAA,EACA,KAAA,EACA,QAAQ,OAAQ,GAAG,EAEnB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,CAExB,CAKA,gBAAgBC,EAAsB,CACpC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,SAAW,EAAG,MAAO,GAEpC,IAAIC,EAAO,GACPuB,EAAO,GAEX,QAASrB,EAAI,EAAGA,EAAIH,EAAW,OAAQG,IAAK,CAC1C,MAAMC,EAAOJ,EAAWG,CAAC,EACnBsB,EAAOtB,EAAIH,EAAW,OAAS,EAAIA,EAAWG,EAAI,CAAC,EAAI,GAC7D,IAAIE,EAAQ,GAEZ,OAAQD,EAAA,CACN,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACHC,EAAQ,IACR,MACF,IAAK,IACL,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCoB,IAAS,IACXpB,EAAQ,IACCoB,IAAS,KAAOA,IAAS,IAClCpB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCoB,IAAS,KAAOtB,EAAI,EAAIH,EAAW,SAAWA,EAAWG,EAAI,CAAC,IAAM,KAAOH,EAAWG,EAAI,CAAC,IAAM,KACnGE,EAAQ,IACCoB,IAAS,KAAOA,IAAS,IAClCpB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IAEH,SACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCoB,IAAS,IACXpB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCoB,IAAS,IACXpB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCoB,IAAS,KAAOtB,IAAM,EACxBE,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,KACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,QACE,QAAA,CAGAA,GAASA,IAAUmB,IACrBvB,GAAQI,GAEVmB,EAAOnB,CACT,CAEA,OAAOJ,GAAQ,GACjB,CAKU,kBAA6B,CACrC,MAAO,CAEL,IACA,IACA,KACA,KACA,IACA,KACA,KACA,KACA,KACA,MACA,MACA,OACA,OACA,OACA,OACA,QACA,OACA,OACA,MACA,MACA,QACA,MACA,MACA,MACA,MACA,OACA,MAAA,CAEJ,CAKA,YAAYF,EAAwB,CAClC,MAAMsC,EAAuC,CAC3C,OAAQ,CAEN,SACA,aAAA,EAEF,SAAU,CAER,UACA,WAAA,EAEF,QAAS,CAEP,UACA,WAAA,EAEF,MAAO,CAEL,OACA,YACA,UAAA,EAEF,KAAM,CAEJ,QACA,WACA,WAAA,EAEF,MAAO,CAEL,MACA,UACA,WAAA,EAEF,OAAQ,CAEN,OACA,YACA,WAAA,EAEF,QAAS,CAEP,SACA,YACA,OAAA,EAEF,OAAQ,CAEN,QACA,WACA,SAAA,EAEF,OAAQ,CAEN,UACA,UACA,UAAA,EAEF,OAAQ,CAEN,SACA,UACA,SAAA,EAEF,QAAS,CAEP,QACA,WACA,WAAA,EAEF,OAAQ,CAEN,QACA,SACA,WAAA,EAEF,MAAO,CAEL,WACA,SAAA,EAEF,MAAO,CAEL,YACA,YACA,WAAA,EAEF,KAAM,CAEJ,SACA,WACA,UAAA,CACF,EAGIrC,EAAa,KAAK,UAAUD,CAAI,EACtC,OAAOsC,EAAWrC,CAAU,GAAK,CAAA,CACnC,CACF,CCvSO,MAAM4C,UAAwB/C,CAAsB,CAChD,SAAW,SACX,YAAc,WACd,kBAAoC,CAE3C,WACA,WACA,qBACA,gBACA,kBACA,eAAA,EAMF,UAAUC,EAAsB,CAC9B,OACEA,EACG,cACA,KAAA,EACA,QAAQ,OAAQ,GAAG,EAEnB,QAAQ,WAAY,GAAG,EACvB,QAAQ,UAAW,GAAG,EACtB,QAAQ,UAAW,GAAG,EACtB,QAAQ,WAAY,GAAG,EACvB,QAAQ,UAAW,GAAG,EACtB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,EACjB,QAAQ,KAAM,GAAG,CAExB,CAKA,gBAAgBC,EAAsB,CACpC,MAAMC,EAAa,KAAK,UAAUD,CAAI,EACtC,GAAIC,EAAW,SAAW,EAAG,MAAO,GAEpC,IAAIC,EAAO,GACPuB,EAAO,GAEX,QAASrB,EAAI,EAAGA,EAAIH,EAAW,OAAQG,IAAK,CAC1C,MAAMC,EAAOJ,EAAWG,CAAC,EACnBsB,EAAOtB,EAAIH,EAAW,OAAS,EAAIA,EAAWG,EAAI,CAAC,EAAI,GACvD0C,EAAQ1C,EAAIH,EAAW,OAAS,EAAIA,EAAWG,EAAI,CAAC,EAAI,GAC9D,IAAIE,EAAQ,GAEZ,OAAQD,EAAA,CACN,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACHC,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCoB,IAAS,IACXpB,EAAQ,IACCoB,IAAS,KAAOA,IAAS,IAClCpB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCoB,IAAS,IACXpB,EAAQ,IACCoB,IAAS,MAAQoB,IAAU,KAAOA,IAAU,KACrDxC,EAAQ,IACCoB,IAAS,KAAOA,IAAS,IAClCpB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IAECF,IAAM,IACRE,EAAQ,KAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACCoB,IAAS,IACXpB,EAAQ,IAERA,EAAQ,IAEV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IAEDA,EAAQ,IAIV,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,IAAK,IACHA,EAAQ,KACR,MACF,IAAK,IACHA,EAAQ,IACR,MACF,QACE,QAAA,CAGAA,GAASA,IAAUmB,IACrBvB,GAAQI,GAEVmB,EAAOnB,CACT,CAEA,OAAOJ,GAAQ,GACjB,CAKU,kBAA6B,CACrC,MAAO,CAAC,IAAK,KAAM,IAAK,IAAK,MAAO,MAAO,OAAQ,OAAQ,OAAQ,MAAO,OAAQ,OAAQ,QAAS,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,MAAO,OAAQ,OAAQ,MAAO,MAAO,KAAK,CAC/N,CAKA,YAAYF,EAAwB,CAClC,MAAMsC,EAAuC,CAC3C,QAAS,CAEP,UACA,WAAA,EAEF,QAAS,CAEP,WACA,gBAAA,EAEF,MAAO,CAEL,gBACA,aAAA,EAEF,QAAS,CAEP,aACA,WACA,MAAA,EAEF,OAAQ,CAEN,WACA,YACA,YAAA,EAEF,IAAK,CAEH,SACA,YACA,MAAA,EAEF,MAAO,CAEL,OACA,UACA,eAAA,EAEF,QAAS,CAEP,SACA,aACA,QAAA,EAEF,OAAQ,CAEN,UACA,UACA,SAAA,EAEF,MAAO,CAEL,QACA,UACA,QAAA,EAEF,MAAO,CAEL,SACA,UACA,aAAA,EAEF,MAAO,CAEL,YACA,SACA,QAAA,EAEF,OAAQ,CAEN,OACA,WACA,QAAA,EAEF,KAAM,CAEJ,YACA,WAAA,EAEF,IAAK,CAEH,YACA,UACA,YAAA,EAEF,QAAS,CAEP,WACA,UACA,UAAA,EAEF,QAAS,CAEP,SACA,UACA,MAAA,EAEF,OAAQ,CAEN,aACA,WACA,cAAA,CACF,EAGIrC,EAAa,KAAK,UAAUD,CAAI,EACtC,OAAOsC,EAAWrC,CAAU,GAAK,CAAA,CACnC,CAKU,sBAAiD,CACzD,MAAO,CACL,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,IACA,GAAA,EAEF,EAAG,CAED,IACA,IACA,IACA,GAAA,CACF,CAEJ,CACF,CC9fO,MAAM8C,CAAiB,CAC5B,OAAe,WAAa,IAAI,IAA+B,CAC7D,CAAC,SAAU,IAAIvB,CAAiB,EAChC,CAAC,UAAW,IAAIe,CAAkB,EAClC,CAAC,UAAW,IAAIK,CAAkB,EAClC,CAAC,SAAU,IAAIC,CAAiB,CAAA,CACjC,EAKD,OAAO,aAAaG,EAAiD,CACnE,OAAO,KAAK,WAAW,IAAIA,EAAS,aAAa,CACnD,CAKA,OAAO,cAAcC,EAA0C,CAC7D,OAAOA,EAAU,IAAKvD,GAAS,KAAK,aAAaA,CAAI,CAAC,EAAE,OAAQwD,GAA8CA,IAAc,MAAS,CACvI,CAKA,OAAO,uBAAkC,CACvC,OAAO,MAAM,KAAK,KAAK,WAAW,MAAM,CAC1C,CAKA,OAAO,kBAAkBA,EAAoC,CAC3D,KAAK,WAAW,IAAIA,EAAU,SAAS,YAAA,EAAeA,CAAS,CACjE,CAKA,OAAO,YAAYF,EAA2B,CAC5C,OAAO,KAAK,WAAW,IAAIA,EAAS,aAAa,CACnD,CAKA,OAAO,kBAIJ,CACD,OAAO,MAAM,KAAK,KAAK,WAAW,QAAQ,EAAE,IAAKE,IAAe,CAC9D,SAAUA,EAAU,SACpB,YAAaA,EAAU,YACvB,kBAAmBA,EAAU,iBAAA,EAC7B,CACJ,CACF,0NCxDO,MAAMC,EAAc,CACjB,KAAY,CAAA,EACZ,QACA,MACA,QAER,YAAYC,EAAkBC,EAAkB,IAAMC,EAA0B,CAC9E,KAAK,QAAUF,EACf,KAAK,QAAUC,EACf,KAAK,MAAQC,CACf,CAKA,SAAa,CACX,MAAMC,EAAM,KAAK,KAAK,IAAA,EACtB,OAAIA,IAAQ,OACHA,EAEF,KAAK,QAAA,CACd,CAKA,QAAQA,EAAc,CAChB,KAAK,KAAK,OAAS,KAAK,UACtB,KAAK,OACP,KAAK,MAAMA,CAAG,EAEhB,KAAK,KAAK,KAAKA,CAAG,EAEtB,CAKA,OAAc,CACZ,KAAK,KAAO,CAAA,CACd,CAKA,MAAe,CACb,OAAO,KAAK,KAAK,MACnB,CACF,CAOO,MAAMC,EAAa,CAChB,KAAc,CAAA,EACd,QAER,YAAYH,EAAkB,IAAM,CAClC,KAAK,QAAUA,CACjB,CAKA,QAAQI,EAAqB,CAC3B,OAAI,KAAK,KAAK,OAAS,EACd,KAAK,KAAK,IAAA,EAEZ,CAAA,CACT,CAKA,QAAQC,EAAgB,CAClB,KAAK,KAAK,OAAS,KAAK,UAE1BA,EAAI,OAAS,EACb,KAAK,KAAK,KAAKA,CAAG,EAEtB,CAKA,OAAc,CACZ,KAAK,KAAO,CAAA,CACd,CAKA,MAAe,CACb,OAAO,KAAK,KAAK,MACnB,CACF,CAKO,MAAMC,EAAkB,IAAIH,GAAe,GAAG,EAK9C,SAASI,GACdC,EACAC,EACG,CACH,MAAMJ,EAAMC,EAAgB,QAAQE,CAAI,EACxC,GAAI,CACF,OAAOC,EAAGJ,CAAG,CACf,QAAA,CACEC,EAAgB,QAAQD,CAAG,CAC7B,CACF,CAKO,MAAMK,EAAc,CACjB,KAAoB,CAAA,EACpB,QAER,YAAYV,EAAkB,IAAK,CACjC,KAAK,QAAUA,CACjB,CAKA,SAAqB,CACnB,MAAMW,EAAM,KAAK,KAAK,IAAA,EACtB,OAAIA,IAAQ,OACHA,MAEE,GACb,CAKA,QAAQA,EAAsB,CACxB,KAAK,KAAK,OAAS,KAAK,UAC1BA,EAAI,MAAA,EACJ,KAAK,KAAK,KAAKA,CAAG,EAEtB,CAKA,OAAc,CACZ,KAAK,KAAO,CAAA,CACd,CAKA,MAAe,CACb,OAAO,KAAK,KAAK,MACnB,CACF,CAKO,MAAMC,EAAW,CACd,KAAiB,CAAA,EACjB,QAER,YAAYZ,EAAkB,IAAK,CACjC,KAAK,QAAUA,CACjB,CAKA,SAAkB,CAChB,MAAMa,EAAM,KAAK,KAAK,IAAA,EACtB,OAAIA,IAAQ,OACHA,MAEE,GACb,CAKA,QAAQA,EAAmB,CACrB,KAAK,KAAK,OAAS,KAAK,UAC1BA,EAAI,MAAA,EACJ,KAAK,KAAK,KAAKA,CAAG,EAEtB,CAKA,OAAc,CACZ,KAAK,KAAO,CAAA,CACd,CAKA,MAAe,CACb,OAAO,KAAK,KAAK,MACnB,CACF,CAKO,MAAMC,GAAgB,IAAIJ,GAAkB,GAAG,EACzCK,GAAgB,IAAIH,GAAa,GAAG,EC3M1C,SAASI,EAEdpD,EACAC,EACAoD,EAAsB,IACd,CACR,MAAMlD,EAAOH,EAAK,OACZI,EAAOH,EAAK,OAGlB,GAAI,KAAK,IAAIE,EAAOC,CAAI,EAAIiD,EAC1B,OAAOA,EAAc,EAGvB,GAAIlD,IAAS,EAAG,OAAOC,EACvB,GAAIA,IAAS,EAAG,OAAOD,EACvB,GAAIH,IAASC,EAAM,MAAO,GAG1B,MAAMqD,EAAcZ,EAAgB,QAAQtC,EAAO,CAAC,EAC9CmD,EAAab,EAAgB,QAAQtC,EAAO,CAAC,EAEnD,GAAI,CAEF,QAASC,EAAI,EAAGA,GAAKD,EAAMC,IACzBiD,EAAYjD,CAAC,EAAIA,EAGnB,QAAS,EAAI,EAAG,GAAKF,EAAM,IAAK,CAC9BoD,EAAW,CAAC,EAAI,EAChB,IAAIC,EAAW,EAEf,QAASnD,EAAI,EAAGA,GAAKD,EAAMC,IAAK,CAC9B,MAAMC,EAAON,EAAK,EAAI,CAAC,IAAMC,EAAKI,EAAI,CAAC,EAAI,EAAI,EAE/CkD,EAAWlD,CAAC,EAAI,KAAK,IACnBkD,EAAWlD,EAAI,CAAC,EAAI,EACpBiD,EAAYjD,CAAC,EAAI,EACjBiD,EAAYjD,EAAI,CAAC,EAAIC,CAAA,EAGvBkD,EAAW,KAAK,IAAIA,EAAUD,EAAWlD,CAAC,CAAC,CAC7C,CAGA,GAAImD,EAAWH,EACb,OAAOA,EAAc,EAIvB,QAAShD,EAAI,EAAGA,GAAKD,EAAMC,IACzBiD,EAAYjD,CAAC,EAAIkD,EAAWlD,CAAC,CAEjC,CAEA,OAAOiD,EAAYlD,CAAI,CACzB,QAAA,CAEEsC,EAAgB,QAAQY,CAAW,EACnCZ,EAAgB,QAAQa,CAAU,CACpC,CACF,CAMO,SAASE,EAAoCzD,EAAcC,EAAcoD,EAAsB,IAAkB,CACtH,MAAMlD,EAAOH,EAAK,OACZI,EAAOH,EAAK,OAElB,GAAI,KAAK,IAAIE,EAAOC,CAAI,EAAIiD,EAC1B,OAAOA,EAAc,EAGvB,GAAIlD,IAAS,EAAG,OAAOC,EACvB,GAAIA,IAAS,EAAG,OAAOD,EACvB,GAAIH,IAASC,EAAM,MAAO,GAE1B,MAAMyD,EAAS,KAAK,IAAIvD,EAAMC,CAAI,EAC5BuD,EAAgB,CAAA,EAChBC,EAAMF,EAAS,EAGrB,QAASvE,EAAI,EAAGA,GAAKgB,EAAO,EAAGhB,IAC7BwE,EAAExE,CAAC,EAAI,IAAI,MAAMiB,EAAO,CAAC,EAAE,KAAKwD,CAAG,EAGrCD,EAAE,CAAC,EAAE,CAAC,EAAIC,EACV,QAASzE,EAAI,EAAGA,GAAKgB,EAAMhB,IACzBwE,EAAExE,EAAI,CAAC,EAAE,CAAC,EAAIyE,EACdD,EAAExE,EAAI,CAAC,EAAE,CAAC,EAAIA,EAEhB,QAASkB,EAAI,EAAGA,GAAKD,EAAMC,IACzBsD,EAAE,CAAC,EAAEtD,EAAI,CAAC,EAAIuD,EACdD,EAAE,CAAC,EAAEtD,EAAI,CAAC,EAAIA,EAGhB,MAAMwD,MAAc,IAEpB,QAAS1E,EAAI,EAAGA,GAAKgB,EAAMhB,IAAK,CAC9B,IAAI2E,EAAe,EAEnB,QAASzD,EAAI,EAAGA,GAAKD,EAAMC,IAAK,CAC9B,MAAMT,EAAQI,EAAKb,EAAI,CAAC,EAClBU,EAAQI,EAAKI,EAAI,CAAC,EAClB0D,EAAeF,EAAQ,IAAIhE,CAAK,GAAK,EAE3C,IAAIS,EAAO,EACPV,IAAUC,IACZS,EAAO,EACPwD,EAAezD,GAGjBsD,EAAExE,EAAI,CAAC,EAAEkB,EAAI,CAAC,EAAI,KAAK,IACrBsD,EAAExE,CAAC,EAAEkB,CAAC,EAAIC,EACVqD,EAAExE,EAAI,CAAC,EAAEkB,CAAC,EAAI,EACdsD,EAAExE,CAAC,EAAEkB,EAAI,CAAC,EAAI,EACdsD,EAAEI,CAAY,EAAED,CAAY,GAAK3E,EAAI4E,EAAe,GAAK,GAAK1D,EAAIyD,EAAe,EAAA,CAErF,CAEAD,EAAQ,IAAI7D,EAAKb,EAAI,CAAC,EAAGA,CAAC,CAC5B,CAEA,MAAM6E,EAASL,EAAExD,EAAO,CAAC,EAAEC,EAAO,CAAC,EACnC,OAAO4D,EAASX,EAAcA,EAAc,EAAIW,CAClD,CAkBO,SAASC,EAAyBjE,EAAcC,EAAc,EAAY,EAAW,CAC1F,GAAID,IAASC,EAAM,MAAO,GAC1B,GAAID,EAAK,SAAW,GAAKC,EAAK,SAAW,EAAG,MAAO,GAEnD,MAAMiE,EAAUC,EAAenE,EAAM,CAAC,EAChCoE,EAAUD,EAAelE,EAAM,CAAC,EAEtC,GAAIiE,EAAQ,SAAW,GAAKE,EAAQ,SAAW,EAAG,MAAO,GACzD,GAAIF,EAAQ,SAAW,GAAKE,EAAQ,SAAW,EAAG,MAAO,GAEzD,MAAMC,EAAO,IAAI,IAAIH,CAAO,EACtBI,EAAO,IAAI,IAAIF,CAAO,EAG5B,IAAIG,EAAmB,EACvB,UAAWC,KAAQH,EACbC,EAAK,IAAIE,CAAI,GACfD,IAKJ,MAAME,EAAYJ,EAAK,KAAOC,EAAK,KAAOC,EAE1C,OAAOE,EAAY,EAAIF,EAAmBE,EAAY,CACxD,CAgBO,SAASN,EAAeO,EAAaC,EAAqB,CAC/D,GAAID,EAAI,OAASC,EAAG,MAAO,CAACD,CAAG,EAG/B,MAAME,EAAQF,EAAI,OAASC,EAAI,EACzB5E,EAAmB,IAAI,MAAM6E,CAAK,EAExC,QAASzF,EAAI,EAAGA,EAAIyF,EAAOzF,IACzBY,EAAOZ,CAAC,EAAIuF,EAAI,MAAMvF,EAAGA,EAAIwF,CAAC,EAGhC,OAAO5E,CACT,CAeO,SAAS8E,GAAqBC,EAAkBC,EAA2B,CAChF,OAAIA,IAAc,EAAUD,IAAa,EAAI,EAAM,EAC5C,KAAK,IAAI,EAAG,EAAIA,EAAWC,CAAS,CAC7C,CAkBO,SAASC,GAAkBhF,EAAcC,EAAcgF,EAAoB,GAAK5B,EAAsB,EAAY,CAEvH,GAAIrD,IAASC,EAAM,MAAO,GAG1B,MAAMyD,EAAS,KAAK,IAAI1D,EAAK,OAAQC,EAAK,MAAM,EAKhD,GAJI,KAAK,IAAID,EAAK,OAASC,EAAK,MAAM,EAAIoD,GAGzBY,EAAyBjE,EAAMC,CAAI,EACrCgF,EAAY,GAAK,MAAO,GAGvC,MAAMH,EAAW1B,EAA6BpD,EAAMC,EAAMoD,CAAW,EAGrE,OAFmBwB,GAAqBC,EAAUpB,CAAM,GAEnCuB,CACvB,CCvQO,MAAMC,CAAK,CACR,KACA,KAER,aAAc,CACZ,KAAK,KAAO,KAAK,WAAA,EACjB,KAAK,KAAO,CACd,CAEQ,YAAuB,CAC7B,MAAO,CACL,aAAc,IACd,YAAa,GACb,WAAY,GAAI,CAEpB,CAKA,OAAOC,EAAcC,EAAwB,CAC3C,GAAI,CAACD,EAAM,OAEX,IAAIE,EAAO,KAAK,KAEhB,UAAWjG,KAAQ+F,EACZE,EAAK,SAAS,IAAIjG,CAAI,GACzBiG,EAAK,SAAS,IAAIjG,EAAM,KAAK,YAAY,EAE3CiG,EAAOA,EAAK,SAAS,IAAIjG,CAAI,EAG/BiG,EAAK,YAAc,GACnBA,EAAK,KAAOF,EACZC,EAAO,QAAQE,GAAMD,EAAK,OAAO,IAAIC,CAAE,CAAC,EACxC,KAAK,MACP,CAMA,eAAexE,EAA2C,CACxD,GAAI,CAACA,EAAQ,MAAO,CAAA,EAGpB,IAAIuE,EAAO,KAAK,KAChB,UAAWjG,KAAQ0B,EAAQ,CACzB,GAAI,CAACuE,EAAK,SAAS,IAAIjG,CAAI,EACzB,MAAO,CAAA,EAETiG,EAAOA,EAAK,SAAS,IAAIjG,CAAI,CAC/B,CAGA,MAAMmG,EAAqC,CAAA,EAC3C,YAAK,aAAaF,EAAME,CAAO,EACxBA,CACT,CAKA,IAAIJ,EAAuB,CACzB,IAAIE,EAAO,KAAK,KAChB,UAAWjG,KAAQ+F,EAAM,CACvB,GAAI,CAACE,EAAK,SAAS,IAAIjG,CAAI,EACzB,MAAO,GAETiG,EAAOA,EAAK,SAAS,IAAIjG,CAAI,CAC/B,CACA,OAAOiG,EAAK,WACd,CAKA,IAAIF,EAA+B,CACjC,IAAIE,EAAO,KAAK,KAChB,UAAWjG,KAAQ+F,EAAM,CACvB,GAAI,CAACE,EAAK,SAAS,IAAIjG,CAAI,EACzB,OAAO,KAETiG,EAAOA,EAAK,SAAS,IAAIjG,CAAI,CAC/B,CACA,OAAOiG,EAAK,YAAc,MAAM,KAAKA,EAAK,MAAM,EAAI,IACtD,CAKQ,aAAaA,EAAgBE,EAA0C,CACzEF,EAAK,aAAeA,EAAK,MAC3BE,EAAQ,KAAK,CAACF,EAAK,KAAM,MAAM,KAAKA,EAAK,MAAM,CAAC,CAAC,EAGnD,UAAWG,KAASH,EAAK,SAAS,OAAA,EAChC,KAAK,aAAaG,EAAOD,CAAO,CAEpC,CAKA,SAAkB,CAChB,OAAO,KAAK,IACd,CAKA,OAAc,CACZ,KAAK,KAAO,KAAK,WAAA,EACjB,KAAK,KAAO,CACd,CAKA,QAAc,CACZ,MAAO,CACL,KAAM,KAAK,cAAc,KAAK,IAAI,EAClC,KAAM,KAAK,IAAA,CAEf,CAKA,OAAO,SAASE,EAAiB,CAC/B,MAAMC,EAAO,IAAIR,EACjB,OAAAQ,EAAK,KAAOR,EAAK,gBAAgBO,EAAK,IAAI,EAC1CC,EAAK,KAAOD,EAAK,KACVC,CACT,CAEQ,cAAcL,EAAqB,CACzC,MAAO,CACL,SAAU,MAAM,KAAKA,EAAK,SAAS,SAAS,EAAE,IAAI,CAAC,CAACjG,EAAMoG,CAAK,IAAM,CACnEpG,EACA,KAAK,cAAcoG,CAAK,CAAA,CACzB,EACD,YAAaH,EAAK,YAClB,OAAQ,MAAM,KAAKA,EAAK,MAAM,EAC9B,KAAMA,EAAK,IAAA,CAEf,CAEA,OAAe,gBAAgBI,EAAqB,CAClD,MAAMJ,EAAiB,CACrB,aAAc,IACd,YAAaI,EAAK,YAClB,OAAQ,IAAI,IAAIA,EAAK,MAAM,EAC3B,KAAMA,EAAK,IAAA,EAGb,SAAW,CAACrG,EAAMuG,CAAS,IAAKF,EAAK,SACnCJ,EAAK,SAAS,IAAIjG,EAAM8F,EAAK,gBAAgBS,CAAS,CAAC,EAGzD,OAAON,CACT,CACF,CC/IO,MAAMO,EAAkC,CAC7C,GAAI,IACJ,EAAG,IACH,OAAQ,EACV,EAkCO,SAASC,GAAaV,EAAcW,EAA0BlH,EAAqBgH,EAA6B,CACrH,MAAMG,EAAKD,EAAY,oBAAoB,IAAIX,CAAI,GAAK,EAClDa,EAAIF,EAAY,UAGtB,GAAIC,IAAO,GAAKC,IAAM,EACpB,OAAOpH,EAAO,OAIhB,MAAMqH,EAAM,KAAK,KAAKD,EAAID,EAAK,KAAQA,EAAK,IAAO,CAAC,EAGpD,OAAO,KAAK,IAAIE,EAAKrH,EAAO,MAAM,CACpC,CAKO,SAASsH,GAAmBf,EAAcgB,EAAyBL,EAA0BlH,EAAqBgH,EAA6B,CACpJ,MAAMQ,EAAKD,EAAS,gBAAgB,IAAIhB,CAAI,GAAK,EAGjD,GAAIiB,IAAO,EACT,MAAO,GAGT,MAAMH,EAAMJ,GAAaV,EAAMW,EAAalH,CAAM,EAC5CyH,EAAYF,EAAS,OACrBG,EAAeR,EAAY,aAG3BS,EAAYH,GAAMxH,EAAO,GAAK,GAC9B4H,EAAcJ,EAAKxH,EAAO,IAAM,EAAIA,EAAO,EAAIA,EAAO,GAAKyH,EAAYC,IAE7E,OAAOL,GAAOM,EAAYC,EAC5B,CAMO,SAASC,GAAmBC,EAAsBP,EAAyBL,EAA0BlH,EAAqBgH,EAA6B,CAC5J,IAAIe,EAAa,EAEjB,UAAWxB,KAAQuB,EACjBC,GAAcT,GAAmBf,EAAMgB,EAAUL,EAAalH,CAAM,EAGtE,OAAO+H,CACT,CAMO,SAASC,GAAiBC,EAAyC,CACxE,MAAMC,EAAYD,EAAU,OAC5B,IAAIE,EAAc,EAClB,MAAMC,MAA0B,IAEhC,UAAWC,KAAOJ,EAAW,CAC3BE,GAAeE,EAAI,OAGnB,MAAMC,EAAc,IAAI,IAAID,EAAI,gBAAgB,MAAM,EACtD,UAAW9B,KAAQ+B,EACjBF,EAAoB,IAAI7B,GAAO6B,EAAoB,IAAI7B,CAAI,GAAK,GAAK,CAAC,CAE1E,CAEA,MAAMmB,EAAeQ,EAAY,EAAIC,EAAcD,EAAY,EAE/D,MAAO,CACL,UAAAA,EACA,aAAAR,EACA,oBAAAU,CAAA,CAEJ,CAMO,SAASG,GAAmBC,EAAeC,EAAmB,GAAY,CAC/E,GAAIA,IAAa,EAAG,MAAO,GAI3B,MAAMC,EAAeF,EAAQC,EAAY,EAAI,EAC7C,MAAO,IAAK,EAAI,KAAK,IAAI,CAACC,CAAW,EACvC,CAMO,SAASC,GAAcC,EAAmBC,EAAoBC,EAAqB,GAAKC,EAAsB,GAAa,CAEhI,MAAMC,EAAcF,EAAaC,EAC3BE,EAAuBH,EAAaE,EACpCE,EAAwBH,EAAcC,EAG5C,OAAOC,EAAuBL,EAAYM,EAAwBL,CACpE,CCzJO,MAAMM,CAAY,CACf,SACA,KACA,iBACA,YAAsB,EAE9B,YAAYnJ,EAA2B,CAIrC,MAAM,EAAIA,EAAO,iBACXoJ,EAAIpJ,EAAO,kBAEjB,KAAK,KAAO,KAAK,KAAK,EAAE,EAAI,KAAK,IAAIoJ,CAAC,GAAK,KAAK,IAAI,CAAC,GAAK,CAAC,EAI3D,KAAK,iBAAmB,KAAK,KAAM,KAAK,KAAO,EAAK,KAAK,IAAI,CAAC,CAAC,EAG/D,KAAK,SAAW,IAAI,WAAW,KAAK,KAAK,KAAK,KAAO,CAAC,CAAC,CACzD,CAKA,IAAIxD,EAAoB,CACtB,MAAMyD,EAAS,KAAK,UAAUzD,CAAI,EAElC,UAAW0D,KAAQD,EAAQ,CACzB,MAAME,EAAY,KAAK,MAAMD,EAAO,CAAC,EAC/BE,EAAWF,EAAO,EACxB,KAAK,SAASC,CAAS,GAAK,GAAKC,CACnC,CAEA,KAAK,aACP,CAQA,aAAa5D,EAAuB,CAClC,MAAMyD,EAAS,KAAK,UAAUzD,CAAI,EAElC,UAAW0D,KAAQD,EAAQ,CACzB,MAAME,EAAY,KAAK,MAAMD,EAAO,CAAC,EAC/BE,EAAWF,EAAO,EAExB,IAAK,KAAK,SAASC,CAAS,EAAK,GAAKC,KAAe,EACnD,MAAO,EAEX,CAEA,MAAO,EACT,CAMQ,UAAU5D,EAAwB,CACxC,MAAM6D,EAAQ,KAAK,KAAK7D,EAAM,CAAC,EACzB8D,EAAQ,KAAK,KAAK9D,EAAM,CAAC,EAEzByD,EAAmB,CAAA,EAEzB,QAAS9I,EAAI,EAAGA,EAAI,KAAK,iBAAkBA,IAAK,CAE9C,MAAMoJ,GAAgBF,EAAQlJ,EAAImJ,GAAS,KAAK,KAChDL,EAAO,KAAK,KAAK,IAAIM,CAAY,CAAC,CACpC,CAEA,OAAON,CACT,CAKQ,KAAKvD,EAAa8D,EAAsB,CAC9C,IAAIN,EAAO,WAAaM,EAExB,QAASrJ,EAAI,EAAGA,EAAIuF,EAAI,OAAQvF,IAC9B+I,GAAQxD,EAAI,WAAWvF,CAAC,EACxB+I,IAASA,GAAQ,IAAMA,GAAQ,IAAMA,GAAQ,IAAMA,GAAQ,IAAMA,GAAQ,IAG3E,OAAOA,IAAS,CAClB,CAMA,sBAA+B,CAC7B,GAAI,KAAK,cAAgB,EAAG,MAAO,GAInC,MAAMO,EAAI,KAAK,iBACT,EAAI,KAAK,YACTC,EAAI,KAAK,KAEf,OAAO,KAAK,IAAI,EAAI,KAAK,IAAK,CAACD,EAAI,EAAKC,CAAC,EAAGD,CAAC,CAC/C,CAKA,UAME,CACA,MAAO,CACL,KAAM,KAAK,KACX,iBAAkB,KAAK,iBACvB,YAAa,KAAK,YAClB,kBAAmB,KAAK,qBAAA,EACxB,YAAa,KAAK,SAAS,UAAA,CAE/B,CAKA,OAAc,CACZ,KAAK,SAAS,KAAK,CAAC,EACpB,KAAK,YAAc,CACrB,CAKA,QAKE,CACA,MAAO,CACL,SAAU,MAAM,KAAK,KAAK,QAAQ,EAClC,KAAM,KAAK,KACX,iBAAkB,KAAK,iBACvB,YAAa,KAAK,WAAA,CAEtB,CAKA,OAAO,SAAShD,EAAwG,CAEtH,MAAMkD,EAAS,IAAIZ,EAAY,CAC7B,iBAAkB,IAClB,kBAAmB,GAAA,CACpB,EAGD,OAAAY,EAAO,SAAW,IAAI,WAAWlD,EAAK,QAAQ,EAC9CkD,EAAO,KAAOlD,EAAK,KACnBkD,EAAO,iBAAmBlD,EAAK,iBAC/BkD,EAAO,YAAclD,EAAK,YAEnBkD,CACT,CACF,CAKO,SAASC,GAAkBC,EAA0BC,EAA4B,IAAmB,CACzG,OAAO,IAAIf,EAAY,CACrB,iBAAAc,EACA,kBAAAC,CAAA,CACD,CACH,CCzLO,MAAMC,GAAwB,4CAoB9B,SAASC,EACdlK,EACAmK,EAOI,GACM,CACV,KAAM,CAAE,UAAAC,EAAY,GAAO,UAAAC,EAAY,EAAG,UAAAC,EAAY,IAAUH,EAGhE,IAAII,EAASvK,EAAK,MAAMiK,EAAqB,EAG7C,OAAKG,IACHG,EAASA,EAAO,OAAQC,GAAUA,EAAM,OAAS,CAAC,GAIhDH,EAAY,IACdE,EAASA,EAAO,OAAQC,GAAUA,EAAM,QAAUH,CAAS,GAIzDC,IACFC,EAASA,EAAO,IAAKC,GAAUA,EAAM,aAAa,GAG7CD,CACT,CC9CO,SAASE,EAEdC,EACAC,EACA7K,EACA8K,EACiE,CACjE,MAAM7C,EAAgC,CAAA,EAChC8C,EAA+B,CACnC,mBAAoB,IACpB,SAAU,IAAIzE,EACd,uBAAwB,IACxB,oBAAqB,IACrB,sBAAuB,IACvB,iBAAkB,IAClB,UAAW,EACX,aAAc,CAAA,EAGhB,IAAI6B,EAAc,EACd6C,EAAQ,EAGZ,UAAW7K,KAAQyK,EAAO,CACxB,GAAI,CAACzK,GAAQA,EAAK,OAAO,OAASH,EAAO,eAAgB,SAEzD,MAAMiL,EAAc9K,EAAK,KAAA,EAGzB,UAAWkD,KAAawH,EAAoB,CAC1C,MAAMzK,EAAaiD,EAAU,UAAU4H,CAAW,EAC5CC,EAAeJ,EAAW,IAAI,UAAU,GAAKzH,EAAU,kBAAkB,SAAS,UAAU,EAAIA,EAAU,gBAAgB4H,CAAW,EAAI,OAEzI1I,EAAgBuI,EAAW,IAAI,UAAU,GAAKzH,EAAU,kBAAkB,SAAS,UAAU,EAAIA,EAAU,mBAAmB4H,CAAW,EAAI,OAG7I5C,EAAwB,CAC5B,GAAI2C,EACJ,KAAMC,EACN,WAAA7K,EACA,aAAA8K,EACA,SAAU7H,EAAU,SACpB,cAAed,GAAiBA,EAAc,OAAS,EAAIA,EAAgB,MAAA,EAG7E0F,EAAU,KAAKI,CAAG,EAClBF,GAAe/H,EAAW,OAG1B+K,EAAiBJ,EAAc,eAAgB3K,EAAY4K,CAAK,EAChED,EAAc,SAAU,OAAO3K,EAAY,CAAC4K,CAAK,CAAC,EAGlD,MAAMI,EAAYH,EAAY,YAAA,EAC9BE,EAAiBJ,EAAc,eAAgBK,EAAWJ,CAAK,EAC/DD,EAAc,SAAU,OAAOK,EAAW,CAACJ,CAAK,CAAC,EAIjD,MAAMP,EAASL,EAASa,EAAa,CAAE,UAAW,GAAM,UAAW,EAAG,EAyCtE,GAxCIR,EAAO,OAAS,GAElBA,EAAO,QAASC,GAAU,CACpBA,EAAM,QAAU1K,EAAO,iBACzBmL,EAAiBJ,EAAc,eAAgBL,EAAOM,CAAK,EAC3DD,EAAc,SAAU,OAAOL,EAAO,CAACM,CAAK,CAAC,EAEjD,CAAC,EAICF,EAAW,IAAI,eAAe,GACfzH,EAAU,gBAAgB4H,EAAajL,EAAO,WAAW,EACjE,QAASqL,GAAY,CAC5BF,EAAiBJ,EAAc,eAAgBM,EAASL,CAAK,EAC7DD,EAAc,SAAU,OAAOM,EAAS,CAACL,CAAK,CAAC,CACjD,CAAC,EAICE,GACFC,EAAiBJ,EAAc,mBAAoBG,EAAcF,CAAK,EAIzDzF,EAAenF,EAAYJ,EAAO,SAAS,EACnD,QAASsL,GAAU,CACxBH,EAAiBJ,EAAc,gBAAiBO,EAAON,CAAK,CAC9D,CAAC,EAGGzI,GAAiBA,EAAc,OAAS,GAC1CA,EAAc,QAASC,GAAS,CAC9B,MAAM+I,EAAiBlI,EAAU,UAAUb,CAAI,EAC/C2I,EAAiBJ,EAAc,eAAgBQ,EAAgBP,CAAK,EACpED,EAAc,SAAU,OAAOQ,EAAgB,CAACP,CAAK,CAAC,CACxD,CAAC,EAICF,EAAW,IAAI,UAAU,IACVzH,EAAU,YAAYjD,CAAU,EACxC,QAASoL,GAAY,CAC5BL,EAAiBJ,EAAc,kBAAmBS,EAASR,CAAK,CAClE,CAAC,EAGGhL,EAAO,gBAAgB,CACzB,MAAMyL,EAAiBzL,EAAO,eAAeI,CAAU,EACnDqL,GACFA,EAAe,QAASD,GAAY,CAClCL,EAAiBJ,EAAc,kBAAmBS,EAASR,CAAK,CAClE,CAAC,CAEL,CAGFA,GACF,CACF,CAMA,GAJAD,EAAc,UAAYC,EAC1BD,EAAc,aAAe5C,EAAc,KAAK,IAAI,EAAG6C,CAAK,EAGxDhL,EAAO,QAAS,CAClB,MAAMoI,MAA0B,IAC1BsD,MAAsB,IAG5B,SAAW,CAACnF,EAAMoF,CAAO,IAAKZ,EAAc,eAAe,UACzD3C,EAAoB,IAAI7B,EAAMoF,EAAQ,OAAO,MAAM,EAIrD1D,EAAU,QAASI,GAAQ,CACzBqD,EAAgB,IAAIrD,EAAI,GAAIA,EAAI,WAAW,MAAM,CACnD,CAAC,EAED0C,EAAc,UAAY,CACxB,oBAAA3C,EACA,gBAAAsD,CAAA,CAEJ,CAKA,GAF6B1L,EAAO,gBAAkB4K,EAAM,QAAU,IAE5C,CACxB,MAAMV,EAAoBlK,EAAO,8BAAgC,IAC3D4L,EAAc,IAAIzC,EAAY,CAClC,iBAAkB4B,EAAc,eAAe,KAC/C,kBAAAb,CAAA,CACD,EAGD,UAAW3D,KAAQwE,EAAc,eAAe,KAAA,EAC9Ca,EAAY,IAAIrF,CAAI,EAGtBwE,EAAc,YAAca,CAC9B,CAEA,MAAO,CAAE,cAAAb,EAAe,UAAA9C,CAAA,CAC1B,CAMO,SAAS4D,GAEdd,EACA9C,EACA6D,EACAC,EACA/L,EACe,CACf,MAAMgM,MAAc,IACdlB,EAAa,IAAI,IAAI9K,EAAO,QAAQ,EAG1C,UAAWqD,KAAa0I,EAAY,CAClC,MAAME,EAAkB5I,EAAU,UAAUyI,EAAM,MAAM,EAGxDI,GAAyBD,EAAiBlB,EAAe9C,EAAW+D,EAAS3I,EAAU,QAAQ,EAG/F8I,GAA0BF,EAAiBlB,EAAe9C,EAAW+D,EAAS3I,EAAU,QAAQ,EAG5FyH,EAAW,IAAI,UAAU,GAAKzH,EAAU,kBAAkB,SAAS,UAAU,GAC/E+I,GAA4BH,EAAiB5I,EAAW0H,EAAe9C,EAAW+D,CAAO,EAIvFlB,EAAW,IAAI,UAAU,GAC3BuB,GAA2BJ,EAAiBlB,EAAe9C,EAAW+D,CAAO,EAI/EM,GAAyBL,EAAiBlB,EAAe9C,EAAW+D,EAAS3I,EAAU,SAAUrD,EAAO,SAAS,EAM7G,EAFoBA,EAAO,cAAgB,QAAU+K,EAAc,eAAe,KAAO,KAAUiB,EAAQ,MAAQhM,EAAO,WAAa,KAElH8K,EAAW,IAAI,iBAAiB,GAAKA,EAAW,IAAI,eAAe,GAAKA,EAAW,IAAI,gBAAgB,IAC9HyB,GAAyBN,EAAiBlB,EAAe9C,EAAW+D,EAAS3I,EAAWrD,EAAO,gBAAiBA,CAAM,CAE1H,CAGA,OAAO,MAAM,KAAKgM,EAAQ,OAAA,CAAQ,CACpC,CAKA,SAASb,EAEPqB,EACAjG,EACAyE,EACM,CACN,IAAIW,EAAUa,EAAS,IAAIjG,CAAI,EAC1BoF,IACHA,EAAU,CAAE,KAAApF,EAAM,OAAQ,CAAA,EAAI,SAAU,IAAI,GAAI,EAChDiG,EAAS,IAAIjG,EAAMoF,CAAO,GAIvBA,EAAQ,WACXA,EAAQ,SAAW,IAAI,IAAIA,EAAQ,MAAM,GAItCA,EAAQ,SAAS,IAAIX,CAAK,IAC7BW,EAAQ,OAAO,KAAKX,CAAK,EACzBW,EAAQ,SAAS,IAAIX,CAAK,EAE9B,CAKA,SAASkB,GAEPJ,EACAf,EACA9C,EACA+D,EACA7I,EACM,CAEN,GAAI4H,EAAc,aAAe,CAACA,EAAc,YAAY,aAAae,CAAK,EAC5E,OAGF,MAAMH,EAAUZ,EAAc,eAAe,IAAIe,CAAK,EACjDH,GAELA,EAAQ,OAAO,QAASX,GAAU,CAChC,MAAM3C,EAAMJ,EAAU+C,CAAK,EACtB3C,IAEA2D,EAAQ,IAAIhB,CAAK,GACpBgB,EAAQ,IAAIhB,EAAO,CACjB,KAAM3C,EAAI,KACV,WAAYyD,EACZ,UAAW,QACX,aAAc,EACd,SAAA3I,EACA,MAAA6H,CAAA,CACD,EAEL,CAAC,CACH,CAMA,SAASmB,GAEPL,EACAf,EACA9C,EACA+D,EACA7I,EACM,CAEN,GAAI4H,EAAc,SAAU,CAC1B,MAAM0B,EAAgB1B,EAAc,SAAS,eAAee,CAAK,EAEjE,SAAW,CAACvF,EAAMC,CAAM,IAAKiG,EACvBlG,IAASuF,GAEXtF,EAAO,QAASwE,GAAkB,CAChC,MAAM3C,EAAMJ,EAAU+C,CAAK,EACtB3C,IAEA2D,EAAQ,IAAIhB,CAAK,GACpBgB,EAAQ,IAAIhB,EAAO,CACjB,KAAM3C,EAAI,KACV,WAAY9B,EACZ,UAAW,SACX,SAAApD,EACA,MAAA6H,CAAA,CACD,EAEL,CAAC,CAGP,KAEE,UAAW,CAACzE,EAAMoF,CAAO,IAAKZ,EAAc,eAAe,UACrDxE,EAAK,WAAWuF,CAAK,GAAKvF,IAASuF,GACrCH,EAAQ,OAAO,QAASX,GAAU,CAChC,MAAM3C,EAAMJ,EAAU+C,CAAK,EACtB3C,IAEA2D,EAAQ,IAAIhB,CAAK,GACpBgB,EAAQ,IAAIhB,EAAO,CACjB,KAAM3C,EAAI,KACV,WAAY9B,EACZ,UAAW,SACX,SAAApD,EACA,MAAA6H,CAAA,CACD,EAEL,CAAC,CAIT,CAKA,SAASoB,GAEPN,EACAzI,EACA0H,EACA9C,EACA+D,EACM,CACN,MAAMd,EAAe7H,EAAU,gBAAgByI,CAAK,EACpD,GAAI,CAACZ,EAAc,OAEnB,MAAMS,EAAUZ,EAAc,mBAAmB,IAAIG,CAAY,EAC5DS,GAELA,EAAQ,OAAO,QAASX,GAAU,CAChC,MAAM3C,EAAMJ,EAAU+C,CAAK,EACtB3C,IAEA2D,EAAQ,IAAIhB,CAAK,GACpBgB,EAAQ,IAAIhB,EAAO,CACjB,KAAM3C,EAAI,KACV,WAAYyD,EACZ,UAAW,WACX,aAAAZ,EACA,SAAU7H,EAAU,SACpB,MAAA2H,CAAA,CACD,EAEL,CAAC,CACH,CAKA,SAASqB,GAEPP,EACAf,EACA9C,EACA+D,EACM,CACN,MAAML,EAAUZ,EAAc,kBAAkB,IAAIe,CAAK,EACpDH,GAELA,EAAQ,OAAO,QAASX,GAAU,CAChC,MAAM3C,EAAMJ,EAAU+C,CAAK,EACtB3C,IAEA2D,EAAQ,IAAIhB,CAAK,GACpBgB,EAAQ,IAAIhB,EAAO,CACjB,KAAM3C,EAAI,KACV,WAAYyD,EACZ,UAAW,UACX,SAAU,UACV,MAAAd,CAAA,CACD,EAEL,CAAC,CACH,CAKA,SAASsB,GAEPR,EACAf,EACA9C,EACA+D,EACA7I,EACAuJ,EACM,CACN,GAAIZ,EAAM,OAASY,EAAW,OAE9B,MAAMC,EAAcpH,EAAeuG,EAAOY,CAAS,EAC7CE,MAAoB,IAG1BD,EAAY,QAASrB,GAAU,CAC7B,MAAMK,EAAUZ,EAAc,gBAAgB,IAAIO,CAAK,EACnDK,GACFA,EAAQ,OAAO,QAASX,GAAU4B,EAAc,IAAI5B,CAAK,CAAC,CAE9D,CAAC,EAGD4B,EAAc,QAAS5B,GAAU,CAC/B,MAAM3C,EAAMJ,EAAU+C,CAAK,EACtB3C,IAEA2D,EAAQ,IAAIhB,CAAK,GACpBgB,EAAQ,IAAIhB,EAAO,CACjB,KAAM3C,EAAI,KACV,WAAYyD,EACZ,UAAW,QACX,SAAA3I,EACA,MAAA6H,CAAA,CACD,EAEL,CAAC,CACH,CAMA,SAASuB,GAEPT,EACAf,EACA9C,EACA+D,EACA3I,EACAoB,EACAzE,EACM,CACN,MAAM6M,EAAWf,EAAM,OACjBgB,EAASD,EAAWpI,EACpBK,EAAS+H,EAAWpI,EAGpBsI,EAAoB/M,EAAO,UAAU,SAAS,gBAAgB,EAI9DgN,EAAcjC,EAAc,eAAe,KAC3CkC,EAAuBD,EAAc,IAAS,IAAOA,EAAc,IAAQ,KAAOA,EAAc,IAAQ,IAAOA,EAAc,IAAQ,IAAO,IAClJ,IAAIE,EAAoB,EAGpBC,EAEJ,GAAIH,EAAc,KAASlB,EAAM,QAAU,GAAKf,EAAc,SAAU,CAGtE,MAAMqC,EAAeJ,EAAc,IAAS,KAAK,IAAI,EAAGlB,EAAM,MAAM,EAAI,KAAK,IAAI,EAAGA,EAAM,MAAM,EAC1F5J,EAAS4J,EAAM,UAAU,EAAGsB,CAAY,EAI9CD,EAHsBpC,EAAc,SAAS,eAAe7I,CAAM,EAGvC,IAAI,CAAC,CAACqE,EAAM8G,CAAO,IAA0B,CAAC9G,EAAMwE,EAAc,eAAe,IAAIxE,CAAI,CAAC,CAAsC,EAAE,OAAQ+G,GAA6EA,EAAM,CAAC,IAAM,MAAS,EAGpQH,EAAW,OAAS,MACtBA,EAAa,MAAM,KAAKpC,EAAc,eAAe,SAAS,EAElE,MACEoC,EAAa,MAAM,KAAKpC,EAAc,eAAe,SAAS,EAIhEoC,EAAW,KAAK,CAACI,EAAG,IAAM,CACxB,MAAMC,EAAQ,KAAK,IAAID,EAAE,CAAC,EAAE,OAASV,CAAQ,EACvCY,EAAQ,KAAK,IAAI,EAAE,CAAC,EAAE,OAASZ,CAAQ,EAC7C,OAAOW,EAAQC,CACjB,CAAC,EAGD,SAAW,CAAClH,EAAMoF,CAAO,IAAKwB,EAAY,CAGxC,MAAMO,EAAUnH,EAAK,OACrB,GAAImH,EAAUZ,GAAUY,EAAU5I,EAChC,SAIF,GAAIoI,GAAqBD,EACvB,MAEFC,IAIA,MAAMS,EAAiB3B,EAAQ,KACzB4B,EAA4BZ,EAAc,IAAQhN,EAAO,WAAa,EAAIA,EAAO,WAAa,EAGpG,GAAI2N,GAAkBC,EAA2B,CAE/C,IAAIC,EAAkBpJ,EAClBqJ,EAAoB,GAExB,UAAWC,KAAS/B,EAAQ,SAC1B,GAAI+B,EAAM,eAAiB,OACzB,GAAIA,EAAM,eAAiB,EAAG,CAE5BD,EAAoB,GACpBD,EAAkB,EAClB,KACF,MAAWE,EAAM,cAAgB,IAC/BF,EAAkB,KAAK,IAAIA,EAAiBE,EAAM,YAAY,GAOpE,GAAID,GAAqBH,GAAkB3N,EAAO,WAAa,GAC7D,KAEJ,CAGA,GAAI8L,EAAM,OAAS,GAAKvF,EAAK,OAAS,GACd,KAAK,IAAIuF,EAAM,WAAW,CAAC,EAAIvF,EAAK,WAAW,CAAC,CAAC,EACnD,IAAM9B,EAAc,EAEtC,SAKJ,MAAMyB,EAAW6G,EAAoBlI,EAAoCiH,EAAOvF,EAAM9B,CAAW,EAAID,EAA6BsH,EAAOvF,EAAM9B,CAAW,EAEtJyB,GAAYzB,GACdkH,EAAQ,OAAO,QAASX,GAAU,CAChC,MAAM3C,EAAMJ,EAAU+C,CAAK,EAC3B,GAAI,CAAC3C,EAAK,OAEV,MAAM2F,EAAgBhC,EAAQ,IAAIhB,CAAK,GAEnC,CAACgD,IAAkBA,EAAc,cAAgB,KAAY9H,IAC/D8F,EAAQ,IAAIhB,EAAO,CACjB,KAAM3C,EAAI,KACV,WAAY9B,EACZ,UAAW,QACX,aAAcL,EACd,SAAU7C,EAAU,SACpB,MAAA2H,CAAA,CACD,CAEL,CAAC,CAEL,CACF,CAMO,SAASiD,GAAoBjC,EAAwBlE,EAAsBiD,EAA8B9C,EAA+BjI,EAAoC,CACjL,GAAI,CAACA,EAAO,SAAW,CAAC+K,EAAc,UACpC,OAAOiB,EAGT,MAAMkC,EAAa,CACjB,GAAGlH,EACH,GAAGhH,EAAO,UAAA,EAINkH,EAA2B,CAC/B,UAAW6D,EAAc,UACzB,aAAcA,EAAc,aAC5B,oBAAqBA,EAAc,UAAU,mBAAA,EAI/C,OAAOiB,EAAQ,IAAK+B,GAAU,CAC5B,GAAIA,EAAM,QAAU,OAClB,OAAOA,EAGT,MAAM1F,EAAMJ,EAAU8F,EAAM,KAAK,EACjC,GAAI,CAAC1F,EACH,OAAO0F,EAIT,MAAMI,MAAsB,IACtBC,EAAkB/F,EAAI,WAAW,YAAA,EAAc,MAAM,KAAK,EAEhE,UAAW9B,KAAQ6H,EACjBD,EAAgB,IAAI5H,GAAO4H,EAAgB,IAAI5H,CAAI,GAAK,GAAK,CAAC,EAGhE,MAAMgB,EAA0B,CAC9B,MAAOc,EAAI,GACX,OAAQ+F,EAAgB,OACxB,gBAAAD,CAAA,EAIIvF,EAAYf,GAAmBC,EAAYP,EAAUL,EAAagH,CAAU,EAC5EG,EAAiB9F,GAAmBK,CAAS,EAEnD,MAAO,CACL,GAAGmF,EACH,UAAWM,CAAA,CAEf,CAAC,CACH,CCroBO,SAASC,GAAoBP,EAAoBjC,EAAeyC,EAAuC,CAC5G,MAAMC,EAA+B,CAAA,EAC/BC,EAAoBF,EAAY,YAAA,EAChCtC,EAAkBH,EAAM,YAAA,EAE9B,OAAQiC,EAAM,UAAA,CACZ,IAAK,QAEHS,EAAW,KAAK,CACd,MAAO,EACP,IAAKD,EAAY,OACjB,KAAM,OAAA,CACP,EACD,MAEF,IAAK,SAEH,MAAMG,EAAY,KAAK,IAAIzC,EAAgB,OAAQsC,EAAY,MAAM,EACrEC,EAAW,KAAK,CACd,MAAO,EACP,IAAKE,EACL,KAAM,QAAA,CACP,EACD,MAEF,IAAK,YAEH,MAAMC,EAAiBF,EAAkB,QAAQxC,CAAe,EAC5D0C,IAAmB,IACrBH,EAAW,KAAK,CACd,MAAOG,EACP,IAAKA,EAAiB1C,EAAgB,OACtC,KAAM,WAAA,CACP,EAEH,MAEF,IAAK,QAEHuC,EAAW,KAAK,GAAGI,GAAyB3C,EAAiBwC,EAAmB,OAAO,CAAC,EACxF,MAEF,IAAK,QAEHD,EAAW,KAAK,GAAGK,GAAyB5C,EAAiBwC,CAAiB,CAAC,EAC/E,MAEF,IAAK,WACL,IAAK,UACL,IAAK,WAEHD,EAAW,KAAK,CACd,MAAO,EACP,IAAKD,EAAY,OACjB,KAAMR,EAAM,SAAA,CACb,EACD,KAAA,CAGJ,OAAOe,GAA2BN,CAAU,CAC9C,CAKA,SAASI,GAAyB9C,EAAe5L,EAAc6O,EAAmC,CAChG,MAAMP,EAA+B,CAAA,EACrC,IAAIQ,EAAW,EACXC,EAAU,EAGd,KAAOD,EAAWlD,EAAM,QAAUmD,EAAU/O,EAAK,QAC/C,GAAI4L,EAAMkD,CAAQ,IAAM9O,EAAK+O,CAAO,EAAG,CAErC,MAAMC,EAAQD,EACd,IAAIE,EAAMF,EAAU,EAKpB,IAFAD,IACAC,IACOD,EAAWlD,EAAM,QAAUmD,EAAU/O,EAAK,QAAU4L,EAAMkD,CAAQ,IAAM9O,EAAK+O,CAAO,GACzFE,IACAH,IACAC,IAGFT,EAAW,KAAK,CAAE,MAAAU,EAAO,IAAAC,EAAK,KAAAJ,EAAM,CACtC,MACEE,IAIJ,OAAOT,CACT,CAKA,SAASK,GAAyB/C,EAAe5L,EAAgC,CAC/E,MAAMsO,EAA+B,CAAA,EAIrC,QAASjO,EAAI,EAAGA,GAAKuL,EAAM,OAAS,EAAWvL,IAAK,CAClD,MAAM+K,EAAQQ,EAAM,MAAMvL,EAAGA,EAAI,CAAS,EAC1C,IAAI6O,EAAc,EAGlB,OAAa,CACX,MAAMC,EAAQnP,EAAK,QAAQoL,EAAO8D,CAAW,EAC7C,GAAIC,IAAU,GAAI,MAElBb,EAAW,KAAK,CACd,MAAOa,EACP,IAAKA,EAAQ,EACb,KAAM,OAAA,CACP,EAEDD,EAAcC,EAAQ,CACxB,CACF,CAEA,OAAOb,CACT,CAKA,SAASM,GAA2BN,EAAgD,CAClF,GAAIA,EAAW,SAAW,EAAG,MAAO,CAAA,EAGpC,MAAMc,EAAS,CAAC,GAAGd,CAAU,EAAE,KAAK,CAACjB,EAAGgC,IAAMhC,EAAE,MAAQgC,EAAE,KAAK,EACzDC,EAA2B,CAACF,EAAO,CAAC,CAAC,EAE3C,QAAS/O,EAAI,EAAGA,EAAI+O,EAAO,OAAQ/O,IAAK,CACtC,MAAMqC,EAAU0M,EAAO/O,CAAC,EAClBkP,EAAOD,EAAOA,EAAO,OAAS,CAAC,EAEjC5M,EAAQ,OAAS6M,EAAK,KAExBA,EAAK,IAAM,KAAK,IAAIA,EAAK,IAAK7M,EAAQ,GAAG,EAErC8M,GAAqB9M,EAAQ,IAAI,EAAI8M,GAAqBD,EAAK,IAAI,IACrEA,EAAK,KAAO7M,EAAQ,OAItB4M,EAAO,KAAK5M,CAAO,CAEvB,CAEA,OAAO4M,CACT,CAKA,SAASE,GAAqBX,EAAyB,CAWrD,MAV8C,CAC5C,MAAO,GACP,OAAQ,EACR,UAAW,EACX,MAAO,EACP,MAAO,EACP,SAAU,EACV,SAAU,EACV,QAAS,CAAA,EAEOA,CAAI,GAAK,CAC7B,CAKO,SAASY,GAEdzP,EACAsO,EACAoB,EAAoB,YACZ,CACR,GAAI,CAACpB,GAAcA,EAAW,SAAW,EACvC,OAAOqB,EAAW3P,CAAI,EAGxB,IAAIkF,EAAS,GACT0K,EAAU,EAEd,UAAWC,KAAavB,EAAY,CAE9BuB,EAAU,MAAQD,IACpB1K,GAAUyK,EAAW3P,EAAK,MAAM4P,EAASC,EAAU,KAAK,CAAC,GAI3D,MAAMC,EAAkB9P,EAAK,MAAM6P,EAAU,MAAOA,EAAU,GAAG,EACjE3K,GAAU,SAAS2K,EAAU,OAAS,QAAU,oBAAsB,EAAE,WAAWH,CAAS,IAAIA,CAAS,KAAKG,EAAU,IAAI,KAAKF,EAAWG,CAAe,CAAC,UAE5JF,EAAUC,EAAU,GACtB,CAGA,OAAID,EAAU5P,EAAK,SACjBkF,GAAUyK,EAAW3P,EAAK,MAAM4P,CAAO,CAAC,GAGnC1K,CACT,CAKA,SAASyK,EAAW3P,EAAsB,CACxC,MAAM+P,EAAM,OAAO,SAAa,IAAc,SAAS,cAAc,KAAK,EAAI,KAC9E,OAAIA,GACFA,EAAI,YAAc/P,EACX+P,EAAI,WAGN/P,EAAK,QAAQ,KAAM,OAAO,EAAE,QAAQ,KAAM,MAAM,EAAE,QAAQ,KAAM,MAAM,EAAE,QAAQ,KAAM,QAAQ,EAAE,QAAQ,KAAM,QAAQ,CAC/H,CC3NO,MAAMgQ,EAAe,CAClB,MACA,SAER,YAAYC,EAAmB,IAAK,CAClC,KAAK,UAAY,IACjB,KAAK,SAAWA,CAClB,CAMA,IAAIC,EAAuB,CACzB,GAAI,CAAC,KAAK,MAAM,IAAIA,CAAG,EACrB,OAIF,MAAMC,EAAQ,KAAK,MAAM,IAAID,CAAG,EAChC,YAAK,MAAM,OAAOA,CAAG,EACrB,KAAK,MAAM,IAAIA,EAAKC,CAAK,EAElBA,CACT,CAMA,IAEED,EACAC,EACM,CAUN,GARI,KAAK,MAAM,IAAID,CAAG,GACpB,KAAK,MAAM,OAAOA,CAAG,EAIvB,KAAK,MAAM,IAAIA,EAAKC,CAAK,EAGrB,KAAK,MAAM,KAAO,KAAK,SAAU,CACnC,MAAMC,EAAW,KAAK,MAAM,KAAA,EAAO,OAAO,MACtCA,IAAa,QACf,KAAK,MAAM,OAAOA,CAAQ,CAE9B,CACF,CAKA,IAAIF,EAAiB,CACnB,OAAO,KAAK,MAAM,IAAIA,CAAG,CAC3B,CAKA,OAAc,CACZ,KAAK,MAAM,MAAA,CACb,CAKA,IAAI,MAAe,CACjB,OAAO,KAAK,MAAM,IACpB,CAKA,UAKE,CACA,MAAO,CACL,KAAM,KAAK,MAAM,KACjB,SAAU,KAAK,SACf,YAAa,KAAK,MAAM,KAAO,KAAK,QAAA,CAExC,CACF,CAMO,MAAMG,EAAY,CACf,MACA,KAAe,EACf,OAAiB,EAEzB,YAAYJ,EAAmB,IAAK,CAClC,KAAK,MAAQ,IAAID,GAASC,CAAQ,CACpC,CAKQ,YAAYrE,EAAe0E,EAAqBnG,EAAuB,CAC7E,MAAMoG,EAAapG,EAAU,KAAK,UAAUA,CAAO,EAAI,GACvD,MAAO,GAAGyB,CAAK,IAAI0E,GAAc,SAAS,IAAIC,CAAU,EAC1D,CAKA,IAAI3E,EAAe0E,EAAqBnG,EAA+C,CACrF,MAAM+F,EAAM,KAAK,YAAYtE,EAAO0E,EAAYnG,CAAO,EACjDjF,EAAS,KAAK,MAAM,IAAIgL,CAAG,EAEjC,OAAIhL,EACF,KAAK,OAEL,KAAK,SAGAA,CACT,CAKA,IAAI0G,EAAenF,EAA6B6J,EAAqBnG,EAAqB,CACxF,MAAM+F,EAAM,KAAK,YAAYtE,EAAO0E,EAAYnG,CAAO,EACvD,KAAK,MAAM,IAAI+F,EAAKzJ,CAAO,CAC7B,CAKA,OAAc,CACZ,KAAK,MAAM,MAAA,EACX,KAAK,KAAO,EACZ,KAAK,OAAS,CAChB,CAKA,UAOE,CACA,MAAM+J,EAAa,KAAK,MAAM,SAAA,EACxBC,EAAQ,KAAK,KAAO,KAAK,OACzBC,EAAUD,EAAQ,EAAI,KAAK,KAAOA,EAAQ,EAEhD,MAAO,CACL,GAAGD,EACH,KAAM,KAAK,KACX,OAAQ,KAAK,OACb,QAAAE,CAAA,CAEJ,CACF,CCxKA,MAAMC,GAAqC,CAEzC,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IACrF,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAErF,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAC/F,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAAK,EAAK,IAE/F,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,KAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IAEH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IACH,EAAG,IAEH,EAAG,KACH,EAAG,KACH,EAAG,KACH,EAAG,KAEH,EAAG,KACH,EAAG,IACL,EAMMC,MAAkB,IAClBC,GAAiB,IAMhB,SAASC,EAAc9Q,EAAsB,CAClD,GAAI,CAACA,EAAM,OAAOA,EAGlB,MAAM+Q,EAASH,EAAY,IAAI5Q,CAAI,EACnC,GAAI+Q,IAAW,OACb,OAAOA,EAIT,MAAMC,EAAkB,CAAA,EACxB,QAAS3Q,EAAI,EAAGA,EAAIL,EAAK,OAAQK,IAAK,CACpC,MAAMC,EAAON,EAAKK,CAAC,EACnB2Q,EAAM,KAAKL,GAAWrQ,CAAI,GAAKA,CAAI,CACrC,CACA,IAAI4E,EAAS8L,EAAM,KAAK,EAAE,EAK1B,OAAA9L,EAASA,EAAO,UAAU,KAAK,EAAE,QAAQ,mBAAoB,EAAE,EAG3D0L,EAAY,KAAOC,GACrBD,EAAY,IAAI5Q,EAAMkF,CAAM,EACnB0L,EAAY,OAASC,KAE9BD,EAAY,MAAA,EACZA,EAAY,IAAI5Q,EAAMkF,CAAM,GAGvBA,CACT,CAMO,SAAS+L,GAAWjR,EAAuB,CAChD,GAAI,CAACA,EAAM,MAAO,GAGlB,QAASK,EAAI,EAAGA,EAAIL,EAAK,OAAQK,IAC/B,GAAIsQ,GAAW3Q,EAAKK,CAAC,CAAC,EACpB,MAAO,GAMX,MAAO,kBAAkB,KAAKL,EAAK,UAAU,KAAK,CAAC,CACrD,CAMO,SAASkR,GAAuBlR,EAAsB,CAC3D,OAAO8Q,EAAc9Q,EAAK,aAAa,CACzC,CAMO,SAASmR,GAAkBlR,EAAwB,CACxD,MAAMC,EAAa4Q,EAAc7Q,CAAI,EAGrC,OAAIC,IAAeD,EACV,CAACA,EAAMC,CAAU,EAInB,CAACD,CAAI,CACd,CCjQO,SAASmR,GAEd1L,EACA2L,EAC+B,CAO/B,GALI,CAACA,GAAUA,EAAO,SAAW,GAK7B,OAAO3L,GAAS,SAClB,OAAO,KAIT,GAAI,OAAOA,GAAS,UAAYA,IAAS,KAAM,CAC7C,MAAM4L,EAAsC,CAAA,EAE5C,UAAWC,KAASF,EAAQ,CAC1B,MAAMlB,EAAQzK,EAAK6L,CAAK,EACGpB,GAAU,OACnCmB,EAAYC,CAAK,EAAI,OAAOpB,CAAK,EAErC,CAEA,OAAO,OAAO,KAAKmB,CAAW,EAAE,OAAS,EAAIA,EAAc,IAC7D,CAEA,OAAO,IACT,CAeO,SAASE,GAEdH,EACAI,EACwB,CACxB,MAAMvR,EAAqC,CAAA,EAE3C,UAAWqR,KAASF,EAClBnR,EAAWqR,CAAK,EAAIE,IAAeF,CAAK,GAAK,EAG/C,OAAOrR,CACT,CCzDO,MAAMwR,GAA+C,CAC1D,QAAS,CAEP,IACA,KACA,MACA,MACA,KACA,KACA,KACA,KACA,MACA,OACA,MACA,KACA,KACA,KACA,KACA,MACA,KACA,KACA,OACA,MACA,KACA,MACA,OACA,OACA,MACA,OACA,MACA,OACA,OACA,MACA,OACA,OACA,QACA,MACA,QACA,MACA,KAAA,EAEF,OAAQ,CAEN,MACA,MACA,MACA,MACA,MACA,MACA,MACA,OACA,QACA,QACA,QACA,QACA,MACA,OACA,OACA,MACA,OACA,MACA,QACA,MACA,QACA,OACA,SACA,MACA,KACA,KACA,KACA,KACA,MACA,MACA,MACA,OACA,MACA,KAAA,EAEF,QAAS,CAEP,KACA,KACA,MACA,MACA,KACA,MACA,OACA,OACA,KACA,MACA,IACA,IACA,OACA,KACA,MACA,MACA,SACA,KACA,MACA,KACA,IACA,KACA,MACA,MACA,OACA,MACA,QACA,OAAA,EAEF,OAAQ,CAEN,KACA,KACA,MACA,KACA,MACA,MACA,KACA,KACA,KACA,KACA,OACA,MACA,OACA,QACA,UACA,IACA,MACA,IACA,KACA,MACA,OACA,OACA,MACA,OACA,MACA,OACA,OAAA,CAEJ,EAKO,SAASC,GACd/F,EACAgG,EACQ,CACR,MAAMC,EAAeD,aAAqB,IAAMA,EAAY,IAAI,IAAIA,EAAU,IAAIE,GAAKA,EAAE,YAAA,CAAa,CAAC,EAIjGC,EADQnG,EAAM,MAAM,KAAK,EACR,OAAO3L,GAAQ,CAAC4R,EAAa,IAAI5R,EAAK,YAAA,CAAa,CAAC,EAG3E,OAAI8R,EAAS,SAAW,EACfnG,EAGFmG,EAAS,KAAK,GAAG,CAC1B,CAKO,SAASC,GAAyB9O,EAAkC,CACzE,MAAM0O,MAAgB,IAEtB,UAAWjS,KAAQuD,EAAW,CAC5B,MAAM+O,EAAgBP,GAAmB/R,EAAK,YAAA,CAAa,EACvDsS,GACFA,EAAc,QAAShS,GAAS2R,EAAU,IAAI3R,CAAI,CAAC,CAEvD,CAEA,OAAO2R,CACT,CAKO,SAASM,GAAWjS,EAAc2R,EAA4C,CAEnF,OADqBA,aAAqB,IAAMA,EAAY,IAAI,IAAIA,EAAU,IAAKE,GAAMA,EAAE,YAAA,CAAa,CAAC,GACrF,IAAI7R,EAAK,YAAA,CAAa,CAC5C,CCpLO,SAASkS,GAAenS,EAAcoS,EAA2B,CAEtE,GAAIA,IAAa,EACf,MAAO,GAIT,MAAMC,EAAarS,EAAKoS,EAAW,CAAC,EAGpC,MAAO,6BAA6B,KAAKC,CAAU,CACrD,CAKO,SAASC,GACdtS,EACAuS,EACAC,EACS,CACT,MAAMC,EAAWF,EAAaC,EAGxBE,EAAgBP,GAAenS,EAAMuS,CAAU,EAG/CI,EAAcF,GAAYzS,EAAK,QAAU,6BAA6B,KAAKA,EAAKyS,CAAQ,CAAC,EAE/F,OAAOC,GAAiBC,CAC1B,CAKO,SAASC,GACd5S,EACA6S,EACAC,EAAyB,GACf,CACV,MAAMC,EAAsB,CAAA,EACtBC,EAAaF,EAAgB9S,EAAOA,EAAK,YAAA,EACzCiT,EAAgBH,EAAgBD,EAAUA,EAAQ,YAAA,EAExD,IAAI1D,EAAQ,EACZ,KAAOA,EAAQ6D,EAAW,QAAQ,CAChC,MAAME,EAAQF,EAAW,QAAQC,EAAe9D,CAAK,EAErD,GAAI+D,IAAU,GACZ,MAIEZ,GAAsBtS,EAAMkT,EAAOD,EAAc,MAAM,GACzDF,EAAU,KAAKG,CAAK,EAGtB/D,EAAQ+D,EAAQ,CAClB,CAEA,OAAOH,CACT,CAKO,SAASI,GAAYlT,EAAc2L,EAAewH,EAAkC,CACzF,OAAKA,EAMaR,GAAwB3S,EAAM2L,EAAO,EAAK,EAC3C,OAAS,EALjB3L,EAAK,YAAA,EAAc,SAAS2L,EAAM,aAAa,CAM1D,CAoBO,SAASyH,GAAcR,EAAyB,CAKrD,MAAMS,EAHUT,EAAQ,QAAQ,qBAAsB,MAAM,EAG/B,QAAQ,MAAO,IAAI,EAGhD,OAAO,IAAI,OAAO,IAAIS,CAAY,IAAK,GAAG,CAC5C,CAKO,SAASC,GAAgBtT,EAAc4S,EAA0B,CAEtE,OADcQ,GAAcR,CAAO,EACtB,KAAK5S,CAAI,CACxB,CCjGO,SAASuT,GAAW5H,EAA4B,CACrD,GAAI,CAACA,GAAS,OAAOA,GAAU,SAC7B,MAAO,CACL,QAAS,CAAA,EACT,MAAO,CAAA,EACP,SAAUA,GAAS,GACnB,WAAY,EAAA,EAIhB,MAAM6H,EAAoB,CAAA,EAC1B,IAAIC,EAAY9H,EAGhB,MAAM+H,EAAmB,aACzB,IAAI9F,EAEJ,MAAQA,EAAQ8F,EAAiB,KAAK/H,CAAK,KAAO,MAAM,CACtD,MAAMgI,EAAS/F,EAAM,CAAC,EAAE,KAAA,EACpB+F,GAEgBA,EAAO,MAAM,KAAK,EAAE,QACrB,IACfH,EAAQ,KAAKG,CAAM,CAGzB,CAGAF,EAAYA,EAAU,QAAQ,WAAY,GAAG,EAG7C,MAAMG,EAAmB,aAEzB,MAAQhG,EAAQgG,EAAiB,KAAKjI,CAAK,KAAO,MAAM,CACtD,MAAMgI,EAAS/F,EAAM,CAAC,EAAE,KAAA,EACpB+F,GAEgBA,EAAO,MAAM,KAAK,EAAE,QACrB,IACfH,EAAQ,KAAKG,CAAM,CAGzB,CAGAF,EAAYA,EAAU,QAAQ,WAAY,GAAG,EAG7C,MAAMI,EAAQJ,EACX,MAAM,KAAK,EACX,IAAIK,GAAKA,EAAE,KAAA,CAAM,EACjB,OAAOA,GAAKA,EAAE,OAAS,CAAC,EAE3B,MAAO,CACL,QAAAN,EACA,MAAAK,EACA,SAAUlI,EACV,WAAY6H,EAAQ,OAAS,CAAA,CAEjC,CAKO,SAASO,GAAgBpI,EAAwB,CACtD,OAAKA,EACE,UAAU,KAAKA,CAAK,GAAK,UAAU,KAAKA,CAAK,EADjC,EAErB,CAKO,SAASqI,GAAgBL,EAAwB,CACtD,OAAOA,EAAO,cAAc,OAAO,QAAQ,OAAQ,GAAG,CACxD,CAKO,SAASM,GAAiBN,EAA0B,CACzD,OAAOA,EACJ,YAAA,EACA,KAAA,EACA,MAAM,KAAK,EACX,OAAO9B,GAAKA,EAAE,OAAS,CAAC,CAC7B,CC9EA,MAAMqC,GAAgD,CACpD,WAAY,GACZ,gBAAiB,EACjB,eAAgB,IAChB,qBAAsB,EACtB,kBAAmB,EACrB,EAKO,SAASC,GAEdpU,EACA4T,EACAzJ,EAA8B,CAAA,EACX,CACnB,MAAMkK,EAAO,CAAE,GAAGF,GAAiB,GAAGhK,CAAA,EAEtC,GAAI,CAACnK,GAAQ,CAAC4T,EACZ,MAAO,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,EAGhD,MAAMU,EAAiBtU,EAAK,YAAA,EACtBuU,EAAmBX,EAAO,YAAA,EAG1BY,EAAaC,GAAgBH,EAAgBC,CAAgB,EACnE,GAAIC,EAAW,QACb,MAAO,CAAE,GAAGA,EAAY,MAAO,EAAK,UAAW,OAAA,EAIjD,GAAIH,EAAK,WACP,MAAO,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,EAIhD,MAAMK,EAAaC,GAAgBL,EAAgBC,EAAkBF,EAAK,gBAAiBA,EAAK,iBAAiB,EACjH,GAAIK,EAAW,QACb,MAAO,CAAE,GAAGA,EAAY,UAAW,OAAA,EAIrC,MAAME,EAAiBC,GAAmBP,EAAgBC,EAAkBF,EAAK,oBAAoB,EACrG,OAAIO,EAAe,QACV,CAAE,GAAGA,EAAgB,UAAW,WAAA,EAGlC,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,CAChD,CAKA,SAASH,GAEPzU,EACA4T,EACmB,CACnB,MAAMzE,EAAQnP,EAAK,QAAQ4T,CAAM,EAEjC,OAAIzE,IAAU,GACL,CACL,QAAS,GACT,MAAO,EACP,UAAW,QACX,SAAUA,EACV,OAAQA,EAAQyE,EAAO,MAAA,EAIpB,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,CAChD,CAKA,SAASe,GAEP3U,EACA4T,EACAkB,EACAjI,EACmB,CAEnB,MAAMkI,EAAc7K,EAAS0J,EAAQ,CAAE,UAAW,GAAM,EAClDoB,EAAY9K,EAASlK,EAAM,CAAE,UAAW,GAAM,EAGpD,QAASK,EAAI,EAAGA,GAAK2U,EAAU,OAASD,EAAY,OAAQ1U,IAAK,CAC/D,MAAM4U,EAAUD,EAAU,MAAM3U,EAAGA,EAAI0U,EAAY,MAAM,EAGzD,IAAIG,EAAgB,EAChBC,EAAW,GAEf,QAAS5T,EAAI,EAAGA,EAAIwT,EAAY,OAAQxT,IAAK,CAC3C,MAAMyE,EAAW6G,EAAoBlI,EAAoCoQ,EAAYxT,CAAC,EAAG0T,EAAQ1T,CAAC,EAAGuT,CAAe,EAAIxQ,EAA6ByQ,EAAYxT,CAAC,EAAG0T,EAAQ1T,CAAC,EAAGuT,CAAe,EAEhM,GAAI9O,EAAW8O,EAAiB,CAC9BK,EAAW,GACX,KACF,CACAD,GAAiBlP,CACnB,CAEA,GAAImP,EAAU,CAEZ,MAAMC,EAAsBL,EAAY,OAASD,EAGjD,MAAO,CACL,QAAS,GACT,MAJYM,EAAsB,EAAI,GAAM,IAAO,EAAIF,EAAgBE,GAAuB,GAK9F,UAAW,QACX,aAAcH,CAAA,CAElB,CACF,CAEA,MAAO,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,CAChD,CAKA,SAASJ,GAEP7U,EACA4T,EACArP,EACmB,CAEnB,MAAMwQ,EAAc7K,EAAS0J,EAAQ,CAAE,UAAW,GAAM,EAClDoB,EAAY9K,EAASlK,EAAM,CAAE,UAAW,GAAM,EAG9C+S,EAAwBgC,EAAY,IAAI,IAAM,CAAA,CAAE,EAWtD,GATAC,EAAU,QAAQ,CAAC/U,EAAMkP,IAAU,CACjC4F,EAAY,QAAQ,CAACM,EAAYC,IAAgB,EAC3CrV,IAASoV,GAAcpV,EAAK,SAASoV,CAAU,GAAKA,EAAW,SAASpV,CAAI,IAC9E8S,EAAUuC,CAAW,EAAE,KAAKnG,CAAK,CAErC,CAAC,CACH,CAAC,EAGG4D,EAAU,KAAM7J,GAAMA,EAAE,SAAW,CAAC,EACtC,MAAO,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,EAIhD,IAAIqM,EAAe,IACfC,EAA0B,CAAA,EAE9B,SAASC,EAAoBC,EAAmBC,EAAkC,CAChF,GAAID,IAAcX,EAAY,OAAQ,CAEpC,MAAM3F,EAAS,CAAC,GAAGuG,CAAgB,EAAE,KAAK,CAACtI,EAAGgC,IAAMhC,EAAIgC,CAAC,EACnDrJ,EAAWoJ,EAAOA,EAAO,OAAS,CAAC,EAAIA,EAAO,CAAC,EAEjDpJ,EAAWuP,IACbA,EAAevP,EACfwP,EAAgB,CAAC,GAAGG,CAAgB,GAEtC,MACF,CAEA,UAAWC,KAAO7C,EAAU2C,CAAS,EACnCD,EAAoBC,EAAY,EAAG,CAAC,GAAGC,EAAkBC,CAAG,CAAC,CAEjE,CAKA,OAHAH,EAAoB,EAAG,EAAE,EAGrBF,GAAgBhR,EAIX,CACL,QAAS,GACT,MAJY,GAAM,IAAO,EAAIgR,EAAehR,GAK5C,UAAW,YACX,aAAciR,EAAc,IAAKnV,GAAM2U,EAAU3U,CAAC,CAAC,CAAA,EAIhD,CAAE,QAAS,GAAO,MAAO,EAAG,UAAW,MAAA,CAChD,CCzMO,SAASwV,GAAgB7V,EAAwB,CACtD,GAAI,CAACA,GAAQA,EAAK,KAAA,EAAO,SAAW,EAClC,MAAO,CAAC,SAAS,EAGnB,MAAM8V,MAAe,IAGrB,OAAAA,EAAS,IAAI,SAAS,EAGlB,YAAY,KAAK9V,CAAI,GACvB8V,EAAS,IAAI,QAAQ,EAInB,uCAAuC,KAAK9V,CAAI,GAClD8V,EAAS,IAAI,QAAQ,EAInB,qBAAqB,KAAK9V,CAAI,GAChC8V,EAAS,IAAI,SAAS,EAGjB,MAAM,KAAKA,CAAQ,CAC5B,CASO,SAASC,GAA8B/V,EAAuC,CACnF,GAAI,CAACA,GAAQA,EAAK,KAAA,EAAO,SAAW,EAClC,MAAO,CACL,UAAW,CAAC,SAAS,EACrB,WAAY,CAAE,QAAS,CAAA,EACvB,QAAS,SAAA,EAIb,MAAMgW,EAAqC,CACzC,QAAS,EAAA,EAGLC,EAAajW,EAAK,OAGlBkW,GAAelW,EAAK,MAAM,YAAY,GAAK,CAAA,GAAI,OACjDkW,EAAc,IAChBF,EAAW,OAAS,KAAK,IAAI,EAAK,GAAOE,EAAcD,EAAc,EAAE,GAIzE,MAAME,GAAenW,EAAK,MAAM,uCAAuC,GAAK,CAAA,GAAI,OAC5EmW,EAAc,IAChBH,EAAW,OAAS,KAAK,IAAI,EAAK,GAAOG,EAAcF,EAAc,EAAE,GAIzE,MAAMG,GAAgBpW,EAAK,MAAM,qBAAqB,GAAK,CAAA,GAAI,OAC3DoW,EAAe,IACjBJ,EAAW,QAAU,KAAK,IAAI,EAAK,GAAOI,EAAeH,EAAc,EAAE,GAI3E,MAAM/S,EAAY,OAAO,QAAQ8S,CAAU,EACxC,OAAO,CAAC,CAACK,EAAGC,CAAI,IAAMA,GAAQ,EAAG,EACjC,IAAI,CAAC,CAAC3W,CAAI,IAAMA,CAAI,EAGjB4W,EAAU,OAAO,QAAQP,CAAU,EACtC,KAAK,CAAC,CAAA,CAAG3I,CAAC,EAAG,CAAA,CAAGgC,CAAC,IAAMA,EAAIhC,CAAC,EAAE,CAAC,EAAE,CAAC,EAErC,MAAO,CACL,UAAAnK,EACA,WAAA8S,EACA,QAAAO,CAAA,CAEJ,CAUO,SAASC,GAEd9L,EAAyB+L,EAAqB,IAAa,CAG3D,OAFe/L,EAAM,MAAM,EAAG,KAAK,IAAI+L,EAAY/L,EAAM,MAAM,CAAC,EAG7D,IAAIhF,GACC,OAAOA,GAAS,SACXA,EACE,OAAOA,GAAS,UAAYA,IAAS,KAEvC,OAAO,OAAOA,CAAI,EACtB,OAAOgR,GAAK,OAAOA,GAAM,QAAQ,EACjC,KAAK,GAAG,EAEN,EACR,EACA,KAAK,GAAG,CACb,CAKO,SAASC,GAAgBhX,EAAuB,CAErD,MADuB,CAAC,UAAW,SAAU,SAAU,UAAW,MAAM,EAClD,SAASA,EAAK,YAAA,CAAa,CACnD,CAMO,SAASiX,GAAsBjX,EAAsB,CAC1D,MAAMO,EAAaP,EAAK,YAAA,EAAc,KAAA,EActC,MAXwC,CACtC,GAAM,UACN,GAAM,SACN,GAAM,SACN,GAAM,UACN,IAAO,UACP,IAAO,SACP,IAAO,SACP,IAAO,SAAA,EAGMO,CAAU,GAAKA,CAChC,CChKO,MAAM2W,EAAY,CACvB,KAAM,OACN,OAAQ,SACR,IAAK,MACL,GAAI,KACJ,IAAK,MACL,OAAQ,SACR,OAAQ,SACR,MAAO,QACP,MAAO,QACP,MAAO,QACP,SAAU,WACV,OAAQ,SACR,MAAO,QACP,SAAU,WACV,KAAM,OACN,MAAO,QACP,SAAU,WACV,OAAQ,SACR,IAAK,KACP,EAUO,MAAMC,EAAS,CACZ,MAAgB,GAChB,SAAmB,EACnB,OAAkB,CAAA,EAK1B,SAASC,EAAwB,CAK/B,IAJA,KAAK,MAAQA,EAAM,KAAA,EACnB,KAAK,SAAW,EAChB,KAAK,OAAS,CAAA,EAEP,KAAK,SAAW,KAAK,MAAM,SAChC,KAAK,eAAA,EAED,OAAK,UAAY,KAAK,MAAM,UAHQ,CAKxC,MAAMzW,EAAO,KAAK,MAAM,KAAK,QAAQ,EAGrC,GAAIA,IAAS,IAAK,CAChB,KAAK,OAAO,KAAK,CAAE,KAAMuW,EAAU,OAAQ,MAAO,IAAK,SAAU,KAAK,QAAA,CAAU,EAChF,KAAK,WACL,QACF,CAEA,GAAIvW,IAAS,IAAK,CAChB,KAAK,OAAO,KAAK,CAAE,KAAMuW,EAAU,OAAQ,MAAO,IAAK,SAAU,KAAK,QAAA,CAAU,EAChF,KAAK,WACL,QACF,CAGA,GAAIvW,IAAS,IAAK,CAChB,KAAK,OAAO,KAAK,CAAE,KAAMuW,EAAU,MAAO,MAAO,IAAK,SAAU,KAAK,QAAA,CAAU,EAC/E,KAAK,WACL,QACF,CAGA,GAAIvW,IAAS,KAAOA,IAAS,IAAK,CAChC,KAAK,qBAAqBA,CAAI,EAC9B,QACF,CAGA,GAAI,KAAK,QAAQA,CAAI,EAAG,CACtB,KAAK,eAAA,EACL,QACF,CAGA,GAAI,KAAK,QAAQA,CAAI,EAAG,CACtB,KAAK,sBAAA,EACL,QACF,CAGA,GAAIA,IAAS,KAAOA,IAAS,IAAK,CAChC,KAAK,sBAAA,EACL,QACF,CAGA,KAAK,UACP,CAGA,YAAK,OAAO,KAAK,CAAE,KAAMuW,EAAU,IAAK,MAAO,GAAI,SAAU,KAAK,QAAA,CAAU,EAErE,KAAK,MACd,CAEQ,gBAAuB,CAC7B,KAAO,KAAK,SAAW,KAAK,MAAM,QAAU,KAAK,KAAK,KAAK,MAAM,KAAK,QAAQ,CAAC,GAC7E,KAAK,UAET,CAEQ,QAAQvW,EAAuB,CACrC,MAAO,mEAAmE,KAAKA,CAAI,CACrF,CAEQ,QAAQA,EAAuB,CACrC,MAAO,SAAS,KAAKA,CAAI,CAC3B,CAEQ,eAAeA,EAAuB,CAC5C,OAAO,KAAK,QAAQA,CAAI,GAAK,KAAK,QAAQA,CAAI,CAChD,CAEQ,qBAAqB0W,EAAqB,CAChD,MAAMhI,EAAQ,KAAK,SACnB,KAAK,WAEL,IAAImB,EAAQ,GACZ,KAAO,KAAK,SAAW,KAAK,MAAM,QAAU,KAAK,MAAM,KAAK,QAAQ,IAAM6G,GACxE7G,GAAS,KAAK,MAAM,KAAK,QAAQ,EACjC,KAAK,WAGP,GAAI,KAAK,UAAY,KAAK,MAAM,OAC9B,MAAM,IAAI,MAAM,8BAA8BnB,CAAK,EAAE,EAGvD,KAAK,WAEL,KAAK,OAAO,KAAK,CAAE,KAAM6H,EAAU,OAAQ,MAAA1G,EAAO,SAAUnB,EAAO,CACrE,CAEQ,gBAAuB,CAC7B,MAAMA,EAAQ,KAAK,SACnB,IAAImB,EAAQ,GAEZ,KAAO,KAAK,SAAW,KAAK,MAAM,QAAU,KAAK,QAAQ,KAAK,MAAM,KAAK,QAAQ,CAAC,GAChFA,GAAS,KAAK,MAAM,KAAK,QAAQ,EACjC,KAAK,WAGP,KAAK,OAAO,KAAK,CAAE,KAAM0G,EAAU,OAAQ,MAAA1G,EAAO,SAAUnB,EAAO,CACrE,CAEQ,uBAA8B,CACpC,MAAMA,EAAQ,KAAK,SACnB,IAAImB,EAAQ,GAEZ,KAAO,KAAK,SAAW,KAAK,MAAM,QAAU,KAAK,eAAe,KAAK,MAAM,KAAK,QAAQ,CAAC,GACvFA,GAAS,KAAK,MAAM,KAAK,QAAQ,EACjC,KAAK,WAGP,MAAM8G,EAAa9G,EAAM,YAAA,EAGzB,OAAQ8G,EAAA,CACN,IAAK,MACH,KAAK,OAAO,KAAK,CAAE,KAAMJ,EAAU,IAAK,MAAOI,EAAY,SAAUjI,CAAA,CAAO,EAC5E,MACF,IAAK,KACH,KAAK,OAAO,KAAK,CAAE,KAAM6H,EAAU,GAAI,MAAOI,EAAY,SAAUjI,CAAA,CAAO,EAC3E,MACF,IAAK,MACH,KAAK,OAAO,KAAK,CAAE,KAAM6H,EAAU,IAAK,MAAOI,EAAY,SAAUjI,CAAA,CAAO,EAC5E,MACF,IAAK,QACH,KAAK,OAAO,KAAK,CAAE,KAAM6H,EAAU,MAAO,MAAOI,EAAY,SAAUjI,CAAA,CAAO,EAC9E,MACF,IAAK,QACH,KAAK,OAAO,KAAK,CAAE,KAAM6H,EAAU,MAAO,MAAOI,EAAY,SAAUjI,CAAA,CAAO,EAC9E,MACF,IAAK,WACH,KAAK,OAAO,KAAK,CAAE,KAAM6H,EAAU,SAAU,MAAOI,EAAY,SAAUjI,CAAA,CAAO,EACjF,MACF,IAAK,SACH,KAAK,OAAO,KAAK,CAAE,KAAM6H,EAAU,OAAQ,MAAOI,EAAY,SAAUjI,CAAA,CAAO,EAC/E,MACF,IAAK,QACH,KAAK,OAAO,KAAK,CAAE,KAAM6H,EAAU,MAAO,MAAOI,EAAY,SAAUjI,CAAA,CAAO,EAC9E,MACF,IAAK,WACH,KAAK,OAAO,KAAK,CAAE,KAAM6H,EAAU,SAAU,MAAOI,EAAY,SAAUjI,CAAA,CAAO,EACjF,MACF,IAAK,OACH,KAAK,OAAO,KAAK,CAAE,KAAM6H,EAAU,KAAM,MAAOI,EAAY,SAAUjI,CAAA,CAAO,EAC7E,MACF,IAAK,QACH,KAAK,OAAO,KAAK,CAAE,KAAM6H,EAAU,MAAO,MAAOI,EAAY,SAAUjI,CAAA,CAAO,EAC9E,MACF,QAEE,KAAK,OAAO,KAAK,CAAE,KAAM6H,EAAU,KAAM,MAAA1G,EAAO,SAAUnB,EAAO,EACjE,KAAA,CAEN,CAEQ,uBAA8B,CACpC,MAAMA,EAAQ,KAAK,SACnB,IAAImB,EAAQ,KAAK,MAAM,KAAK,QAAQ,EACpC,KAAK,WAGD,KAAK,SAAW,KAAK,MAAM,QAAU,KAAK,MAAM,KAAK,QAAQ,IAAM,MACrEA,GAAS,IACT,KAAK,YAGP,KAAK,OAAO,KAAK,CAAE,KAAM0G,EAAU,SAAU,MAAA1G,EAAO,SAAUnB,EAAO,CACvE,CACF,CCvNO,MAAMkI,UAAuB,KAAM,CACjC,SAEP,YAAYC,EAAiB/E,EAAkB,CAC7C,MAAM+E,CAAO,EACb,KAAK,KAAO,iBACZ,KAAK,SAAW/E,CAClB,CACF,CAEO,MAAMgF,EAAU,CACb,OAAkB,CAAA,EAClB,QAAkB,EAK1B,MAAM7M,EAA0B,CAI9B,GAHA,KAAK,OAASA,EACd,KAAK,QAAU,EAEX,KAAK,OAAO,SAAW,GAAK,KAAK,OAAO,CAAC,EAAE,OAASsM,EAAU,IAChE,MAAM,IAAIK,EAAe,cAAe,CAAC,EAG3C,MAAMG,EAAM,KAAK,gBAAA,EAGjB,GAAI,CAAC,KAAK,UACR,MAAM,IAAIH,EAAe,qBAAqB,KAAK,KAAA,EAAO,KAAK,iBAAiB,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAG9H,OAAOG,CACT,CAKQ,iBAA2B,CACjC,OAAO,KAAK,kBAAA,CACd,CAKQ,mBAA6B,CACnC,IAAIC,EAAO,KAAK,mBAAA,EAEhB,KAAO,KAAK,MAAMT,EAAU,EAAE,GAAG,CAC/B,MAAMU,EAAQ,KAAK,mBAAA,EACnBD,EAAO,CACL,KAAM,KACN,KAAAA,EACA,MAAAC,CAAA,CAEJ,CAEA,OAAOD,CACT,CAKQ,oBAA8B,CACpC,IAAIA,EAAO,KAAK,mBAAA,EAEhB,KAAO,KAAK,MAAMT,EAAU,GAAG,GAAG,CAChC,MAAMU,EAAQ,KAAK,mBAAA,EACnBD,EAAO,CACL,KAAM,MACN,KAAAA,EACA,MAAAC,CAAA,CAEJ,CAEA,OAAOD,CACT,CAKQ,oBAA8B,CACpC,OAAI,KAAK,MAAMT,EAAU,GAAG,EAEnB,CACL,KAAM,MACN,MAHY,KAAK,aAAA,CAGjB,EAIG,KAAK,aAAA,CACd,CAKQ,cAAwB,CAE9B,GAAI,KAAK,MAAMA,EAAU,MAAM,EAAG,CAChC,MAAMW,EAAO,KAAK,gBAAA,EAClB,GAAI,CAAC,KAAK,MAAMX,EAAU,MAAM,EAC9B,MAAM,IAAIK,EAAe,4BAA4B,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAEnG,OAAOM,CACT,CAGA,GAAI,KAAK,MAAMX,EAAU,KAAK,GAAK,KAAK,MAAMA,EAAU,KAAK,GAAK,KAAK,MAAMA,EAAU,QAAQ,GAAK,KAAK,MAAMA,EAAU,MAAM,GAAK,KAAK,MAAMA,EAAU,KAAK,GAAK,KAAK,MAAMA,EAAU,QAAQ,EAC9L,OAAO,KAAK,YAAA,EAId,GAAI,KAAK,MAAMA,EAAU,IAAI,EAC3B,OAAO,KAAK,UAAA,EAId,GAAI,KAAK,MAAMA,EAAU,MAAM,EAAG,CAEhC,MAAMjD,EAAqB,CACzB,KAAM,SACN,MAHY,KAAK,QAAA,EAGJ,KAAA,EAIf,OAAI,KAAK,MAAMiD,EAAU,KAAK,EACrB,KAAK,WAAWjD,CAAM,EAGxBA,CACT,CAGA,GAAI,KAAK,MAAMiD,EAAU,IAAI,EAAG,CAC9B,MAAMrM,EAAQ,KAAK,QAAA,EAGnB,GAAI,KAAK,MAAMqM,EAAU,KAAK,EAAG,CAC/B,MAAMnQ,EAAQ,KAAK,aAAA,EAMnB,MALyB,CACvB,KAAM,QACN,MAAO8D,EAAM,MACb,MAAA9D,CAAA,CAGJ,CAGA,MAAML,EAAiB,CACrB,KAAM,OACN,MAAOmE,EAAM,KAAA,EAIf,OAAI,KAAK,MAAMqM,EAAU,KAAK,EACrB,KAAK,WAAWxQ,CAAI,EAGtBA,CACT,CAEA,MAAM,IAAI6Q,EAAe,qBAAqB,KAAK,KAAA,EAAO,KAAK,iBAAiB,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,CAC9H,CAKQ,aAAuB,CAC7B,MAAMO,EAAc,KAAK,QAAA,EACnBC,EAAaD,EAAY,MAAM,YAAA,EAErC,GAAI,CAAC,KAAK,MAAMZ,EAAU,KAAK,EAC7B,MAAM,IAAIK,EAAe,sBAAsBO,EAAY,KAAK,gBAAgB,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAG9H,IAAItH,EAEJ,GAAI,KAAK,MAAM0G,EAAU,MAAM,EAC7B1G,EAAQ,KAAK,UAAU,cACd,KAAK,MAAM0G,EAAU,IAAI,EAClC1G,EAAQ,KAAK,UAAU,UAEvB,OAAM,IAAI+G,EAAe,wBAAwBO,EAAY,KAAK,iBAAiB,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAGjI,MAAM5N,EAAqB,CACzB,KAAM,SACN,WAAA6N,EACA,MAAAvH,CAAA,EAIF,OAAI,KAAK,MAAM0G,EAAU,KAAK,EACrB,KAAK,WAAWhN,CAAM,EAGxBA,CACT,CAKQ,WAAsB,CAG5B,GAFA,KAAK,QAAA,EAED,CAAC,KAAK,MAAMgN,EAAU,KAAK,EAC7B,MAAM,IAAIK,EAAe,uCAAuC,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAG9G,GAAI,CAAC,KAAK,MAAML,EAAU,IAAI,EAC5B,MAAM,IAAIK,EAAe,kDAAkD,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAGzH,MAAMjU,EAAW,KAAK,QAAA,EAAU,MAC1ByD,EAAQ,KAAK,aAAA,EAEnB,MAAO,CACL,KAAM,OACN,SAAAzD,EACA,MAAAyD,CAAA,CAEJ,CAKQ,WAAWA,EAA2B,CAG5C,GAFA,KAAK,QAAA,EAED,CAAC,KAAK,MAAMmQ,EAAU,QAAQ,EAChC,MAAM,IAAIK,EAAe,sDAAsD,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAG7H,MAAMS,EAAW,KAAK,QAAA,EAAU,MAEhC,GAAI,CAAC,KAAK,MAAMd,EAAU,MAAM,EAC9B,MAAM,IAAIK,EAAe,yBAAyBS,CAAQ,gBAAgB,KAAK,KAAA,EAAO,QAAQ,GAAI,KAAK,KAAA,EAAO,QAAQ,EAGxH,MAAMxR,EAAY,WAAW,KAAK,QAAA,EAAU,KAAK,EAEjD,GAAI,MAAMA,CAAS,GAAKA,EAAY,GAAKA,EAAY,EACnD,MAAM,IAAI+Q,EAAe,0CAA2C,KAAK,SAAA,EAAW,QAAQ,EAG9F,MAAO,CACL,KAAM,QACN,SAAAS,EACA,UAAAxR,EACA,MAAAO,CAAA,CAEJ,CAIQ,SAASkR,EAA6B,CAC5C,UAAW/I,KAAQ+I,EACjB,GAAI,KAAK,MAAM/I,CAAI,EACjB,YAAK,QAAA,EACE,GAGX,MAAO,EACT,CAEQ,MAAMA,EAA0B,CACtC,OAAI,KAAK,QAAA,EAAkB,GACpB,KAAK,OAAO,OAASA,CAC9B,CAEQ,SAAiB,CACvB,OAAK,KAAK,WAAW,KAAK,UACnB,KAAK,SAAA,CACd,CAEQ,SAAmB,CACzB,OAAO,KAAK,KAAA,EAAO,OAASgI,EAAU,GACxC,CAEQ,MAAc,CACpB,OAAO,KAAK,OAAO,KAAK,OAAO,CACjC,CAEQ,UAAkB,CACxB,OAAO,KAAK,OAAO,KAAK,QAAU,CAAC,CACrC,CACF,CC/MO,SAASgB,GAAWtR,EAAiC,CAC1D,OAAOA,EAAK,OAAS,MACvB,CAEO,SAASuR,GAAavR,EAAmC,CAC9D,OAAOA,EAAK,OAAS,QACvB,CAEO,SAASwR,GAAUxR,EAAgC,CACxD,OAAOA,EAAK,OAAS,KACvB,CAEO,SAASyR,GAASzR,EAA+B,CACtD,OAAOA,EAAK,OAAS,IACvB,CAEO,SAAS0R,GAAU1R,EAAgC,CACxD,OAAOA,EAAK,OAAS,KACvB,CAEO,SAAS2R,GAAa3R,EAAmC,CAC9D,OAAOA,EAAK,OAAS,QACvB,CAEO,SAAS4R,GAAY5R,EAAkC,CAC5D,OAAOA,EAAK,OAAS,OACvB,CAEO,SAAS6R,GAAY7R,EAAkC,CAC5D,OAAOA,EAAK,OAAS,OACvB,CAEO,SAAS8R,GAAW9R,EAAiC,CAC1D,OAAOA,EAAK,OAAS,MACvB,CChHO,MAAM+R,WAAwB,KAAM,CACzC,YAAYnB,EAAiB,CAC3B,MAAMA,CAAO,EACb,KAAK,KAAO,iBACd,CACF,CAEO,MAAMoB,EAAY,CACf,MACA,QACA,UAAoB,EACpB,QAAkB,IAE1B,YAAYpJ,EAAmBhF,EAAyB,GAAI,CAC1D,KAAK,MAAQgF,EACb,KAAK,QAAUhF,EACf,KAAK,QAAUA,EAAQ,YAAY,SAAW,GAChD,CAKA,QAAQkN,EAAkC,CACxC,YAAK,UAAY,KAAK,IAAA,EACf,KAAK,YAAYA,CAAG,CAC7B,CAEQ,cAAqB,CAC3B,GAAI,KAAK,IAAA,EAAQ,KAAK,UAAY,KAAK,QACrC,MAAM,IAAIiB,GAAgB,iCAAiC,KAAK,OAAO,IAAI,CAE/E,CAEQ,YAAY/R,EAAmC,CAGrD,OAFA,KAAK,aAAA,EAEDwR,GAAUxR,CAAI,EACT,KAAK,WAAWA,CAAI,EAGzByR,GAASzR,CAAI,EACR,KAAK,UAAUA,CAAI,EAGxB0R,GAAU1R,CAAI,EACT,KAAK,WAAWA,CAAI,EAGzBsR,GAAWtR,CAAI,EACV,KAAK,YAAYA,EAAK,KAAK,EAGhCuR,GAAavR,CAAI,EACZ,KAAK,cAAcA,EAAK,KAAK,EAGlC2R,GAAa3R,CAAI,EACZ,KAAK,cAAcA,CAAI,EAG5B4R,GAAY5R,CAAI,EACX,KAAK,aAAaA,CAAI,EAG3B6R,GAAY7R,CAAI,EACX,KAAK,aAAaA,CAAI,EAG3B8R,GAAW9R,CAAI,EACV,KAAK,YAAYA,CAAI,EAGvB,CAAA,CACT,CAKQ,WAAWA,EAA6D,CAC9E,MAAMiS,EAAc,KAAK,YAAYjS,EAAK,IAAI,EACxCkS,EAAe,KAAK,YAAYlS,EAAK,KAAK,EAG1CmS,EAAgB,IAAI,IAAID,EAAa,IAAKE,GAAMA,EAAE,OAAO,CAAC,EAIhE,OAHqBH,EAAY,OAAQG,GAAMD,EAAc,IAAIC,EAAE,OAAO,CAAC,EAGvD,KAAK,CAAC,EAAGtJ,IAAMA,EAAE,MAAQ,EAAE,KAAK,CACtD,CAKQ,UAAU9I,EAA6D,CAC7E,MAAMiS,EAAc,KAAK,YAAYjS,EAAK,IAAI,EACxCkS,EAAe,KAAK,YAAYlS,EAAK,KAAK,EAG1CqS,MAAgB,IAEtB,UAAW1T,KAAUsT,EACnBI,EAAU,IAAI1T,EAAO,QAASA,CAAM,EAGtC,UAAWA,KAAUuT,EAAc,CACjC,MAAMI,EAAWD,EAAU,IAAI1T,EAAO,OAAO,GAEzC,CAAC2T,GAAY3T,EAAO,MAAQ2T,EAAS,QACvCD,EAAU,IAAI1T,EAAO,QAASA,CAAM,CAExC,CAGA,OAAO,MAAM,KAAK0T,EAAU,OAAA,CAAQ,EAAE,KAAK,CAACvL,EAAGgC,IAAMA,EAAE,MAAQhC,EAAE,KAAK,CACxE,CAKQ,WAAW9G,EAA8C,CAC/D,MAAMuS,EAAe,KAAK,YAAYvS,EAAK,KAAK,EAC1CwS,EAAkB,IAAI,IAAID,EAAa,IAAKH,GAAMA,EAAE,OAAO,CAAC,EAIlE,OADmBK,EAAe,KAAK,MAAO,GAAI,KAAK,MAAM,KAAK,OAAQ,KAAK,OAAO,EACpE,OAAQL,GAAM,CAACI,EAAgB,IAAIJ,EAAE,OAAO,CAAC,EAAE,KAAK,CAACtL,EAAGgC,IAAMA,EAAE,MAAQhC,EAAE,KAAK,CACnG,CAKQ,YAAYhH,EAAkC,CACpD,OAAO2S,EAAe,KAAK,MAAO3S,EAAM,KAAK,MAAM,KAAK,OAAQ,KAAK,OAAO,CAC9E,CAKQ,cAAcuN,EAAoC,CAExD,OAAOoF,EAAe,KAAK,MAAO,IAAIpF,CAAM,IAAK,KAAK,MAAM,KAAK,OAAQ,KAAK,OAAO,CACvF,CAKQ,cAAcrN,EAAiE,CACrF,KAAM,CAAE,WAAAmR,EAAY,MAAAvH,CAAA,EAAU5J,EAGxBE,EAAUuS,EAAe,KAAK,MAAO7I,EAAO,KAAK,MAAM,KAAK,OAAQ,KAAK,OAAO,EAGtF,OAAQuH,EAAA,CACN,IAAK,QACH,OAAOjR,EAAQ,OAAQkS,GAAOA,EAAU,mBAAqB,OAAO,EAEtE,IAAK,QACH,OAAOlS,EAAQ,OAAQkS,GAAOA,EAAU,mBAAqB,OAAO,EAEtE,IAAK,WACH,OAAOlS,EAAQ,OAAQkS,GAAOA,EAAU,mBAAqB,UAAU,EAEzE,IAAK,SACH,OAAOlS,EAAQ,OAAQkS,GAAOA,EAAU,mBAAqB,QAAQ,EAEvE,IAAK,WACH,OAAOlS,EAAQ,OAAQkS,GAAOA,EAAU,mBAAqB,UAAU,EAEzE,IAAK,QACH,OAAO,KAAK,aAAaxI,CAAK,EAEhC,QACE,OAAO1J,CAAA,CAEb,CAKQ,aAAaoM,EAAqC,CAExD,GAAI,CAAC,KAAK,QAAQ,YAAY,WAC5B,MAAM,IAAI,MAAM,qDAAqD,EAGvE,GAAI,CACF,MAAMoG,EAAQ,IAAI,OAAOpG,CAAO,EAC1BpM,EAA8B,CAAA,EAEpC,UAAWxG,KAAQ,KAAK,MAAM,KACxBgZ,EAAM,KAAKhZ,CAAI,GACjBwG,EAAQ,KAAK,CACX,QAASxG,EACT,SAAUA,EACV,MAAO,EACP,UAAW,GACX,SAAU,UACV,iBAAkB,OAAA,CACZ,EAIZ,OAAOwG,CACT,MAAgB,CACd,MAAM,IAAI,MAAM,0BAA0BoM,CAAO,EAAE,CACrD,CACF,CAKQ,aAAatM,EAA6D,CAEhF,MAAMuS,EAAe,KAAK,YAAYvS,EAAK,KAAK,EAGhD,OAAK,KAAK,MAAM,UAMTuS,EAAa,OAAQ5T,GACtBA,EAAO,QAAUqB,EAAK,KAI3B,EATQuS,CAUX,CAKQ,aAAavS,EAAmF,CACtG,MAAMuS,EAAe,KAAK,YAAYvS,EAAK,KAAK,EAC1C,CAAE,SAAAoR,EAAU,UAAAxR,CAAA,EAAcI,EAEhC,OAAOuS,EAAa,OAAQ5T,GAAW,CACrC,OAAQyS,EAAA,CACN,IAAK,IACH,OAAOzS,EAAO,MAAQiB,EACxB,IAAK,IACH,OAAOjB,EAAO,MAAQiB,EACxB,IAAK,KACH,OAAOjB,EAAO,OAASiB,EACzB,IAAK,KACH,OAAOjB,EAAO,OAASiB,EACzB,QACE,MAAO,EAAA,CAEb,CAAC,CACH,CAKQ,YAAYI,EAAgE,CAClF,MAAMuS,EAAe,KAAK,YAAYvS,EAAK,KAAK,EAC1C2S,EAAa3S,EAAK,SAAS,YAAA,EAEjC,OAAOuS,EAAa,OAAQ5T,GACnBA,EAAO,UAAU,YAAA,IAAkBgU,CAC3C,CACH,CACF,CCvQO,SAASC,GAAWvN,EAAwB,CACjD,MAAMwN,EAAUxN,EAAM,KAAA,EACtB,OAAOwN,EAAQ,WAAW,MAAM,GAAKA,EAAQ,SAAS,GAAG,CAC3D,CAKO,SAASC,GAAgBzN,EAAuB,CACrD,MAAMwN,EAAUxN,EAAM,KAAA,EACtB,GAAI,CAACuN,GAAWC,CAAO,EACrB,MAAM,IAAI,MAAM,oDAAoD,EAItE,OAAOA,EAAQ,MAAM,EAAG,EAAE,EAAE,KAAA,CAC9B,CAKO,SAASE,GACdnK,EACAvD,EACA0E,EACAnG,EAAyB,CAAA,EACL,CACpB,GAAI,CAEF,MAAMoP,EAAWF,GAAgBzN,CAAK,EAIhCrB,EADQ,IAAIuM,GAAA,EACG,SAASyC,CAAQ,EAIhClC,EADS,IAAID,GAAA,EACA,MAAM7M,CAAM,EAIzB9D,EADW,IAAI8R,GAAYpJ,EAAOhF,CAAO,EACtB,QAAQkN,CAAG,EAG9BmC,EAAQlJ,GAAcnG,EAAQ,YAAc,GAClD,OAAO1D,EAAQ,MAAM,EAAG+S,CAAK,CAC/B,OAASC,EAAO,CAEd,MAAIA,aAAiBvC,GAAkBuC,aAAiBnB,GAChDmB,EAIF,IAAI,MAAM,wBAAyBA,EAAgB,OAAO,EAAE,CACpE,CACF,CCzCO,SAASC,GAAe9T,EAAsB,CACnD,MAAM+T,EAAa,WAAW,KAAK/T,CAAG,EAChCgU,EAAa,QAAQ,KAAKhU,CAAG,EACnC,OAAO+T,GAAcC,CACvB,CA0BO,SAASC,GAAcjU,EAAwB,CACpD,MAAMkU,EAAsB,CAAA,EAC5B,IAAIC,EAAkC,KAClCC,EAAe,GACfC,EAAe,EAEnB,QAAS5Z,EAAI,EAAGA,EAAIuF,EAAI,OAAQvF,IAAK,CACnC,MAAMC,EAAOsF,EAAIvF,CAAC,EAClB,IAAI6Z,EAEA,WAAW,KAAK5Z,CAAI,EACtB4Z,EAAW,QACF,QAAQ,KAAK5Z,CAAI,EAC1B4Z,EAAW,UAEXA,EAAW,QAGTH,IAAgB,MAElBA,EAAcG,EACdF,EAAe1Z,EACf2Z,EAAe5Z,GACN0Z,IAAgBG,EAEzBF,GAAgB1Z,GAGhBwZ,EAAS,KAAK,CACZ,KAAMC,EACN,MAAOC,EACP,MAAOC,EACP,IAAK5Z,CAAA,CACN,EACD0Z,EAAcG,EACdF,EAAe1Z,EACf2Z,EAAe5Z,EAEnB,CAGA,OAAI0Z,IAAgB,MAAQC,EAAa,OAAS,GAChDF,EAAS,KAAK,CACZ,KAAMC,EACN,MAAOC,EACP,MAAOC,EACP,IAAKrU,EAAI,MAAA,CACV,EAGIkU,CACT,CAQO,SAASK,GAAiBvU,EAAwB,CACvD,OAAOiU,GAAcjU,CAAG,EAAE,OAAOwU,GAAKA,EAAE,OAAS,OAAO,CAC1D,CAQO,SAASC,GAAmBzU,EAAwB,CACzD,OAAOiU,GAAcjU,CAAG,EAAE,OAAOwU,GAAKA,EAAE,OAAS,SAAS,CAC5D,CAcO,SAASE,EAAiB1U,EAAqB,CACpD,OAAOuU,GAAiBvU,CAAG,EAAE,OAASwU,EAAE,KAAK,EAAE,KAAK,EAAE,CACxD,CAcO,SAASG,EAAmB3U,EAAqB,CACtD,OAAOyU,GAAmBzU,CAAG,EAAE,OAASwU,EAAE,KAAK,EAAE,KAAK,EAAE,CAC1D,CAUO,SAASI,GACdtZ,EACAC,EAMA,CACA,MAAMsZ,EAASH,EAAiBpZ,CAAI,EAC9BwZ,EAASJ,EAAiBnZ,CAAI,EAC9BwZ,EAAWJ,EAAmBrZ,CAAI,EAClC0Z,EAAWL,EAAmBpZ,CAAI,EAElC0Z,EAAWJ,EAAO,OAAS,GAAKC,EAAO,OAAS,EAChDI,EAAaH,EAAS,OAAS,GAAKC,EAAS,OAAS,EAG5D,IAAIG,EAAkB,EACtB,GAAIF,EACF,GAAIJ,IAAWC,EACbK,EAAkB,UACTN,EAAO,SAAW,GAAKC,EAAO,SAAW,EAClDK,EAAkB,MACb,CAEL,IAAIC,EAAe,EACnB,MAAMpO,EAAS,KAAK,IAAI6N,EAAO,OAAQC,EAAO,MAAM,EACpD,QAASra,EAAI,EAAGA,EAAIuM,GACd6N,EAAOpa,CAAC,EAAE,YAAA,IAAkBqa,EAAOra,CAAC,EAAE,cADhBA,IAExB2a,IAKJ,MAAMpW,EAAS,KAAK,IAAI6V,EAAO,OAAQC,EAAO,MAAM,EACpDK,EAAkBC,EAAepW,CACnC,CAIF,IAAIqW,EAAoB,EACxB,GAAIH,EACF,GAAIH,IAAaC,EACfK,EAAoB,UACXN,EAAS,SAAW,GAAKC,EAAS,SAAW,EACtDK,EAAoB,MACf,CAEL,MAAMC,EAASP,EAAS,OAASC,EAAS,OAASD,EAAWC,EACxDO,EAAUR,EAAS,OAASC,EAAS,OAASA,EAAWD,EAC/D,GAAIO,EAAO,SAASC,CAAO,EACzBF,EAAoBE,EAAQ,OAASD,EAAO,WACvC,CAEL,IAAIE,EAAiB,EACrB,MAAMxO,EAAS,KAAK,IAAI+N,EAAS,OAAQC,EAAS,MAAM,EACxD,QAASva,EAAI,EAAGA,EAAIuM,EAAQvM,IACtBsa,EAASta,CAAC,IAAMua,EAASva,CAAC,GAC5B+a,IAGJH,EAAoBG,EAAiB,KAAK,IAAIT,EAAS,OAAQC,EAAS,MAAM,CAChF,CACF,CAGF,MAAO,CACL,gBAAAG,EACA,kBAAAE,EACA,SAAAJ,EACA,WAAAC,CAAA,CAEJ,CCpMO,SAASO,GAAa5U,EAA6B6U,EAA4C,CACpG,IAAIvJ,EAAWtL,EAEf,OAAI6U,EAAQ,QAAUA,EAAQ,OAAO,OAAS,IAC5CvJ,EAAWA,EAAS,OAAQ7M,GACrBA,EAAO,OAELoW,EAAQ,OAAQ,MAAOC,GAAU,CACtC,MAAMpL,EAAQjL,EAAO,OAAQqW,EAAM,KAAK,EACxC,GAAIpL,IAAU,OAAW,MAAO,GAEhC,MAAMqL,EAAW,OAAOrL,CAAK,EAC7B,OAAI,MAAMqL,CAAQ,EAAU,GAExB,EAAAD,EAAM,MAAQ,QAAaC,EAAWD,EAAM,KAC5CA,EAAM,MAAQ,QAAaC,EAAWD,EAAM,IAGlD,CAAC,EAb0B,EAc5B,GAGCD,EAAQ,OAASA,EAAQ,MAAM,OAAS,IAC1CvJ,EAAWA,EAAS,OAAQ7M,GACrBA,EAAO,OAELoW,EAAQ,MAAO,MAAOjV,GAAS,CACpC,MAAM8J,EAAQjL,EAAO,OAAQmB,EAAK,KAAK,EACvC,OAAI8J,IAAU,OAAkB,IAEf9J,EAAK,UAAY,QAEjB,KACRA,EAAK,OAAO,KAAMoV,GAAgBC,GAAWvL,EAAOsL,CAAW,CAAC,EAGnE,MAAM,QAAQtL,CAAK,EACd9J,EAAK,OAAO,MAAOoV,GACxBtL,EAAM,KAAMuG,GAAMgF,GAAWhF,EAAG+E,CAAW,CAAC,CAAA,EAGzCpV,EAAK,OAAO,KAAMoV,GAAgBC,GAAWvL,EAAOsL,CAAW,CAAC,CAE3E,CAAC,EAnB0B,EAoB5B,GAGCH,EAAQ,UAAYA,EAAQ,SAAS,OAAS,IAChDvJ,EAAWA,EAAS,OAAQ7M,GACrBA,EAAO,OAELoW,EAAQ,SAAU,MAAOK,GAAe,CAC7C,MAAMxL,EAAQjL,EAAO,OAAQyW,EAAW,KAAK,EAC7C,OAAIxL,IAAU,OAAkB,IAEd,OAAOA,GAAU,UAAYA,EAAQ,OAAOA,CAAK,IAAM,QAAU,OAAOA,CAAK,IAAM,KAEhFwL,EAAW,KAClC,CAAC,EAT0B,EAU5B,GAGI5J,CACT,CAEA,SAAS2J,GAAWvL,EAAYsL,EAA2B,CACzD,GAAItL,IAAUsL,EAAa,MAAO,GAElC,GAAI,OAAOtL,GAAU,UAAY,OAAOsL,GAAgB,SACtD,OAAOtL,EAAM,gBAAkBsL,EAAY,YAAA,EAG7C,MAAMD,EAAW,OAAOrL,CAAK,EACvByL,EAAiB,OAAOH,CAAW,EACzC,MAAI,CAAC,MAAMD,CAAQ,GAAK,CAAC,MAAMI,CAAc,EACpCJ,IAAaI,EAGf,EACT,CChGO,SAASC,GAAapV,EAA6BqV,EAA4C,CACpG,MAAM1M,EAAS,CAAC,GAAG3I,CAAO,EAE1B,OAAA2I,EAAO,KAAK,CAAC/B,EAAGgC,IAAM,CAEpB,MAAM0M,EAAiBC,GAAe3O,EAAGgC,EAAGyM,EAAW,OAAO,EAC9D,GAAIC,IAAmB,EAAG,OAAOA,EAGjC,GAAID,EAAW,UAAW,CACxB,MAAMG,EAAmBD,GAAe3O,EAAGgC,EAAGyM,EAAW,SAAS,EAClE,GAAIG,IAAqB,EAAG,OAAOA,CACrC,CAGA,OAAIH,EAAW,gBAAkB,GACxBzM,EAAE,MAAQhC,EAAE,MAGd,CACT,CAAC,EAEM+B,CACT,CAEA,SAAS4M,GAAe3O,EAAqBgC,EAAqB6M,EAA0B,CAC1F,MAAMC,EAAS9O,EAAE,SAAS6O,EAAK,KAAK,EAC9BE,EAAS/M,EAAE,SAAS6M,EAAK,KAAK,EAEpC,GAAIC,IAAW,QAAaC,IAAW,OAAW,MAAO,GACzD,GAAID,IAAW,OAAW,MAAO,GACjC,GAAIC,IAAW,OAAW,MAAO,GAEjC,MAAMvN,EAAOqN,EAAK,MAAQG,GAAWF,CAAM,EAE3C,IAAIG,EAAa,EAEjB,OAAQzN,EAAA,CACN,IAAK,SACHyN,EAAaC,GAAeJ,EAAQC,CAAM,EAC1C,MACF,IAAK,OACHE,EAAaE,GAAaL,EAAQC,CAAM,EACxC,MACF,IAAK,SACL,QACEE,EAAaG,GAAeN,EAAQC,CAAM,CAAA,CAG9C,OAAOF,EAAK,QAAU,OAAS,CAACI,EAAaA,CAC/C,CAEA,SAASC,GAAelP,EAAQgC,EAAgB,CAC9C,MAAMqN,EAAO,OAAOrP,CAAC,EACfsP,EAAO,OAAOtN,CAAC,EAErB,OAAI,MAAMqN,CAAI,GAAK,MAAMC,CAAI,EAAU,EACnC,MAAMD,CAAI,EAAU,EACpB,MAAMC,CAAI,EAAU,GAEjBD,EAAOC,CAChB,CAEA,SAASH,GAAanP,EAAQgC,EAAgB,CAC5C,MAAMuN,EAAQ,IAAI,KAAKvP,CAAC,EAClBwP,EAAQ,IAAI,KAAKxN,CAAC,EAElByN,EAAQF,EAAM,QAAA,EACdG,EAAQF,EAAM,QAAA,EAEpB,OAAI,MAAMC,CAAK,GAAK,MAAMC,CAAK,EAAU,EACrC,MAAMD,CAAK,EAAU,EACrB,MAAMC,CAAK,EAAU,GAElBD,EAAQC,CACjB,CAEA,SAASN,GAAepP,EAAQgC,EAAgB,CAC9C,OAAO,OAAOhC,CAAC,EAAE,cAAc,OAAOgC,CAAC,CAAC,CAC1C,CAEA,SAASgN,GAAWlM,EAA0C,CAG5D,GAFI,OAAOA,GAAU,UAEjB,OAAOA,GAAU,UAAY,CAAC,MAAM,WAAWA,CAAK,CAAC,GAAK,SAAS,OAAOA,CAAK,CAAC,EAClF,MAAO,SAGT,GAAIA,aAAiB,KAAM,MAAO,OAElC,GAAI,OAAOA,GAAU,SAAU,CAC7B,MAAM6M,EAAO,IAAI,KAAK7M,CAAK,EAC3B,GAAI,CAAC,MAAM6M,EAAK,QAAA,CAAS,GAAK,wCAAwC,KAAK7M,CAAK,EAC9E,MAAO,MAEX,CAEA,MAAO,QACT,CCxBO,SAAS8M,GAAgBvS,EAA0B,GAAIP,EAA6B,CAAA,EAAgB,CAEzG,MAAM+S,EAAyB/S,EAAQ,QAAQ,UACzCgT,EAAmB,CAACD,GAA0BA,EAAuB,SAAS,MAAM,EAEpFpd,EAAST,GAAY8K,EAAQ,MAAM,EAEzC,GAAIgT,EAAkB,CACpB,MAAMC,EAAa5G,GAAuB9L,EAAO,GAAG,EAC9C2S,EAAoBxH,GAAgBuH,CAAU,EACpDtd,EAAO,UAAYud,CACrB,CAEAxd,GAAeC,CAAM,EAGrB,MAAM8K,EAAa,IAAI,IAAI9K,EAAO,QAAQ,EAEpC6K,EAAqBR,EAAQ,oBAAsBnH,EAAiB,cAAclD,EAAO,SAAS,EAExG,GAAI6K,EAAmB,SAAW,EAChC,MAAM,IAAI,MAAM,qCAAqC7K,EAAO,UAAU,KAAK,IAAI,CAAC,EAAE,EAIpF,MAAMwd,EAAYnT,EAAQ,QAAUA,EAAQ,OAAO,OAAS,EACtDoT,EAAgB7S,EAAM,OAAS,GAAK,OAAOA,EAAM,CAAC,GAAM,UAAYA,EAAM,CAAC,IAAM,KAGvF,GAAI6S,GAAiB,CAACD,EACpB,MAAM,IAAI,MAAM,kFAAkF,EAGpG,MAAMnO,EAAoB,CACxB,KAAM,CAAA,EACN,kBAAmB,IACnB,mBAAoB,IACpB,eAAgB,IAChB,eAAgB,IAChB,uBAAwB,IACxB,OAAArP,CAAA,EAIEwd,IACFnO,EAAM,OAAShF,EAAQ,OACvBgF,EAAM,aAAeqC,GAAsBrH,EAAQ,OAASA,EAAQ,YAAY,EAChFgF,EAAM,cAAgB,KAIxBxE,EAAmB,QAASxH,GAAc,CACxCgM,EAAM,mBAAmB,IAAIhM,EAAU,SAAUA,CAAS,CAC5D,CAAC,EAID,MAAMqa,EAAyBrT,EAAQ,kBAAoBrK,EAAO,kBAAoBA,EAAO,SAAWA,EAAO,gBAAkB4K,EAAM,QAAU,IAE3I+S,MAAqB,IAC3B,IAAIC,EAAY,EAIhB,GAAI,CAACF,GACH,UAAW9X,KAAQgF,EACjB,GAAKhF,EAGL,IAAI4X,GAAaC,EAAe,CAC9B,MAAMjM,EAAcF,GAAmB1L,EAAMyE,EAAQ,MAAM,EAC3D,GAAI,CAACmH,EAAa,SAGlB,MAAMqM,EAAS,OAAO,OAAOrM,CAAW,EAAE,CAAC,GAAK,QAAQoM,CAAS,GAGjEvO,EAAM,UAAW,IAAIwO,EAAQrM,CAAW,EAGxC,SAAW,CAACsM,EAAWC,CAAU,IAAK,OAAO,QAAQvM,CAAW,EAAG,CACjE,GAAI,CAACuM,GAAcA,EAAW,OAAO,OAAS/d,EAAO,eAAgB,SAErE,MAAMge,EAAeD,EAAW,KAAA,EAG3BJ,EAAe,IAAIE,EAAO,YAAA,CAAa,IAC1CF,EAAe,IAAIE,EAAO,aAAa,EACvCxO,EAAM,KAAK,KAAKwO,CAAM,GAIxB,UAAWxa,KAAawH,EACtBoT,GAAiCD,EAAcH,EAAQC,EAAWza,EAAWgM,EAAOrP,EAAQ8K,CAAU,CAE1G,CACF,KAAO,CAEL,MAAM3K,EAAO,OAAOyF,GAAS,SAAWA,EAAO,OAAOA,CAAI,EAC1D,GAAIzF,EAAK,KAAA,EAAO,OAASH,EAAO,eAAgB,SAEhD,MAAMiL,EAAc9K,EAAK,KAAA,EACzB,GAAIwd,EAAe,IAAI1S,EAAY,YAAA,CAAa,EAAG,SAEnD0S,EAAe,IAAI1S,EAAY,aAAa,EAC5CoE,EAAM,KAAK,KAAKpE,CAAW,EAG3B,UAAW5H,KAAawH,EACtBqT,GAAyBjT,EAAa5H,EAAWgM,EAAOrP,EAAQ8K,CAAU,CAE9E,CAEA8S,IACIvT,EAAQ,YACVA,EAAQ,WAAWuT,EAAWhT,EAAM,MAAM,GAMhD,GAAI8S,EAAwB,CAC1B,KAAM,CAAE,cAAA3S,EAAe,UAAA9C,GAAc0C,EAAmBC,EAAOC,EAAoB7K,EAAQ8K,CAAU,EACrGuE,EAAM,cAAgBtE,EACtBsE,EAAM,UAAYpH,EAGlBoH,EAAM,KAAOpH,EAAU,IAAII,GAAOA,EAAI,IAAI,CAC5C,CAIA,GADoBrI,EAAO,cAAgB,GAC1B,CACf,MAAMme,EAAYne,EAAO,WAAa,IACtCqP,EAAM,OAAS,IAAIkB,GAAY4N,CAAS,CAC1C,CAEA,OAAO9O,CACT,CAKA,SAAS6O,GAAyB/d,EAAckD,EAA8BgM,EAAmBrP,EAAqB8K,EAA+B,CACnJ,MAAM1K,EAAaiD,EAAU,UAAUlD,CAAI,EAI3Cie,EAAgB/O,EAAM,cAAejP,EAAW,YAAA,EAAeD,CAAI,EAGnE,MAAMke,EAAiBrN,EAAc7Q,CAAI,EACzC,GAAIke,IAAmBle,EAAM,CAC3B,MAAMme,EAAuBjb,EAAU,UAAUgb,CAAc,EAAE,YAAA,EAE7DC,IAAyBle,EAAW,eACtCge,EAAgB/O,EAAM,cAAeiP,EAAsBne,CAAI,CAEnE,CAWA,GARI2K,EAAW,IAAI,eAAe,GACfzH,EAAU,gBAAgBlD,EAAMH,EAAO,WAAW,EAC1D,QAASqL,GAAY,CAC5B+S,EAAgB/O,EAAM,cAAehE,EAAQ,YAAA,EAAelL,CAAI,CAClE,CAAC,EAIC2K,EAAW,IAAI,UAAU,GAAKzH,EAAU,kBAAkB,SAAS,UAAU,EAAG,CAClF,MAAM6H,EAAe7H,EAAU,gBAAgBlD,CAAI,EAC/C+K,GACFkT,EAAgB/O,EAAM,eAAgBnE,EAAc/K,CAAI,CAE5D,CAKA,MAAMoe,EADoBve,EAAO,cAAgB,QAAUI,EAAW,OAAS,GACvCA,EAAW,UAAU,EAAG,EAAE,EAAIA,EAiBtE,GAhBemF,GAAegZ,EAAY,YAAA,EAAeve,EAAO,SAAS,EAClE,QAASsL,GAAkB,CAChC8S,EAAgB/O,EAAM,WAAY/D,EAAOnL,CAAI,CAC/C,CAAC,EAGG2K,EAAW,IAAI,UAAU,GAAKzH,EAAU,kBAAkB,SAAS,UAAU,GACzDA,EAAU,mBAAmBlD,CAAI,EACzC,QAASqC,GAAS,CAC1BA,IAASrC,GACXie,EAAgB/O,EAAM,cAAehM,EAAU,UAAUb,CAAI,EAAE,YAAA,EAAerC,CAAI,CAEtF,CAAC,EAIC2K,EAAW,IAAI,UAAU,IACVzH,EAAU,YAAYjD,CAAU,EACxC,QAASoL,GAAY,CAC5B4S,EAAgB/O,EAAM,WAAY7D,EAAQ,YAAA,EAAerL,CAAI,CAC/D,CAAC,EAGGH,EAAO,gBAAgB,CACzB,MAAMyL,EAAiBzL,EAAO,eAAeI,EAAW,aAAa,EACjEqL,GACFA,EAAe,QAASD,GAAY,CAClC4S,EAAgB/O,EAAM,WAAY7D,EAAQ,YAAA,EAAerL,CAAI,CAC/D,CAAC,CAEL,CAEJ,CAKA,SAAS8d,GAAiCF,EAAoBF,EAAgBC,EAAmBza,EAA8BgM,EAAmBrP,EAAqB8K,EAA+B,CACpM,MAAM1K,EAAaiD,EAAU,UAAU0a,CAAU,EAGjDS,EAAyBnP,EAAM,cAAejP,EAAW,YAAA,EAAeyd,CAAiB,EAGzF,MAAMQ,EAAiBrN,EAAc+M,CAAU,EAC/C,GAAIM,IAAmBN,EAAY,CACjC,MAAMO,EAAuBjb,EAAU,UAAUgb,CAAc,EAAE,YAAA,EAC7DC,IAAyBle,EAAW,eACtCoe,EAAyBnP,EAAM,cAAeiP,EAAsBT,CAAiB,CAEzF,CAWA,GARI/S,EAAW,IAAI,eAAe,GACfzH,EAAU,gBAAgB0a,EAAY/d,EAAO,WAAW,EAChE,QAASqL,GAAY,CAC5BmT,EAAyBnP,EAAM,cAAehE,EAAQ,YAAA,EAAewS,CAAiB,CACxF,CAAC,EAIC/S,EAAW,IAAI,UAAU,GAAKzH,EAAU,kBAAkB,SAAS,UAAU,EAAG,CAClF,MAAM6H,EAAe7H,EAAU,gBAAgB0a,CAAU,EACrD7S,GACFsT,EAAyBnP,EAAM,eAAgBnE,EAAc2S,CAAiB,CAElF,CAKA,MAAMU,EADoBve,EAAO,cAAgB,QAAUI,EAAW,OAAS,GACvCA,EAAW,UAAU,EAAG,EAAE,EAAIA,EAiBtE,GAhBemF,GAAegZ,EAAY,YAAA,EAAeve,EAAO,SAAS,EAClE,QAASsL,GAAkB,CAChCkT,EAAyBnP,EAAM,WAAY/D,EAAOuS,CAAiB,CACrE,CAAC,EAGG/S,EAAW,IAAI,UAAU,GAAKzH,EAAU,kBAAkB,SAAS,UAAU,GACjEA,EAAU,mBAAmB0a,CAAU,EAC/C,QAASvb,GAAS,CAClBA,EAAK,QAAUxC,EAAO,gBACxBwe,EAAyBnP,EAAM,cAAehM,EAAU,UAAUb,CAAI,EAAE,YAAA,EAAeqb,CAAiB,CAE5G,CAAC,EAIC/S,EAAW,IAAI,UAAU,IACVzH,EAAU,YAAYjD,CAAU,EACxC,QAASoL,GAAY,CAC5BgT,EAAyBnP,EAAM,WAAY7D,EAAQ,YAAA,EAAeqS,CAAiB,CACrF,CAAC,EAGG7d,EAAO,gBAAgB,CACzB,MAAMyL,EAAiBzL,EAAO,eAAeI,EAAW,aAAa,EACjEqL,GACFA,EAAe,QAASD,GAAY,CAClCgT,EAAyBnP,EAAM,WAAY7D,EAAQ,YAAA,EAAeqS,CAAiB,CACrF,CAAC,CAEL,CAEJ,CAKA,SAASW,EAAyBra,EAA+BiM,EAAaC,EAAeoO,EAA0B,CAIhHta,EAAI,IAAIiM,CAAG,GACdjM,EAAI,IAAIiM,EAAK,IAAI,GAAK,EAExBjM,EAAI,IAAIiM,CAAG,EAAG,IAAIC,CAAK,CACzB,CAKA,SAAS+N,EAAgBja,EAA+BiM,EAAaC,EAAqB,CACnFlM,EAAI,IAAIiM,CAAG,GACdjM,EAAI,IAAIiM,EAAK,IAAI,GAAK,EAExBjM,EAAI,IAAIiM,CAAG,EAAG,IAAIC,CAAK,CACzB,CA8BO,SAASqO,GAAYrP,EAAmBsP,EAAmBnO,EAAqBnG,EAAyB,CAAA,EAAwC,CACtJ,MAAM1D,EAA8C,CAAA,EAC9CiY,EAAgB,CAAC,GAAG,IAAI,IAAID,CAAO,CAAC,EAE1C,UAAW7S,KAAS8S,EAClBjY,EAAQmF,CAAK,EAAIoN,EAAe7J,EAAOvD,EAAO0E,EAAYnG,CAAO,EAGnE,OAAO1D,CACT,CAmDO,SAASuS,EAAe7J,EAAmBvD,EAAe0E,EAAqBnG,EAAyB,CAAA,EAAwB,CACrI,MAAMrK,EAASqP,EAAM,OACfqK,EAAQlJ,GAAcnG,EAAQ,YAAcrK,EAAO,WACnDqG,EAAYgE,EAAQ,gBAAkBrK,EAAO,eAEnD,GAAI,CAAC8L,GAASA,EAAM,OAAO,OAAS9L,EAAO,eACzC,MAAO,CAAA,EAIT,GAAIqK,EAAQ,WAAagP,GAAWvN,CAAK,EACvC,OAAO0N,GAAgBnK,EAAOvD,EAAO4N,EAAOrP,CAAO,EAIrD,MAAMwU,EAAcnL,GAAW5H,CAAK,EAGpC,GAAI+S,EAAY,WACd,OAAOC,GAAkBzP,EAAOwP,EAAanF,EAAOrT,EAAWgE,CAAO,EAIxE,IAAI0U,EAAiBjT,EAMrB,GALI9L,EAAO,iBAAmBA,EAAO,WAAaA,EAAO,UAAU,OAAS,IAC1E+e,EAAiBlN,GAAgB/F,EAAO9L,EAAO,SAAS,GAItD,CAAC+e,GAAkBA,EAAe,KAAA,EAAO,SAAW,EACtD,MAAO,CAAA,EAIT,GAAI1P,EAAM,OAAQ,CAChB,MAAM4B,EAAS5B,EAAM,OAAO,IAAI0P,EAAgBrF,EAAOrP,CAAO,EAC9D,GAAI4G,EACF,OAAOA,CAEX,CAIA,MAAMlF,GADkB1B,EAAQ,WAAarK,EAAO,WACjB,IAAKH,GAASwP,EAAM,mBAAmB,IAAIxP,CAAI,CAAC,EAAE,OAAQuJ,GAA8BA,IAAM,MAAS,EAE1I,GAAI2C,EAAW,SAAW,EACxB,MAAO,CAAA,EAIT,GAAIsD,EAAM,eAAiBA,EAAM,UAAW,CAC1C,MAAM1I,EAAUqY,GAAuB3P,EAAO0P,EAAgBrF,EAAOrT,EAAW0F,EAAY1B,CAAO,EAEnG,OAAIgF,EAAM,QACRA,EAAM,OAAO,IAAI0P,EAAgBpY,EAAS+S,EAAOrP,CAAO,EAEnD1D,CACT,CAGA,MAAMqF,MAAc,IAGpB,UAAW3I,KAAa0I,EAAY,CAClC,MAAME,EAAkB5I,EAAU,UAAU0b,EAAe,MAAM,EAGjEE,GAAiBhT,EAAiBoD,EAAOrD,EAAS3I,EAAU,QAAQ,EAGpE,MAAM6b,EAAe,MAAM,KAAKlT,EAAQ,OAAA,CAAQ,EAAE,OAAOlC,GAAKA,EAAE,YAAc,OAAO,EACrF,GAAIoV,EAAa,QAAUxF,GAASwF,EAAa,KAAKpV,GAAKA,EAAE,OAASmC,CAAe,EACnF,MAGFkT,GAAkBlT,EAAiBoD,EAAOrD,EAAS3I,EAAU,QAAQ,EACrE+b,GAAqBnT,EAAiBoD,EAAOrD,EAAS3I,EAAU,QAAQ,EAG7C,MAAM,KAAK2I,EAAQ,OAAA,CAAQ,EAAE,OAAOlC,GAC7DA,EAAE,YAAc,SAAWA,EAAE,YAAc,UAAYA,EAAE,YAAc,WAAA,EAElD,QAAU4P,EAAQ,GAEvC2F,GAAoBpT,EAAiB5I,EAAWgM,EAAOrD,CAAO,EAC9DsT,GAAmBrT,EAAiBoD,EAAOrD,CAAO,EAG9CA,EAAQ,KAAO0N,EAAQ,IACzB6F,GAAiBtT,EAAiBoD,EAAOrD,EAAS3I,EAAU,SAAUrD,EAAO,SAAS,GAElFA,EAAO,SAAS,SAAS,iBAAiB,GAAKA,EAAO,SAAS,SAAS,eAAe,GAAKA,EAAO,SAAS,SAAS,gBAAgB,IACvIwf,GAAiBvT,EAAiBoD,EAAOrD,EAAS3I,EAAWrD,CAAM,KAKvEqf,GAAoBpT,EAAiB5I,EAAWgM,EAAOrD,CAAO,EAC9DsT,GAAmBrT,EAAiBoD,EAAOrD,CAAO,EAClDuT,GAAiBtT,EAAiBoD,EAAOrD,EAAS3I,EAAU,SAAUrD,EAAO,SAAS,GAElFA,EAAO,SAAS,SAAS,iBAAiB,GAAKA,EAAO,SAAS,SAAS,eAAe,GAAKA,EAAO,SAAS,SAAS,gBAAgB,IACvIwf,GAAiBvT,EAAiBoD,EAAOrD,EAAS3I,EAAWrD,CAAM,EAGzE,CAGA,IAAI2G,EAAU,MAAM,KAAKqF,EAAQ,QAAQ,EACtC,IAAK+B,GAAU0R,GAAuB1R,EAAOgR,EAAgB1Y,EAAWgJ,EAAOhF,CAAO,CAAC,EACvF,OAAQjF,GAAuCA,IAAW,IAAI,EAGjE,OAAIiF,EAAQ,UACV1D,EAAU4U,GAAa5U,EAAS0D,EAAQ,OAAO,GAI7CA,EAAQ,KACV1D,EAAUoV,GAAapV,EAAS0D,EAAQ,IAAI,EAG5C1D,EAAUA,EAAQ,KAAK,CAAC4G,EAAGgC,IAAMA,EAAE,MAAQhC,EAAE,KAAK,EAIpD5G,EAAUA,EAAQ,MAAM,EAAG+S,CAAK,EAG5BrK,EAAM,QACRA,EAAM,OAAO,IAAI0P,EAAgBpY,EAAS+S,EAAOrP,CAAO,EAGnD1D,CACT,CAKA,SAASsY,GAAiBnT,EAAeuD,EAAmBrD,EAAmC7I,EAAwB,CACrH,MAAMmQ,EAAiBjE,EAAM,OAAO,gBAAkB,GAGtD,GAAIvD,EAAM,SAAS,GAAG,EAAG,CAEvB,UAAW4T,KAAYrQ,EAAM,KACvBoE,GAAgBiM,EAAU5T,CAAK,IAC5BE,EAAQ,IAAI0T,CAAQ,GACvB1T,EAAQ,IAAI0T,EAAU,CACpB,KAAMA,EACN,WAAY5T,EACZ,UAAW,QACX,aAAc,EACd,SAAA3I,CAAA,CACD,GAIP,MACF,CAGA,MAAM+b,EAAe7P,EAAM,cAAc,IAAIvD,EAAM,aAAa,EAC5DoT,GACFA,EAAa,QAAS/e,GAAS,CAE7B,GAAImT,GAAkB,CAACD,GAAYlT,EAAM2L,EAAOwH,CAAc,EAC5D,OAIF,MAAMyF,EAAW/M,EAAQ,IAAI7L,CAAI,GAC7B,CAAC4Y,GAAYA,EAAS,YAAc,UACtC/M,EAAQ,IAAI7L,EAAM,CAChB,KAAAA,EACA,WAAY2L,EACZ,UAAW,QACX,aAAc,EACd,SAAA3I,CAAA,CACD,CAEL,CAAC,EAIH,MAAMwc,EAAa7T,EAAM,YAAA,EACzB,UAAW4T,KAAYrQ,EAAM,KACvBqQ,EAAS,YAAA,IAAkBC,IACxB3T,EAAQ,IAAI0T,CAAQ,GACvB1T,EAAQ,IAAI0T,EAAU,CACpB,KAAMA,EACN,WAAY5T,EACZ,UAAW,QACX,aAAc,EACd,SAAA3I,CAAA,CACD,EAIT,CAKA,SAASgc,GAAkBrT,EAAeuD,EAAmBrD,EAAmC7I,EAAwB,CACtH,MAAMmQ,EAAiBjE,EAAM,OAAO,gBAAkB,GAChDsQ,EAAa7T,EAAM,YAAA,EAEzB,SAAW,CAACT,EAAST,CAAK,IAAKyE,EAAM,cAAc,UAC7ChE,EAAQ,WAAWsU,CAAU,GAAKtU,IAAYsU,GAChD/U,EAAM,QAASzK,GAAS,CAElBmT,GAAkB,CAACD,GAAYlT,EAAM2L,EAAOwH,CAAc,GAIzDtH,EAAQ,IAAI7L,CAAI,GACnB6L,EAAQ,IAAI7L,EAAM,CAChB,KAAAA,EACA,WAAYkL,EACZ,UAAW,SACX,SAAAlI,CAAA,CACD,CAEL,CAAC,CAGP,CAKA,SAASic,GAAqBtT,EAAeuD,EAAmBrD,EAAmC7I,EAAwB,CACzH,MAAMwc,EAAa7T,EAAM,YAAA,EAGzB,GAAI,EAAA6T,EAAW,OAAS,GAExB,SAAW,CAACtU,EAAST,CAAK,IAAKyE,EAAM,cAAc,UAE7ChE,EAAQ,SAASsU,CAAU,GAAK,CAACtU,EAAQ,WAAWsU,CAAU,GAAKtU,IAAYsU,GACjF/U,EAAM,QAASzK,GAAS,CACtB,MAAM6N,EAAgBhC,EAAQ,IAAI7L,CAAI,GAElC,CAAC6N,GAAkBA,EAAc,YAAc,SAAWA,EAAc,YAAc,WACxFhC,EAAQ,IAAI7L,EAAM,CAChB,KAAAA,EACA,WAAYkL,EACZ,UAAW,YACX,SAAAlI,CAAA,CACD,CAEL,CAAC,CAGP,CAKA,SAASkc,GAAoBvT,EAAezI,EAA8BgM,EAAmBrD,EAAyC,CACpI,GAAI,CAAC3I,EAAU,kBAAkB,SAAS,UAAU,EAAG,OAEvD,MAAM6H,EAAe7H,EAAU,gBAAgByI,CAAK,EACpD,GAAIZ,EAAc,CAChB,MAAM0U,EAAkBvQ,EAAM,eAAe,IAAInE,CAAY,EACzD0U,GACFA,EAAgB,QAASzf,GAAS,CAC3B6L,EAAQ,IAAI7L,CAAI,GACnB6L,EAAQ,IAAI7L,EAAM,CAChB,KAAAA,EACA,WAAY2L,EACZ,UAAW,WACX,aAAAZ,EACA,SAAU7H,EAAU,QAAA,CACrB,CAEL,CAAC,CAEL,CACF,CAKA,SAASic,GAAmBxT,EAAeuD,EAAmBrD,EAAyC,CACrG,MAAM6T,EAAiBxQ,EAAM,WAAW,IAAIvD,EAAM,aAAa,EAC3D+T,GACFA,EAAe,QAAS1f,GAAS,CAC1B6L,EAAQ,IAAI7L,CAAI,GACnB6L,EAAQ,IAAI7L,EAAM,CAChB,KAAAA,EACA,WAAY2L,EACZ,UAAW,UACX,SAAU,SAAA,CACX,CAEL,CAAC,CAEL,CAKA,SAASyT,GAAiBzT,EAAeuD,EAAmBrD,EAAmC7I,EAAkBuJ,EAAyB,CACxI,GAAIZ,EAAM,OAASY,EAAW,OAE9B,MAAMC,EAAcpH,GAAeuG,EAAOY,CAAS,EAC7CoT,MAAqB,IAE3BnT,EAAY,QAASrB,GAAU,CAC7B,MAAMyU,EAAe1Q,EAAM,WAAW,IAAI/D,CAAK,EAC3CyU,GACFA,EAAa,QAAS5f,GAAS2f,EAAe,IAAI3f,CAAI,CAAC,CAE3D,CAAC,EAED2f,EAAe,QAAS3f,GAAS,CAC1B6L,EAAQ,IAAI7L,CAAI,GACnB6L,EAAQ,IAAI7L,EAAM,CAChB,KAAAA,EACA,WAAY2L,EACZ,UAAW,QACX,SAAA3I,CAAA,CACD,CAEL,CAAC,CACH,CAKA,SAASqc,GAAiB1T,EAAeuD,EAAmBrD,EAAmC3I,EAA8BrD,EAA2B,CAEtJ,IAAIyE,EAAczE,EAAO,iBAGrB8L,EAAM,QAAU,GAETA,EAAM,QAAU,KACzBrH,EAAc,KAAK,IAAIA,EAAa,CAAC,GAGvC,SAAW,CAAC4G,EAAST,CAAK,IAAKyE,EAAM,cAAc,UAAW,CAE5D,MAAM2Q,EAAa,KAAK,IAAI3U,EAAQ,OAASS,EAAM,MAAM,EACnDmU,EAAgBnU,EAAM,QAAU,EAAI,EAAKA,EAAM,QAAU,EAAI,EAAIrH,EAEvE,GAAIub,GAAcC,EAAe,CAG/B,MAAM/Z,EADoBmJ,EAAM,OAAO,UAAU,SAAS,gBAAgB,EACrCxK,EAAoCiH,EAAOT,EAAS5G,CAAW,EAAID,EAA6BsH,EAAOT,EAAS5G,CAAW,EAG1Jyb,EAAoBpU,EAAM,QAAU,EAAI,EAAIrH,EAE9CyB,GAAYga,GACdtV,EAAM,QAASzK,GAAS,CACtB,MAAM6N,EAAgBhC,EAAQ,IAAI7L,CAAI,GAElC,CAAC6N,GAAkBA,EAAc,YAAc,SAAWA,EAAc,YAAc,WAAaA,EAAc,cAAgB,KAAY9H,IAC/I8F,EAAQ,IAAI7L,EAAM,CAChB,KAAAA,EACA,WAAYkL,EACZ,UAAW,QACX,aAAcnF,EACd,SAAU7C,EAAU,QAAA,CACrB,CAEL,CAAC,CAEL,CACF,CACF,CAKA,SAASoc,GAAuB1R,EAAoBoS,EAAuB9Z,EAAmBgJ,EAAmBhF,EAAkD,CACjK,IAAI7B,EAAQ4X,GAAoBrS,EAAOoS,EAAe9Q,EAAM,MAAM,EAGlE,GAAItB,EAAM,YAAc,QAAasB,EAAM,OAAO,QAAS,CACzD,MAAMvG,EAAauG,EAAM,OAAO,YAAc,GACxCtG,EAAc,EAAID,EACxBN,EAAQM,EAAaiF,EAAM,UAAYhF,EAAcP,CACvD,CAOA,GAJIuF,EAAM,cACRvF,EAAQ,KAAK,IAAI,EAAKA,EAAQuF,EAAM,WAAW,GAG7CvF,EAAQnC,EACV,OAAO,KAGT,MAAMjB,EAA2B,CAC/B,QAAS2I,EAAM,KACf,SAAUA,EAAM,KAChB,UAAWA,EAAM,YAAc,UAC/B,MAAAvF,EACA,SAAUuF,EAAM,SAEhB,iBAAkBA,EAAM,SAAA,EAI1B,OAAIsB,EAAM,WAAaA,EAAM,UAAU,IAAItB,EAAM,IAAI,IACnD3I,EAAO,OAASiK,EAAM,UAAU,IAAItB,EAAM,IAAI,EAC9C3I,EAAO,MAAQ2I,EAAM,OAInB1D,GAAS,oBACXjF,EAAO,WAAakJ,GAAoBP,EAAOoS,EAAepS,EAAM,IAAI,GAGnE3I,CACT,CAKA,SAASgb,GAEPrS,EACAjC,EACA9L,EACQ,CAER,MAAMqgB,EAAS,CACb,GAAGnhB,EACH,GAAIc,GAAQ,iBAAmB,CAAA,CAAC,EAE5BsgB,EAAY,CAChB,GAAGnhB,EACH,GAAIa,GAAQ,kBAAoB,CAAA,CAAC,EAG7B6M,EAAWf,EAAM,OACjByU,EAAUxS,EAAM,KAAK,OACrBjJ,EAAS,KAAK,IAAI+H,EAAU0T,CAAO,EAEzC,IAAI/X,EAAQ8X,EAAU,UAEtB,OAAQvS,EAAM,UAAA,CACZ,IAAK,QACHvF,EAAQ6X,EAAO,MACf,MACF,IAAK,SACH7X,EAAQ6X,EAAO,OAEXC,EAAU,sBACZ9X,IAAU+X,EAAU1T,IAAa/H,EAAS,IAE5C,MACF,IAAK,YACH0D,EAAQ6X,EAAO,UAEf,MAAMG,EAAezS,EAAM,WAAW,YAAA,EAAc,QAAQjC,EAAM,aAAa,EAC/E,GAAI0U,IAAiB,GAAI,CAEvB,MAAMC,EAAgB,KAAK,IAAI,EAAG,IAAO,EAAID,EAAezS,EAAM,WAAW,OAAO,EACpFvF,GAASiY,CACX,CACA,MACF,IAAK,WACHjY,EAAQ6X,EAAO,SACf,MACF,IAAK,QACCtS,EAAM,eAAiB,SAErB/N,GAAQ,gCAAkC4Z,GAAe9N,CAAK,GAAK8N,GAAe7L,EAAM,IAAI,EAC9FvF,EAAQkY,GAA2B5U,EAAOiC,EAAM,KAAM/N,CAAM,EAG5DwI,EAAQ,KAAK,IAAI6X,EAAO,SAAUA,EAAO,MAAStS,EAAM,aAAejJ,EAAU,EAAG,GAGxF,MACF,IAAK,UACH0D,EAAQ6X,EAAO,QACf,MACF,IAAK,WACH7X,EAAQ6X,EAAO,SACf,MACF,IAAK,QACH7X,EAAQnD,EAAyByG,EAAM,YAAA,EAAeiC,EAAM,WAAY,CAAC,EAAIsS,EAAO,MACpF,KAAA,CAWJ,OALIE,GAAW1T,EAAWyT,EAAU,kBAAoBvS,EAAM,YAAc,UAC1EvF,GAAS8X,EAAU,gBAIjBvS,EAAM,YAAc,QACf,KAAK,IAAI,EAAK,KAAK,IAAI,EAAKsS,EAAO,KAAK,CAAC,EAG3C,KAAK,IAAI,EAAK,KAAK,IAAI,EAAK7X,CAAK,CAAC,CAC3C,CAMA,SAASkY,GACP5U,EACA6U,EACA3gB,EACQ,CAER,MAAM4gB,EAAapG,EAAiB1O,CAAK,EAAE,YAAA,EACrC+U,EAAcrG,EAAiBmG,CAAM,EAAE,YAAA,EACvCG,EAAerG,EAAmB3O,CAAK,EACvCiV,EAAgBtG,EAAmBkG,CAAM,EAEzCK,EAAchhB,EAAO,yBAA2B,GAChDihB,EAAgBjhB,EAAO,2BAA6B,GAE1D,IAAIkhB,EAAa,EACbC,EAAe,EAGnB,GAAIP,EAAW,OAAS,GAAKC,EAAY,OAAS,EAAG,CACnD,MAAMO,EAAc,KAAK,IAAIR,EAAW,OAAQC,EAAY,MAAM,EAC5DQ,EAAgB7c,EAA6Boc,EAAYC,EAAa7gB,EAAO,eAAe,EAClGkhB,EAAa,KAAK,IAAI,EAAG,EAAMG,EAAgBD,CAAW,CAC5D,MAAWR,EAAW,SAAW,GAAKC,EAAY,SAAW,IAC3DK,EAAa,GAIf,GAAIJ,EAAa,OAAS,GAAKC,EAAc,OAAS,EACpD,GAAID,IAAiBC,EACnBI,EAAe,UAGXJ,EAAc,SAASD,CAAY,GAAKA,EAAa,SAASC,CAAa,EAAG,CAChF,MAAM1F,EAAUyF,EAAa,OAASC,EAAc,OAASD,EAAeC,EACtE3F,EAAS0F,EAAa,OAASC,EAAc,OAASA,EAAgBD,EAC5EK,EAAe9F,EAAQ,OAASD,EAAO,MACzC,KAAO,CAEL,MAAMkG,EAAgB,KAAK,IAAIR,EAAa,OAAQC,EAAc,MAAM,EAClEQ,EAAavhB,EAAO,2CAA6C,IACjEwhB,EAAkBhd,EAA6Bsc,EAAcC,EAAe,KAAK,KAAK/gB,EAAO,gBAAkBuhB,CAAU,CAAC,EAChIJ,EAAe,KAAK,IAAI,EAAG,EAAMK,EAAkBF,CAAa,CAClE,MAEOR,EAAa,SAAW,GAAKC,EAAc,SAAW,EAC/DI,EAAe,EAGfA,EAAe,GAIjB,MAAMM,EAAgBP,EAAaF,EAAcG,EAAeF,EAGhE,OAAO,KAAK,IAAI,GAAKQ,CAAa,CACpC,CAKA,SAASlc,GAEPO,EACAC,EACU,CACV,GAAID,EAAI,OAASC,EAAG,MAAO,CAACD,CAAG,EAE/B,MAAM3E,EAAmB,CAAA,EACzB,QAASZ,EAAI,EAAGA,GAAKuF,EAAI,OAASC,EAAGxF,IACnCY,EAAO,KAAK2E,EAAI,MAAMvF,EAAGA,EAAIwF,CAAC,CAAC,EAEjC,OAAO5E,CACT,CAMA,SAAS6d,GAEP3P,EACAvD,EACA4N,EACArT,EACA0F,EACA1B,EACoB,CACpB,GAAI,CAACgF,EAAM,eAAiB,CAACA,EAAM,UACjC,MAAM,IAAI,MAAM,8BAA8B,EAIhD,IAAIrD,EAAUH,GAAoBwD,EAAM,cAAeA,EAAM,UAAWvD,EAAOC,EAAYsD,EAAM,MAAM,EAGvG,GAAIA,EAAM,OAAO,QAAS,CACxB,MAAMvH,EAAagE,EAAM,YAAA,EAAc,MAAM,KAAK,EAAE,OAAOmI,GAAKA,EAAE,OAAS,CAAC,EAC5EjI,EAAUiC,GAAoBjC,EAASlE,EAAYuH,EAAM,cAAeA,EAAM,UAAWA,EAAM,MAAM,CACvG,CAGA,IAAI1I,EAAUqF,EACX,IAAK+B,GAAU0R,GAAuB1R,EAAOjC,EAAOzF,EAAWgJ,EAAOhF,CAAO,CAAC,EAC9E,OAAQjF,GAAuCA,IAAW,IAAI,EAGjE,OAAIiF,GAAS,UACX1D,EAAU4U,GAAa5U,EAAS0D,EAAQ,OAAO,GAI7CA,GAAS,KACX1D,EAAUoV,GAAapV,EAAS0D,EAAQ,IAAI,EAG5C1D,EAAUA,EAAQ,KAAK,CAAC4G,EAAGgC,IAAMA,EAAE,MAAQhC,EAAE,KAAK,EAIpD5G,EAAUA,EAAQ,MAAM,EAAG+S,CAAK,EAEzB/S,CACT,CAMA,SAASmY,GACPzP,EACAwP,EACAnF,EACArT,EACAgE,EACoB,CACpB,MAAMrK,EAASqP,EAAM,OAIfqS,EAAgB,CACpB,WAAY,GACZ,gBAAiB,EACjB,eAAgB,IAChB,qBAAsB,EACtB,kBARwB1hB,EAAO,SAAS,SAAS,gBAAgB,CAQjE,EAII2hB,MAAoB,IAG1B,UAAW7N,KAAU+K,EAAY,QAC/B,UAAW1e,KAAQkP,EAAM,KAAM,CAC7B,MAAMtB,EAAQuG,GAAYnU,EAAM2T,EAAQ4N,CAAa,EAErD,GAAI3T,EAAM,QAAS,CACjB,MAAMgL,EAAW4I,EAAc,IAAIxhB,CAAI,EACjCyhB,EAAW7T,EAAM,MAAQ2T,EAAc,eAEzC3I,EAEF4I,EAAc,IAAIxhB,EAAM,CACtB,MAAO,KAAK,IAAI4Y,EAAS,MAAO6I,CAAQ,EACxC,YAAa7I,EAAS,YAAc,CAAA,CACrC,EAED4I,EAAc,IAAIxhB,EAAM,CAAE,MAAOyhB,EAAU,YAAa,EAAG,CAE/D,CACF,CAIF,IAAIC,MAAkB,IAEtB,GAAIhD,EAAY,MAAM,OAAS,EAAG,CAChC,MAAMiD,EAAYjD,EAAY,MAAM,KAAK,GAAG,EACtC9S,EAAa/L,EAAO,UACvB,IAAKH,GAASwP,EAAM,mBAAmB,IAAIxP,CAAI,CAAC,EAChD,OAAQuJ,GAA8BA,IAAM,MAAS,EAExD,UAAW/F,KAAa0I,EAAY,CAClC,MAAME,EAAkB5I,EAAU,UAAUye,CAAS,EAGrD7C,GAAiBhT,EAAiBoD,EAAOwS,EAAaxe,EAAU,QAAQ,EACxE8b,GAAkBlT,EAAiBoD,EAAOwS,EAAaxe,EAAU,QAAQ,EACzEgc,GAAoBpT,EAAiB5I,EAAWgM,EAAOwS,CAAW,EAClEtC,GAAiBtT,EAAiBoD,EAAOwS,EAAaxe,EAAU,SAAUrD,EAAO,SAAS,GAEtFA,EAAO,SAAS,SAAS,iBAAiB,GAAKA,EAAO,SAAS,SAAS,eAAe,GAAKA,EAAO,SAAS,SAAS,gBAAgB,IACvIwf,GAAiBvT,EAAiBoD,EAAOwS,EAAaxe,EAAWrD,CAAM,CAE3E,CACF,CAGA,MAAM+hB,MAAsB,IAG5B,SAAW,CAAC5hB,EAAM6hB,CAAU,IAAKL,EAAc,UAAW,CACxD,MAAMvc,EAA2B,CAC/B,QAASjF,EACT,SAAUA,EACV,UAAW,GACX,MAAO6hB,EAAW,KAAA,EAIFH,EAAY,IAAI1hB,CAAI,IAEpCiF,EAAO,MAAQ,KAAK,IAAI,EAAKA,EAAO,MAAQ,GAAG,GAGjD2c,EAAgB,IAAI5hB,EAAMiF,CAAM,CAClC,CAGA,SAAW,CAACjF,EAAM4N,CAAK,IAAK8T,EAAY,UACtC,GAAI,CAACE,EAAgB,IAAI5hB,CAAI,EAAG,CAC9B,MAAMiF,EAASqa,GAAuB1R,EAAO8Q,EAAY,MAAM,KAAK,GAAG,EAAGxY,EAAWgJ,EAAOhF,CAAO,EAC/FjF,IAEFA,EAAO,OAAS,GAChB2c,EAAgB,IAAI5hB,EAAMiF,CAAM,EAEpC,CAIF,MAAMuB,EAAU,MAAM,KAAKob,EAAgB,QAAQ,EAChD,OAAOlJ,GAAKA,EAAE,OAASxS,CAAS,EAChC,KAAK,CAACkH,EAAGgC,IAAMA,EAAE,MAAQhC,EAAE,KAAK,EAChC,MAAM,EAAGmM,CAAK,EAGjB,OAAIrK,EAAM,QACRA,EAAM,OAAO,IAAIwP,EAAY,SAAUlY,EAAS+S,EAAOrP,CAAO,EAGzD1D,CACT,CAgBO,SAASsb,GACd5S,EACA6S,EAA6B,CAAA,EAC7B7X,EAAsC,CAAA,EAC1B,CACZ,GAAI,CAACgF,GAAS,CAACA,EAAM,OACnB,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GAAI,CAAC6S,GAAYA,EAAS,SAAW,EACnC,OAAO7S,EAIT,MAAMrP,EAASqP,EAAM,OACfvE,EAAa,IAAI,IAAI9K,EAAO,QAAQ,EAGpC6K,EAAqB,MAAM,KAAKwE,EAAM,mBAAmB,QAAQ,EAEvE,GAAIxE,EAAmB,SAAW,EAChC,MAAM,IAAI,MAAM,uCAAuC,EAIzD,MAAM2S,EAAYnO,EAAM,QAAUA,EAAM,OAAO,OAAS,EAClDoO,EAAgByE,EAAS,OAAS,GAAK,OAAOA,EAAS,CAAC,GAAM,UAAYA,EAAS,CAAC,IAAM,KAGhG,GAAIzE,GAAiB,CAACD,EACpB,MAAM,IAAI,MAAM,qDAAqD,EAIvE,MAAM2E,EAAgB,IAAI,IAAI9S,EAAM,KAAK,IAAI2C,GAAKA,EAAE,YAAA,CAAa,CAAC,EAClE,IAAI4L,EAAY,EAEhB,UAAWhY,KAAQsc,EACjB,GAAKtc,EAGL,IAAI4X,GAAaC,EAAe,CAC9B,MAAMjM,EAAcF,GAAmB1L,EAAMyJ,EAAM,MAAM,EACzD,GAAI,CAACmC,EAAa,SAGlB,MAAMqM,EAAS,OAAO,OAAOrM,CAAW,EAAE,CAAC,GAAK,QAAQnC,EAAM,KAAK,OAASuO,CAAS,GAGrF,GAAIuE,EAAc,IAAItE,EAAO,YAAA,CAAa,EAAG,SAGzCxO,EAAM,WACRA,EAAM,UAAU,IAAIwO,EAAQrM,CAAW,EAIzC2Q,EAAc,IAAItE,EAAO,aAAa,EACtCxO,EAAM,KAAK,KAAKwO,CAAM,EAGtB,SAAW,CAACC,EAAWC,CAAU,IAAK,OAAO,QAAQvM,CAAW,EAAG,CACjE,GAAI,CAACuM,GAAcA,EAAW,OAAO,OAAS/d,EAAO,eAAgB,SAErE,MAAMge,EAAeD,EAAW,KAAA,EAGhC,UAAW1a,KAAawH,EACtBoT,GAAiCD,EAAcH,EAAQC,EAAWza,EAAWgM,EAAOrP,EAAQ8K,CAAU,CAE1G,CACF,KAAO,CAEL,MAAM3K,EAAO,OAAOyF,GAAS,SAAWA,EAAO,OAAOA,CAAI,EAC1D,GAAIzF,EAAK,KAAA,EAAO,OAASH,EAAO,eAAgB,SAEhD,MAAMiL,EAAc9K,EAAK,KAAA,EAGzB,GAAIgiB,EAAc,IAAIlX,EAAY,YAAA,CAAa,EAAG,SAElDkX,EAAc,IAAIlX,EAAY,aAAa,EAC3CoE,EAAM,KAAK,KAAKpE,CAAW,EAG3B,UAAW5H,KAAawH,EACtBqT,GAAyBjT,EAAa5H,EAAWgM,EAAOrP,EAAQ8K,CAAU,CAE9E,CAEA8S,IACIvT,EAAQ,YACVA,EAAQ,WAAWuT,EAAWsE,EAAS,MAAM,EAKjD,GAAI7S,EAAM,eAAiBA,EAAM,UAAW,CAC1C,KAAM,CAAE,cAAAtE,EAAe,UAAA9C,CAAA,EAAc0C,EACnC0E,EAAM,KACNxE,EACA7K,EACA8K,CAAA,EAEFuE,EAAM,cAAgBtE,EACtBsE,EAAM,UAAYpH,CACpB,CAGA,OAAIoH,EAAM,QACRA,EAAM,OAAO,MAAA,EAGRA,CACT,CAcO,SAAS+S,GACd/S,EACAgT,EAA0B,GACd,CACZ,GAAI,CAAChT,GAAS,CAACA,EAAM,OACnB,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GAAI,CAACgT,GAAiBA,EAAc,SAAW,EAC7C,OAAOhT,EAIT,MAAMiT,EAAW,IAAI,IAAID,EAAc,IAAIzc,GAAQA,EAAK,YAAA,CAAa,CAAC,EAGtEyJ,EAAM,KAAOA,EAAM,KAAK,OAAOlP,GAAQ,CAACmiB,EAAS,IAAIniB,EAAK,YAAA,CAAa,CAAC,EAGxE,SAAW,CAACkL,EAASkX,CAAS,IAAKlT,EAAM,cAAc,UAAW,CAChE,MAAM4C,EAAW,IAAI,IAAI,MAAM,KAAKsQ,CAAS,EAAE,OAAQpiB,GAAiB,CAACmiB,EAAS,IAAIniB,EAAK,YAAA,CAAa,CAAC,CAAC,EACtG8R,EAAS,OAAS,EACpB5C,EAAM,cAAc,OAAOhE,CAAO,EAElCgE,EAAM,cAAc,IAAIhE,EAAS4G,CAAQ,CAE7C,CAGA,SAAW,CAACuQ,EAAUD,CAAS,IAAKlT,EAAM,eAAe,UAAW,CAClE,MAAM4C,EAAW,IAAI,IAAI,MAAM,KAAKsQ,CAAS,EAAE,OAAQpiB,GAAiB,CAACmiB,EAAS,IAAIniB,EAAK,YAAA,CAAa,CAAC,CAAC,EACtG8R,EAAS,OAAS,EACpB5C,EAAM,eAAe,OAAOmT,CAAQ,EAEpCnT,EAAM,eAAe,IAAImT,EAAUvQ,CAAQ,CAE/C,CAGA,SAAW,CAAC3G,EAAOiX,CAAS,IAAKlT,EAAM,WAAW,UAAW,CAC3D,MAAM4C,EAAW,IAAI,IAAI,MAAM,KAAKsQ,CAAS,EAAE,OAAQpiB,GAAiB,CAACmiB,EAAS,IAAIniB,EAAK,YAAA,CAAa,CAAC,CAAC,EACtG8R,EAAS,OAAS,EACpB5C,EAAM,WAAW,OAAO/D,CAAK,EAE7B+D,EAAM,WAAW,IAAI/D,EAAO2G,CAAQ,CAExC,CAGA,SAAW,CAACzG,EAAS+W,CAAS,IAAKlT,EAAM,WAAW,UAAW,CAC7D,MAAM4C,EAAW,IAAI,IAAI,MAAM,KAAKsQ,CAAS,EAAE,OAAQpiB,GAAiB,CAACmiB,EAAS,IAAIniB,EAAK,YAAA,CAAa,CAAC,CAAC,EACtG8R,EAAS,OAAS,EACpB5C,EAAM,WAAW,OAAO7D,CAAO,EAE/B6D,EAAM,WAAW,IAAI7D,EAASyG,CAAQ,CAE1C,CAGA,GAAI5C,EAAM,UACR,UAAWzJ,KAAQyc,EACjBhT,EAAM,UAAU,OAAOzJ,CAAI,EAK/B,GAAIyJ,EAAM,eAAiBA,EAAM,UAAW,CAC1C,MAAMrP,EAASqP,EAAM,OACfvE,EAAa,IAAI,IAAI9K,EAAO,QAAQ,EACpC6K,EAAqB,MAAM,KAAKwE,EAAM,mBAAmB,QAAQ,EAEjE,CAAE,cAAAtE,EAAe,UAAA9C,CAAA,EAAc0C,EACnC0E,EAAM,KACNxE,EACA7K,EACA8K,CAAA,EAEFuE,EAAM,cAAgBtE,EACtBsE,EAAM,UAAYpH,CACpB,CAGA,OAAIoH,EAAM,QACRA,EAAM,OAAO,MAAA,EAGRA,CACT,CCj7CO,SAASoT,GAAepT,EAA2B,CACxD,MAAMqT,EAA8B,CAClC,QAAS,MACT,KAAMrT,EAAM,KACZ,cAAe,MAAM,KAAKA,EAAM,cAAc,QAAA,CAAS,EAAE,IAAI,CAAC,CAACxF,EAAG+M,CAAC,IAAM,CAAC/M,EAAG,MAAM,KAAK+M,CAAC,CAAC,CAAC,EAC3F,eAAgB,MAAM,KAAKvH,EAAM,eAAe,QAAA,CAAS,EAAE,IAAI,CAAC,CAACxF,EAAG+M,CAAC,IAAM,CAAC/M,EAAG,MAAM,KAAK+M,CAAC,CAAC,CAAC,EAC7F,WAAY,MAAM,KAAKvH,EAAM,WAAW,QAAA,CAAS,EAAE,IAAI,CAAC,CAACxF,EAAG+M,CAAC,IAAM,CAAC/M,EAAG,MAAM,KAAK+M,CAAC,CAAC,CAAC,EACrF,WAAY,MAAM,KAAKvH,EAAM,WAAW,QAAA,CAAS,EAAE,IAAI,CAAC,CAACxF,EAAG+M,CAAC,IAAM,CAAC/M,EAAG,MAAM,KAAK+M,CAAC,CAAC,CAAC,EACrF,OAAQvH,EAAM,OACd,uBAAwB,MAAM,KAAKA,EAAM,mBAAmB,MAAM,CAAA,EAIpE,OAAIA,EAAM,gBACRqT,EAAW,cAAgB,CACzB,eAAgB,MAAM,KAAKrT,EAAM,cAAc,eAAe,SAAS,EACvE,mBAAoB,MAAM,KAAKA,EAAM,cAAc,mBAAmB,SAAS,EAC/E,gBAAiB,MAAM,KAAKA,EAAM,cAAc,gBAAgB,SAAS,EACzE,kBAAmB,MAAM,KAAKA,EAAM,cAAc,kBAAkB,SAAS,EAC7E,UAAWA,EAAM,cAAc,UAC/B,aAAcA,EAAM,cAAc,YAAA,GAKlCA,EAAM,YACRqT,EAAW,UAAYrT,EAAM,WAGxB,KAAK,UAAUqT,CAAU,CAClC,CAKA,eAAsBC,GAAiBC,EAAmC,CACxE,MAAM/b,EAAwB,KAAK,MAAM+b,CAAI,EAGvCC,EAAgB,IAAI,IAAIhc,EAAK,cAAc,IAAI,CAAC,CAACgD,EAAG+M,CAAC,IAAM,CAAC/M,EAAG,IAAI,IAAI+M,CAAC,CAAC,CAAC,CAAC,EAC3EkM,EAAiB,IAAI,IAAIjc,EAAK,eAAe,IAAI,CAAC,CAACgD,EAAG+M,CAAC,IAAM,CAAC/M,EAAG,IAAI,IAAI+M,CAAC,CAAC,CAAC,CAAC,EAC7EmM,EAAa,IAAI,IAAIlc,EAAK,WAAW,IAAI,CAAC,CAACgD,EAAG+M,CAAC,IAAM,CAAC/M,EAAG,IAAI,IAAI+M,CAAC,CAAC,CAAC,CAAC,EACrEnU,EAAa,IAAI,IAAIoE,EAAK,WAAW,IAAI,CAAC,CAACgD,EAAG+M,CAAC,IAAM,CAAC/M,EAAG,IAAI,IAAI+M,CAAC,CAAC,CAAC,CAAC,EAGrE,CAAE,iBAAA1T,CAAA,EAAqB,MAAM,QAAA,QAAA,EAAA,KAAA,IAAAmM,EAAA,EAC7BxE,MAAyB,IAC/B,UAAWmY,KAAYnc,EAAK,uBAAwB,CAClD,MAAMxD,EAAYH,EAAiB,aAAa8f,CAAQ,EACpD3f,GACFwH,EAAmB,IAAImY,EAAU3f,CAAS,CAE9C,CAEA,MAAMgM,EAAoB,CACxB,KAAMxI,EAAK,KACX,cAAAgc,EACA,eAAAC,EACA,WAAAC,EACA,WAAAtgB,EACA,mBAAAoI,EACA,OAAQhE,EAAK,MAAA,EAqBf,GAjBIA,EAAK,gBACPwI,EAAM,cAAgB,CACpB,eAAgB,IAAI,IAAIxI,EAAK,cAAc,cAAc,EACzD,mBAAoB,IAAI,IAAIA,EAAK,cAAc,kBAAkB,EACjE,gBAAiB,IAAI,IAAIA,EAAK,cAAc,eAAe,EAC3D,kBAAmB,IAAI,IAAIA,EAAK,cAAc,iBAAiB,EAC/D,UAAWA,EAAK,cAAc,UAC9B,aAAcA,EAAK,cAAc,YAAA,GAKjCA,EAAK,YACPwI,EAAM,UAAYxI,EAAK,WAIrBA,EAAK,OAAO,cAAgB,GAAO,CACrC,MAAMsX,EAAYtX,EAAK,OAAO,WAAa,IAC3CwI,EAAM,OAAS,IAAIkB,GAAY4N,CAAS,CAC1C,CAEA,OAAO9O,CACT,CAKO,SAAS4T,GAAwB5T,EAAmBe,EAAc,qBAA4B,CACnG,GAAI,OAAO,aAAiB,IAC1B,MAAM,IAAI,MAAM,+BAA+B,EAEjD,MAAMsS,EAAaD,GAAepT,CAAK,EACvC,aAAa,QAAQe,EAAKsS,CAAU,CACtC,CAKA,eAAsBQ,GAA0B9S,EAAc,qBAAkD,CAC9G,GAAI,OAAO,aAAiB,IAC1B,MAAM,IAAI,MAAM,+BAA+B,EAEjD,MAAMsS,EAAa,aAAa,QAAQtS,CAAG,EAC3C,OAAKsS,EAGE,MAAMC,GAAiBD,CAAU,EAF/B,IAGX,CAKO,SAASS,GAAkB9T,EAA2B,CAC3D,MAAMqT,EAAaD,GAAepT,CAAK,EACvC,OAAO,IAAI,KAAK,CAACqT,CAAU,CAAC,EAAE,IAChC,CChGO,SAASU,GAEdC,EACAhZ,EAA8B,GACpB,CACV,KAAM,CAEJ,UAAAE,EAAY,EACZ,WAAA+Y,EAAa,GACb,UAAAxR,EAAY,GACZ,QAAAyR,EAAU,EACV,UAAAC,EAAY,EACZ,QAAAC,EAAU,OACV,OAAAC,EAAS,SACT,cAAAC,EAAgB,GAChB,cAAA3Q,EAAgB,EAAA,EACd3I,EAEJ,IAAInK,EAAOmjB,EAGX,OAAQK,EAAA,CACN,IAAK,SACH,GAAI,CACFxjB,EAAO,KAAKmjB,CAAO,CACrB,OAASO,EAAG,CACV,eAAQ,MAAM,2BAA4BA,CAAC,EACpC,CAAA,CACT,CACA,MAEF,IAAK,OACH1jB,EAAO2jB,GAAUR,CAAO,EACxB,MAEF,IAAK,OACHnjB,EAAO4jB,GAAgBT,CAAO,EAC9B,MAEF,IAAK,MAEH,MAAM,IAAI,MAAM,4DAA4D,CAK5E,CAIAG,EAAY,IAEdtjB,EADe6jB,GAAU7jB,EAAMsjB,EAAWD,EAASE,CAAO,EAC5C,KAAK,GAAG,GAIxB,IAAI7Y,EAAkB,CAAA,EAiCtB,GA/BI0Y,EAEF1Y,EAAQR,EAASlK,EAAM,CAAE,UAAW,GAAO,EAE3C0K,EAAQ,CAAC1K,CAAI,EAIf0K,EAAQA,EACL,IAAKzK,IAEJA,EAAOA,EAAK,QAAQ,oCAAqC,EAAE,EAGtD6S,IACH7S,EAAOA,EAAK,YAAA,GAGPA,EACR,EACA,OAAQA,GAEH,EAAAA,EAAK,OAASoK,GAGdoZ,GAAiB,QAAQ,KAAKxjB,CAAI,EAGvC,EAGC2R,GAAa,MAAM,QAAQA,CAAS,EAAG,CACzC,MAAMC,EAAe,IAAI,IAAID,EAAU,IAAKE,GAAMA,EAAE,YAAA,CAAa,CAAC,EAClEpH,EAAQA,EAAM,OAAQzK,GAAS,CAAC4R,EAAa,IAAI5R,EAAK,YAAA,CAAa,CAAC,CACtE,CAGA,OAAO,MAAM,KAAK,IAAI,IAAIyK,CAAK,CAAC,CAClC,CAKA,SAASiZ,GAAUG,EAAsB,CAEvC,IAAI9jB,EAAO8jB,EAAK,QAAQ,sDAAuD,GAAG,EAClF,OAAA9jB,EAAOA,EAAK,QAAQ,mDAAoD,GAAG,EAG3EA,EAAOA,EAAK,QAAQ,mBAAoB,GAAG,EAG3CA,EAAOA,EAAK,QAAQ,WAAY,GAAG,EAGnCA,EAAOA,EACJ,QAAQ,UAAW,GAAG,EACtB,QAAQ,SAAU,GAAG,EACrB,QAAQ,QAAS,GAAG,EACpB,QAAQ,QAAS,GAAG,EACpB,QAAQ,UAAW,GAAG,EACtB,QAAQ,SAAU,GAAG,EACrB,QAAQ,UAAW,GAAG,EAGzBA,EAAOA,EAAK,QAAQ,OAAQ,GAAG,EAAE,KAAA,EAE1BA,CACT,CAKA,SAAS4jB,GAAgBG,EAA4B,CACnD,GAAI,CAIF,IAASC,EAAT,SAAuBxgB,EAAUygB,EAAgB,EAAS,CAEpDA,EAAQ,KAER,OAAOzgB,GAAQ,SACjB0gB,EAAO,KAAK1gB,CAAG,EACN,MAAM,QAAQA,CAAG,EAC1BA,EAAI,QAASkC,GAASse,EAActe,EAAMue,EAAQ,CAAC,CAAC,EAC3C,OAAOzgB,GAAQ,UAAYA,IAAQ,MAC5C,OAAO,OAAOA,CAAG,EAAE,QAAS2M,GAAU6T,EAAc7T,EAAO8T,EAAQ,CAAC,CAAC,EAEzE,EAdA,MAAMtd,EAAO,KAAK,MAAMod,CAAU,EAC5BG,EAAmB,CAAA,EAezB,OAAAF,EAAcrd,CAAI,EACXud,EAAO,KAAK,GAAG,CACxB,OAAS,EAAG,CACV,eAAQ,MAAM,wBAAyB,CAAC,EACjC,EACT,CACF,CAKA,SAASL,GAEP7jB,EACAsjB,EACAD,EACAE,EACU,CACV,MAAMY,EAAmB,CAAA,EAEzB,GAAIZ,IAAY,YAAa,CAE3B,MAAMa,EAAapkB,EAAK,MAAM,OAAO,EACrC,IAAIqkB,EAAe,GAEnB,UAAWC,KAAQF,GACZC,EAAeC,GAAM,QAAUhB,EAClCe,IAAiBA,EAAe;AAAA;AAAA,EAAS,IAAMC,GAE3CD,GAAcF,EAAO,KAAKE,CAAY,EAC1CA,EAAeC,GAGfD,GAAcF,EAAO,KAAKE,CAAY,CAC5C,SAAWd,IAAY,WAAY,CAEjC,MAAMgB,EAAYvkB,EAAK,MAAM,WAAW,EACxC,IAAIqkB,EAAe,GAEnB,UAAWG,KAAYD,GAChBF,EAAeG,GAAU,QAAUlB,EACtCe,IAAiBA,EAAe,IAAM,IAAMG,GAExCH,GAAcF,EAAO,KAAKE,CAAY,EAC1CA,EAAeG,GAGfH,GAAcF,EAAO,KAAKE,CAAY,CAC5C,KAAO,CAEL,MAAM3Z,EAAQ1K,EAAK,MAAM,KAAK,EAC9B,IAAIqkB,EAAe,GAEnB,UAAWpkB,KAAQyK,GACZ2Z,EAAe,IAAMpkB,GAAM,QAAUqjB,EACxCe,IAAiBA,EAAe,IAAM,IAAMpkB,GAExCokB,GAAcF,EAAO,KAAKE,CAAY,EAGtChB,EAAU,GAAKgB,EAEjBA,EADqBA,EAAa,MAAM,KAAK,EAAE,MAAM,CAAC,KAAK,KAAKhB,EAAU,EAAE,CAAC,EACjD,KAAK,GAAG,EAAI,IAAMpjB,EAE9CokB,EAAepkB,GAIjBokB,GAAcF,EAAO,KAAKE,CAAY,CAC5C,CAEA,OAAOF,CACT,CAQA,eAAsBM,GAEpBtB,EACAhZ,EAA8B,GACX,CACnB,KAAM,CAAE,OAAAqZ,EAAS,QAAA,EAAarZ,EAE9B,GAAIqZ,IAAW,MACb,GAAI,CAEF,MAAMM,EAAO,MADI,MAAM,MAAMX,CAAO,GACR,KAAA,EAC5B,OAAOD,GAAYY,EAAM,CAAE,GAAG3Z,EAAS,OAAQ,OAAQ,CACzD,OAASuZ,EAAG,CACV,eAAQ,MAAM,uBAAwBA,CAAC,EAChC,CAAA,CACT,CAGF,OAAOR,GAAYC,EAAShZ,CAAO,CACrC,CC/BO,SAASua,GAEdC,EACAxa,EAII,GACJ,CACA,MAAMgF,EAAQ8N,GAAgB0H,EAAY,CACxC,OAAQ,CACN,UAAWxa,EAAQ,WAAa,CAAC,SAAS,EAC1C,YAAaA,EAAQ,aAAe,WACpC,WAAYA,EAAQ,YAAc,CAAA,CACpC,CACD,EAED,MAAO,CACL,OAAQ,CAACyB,EAAe0E,IAAwB0I,EAAe7J,EAAOvD,EAAO0E,CAAU,EACvF,MAAAnB,CAAA,CAEJ,CAKO,MAAMyV,GAAU"}