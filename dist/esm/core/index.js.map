{"version":3,"file":"index.js","sources":["../../../src/core/index.ts"],"sourcesContent":["import type { FuzzyIndex, FuzzyConfig, SuggestionResult, SearchMatch, BuildIndexOptions, SearchOptions, LanguageProcessor } from \"./types.js\";\nimport { mergeConfig, validateConfig } from \"./config.js\";\nimport { LanguageRegistry } from \"../languages/index.js\";\nimport { calculateLevenshteinDistance, calculateNgramSimilarity } from \"../algorithms/levenshtein.js\";\nimport { buildInvertedIndex, searchInvertedIndex } from \"./inverted-index.js\";\nimport { calculateHighlights } from \"./highlighting.js\";\nimport { SearchCache } from \"./cache.js\";\nimport { removeAccents } from \"../utils/accent-normalization.js\";\nimport { extractFieldValues, normalizeFieldWeights } from \"./field-weighting.js\";\nimport { filterStopWords } from \"../utils/stop-words.js\";\nimport { matchesWord, matchesWildcard } from \"../utils/word-boundaries.js\";\n\n/**\n * Build a fuzzy search index from a dictionary of words or objects\n */\nexport function buildFuzzyIndex(words: (string | any)[] = [], options: BuildIndexOptions = {}): FuzzyIndex {\n  const config = mergeConfig(options.config);\n  validateConfig(config);\n\n  // Convert features array to Set for O(1) lookup performance\n  const featureSet = new Set(config.features);\n\n  const languageProcessors = options.languageProcessors || LanguageRegistry.getProcessors(config.languages);\n\n  if (languageProcessors.length === 0) {\n    throw new Error(`No language processors found for: ${config.languages.join(\", \")}`);\n  }\n\n  // Check if we're doing multi-field search\n  const hasFields = options.fields && options.fields.length > 0;\n  const isObjectArray = words.length > 0 && typeof words[0] === \"object\" && words[0] !== null;\n\n  // Validate: if objects are provided, fields must be specified\n  if (isObjectArray && !hasFields) {\n    throw new Error(\"When indexing objects, you must specify which fields to index via options.fields\");\n  }\n\n  const index: FuzzyIndex = {\n    base: [],\n    variantToBase: new Map(),\n    phoneticToBase: new Map(),\n    ngramIndex: new Map(),\n    synonymMap: new Map(),\n    languageProcessors: new Map(),\n    config,\n  };\n\n  // Store field configuration if provided\n  if (hasFields) {\n    index.fields = options.fields;\n    index.fieldWeights = normalizeFieldWeights(options.fields!, options.fieldWeights);\n    index.fieldData = new Map();\n  }\n\n  // Store language processors\n  languageProcessors.forEach((processor) => {\n    index.languageProcessors.set(processor.language, processor);\n  });\n\n  const processedWords = new Set<string>();\n  let processed = 0;\n\n  for (const item of words) {\n    if (!item) continue;\n\n    // Handle multi-field objects\n    if (hasFields && isObjectArray) {\n      const fieldValues = extractFieldValues(item, options.fields);\n      if (!fieldValues) continue;\n\n      // Generate a unique ID for this object (use first field value as base)\n      const baseId = Object.values(fieldValues)[0] || `item_${processed}`;\n\n      // Store field data\n      index.fieldData!.set(baseId, fieldValues);\n\n      // Index each field separately\n      for (const [fieldName, fieldValue] of Object.entries(fieldValues)) {\n        if (!fieldValue || fieldValue.trim().length < config.minQueryLength) continue;\n\n        const trimmedValue = fieldValue.trim();\n\n        // Add to base if not already there\n        if (!processedWords.has(baseId.toLowerCase())) {\n          processedWords.add(baseId.toLowerCase());\n          index.base.push(baseId);\n        }\n\n        // Process this field value with each language processor\n        for (const processor of languageProcessors) {\n          processWordWithProcessorAndField(trimmedValue, baseId, fieldName, processor, index, config, featureSet);\n        }\n      }\n    } else {\n      // Handle simple string array (backwards compatible)\n      const word = typeof item === \"string\" ? item : String(item);\n      if (word.trim().length < config.minQueryLength) continue;\n\n      const trimmedWord = word.trim();\n      if (processedWords.has(trimmedWord.toLowerCase())) continue;\n\n      processedWords.add(trimmedWord.toLowerCase());\n      index.base.push(trimmedWord);\n\n      // Process with each language processor\n      for (const processor of languageProcessors) {\n        processWordWithProcessor(trimmedWord, processor, index, config, featureSet);\n      }\n    }\n\n    processed++;\n    if (options.onProgress) {\n      options.onProgress(processed, words.length);\n    }\n  }\n\n  // INVERTED INDEX: Build if enabled or auto-enable for large datasets\n  const shouldUseInvertedIndex = options.useInvertedIndex || config.useInvertedIndex || words.length >= 10000; // Auto-enable for 10k+ words\n\n  if (shouldUseInvertedIndex) {\n    const { invertedIndex, documents } = buildInvertedIndex(words, languageProcessors, config, featureSet);\n    index.invertedIndex = invertedIndex;\n    index.documents = documents;\n  }\n\n  // CACHE: Initialize search result cache if enabled (default: true)\n  const enableCache = config.enableCache !== false; // Default to true\n  if (enableCache) {\n    const cacheSize = config.cacheSize || 100;\n    index._cache = new SearchCache(cacheSize);\n  }\n\n  return index;\n}\n\n/**\n * Process a word with a specific language processor\n */\nfunction processWordWithProcessor(word: string, processor: LanguageProcessor, index: FuzzyIndex, config: FuzzyConfig, featureSet: Set<string>): void {\n  const normalized = processor.normalize(word);\n\n  // Add base word mapping\n  addToVariantMap(index.variantToBase, normalized, word);\n  addToVariantMap(index.variantToBase, word.toLowerCase(), word);\n  // Also add the original word as-is for exact matching\n  addToVariantMap(index.variantToBase, word, word);\n\n  // Add accent-insensitive variants\n  const accentFreeWord = removeAccents(word);\n  if (accentFreeWord !== word) {\n    // Add the accent-free version in multiple forms\n    addToVariantMap(index.variantToBase, accentFreeWord, word); // Original case\n    addToVariantMap(index.variantToBase, accentFreeWord.toLowerCase(), word); // Lowercase\n    const normalizedAccentFree = processor.normalize(accentFreeWord);\n    if (normalizedAccentFree !== accentFreeWord.toLowerCase()) {\n      addToVariantMap(index.variantToBase, normalizedAccentFree, word); // Processor normalized\n    }\n  }\n\n  // Generate and index variants\n  if (featureSet.has(\"partial-words\")) {\n    const variants = processor.getWordVariants(word);\n    variants.forEach((variant) => {\n      addToVariantMap(index.variantToBase, variant, word);\n    });\n  }\n\n  // Generate phonetic codes\n  if (featureSet.has(\"phonetic\") && processor.supportedFeatures.includes(\"phonetic\")) {\n    const phoneticCode = processor.getPhoneticCode(word);\n    if (phoneticCode) {\n      addToVariantMap(index.phoneticToBase, phoneticCode, word);\n    }\n  }\n\n  // Generate n-grams for partial matching\n  const ngrams = generateNgrams(normalized, config.ngramSize);\n  ngrams.forEach((ngram: string) => {\n    addToVariantMap(index.ngramIndex, ngram, word);\n  });\n\n  // Handle compound words\n  if (featureSet.has(\"compound\") && processor.supportedFeatures.includes(\"compound\")) {\n    const compoundParts = processor.splitCompoundWords(word);\n    compoundParts.forEach((part) => {\n      if (part !== word) {\n        addToVariantMap(index.variantToBase, processor.normalize(part), word);\n      }\n    });\n  }\n\n  // Add synonyms\n  if (featureSet.has(\"synonyms\")) {\n    const synonyms = processor.getSynonyms(normalized);\n    synonyms.forEach((synonym) => {\n      addToVariantMap(index.synonymMap, synonym, word);\n    });\n\n    // Add custom synonyms\n    if (config.customSynonyms) {\n      const customSynonyms = config.customSynonyms[normalized];\n      if (customSynonyms) {\n        customSynonyms.forEach((synonym) => {\n          addToVariantMap(index.synonymMap, synonym, word);\n        });\n      }\n    }\n  }\n}\n\n/**\n * Process a word with field information for multi-field search\n */\nfunction processWordWithProcessorAndField(fieldValue: string, baseId: string, fieldName: string, processor: LanguageProcessor, index: FuzzyIndex, config: FuzzyConfig, featureSet: Set<string>): void {\n  const normalized = processor.normalize(fieldValue);\n\n  // Add base word mapping with field metadata\n  addToVariantMapWithField(index.variantToBase, normalized, baseId, fieldName);\n  addToVariantMapWithField(index.variantToBase, fieldValue.toLowerCase(), baseId, fieldName);\n  addToVariantMapWithField(index.variantToBase, fieldValue, baseId, fieldName);\n\n  // Add accent-insensitive variants\n  const accentFreeWord = removeAccents(fieldValue);\n  if (accentFreeWord !== fieldValue) {\n    addToVariantMapWithField(index.variantToBase, accentFreeWord, baseId, fieldName);\n    addToVariantMapWithField(index.variantToBase, accentFreeWord.toLowerCase(), baseId, fieldName);\n    const normalizedAccentFree = processor.normalize(accentFreeWord);\n    if (normalizedAccentFree !== accentFreeWord.toLowerCase()) {\n      addToVariantMapWithField(index.variantToBase, normalizedAccentFree, baseId, fieldName);\n    }\n  }\n\n  // Generate and index variants\n  if (featureSet.has(\"partial-words\")) {\n    const variants = processor.getWordVariants(fieldValue);\n    variants.forEach((variant) => {\n      addToVariantMapWithField(index.variantToBase, variant, baseId, fieldName);\n    });\n  }\n\n  // Generate phonetic codes\n  if (featureSet.has(\"phonetic\") && processor.supportedFeatures.includes(\"phonetic\")) {\n    const phoneticCode = processor.getPhoneticCode(fieldValue);\n    if (phoneticCode) {\n      addToVariantMapWithField(index.phoneticToBase, phoneticCode, baseId, fieldName);\n    }\n  }\n\n  // Generate n-grams for partial matching\n  const ngrams = generateNgrams(normalized, config.ngramSize);\n  ngrams.forEach((ngram: string) => {\n    addToVariantMapWithField(index.ngramIndex, ngram, baseId, fieldName);\n  });\n\n  // Handle compound words\n  if (featureSet.has(\"compound\") && processor.supportedFeatures.includes(\"compound\")) {\n    const parts = processor.splitCompoundWords(fieldValue);\n    parts.forEach((part) => {\n      if (part.length >= config.minQueryLength) {\n        addToVariantMapWithField(index.variantToBase, part, baseId, fieldName);\n        addToVariantMapWithField(index.variantToBase, processor.normalize(part), baseId, fieldName);\n      }\n    });\n  }\n\n  // Add synonyms\n  if (featureSet.has(\"synonyms\")) {\n    const synonyms = processor.getSynonyms(normalized);\n    synonyms.forEach((synonym) => {\n      addToVariantMapWithField(index.synonymMap, synonym, baseId, fieldName);\n    });\n\n    // Add custom synonyms\n    if (config.customSynonyms) {\n      const customSynonyms = config.customSynonyms[normalized];\n      if (customSynonyms) {\n        customSynonyms.forEach((synonym) => {\n          addToVariantMapWithField(index.synonymMap, synonym, baseId, fieldName);\n        });\n      }\n    }\n  }\n}\n\n/**\n * Helper function to add mappings to variant maps with field information\n */\nfunction addToVariantMapWithField(map: Map<string, Set<string>>, key: string, value: string, _fieldName: string): void {\n  // For now, we'll use a simple approach: store the value with field metadata\n  // The field information will be tracked separately in the index\n  // _fieldName is prefixed with _ to indicate it's reserved for future use\n  if (!map.has(key)) {\n    map.set(key, new Set());\n  }\n  map.get(key)!.add(value);\n}\n\n/**\n * Helper function to add mappings to variant maps\n */\nfunction addToVariantMap(map: Map<string, Set<string>>, key: string, value: string): void {\n  if (!map.has(key)) {\n    map.set(key, new Set());\n  }\n  map.get(key)!.add(value);\n}\n\n/**\n * Batch search multiple queries at once\n * Deduplicates identical queries and returns results for all\n */\nexport function batchSearch(index: FuzzyIndex, queries: string[], maxResults?: number, options: SearchOptions = {}): Record<string, SuggestionResult[]> {\n  const results: Record<string, SuggestionResult[]> = {};\n  const uniqueQueries = [...new Set(queries)]; // Deduplicate\n\n  for (const query of uniqueQueries) {\n    results[query] = getSuggestions(index, query, maxResults, options);\n  }\n\n  return results;\n}\n\n/**\n * Get fuzzy search suggestions from an index\n * Auto-detects whether to use inverted index or classic hash-based approach\n */\nexport function getSuggestions(index: FuzzyIndex, query: string, maxResults?: number, options: SearchOptions = {}): SuggestionResult[] {\n  const config = index.config;\n  const limit = maxResults || options.maxResults || config.maxResults;\n  const threshold = options.fuzzyThreshold || config.fuzzyThreshold;\n\n  if (!query || query.trim().length < config.minQueryLength) {\n    return [];\n  }\n\n  // STOP WORDS: Filter stop words from query if enabled\n  let processedQuery = query;\n  if (config.enableStopWords && config.stopWords && config.stopWords.length > 0) {\n    processedQuery = filterStopWords(query, config.stopWords);\n  }\n\n  // CACHE: Check cache first (use processed query for cache key)\n  if (index._cache) {\n    const cached = index._cache.get(processedQuery, limit, options);\n    if (cached) {\n      return cached; // Cache hit - return immediately!\n    }\n  }\n\n  // Get active language processors\n  const activeLanguages = options.languages || config.languages;\n  const processors = activeLanguages.map((lang) => index.languageProcessors.get(lang)).filter((p): p is LanguageProcessor => p !== undefined);\n\n  if (processors.length === 0) {\n    return [];\n  }\n\n  // AUTO-DETECTION: Use inverted index if available\n  if (index.invertedIndex && index.documents) {\n    const results = getSuggestionsInverted(index, processedQuery, limit, threshold, processors, options);\n    // Cache the results\n    if (index._cache) {\n      index._cache.set(processedQuery, results, limit, options);\n    }\n    return results;\n  }\n\n  // CLASSIC: Use hash-based approach (existing implementation)\n  const matches = new Map<string, SearchMatch>();\n\n  // Process query with each language processor\n  for (const processor of processors) {\n    const normalizedQuery = processor.normalize(processedQuery.trim());\n\n    // Find matches using different strategies\n    findExactMatches(normalizedQuery, index, matches, processor.language);\n    findPrefixMatches(normalizedQuery, index, matches, processor.language);\n    findPhoneticMatches(normalizedQuery, processor, index, matches);\n    findSynonymMatches(normalizedQuery, index, matches);\n    findNgramMatches(normalizedQuery, index, matches, processor.language, config.ngramSize);\n\n    if (config.features.includes(\"missing-letters\") || config.features.includes(\"extra-letters\") || config.features.includes(\"transpositions\")) {\n      findFuzzyMatches(normalizedQuery, index, matches, processor, config);\n    }\n  }\n\n  // Convert matches to results and rank them\n  const results = Array.from(matches.values())\n    .map((match) => createSuggestionResult(match, processedQuery, threshold, index, options))\n    .filter((result): result is SuggestionResult => result !== null)\n    .sort((a, b) => b.score - a.score)\n    .slice(0, limit);\n\n  // Cache the results\n  if (index._cache) {\n    index._cache.set(processedQuery, results, limit, options);\n  }\n\n  return results;\n}\n\n/**\n * Find exact matches\n */\nfunction findExactMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>, language: string): void {\n  const wordBoundaries = index.config.wordBoundaries || false;\n  \n  // Check for wildcard pattern\n  if (query.includes('*')) {\n    // Wildcard search\n    for (const baseWord of index.base) {\n      if (matchesWildcard(baseWord, query)) {\n        if (!matches.has(baseWord)) {\n          matches.set(baseWord, {\n            word: baseWord,\n            normalized: query,\n            matchType: \"exact\",\n            editDistance: 0,\n            language,\n          });\n        }\n      }\n    }\n    return;\n  }\n  \n  // Check for exact matches in the variant map\n  const exactMatches = index.variantToBase.get(query);\n  if (exactMatches) {\n    exactMatches.forEach((word) => {\n      // With word boundaries, verify the match\n      if (wordBoundaries && !matchesWord(word, query, wordBoundaries)) {\n        return;\n      }\n      \n      // Always add exact matches, even if already found with lower score\n      const existing = matches.get(word);\n      if (!existing || existing.matchType !== \"exact\") {\n        matches.set(word, {\n          word,\n          normalized: query,\n          matchType: \"exact\",\n          editDistance: 0,\n          language,\n        });\n      }\n    });\n  }\n\n  // Also check if the query exactly matches any base word (case-insensitive)\n  const queryLower = query.toLowerCase();\n  for (const baseWord of index.base) {\n    if (baseWord.toLowerCase() === queryLower) {\n      if (!matches.has(baseWord)) {\n        matches.set(baseWord, {\n          word: baseWord,\n          normalized: query,\n          matchType: \"exact\",\n          editDistance: 0,\n          language,\n        });\n      }\n    }\n  }\n}\n\n/**\n * Find prefix matches\n */\nfunction findPrefixMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>, language: string): void {\n  const wordBoundaries = index.config.wordBoundaries || false;\n  \n  for (const [variant, words] of index.variantToBase.entries()) {\n    if (variant.startsWith(query) && variant !== query) {\n      words.forEach((word) => {\n        // With word boundaries, verify the match\n        if (wordBoundaries && !matchesWord(word, query, wordBoundaries)) {\n          return;\n        }\n        \n        if (!matches.has(word)) {\n          matches.set(word, {\n            word,\n            normalized: variant,\n            matchType: \"prefix\",\n            language,\n          });\n        }\n      });\n    }\n  }\n}\n\n/**\n * Find phonetic matches\n */\nfunction findPhoneticMatches(query: string, processor: LanguageProcessor, index: FuzzyIndex, matches: Map<string, SearchMatch>): void {\n  if (!processor.supportedFeatures.includes(\"phonetic\")) return;\n\n  const phoneticCode = processor.getPhoneticCode(query);\n  if (phoneticCode) {\n    const phoneticMatches = index.phoneticToBase.get(phoneticCode);\n    if (phoneticMatches) {\n      phoneticMatches.forEach((word) => {\n        if (!matches.has(word)) {\n          matches.set(word, {\n            word,\n            normalized: query,\n            matchType: \"phonetic\",\n            phoneticCode,\n            language: processor.language,\n          });\n        }\n      });\n    }\n  }\n}\n\n/**\n * Find synonym matches\n */\nfunction findSynonymMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>): void {\n  const synonymMatches = index.synonymMap.get(query);\n  if (synonymMatches) {\n    synonymMatches.forEach((word) => {\n      if (!matches.has(word)) {\n        matches.set(word, {\n          word,\n          normalized: query,\n          matchType: \"synonym\",\n          language: \"synonym\",\n        });\n      }\n    });\n  }\n}\n\n/**\n * Find n-gram matches\n */\nfunction findNgramMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>, language: string, ngramSize: number): void {\n  if (query.length < ngramSize) return;\n\n  const queryNgrams = generateNgrams(query, ngramSize);\n  const candidateWords = new Set<string>();\n\n  queryNgrams.forEach((ngram) => {\n    const ngramMatches = index.ngramIndex.get(ngram);\n    if (ngramMatches) {\n      ngramMatches.forEach((word) => candidateWords.add(word));\n    }\n  });\n\n  candidateWords.forEach((word) => {\n    if (!matches.has(word)) {\n      matches.set(word, {\n        word,\n        normalized: query,\n        matchType: \"ngram\",\n        language,\n      });\n    }\n  });\n}\n\n/**\n * Find fuzzy matches using edit distance\n */\nfunction findFuzzyMatches(query: string, index: FuzzyIndex, matches: Map<string, SearchMatch>, processor: LanguageProcessor, config: FuzzyConfig): void {\n  const maxDistance = config.maxEditDistance;\n\n  for (const [variant, words] of index.variantToBase.entries()) {\n    if (Math.abs(variant.length - query.length) <= maxDistance) {\n      const distance = calculateLevenshteinDistance(query, variant, maxDistance);\n\n      if (distance <= maxDistance) {\n        words.forEach((word) => {\n          const existingMatch = matches.get(word);\n          // Don't replace exact or prefix matches with fuzzy matches\n          if (!existingMatch || (existingMatch.matchType !== \"exact\" && existingMatch.matchType !== \"prefix\" && (existingMatch.editDistance || Infinity) > distance)) {\n            matches.set(word, {\n              word,\n              normalized: variant,\n              matchType: \"fuzzy\",\n              editDistance: distance,\n              language: processor.language,\n            });\n          }\n        });\n      }\n    }\n  }\n}\n\n/**\n * Create a suggestion result from a search match\n */\nfunction createSuggestionResult(match: SearchMatch, originalQuery: string, threshold: number, index: FuzzyIndex, options?: SearchOptions): SuggestionResult | null {\n  let score = calculateMatchScore(match, originalQuery);\n\n  // Apply field weight if present\n  if (match.fieldWeight) {\n    score = Math.min(1.0, score * match.fieldWeight);\n  }\n\n  if (score < threshold) {\n    return null;\n  }\n\n  const result: SuggestionResult = {\n    display: match.word,\n    baseWord: match.word,\n    isSynonym: match.matchType === \"synonym\",\n    score,\n    language: match.language,\n    // @ts-ignore - temporary debug property\n    _debug_matchType: match.matchType,\n  };\n\n  // Add field information if this is a multi-field search\n  if (index.fieldData && index.fieldData.has(match.word)) {\n    result.fields = index.fieldData.get(match.word);\n    result.field = match.field;\n  }\n\n  // Add highlights if requested\n  if (options?.includeHighlights) {\n    result.highlights = calculateHighlights(match, originalQuery, match.word);\n  }\n\n  return result;\n}\n\n/**\n * Calculate match score (0-1, higher is better)\n */\nfunction calculateMatchScore(\n  //\n  match: SearchMatch,\n  query: string\n): number {\n  const queryLen = query.length;\n  const wordLen = match.word.length;\n  const maxLen = Math.max(queryLen, wordLen);\n\n  let score = 0.5; // Base score\n\n  switch (match.matchType) {\n    case \"exact\":\n      score = 1.0;\n      break;\n    case \"prefix\":\n      score = 0.9 - (wordLen - queryLen) / (maxLen * 2);\n      break;\n    case \"substring\":\n      score = 0.8;\n      break;\n    case \"phonetic\":\n      score = 0.7;\n      break;\n    case \"fuzzy\":\n      if (match.editDistance !== undefined) {\n        score = Math.max(0.3, 1.0 - match.editDistance / maxLen);\n      }\n      break;\n    case \"synonym\":\n      score = 0.6;\n      break;\n    case \"compound\":\n      score = 0.75;\n      break;\n    case \"ngram\":\n      score = calculateNgramSimilarity(query.toLowerCase(), match.normalized, 3) * 0.8;\n      break;\n  }\n\n  // Boost score for shorter words (more likely to be what user wants)\n  // But don't boost exact matches - they should stay at 1.0\n  if (wordLen <= queryLen + 2 && match.matchType !== \"exact\") {\n    score += 0.1;\n  }\n\n  return Math.min(1.0, Math.max(0.0, score));\n}\n\n/**\n * Generate n-grams from a string\n */\nfunction generateNgrams(\n  //\n  str: string,\n  n: number\n): string[] {\n  if (str.length < n) return [str];\n\n  const ngrams: string[] = [];\n  for (let i = 0; i <= str.length - n; i++) {\n    ngrams.push(str.slice(i, i + n));\n  }\n  return ngrams;\n}\n\n/**\n * Get suggestions using inverted index (for large datasets)\n * This is a wrapper that converts inverted index results to the same format\n */\nfunction getSuggestionsInverted(\n  //\n  index: FuzzyIndex,\n  query: string,\n  limit: number,\n  threshold: number,\n  processors: LanguageProcessor[],\n  options?: SearchOptions\n): SuggestionResult[] {\n  if (!index.invertedIndex || !index.documents) {\n    throw new Error(\"Inverted index not available\");\n  }\n\n  // Use inverted index search\n  const matches = searchInvertedIndex(index.invertedIndex, index.documents, query, processors, index.config);\n\n  // Convert to suggestion results (same as classic approach)\n  const results = matches\n    .map((match) => createSuggestionResult(match, query, threshold, index, options))\n    .filter((result): result is SuggestionResult => result !== null)\n    .sort((a, b) => b.score - a.score)\n    .slice(0, limit);\n\n  return results;\n}\n"],"names":["results"],"mappings":";;;;;;;;;;AAeO,SAAS,gBAAgB,QAA0B,IAAI,UAA6B,CAAA,GAAgB;AACzG,QAAM,SAAS,YAAY,QAAQ,MAAM;AACzC,iBAAe,MAAM;AAGrB,QAAM,aAAa,IAAI,IAAI,OAAO,QAAQ;AAE1C,QAAM,qBAAqB,QAAQ,sBAAsB,iBAAiB,cAAc,OAAO,SAAS;AAExG,MAAI,mBAAmB,WAAW,GAAG;AACnC,UAAM,IAAI,MAAM,qCAAqC,OAAO,UAAU,KAAK,IAAI,CAAC,EAAE;AAAA,EACpF;AAGA,QAAM,YAAY,QAAQ,UAAU,QAAQ,OAAO,SAAS;AAC5D,QAAM,gBAAgB,MAAM,SAAS,KAAK,OAAO,MAAM,CAAC,MAAM,YAAY,MAAM,CAAC,MAAM;AAGvF,MAAI,iBAAiB,CAAC,WAAW;AAC/B,UAAM,IAAI,MAAM,kFAAkF;AAAA,EACpG;AAEA,QAAM,QAAoB;AAAA,IACxB,MAAM,CAAA;AAAA,IACN,mCAAmB,IAAA;AAAA,IACnB,oCAAoB,IAAA;AAAA,IACpB,gCAAgB,IAAA;AAAA,IAChB,gCAAgB,IAAA;AAAA,IAChB,wCAAwB,IAAA;AAAA,IACxB;AAAA,EAAA;AAIF,MAAI,WAAW;AACb,UAAM,SAAS,QAAQ;AACvB,UAAM,eAAe,sBAAsB,QAAQ,QAAS,QAAQ,YAAY;AAChF,UAAM,gCAAgB,IAAA;AAAA,EACxB;AAGA,qBAAmB,QAAQ,CAAC,cAAc;AACxC,UAAM,mBAAmB,IAAI,UAAU,UAAU,SAAS;AAAA,EAC5D,CAAC;AAED,QAAM,qCAAqB,IAAA;AAC3B,MAAI,YAAY;AAEhB,aAAW,QAAQ,OAAO;AACxB,QAAI,CAAC,KAAM;AAGX,QAAI,aAAa,eAAe;AAC9B,YAAM,cAAc,mBAAmB,MAAM,QAAQ,MAAM;AAC3D,UAAI,CAAC,YAAa;AAGlB,YAAM,SAAS,OAAO,OAAO,WAAW,EAAE,CAAC,KAAK,QAAQ,SAAS;AAGjE,YAAM,UAAW,IAAI,QAAQ,WAAW;AAGxC,iBAAW,CAAC,WAAW,UAAU,KAAK,OAAO,QAAQ,WAAW,GAAG;AACjE,YAAI,CAAC,cAAc,WAAW,OAAO,SAAS,OAAO,eAAgB;AAErE,cAAM,eAAe,WAAW,KAAA;AAGhC,YAAI,CAAC,eAAe,IAAI,OAAO,YAAA,CAAa,GAAG;AAC7C,yBAAe,IAAI,OAAO,aAAa;AACvC,gBAAM,KAAK,KAAK,MAAM;AAAA,QACxB;AAGA,mBAAW,aAAa,oBAAoB;AAC1C,2CAAiC,cAAc,QAAQ,WAAW,WAAW,OAAO,QAAQ,UAAU;AAAA,QACxG;AAAA,MACF;AAAA,IACF,OAAO;AAEL,YAAM,OAAO,OAAO,SAAS,WAAW,OAAO,OAAO,IAAI;AAC1D,UAAI,KAAK,KAAA,EAAO,SAAS,OAAO,eAAgB;AAEhD,YAAM,cAAc,KAAK,KAAA;AACzB,UAAI,eAAe,IAAI,YAAY,YAAA,CAAa,EAAG;AAEnD,qBAAe,IAAI,YAAY,aAAa;AAC5C,YAAM,KAAK,KAAK,WAAW;AAG3B,iBAAW,aAAa,oBAAoB;AAC1C,iCAAyB,aAAa,WAAW,OAAO,QAAQ,UAAU;AAAA,MAC5E;AAAA,IACF;AAEA;AACA,QAAI,QAAQ,YAAY;AACtB,cAAQ,WAAW,WAAW,MAAM,MAAM;AAAA,IAC5C;AAAA,EACF;AAGA,QAAM,yBAAyB,QAAQ,oBAAoB,OAAO,oBAAoB,MAAM,UAAU;AAEtG,MAAI,wBAAwB;AAC1B,UAAM,EAAE,eAAe,cAAc,mBAAmB,OAAO,oBAAoB,QAAQ,UAAU;AACrG,UAAM,gBAAgB;AACtB,UAAM,YAAY;AAAA,EACpB;AAGA,QAAM,cAAc,OAAO,gBAAgB;AAC3C,MAAI,aAAa;AACf,UAAM,YAAY,OAAO,aAAa;AACtC,UAAM,SAAS,IAAI,YAAY,SAAS;AAAA,EAC1C;AAEA,SAAO;AACT;AAKA,SAAS,yBAAyB,MAAc,WAA8B,OAAmB,QAAqB,YAA+B;AACnJ,QAAM,aAAa,UAAU,UAAU,IAAI;AAG3C,kBAAgB,MAAM,eAAe,YAAY,IAAI;AACrD,kBAAgB,MAAM,eAAe,KAAK,YAAA,GAAe,IAAI;AAE7D,kBAAgB,MAAM,eAAe,MAAM,IAAI;AAG/C,QAAM,iBAAiB,cAAc,IAAI;AACzC,MAAI,mBAAmB,MAAM;AAE3B,oBAAgB,MAAM,eAAe,gBAAgB,IAAI;AACzD,oBAAgB,MAAM,eAAe,eAAe,YAAA,GAAe,IAAI;AACvE,UAAM,uBAAuB,UAAU,UAAU,cAAc;AAC/D,QAAI,yBAAyB,eAAe,eAAe;AACzD,sBAAgB,MAAM,eAAe,sBAAsB,IAAI;AAAA,IACjE;AAAA,EACF;AAGA,MAAI,WAAW,IAAI,eAAe,GAAG;AACnC,UAAM,WAAW,UAAU,gBAAgB,IAAI;AAC/C,aAAS,QAAQ,CAAC,YAAY;AAC5B,sBAAgB,MAAM,eAAe,SAAS,IAAI;AAAA,IACpD,CAAC;AAAA,EACH;AAGA,MAAI,WAAW,IAAI,UAAU,KAAK,UAAU,kBAAkB,SAAS,UAAU,GAAG;AAClF,UAAM,eAAe,UAAU,gBAAgB,IAAI;AACnD,QAAI,cAAc;AAChB,sBAAgB,MAAM,gBAAgB,cAAc,IAAI;AAAA,IAC1D;AAAA,EACF;AAGA,QAAM,SAAS,eAAe,YAAY,OAAO,SAAS;AAC1D,SAAO,QAAQ,CAAC,UAAkB;AAChC,oBAAgB,MAAM,YAAY,OAAO,IAAI;AAAA,EAC/C,CAAC;AAGD,MAAI,WAAW,IAAI,UAAU,KAAK,UAAU,kBAAkB,SAAS,UAAU,GAAG;AAClF,UAAM,gBAAgB,UAAU,mBAAmB,IAAI;AACvD,kBAAc,QAAQ,CAAC,SAAS;AAC9B,UAAI,SAAS,MAAM;AACjB,wBAAgB,MAAM,eAAe,UAAU,UAAU,IAAI,GAAG,IAAI;AAAA,MACtE;AAAA,IACF,CAAC;AAAA,EACH;AAGA,MAAI,WAAW,IAAI,UAAU,GAAG;AAC9B,UAAM,WAAW,UAAU,YAAY,UAAU;AACjD,aAAS,QAAQ,CAAC,YAAY;AAC5B,sBAAgB,MAAM,YAAY,SAAS,IAAI;AAAA,IACjD,CAAC;AAGD,QAAI,OAAO,gBAAgB;AACzB,YAAM,iBAAiB,OAAO,eAAe,UAAU;AACvD,UAAI,gBAAgB;AAClB,uBAAe,QAAQ,CAAC,YAAY;AAClC,0BAAgB,MAAM,YAAY,SAAS,IAAI;AAAA,QACjD,CAAC;AAAA,MACH;AAAA,IACF;AAAA,EACF;AACF;AAKA,SAAS,iCAAiC,YAAoB,QAAgB,WAAmB,WAA8B,OAAmB,QAAqB,YAA+B;AACpM,QAAM,aAAa,UAAU,UAAU,UAAU;AAGjD,2BAAyB,MAAM,eAAe,YAAY,MAAiB;AAC3E,2BAAyB,MAAM,eAAe,WAAW,YAAA,GAAe,MAAiB;AACzF,2BAAyB,MAAM,eAAe,YAAY,MAAiB;AAG3E,QAAM,iBAAiB,cAAc,UAAU;AAC/C,MAAI,mBAAmB,YAAY;AACjC,6BAAyB,MAAM,eAAe,gBAAgB,MAAiB;AAC/E,6BAAyB,MAAM,eAAe,eAAe,YAAA,GAAe,MAAiB;AAC7F,UAAM,uBAAuB,UAAU,UAAU,cAAc;AAC/D,QAAI,yBAAyB,eAAe,eAAe;AACzD,+BAAyB,MAAM,eAAe,sBAAsB,MAAiB;AAAA,IACvF;AAAA,EACF;AAGA,MAAI,WAAW,IAAI,eAAe,GAAG;AACnC,UAAM,WAAW,UAAU,gBAAgB,UAAU;AACrD,aAAS,QAAQ,CAAC,YAAY;AAC5B,+BAAyB,MAAM,eAAe,SAAS,MAAiB;AAAA,IAC1E,CAAC;AAAA,EACH;AAGA,MAAI,WAAW,IAAI,UAAU,KAAK,UAAU,kBAAkB,SAAS,UAAU,GAAG;AAClF,UAAM,eAAe,UAAU,gBAAgB,UAAU;AACzD,QAAI,cAAc;AAChB,+BAAyB,MAAM,gBAAgB,cAAc,MAAiB;AAAA,IAChF;AAAA,EACF;AAGA,QAAM,SAAS,eAAe,YAAY,OAAO,SAAS;AAC1D,SAAO,QAAQ,CAAC,UAAkB;AAChC,6BAAyB,MAAM,YAAY,OAAO,MAAiB;AAAA,EACrE,CAAC;AAGD,MAAI,WAAW,IAAI,UAAU,KAAK,UAAU,kBAAkB,SAAS,UAAU,GAAG;AAClF,UAAM,QAAQ,UAAU,mBAAmB,UAAU;AACrD,UAAM,QAAQ,CAAC,SAAS;AACtB,UAAI,KAAK,UAAU,OAAO,gBAAgB;AACxC,iCAAyB,MAAM,eAAe,MAAM,MAAiB;AACrE,iCAAyB,MAAM,eAAe,UAAU,UAAU,IAAI,GAAG,MAAiB;AAAA,MAC5F;AAAA,IACF,CAAC;AAAA,EACH;AAGA,MAAI,WAAW,IAAI,UAAU,GAAG;AAC9B,UAAM,WAAW,UAAU,YAAY,UAAU;AACjD,aAAS,QAAQ,CAAC,YAAY;AAC5B,+BAAyB,MAAM,YAAY,SAAS,MAAiB;AAAA,IACvE,CAAC;AAGD,QAAI,OAAO,gBAAgB;AACzB,YAAM,iBAAiB,OAAO,eAAe,UAAU;AACvD,UAAI,gBAAgB;AAClB,uBAAe,QAAQ,CAAC,YAAY;AAClC,mCAAyB,MAAM,YAAY,SAAS,MAAiB;AAAA,QACvE,CAAC;AAAA,MACH;AAAA,IACF;AAAA,EACF;AACF;AAKA,SAAS,yBAAyB,KAA+B,KAAa,OAAe,YAA0B;AAIrH,MAAI,CAAC,IAAI,IAAI,GAAG,GAAG;AACjB,QAAI,IAAI,KAAK,oBAAI,IAAA,CAAK;AAAA,EACxB;AACA,MAAI,IAAI,GAAG,EAAG,IAAI,KAAK;AACzB;AAKA,SAAS,gBAAgB,KAA+B,KAAa,OAAqB;AACxF,MAAI,CAAC,IAAI,IAAI,GAAG,GAAG;AACjB,QAAI,IAAI,KAAK,oBAAI,IAAA,CAAK;AAAA,EACxB;AACA,MAAI,IAAI,GAAG,EAAG,IAAI,KAAK;AACzB;AAMO,SAAS,YAAY,OAAmB,SAAmB,YAAqB,UAAyB,CAAA,GAAwC;AACtJ,QAAM,UAA8C,CAAA;AACpD,QAAM,gBAAgB,CAAC,GAAG,IAAI,IAAI,OAAO,CAAC;AAE1C,aAAW,SAAS,eAAe;AACjC,YAAQ,KAAK,IAAI,eAAe,OAAO,OAAO,YAAY,OAAO;AAAA,EACnE;AAEA,SAAO;AACT;AAMO,SAAS,eAAe,OAAmB,OAAe,YAAqB,UAAyB,CAAA,GAAwB;AACrI,QAAM,SAAS,MAAM;AACrB,QAAM,QAAQ,cAAc,QAAQ,cAAc,OAAO;AACzD,QAAM,YAAY,QAAQ,kBAAkB,OAAO;AAEnD,MAAI,CAAC,SAAS,MAAM,OAAO,SAAS,OAAO,gBAAgB;AACzD,WAAO,CAAA;AAAA,EACT;AAGA,MAAI,iBAAiB;AACrB,MAAI,OAAO,mBAAmB,OAAO,aAAa,OAAO,UAAU,SAAS,GAAG;AAC7E,qBAAiB,gBAAgB,OAAO,OAAO,SAAS;AAAA,EAC1D;AAGA,MAAI,MAAM,QAAQ;AAChB,UAAM,SAAS,MAAM,OAAO,IAAI,gBAAgB,OAAO,OAAO;AAC9D,QAAI,QAAQ;AACV,aAAO;AAAA,IACT;AAAA,EACF;AAGA,QAAM,kBAAkB,QAAQ,aAAa,OAAO;AACpD,QAAM,aAAa,gBAAgB,IAAI,CAAC,SAAS,MAAM,mBAAmB,IAAI,IAAI,CAAC,EAAE,OAAO,CAAC,MAA8B,MAAM,MAAS;AAE1I,MAAI,WAAW,WAAW,GAAG;AAC3B,WAAO,CAAA;AAAA,EACT;AAGA,MAAI,MAAM,iBAAiB,MAAM,WAAW;AAC1C,UAAMA,WAAU,uBAAuB,OAAO,gBAAgB,OAAO,WAAW,YAAY,OAAO;AAEnG,QAAI,MAAM,QAAQ;AAChB,YAAM,OAAO,IAAI,gBAAgBA,UAAS,OAAO,OAAO;AAAA,IAC1D;AACA,WAAOA;AAAAA,EACT;AAGA,QAAM,8BAAc,IAAA;AAGpB,aAAW,aAAa,YAAY;AAClC,UAAM,kBAAkB,UAAU,UAAU,eAAe,MAAM;AAGjE,qBAAiB,iBAAiB,OAAO,SAAS,UAAU,QAAQ;AACpE,sBAAkB,iBAAiB,OAAO,SAAS,UAAU,QAAQ;AACrE,wBAAoB,iBAAiB,WAAW,OAAO,OAAO;AAC9D,uBAAmB,iBAAiB,OAAO,OAAO;AAClD,qBAAiB,iBAAiB,OAAO,SAAS,UAAU,UAAU,OAAO,SAAS;AAEtF,QAAI,OAAO,SAAS,SAAS,iBAAiB,KAAK,OAAO,SAAS,SAAS,eAAe,KAAK,OAAO,SAAS,SAAS,gBAAgB,GAAG;AAC1I,uBAAiB,iBAAiB,OAAO,SAAS,WAAW,MAAM;AAAA,IACrE;AAAA,EACF;AAGA,QAAM,UAAU,MAAM,KAAK,QAAQ,QAAQ,EACxC,IAAI,CAAC,UAAU,uBAAuB,OAAO,gBAAgB,WAAW,OAAO,OAAO,CAAC,EACvF,OAAO,CAAC,WAAuC,WAAW,IAAI,EAC9D,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK,EAChC,MAAM,GAAG,KAAK;AAGjB,MAAI,MAAM,QAAQ;AAChB,UAAM,OAAO,IAAI,gBAAgB,SAAS,OAAO,OAAO;AAAA,EAC1D;AAEA,SAAO;AACT;AAKA,SAAS,iBAAiB,OAAe,OAAmB,SAAmC,UAAwB;AACrH,QAAM,iBAAiB,MAAM,OAAO,kBAAkB;AAGtD,MAAI,MAAM,SAAS,GAAG,GAAG;AAEvB,eAAW,YAAY,MAAM,MAAM;AACjC,UAAI,gBAAgB,UAAU,KAAK,GAAG;AACpC,YAAI,CAAC,QAAQ,IAAI,QAAQ,GAAG;AAC1B,kBAAQ,IAAI,UAAU;AAAA,YACpB,MAAM;AAAA,YACN,YAAY;AAAA,YACZ,WAAW;AAAA,YACX,cAAc;AAAA,YACd;AAAA,UAAA,CACD;AAAA,QACH;AAAA,MACF;AAAA,IACF;AACA;AAAA,EACF;AAGA,QAAM,eAAe,MAAM,cAAc,IAAI,KAAK;AAClD,MAAI,cAAc;AAChB,iBAAa,QAAQ,CAAC,SAAS;AAE7B,UAAI,kBAAkB,CAAC,YAAY,MAAM,OAAO,cAAc,GAAG;AAC/D;AAAA,MACF;AAGA,YAAM,WAAW,QAAQ,IAAI,IAAI;AACjC,UAAI,CAAC,YAAY,SAAS,cAAc,SAAS;AAC/C,gBAAQ,IAAI,MAAM;AAAA,UAChB;AAAA,UACA,YAAY;AAAA,UACZ,WAAW;AAAA,UACX,cAAc;AAAA,UACd;AAAA,QAAA,CACD;AAAA,MACH;AAAA,IACF,CAAC;AAAA,EACH;AAGA,QAAM,aAAa,MAAM,YAAA;AACzB,aAAW,YAAY,MAAM,MAAM;AACjC,QAAI,SAAS,YAAA,MAAkB,YAAY;AACzC,UAAI,CAAC,QAAQ,IAAI,QAAQ,GAAG;AAC1B,gBAAQ,IAAI,UAAU;AAAA,UACpB,MAAM;AAAA,UACN,YAAY;AAAA,UACZ,WAAW;AAAA,UACX,cAAc;AAAA,UACd;AAAA,QAAA,CACD;AAAA,MACH;AAAA,IACF;AAAA,EACF;AACF;AAKA,SAAS,kBAAkB,OAAe,OAAmB,SAAmC,UAAwB;AACtH,QAAM,iBAAiB,MAAM,OAAO,kBAAkB;AAEtD,aAAW,CAAC,SAAS,KAAK,KAAK,MAAM,cAAc,WAAW;AAC5D,QAAI,QAAQ,WAAW,KAAK,KAAK,YAAY,OAAO;AAClD,YAAM,QAAQ,CAAC,SAAS;AAEtB,YAAI,kBAAkB,CAAC,YAAY,MAAM,OAAO,cAAc,GAAG;AAC/D;AAAA,QACF;AAEA,YAAI,CAAC,QAAQ,IAAI,IAAI,GAAG;AACtB,kBAAQ,IAAI,MAAM;AAAA,YAChB;AAAA,YACA,YAAY;AAAA,YACZ,WAAW;AAAA,YACX;AAAA,UAAA,CACD;AAAA,QACH;AAAA,MACF,CAAC;AAAA,IACH;AAAA,EACF;AACF;AAKA,SAAS,oBAAoB,OAAe,WAA8B,OAAmB,SAAyC;AACpI,MAAI,CAAC,UAAU,kBAAkB,SAAS,UAAU,EAAG;AAEvD,QAAM,eAAe,UAAU,gBAAgB,KAAK;AACpD,MAAI,cAAc;AAChB,UAAM,kBAAkB,MAAM,eAAe,IAAI,YAAY;AAC7D,QAAI,iBAAiB;AACnB,sBAAgB,QAAQ,CAAC,SAAS;AAChC,YAAI,CAAC,QAAQ,IAAI,IAAI,GAAG;AACtB,kBAAQ,IAAI,MAAM;AAAA,YAChB;AAAA,YACA,YAAY;AAAA,YACZ,WAAW;AAAA,YACX;AAAA,YACA,UAAU,UAAU;AAAA,UAAA,CACrB;AAAA,QACH;AAAA,MACF,CAAC;AAAA,IACH;AAAA,EACF;AACF;AAKA,SAAS,mBAAmB,OAAe,OAAmB,SAAyC;AACrG,QAAM,iBAAiB,MAAM,WAAW,IAAI,KAAK;AACjD,MAAI,gBAAgB;AAClB,mBAAe,QAAQ,CAAC,SAAS;AAC/B,UAAI,CAAC,QAAQ,IAAI,IAAI,GAAG;AACtB,gBAAQ,IAAI,MAAM;AAAA,UAChB;AAAA,UACA,YAAY;AAAA,UACZ,WAAW;AAAA,UACX,UAAU;AAAA,QAAA,CACX;AAAA,MACH;AAAA,IACF,CAAC;AAAA,EACH;AACF;AAKA,SAAS,iBAAiB,OAAe,OAAmB,SAAmC,UAAkB,WAAyB;AACxI,MAAI,MAAM,SAAS,UAAW;AAE9B,QAAM,cAAc,eAAe,OAAO,SAAS;AACnD,QAAM,qCAAqB,IAAA;AAE3B,cAAY,QAAQ,CAAC,UAAU;AAC7B,UAAM,eAAe,MAAM,WAAW,IAAI,KAAK;AAC/C,QAAI,cAAc;AAChB,mBAAa,QAAQ,CAAC,SAAS,eAAe,IAAI,IAAI,CAAC;AAAA,IACzD;AAAA,EACF,CAAC;AAED,iBAAe,QAAQ,CAAC,SAAS;AAC/B,QAAI,CAAC,QAAQ,IAAI,IAAI,GAAG;AACtB,cAAQ,IAAI,MAAM;AAAA,QAChB;AAAA,QACA,YAAY;AAAA,QACZ,WAAW;AAAA,QACX;AAAA,MAAA,CACD;AAAA,IACH;AAAA,EACF,CAAC;AACH;AAKA,SAAS,iBAAiB,OAAe,OAAmB,SAAmC,WAA8B,QAA2B;AACtJ,QAAM,cAAc,OAAO;AAE3B,aAAW,CAAC,SAAS,KAAK,KAAK,MAAM,cAAc,WAAW;AAC5D,QAAI,KAAK,IAAI,QAAQ,SAAS,MAAM,MAAM,KAAK,aAAa;AAC1D,YAAM,WAAW,6BAA6B,OAAO,SAAS,WAAW;AAEzE,UAAI,YAAY,aAAa;AAC3B,cAAM,QAAQ,CAAC,SAAS;AACtB,gBAAM,gBAAgB,QAAQ,IAAI,IAAI;AAEtC,cAAI,CAAC,iBAAkB,cAAc,cAAc,WAAW,cAAc,cAAc,aAAa,cAAc,gBAAgB,YAAY,UAAW;AAC1J,oBAAQ,IAAI,MAAM;AAAA,cAChB;AAAA,cACA,YAAY;AAAA,cACZ,WAAW;AAAA,cACX,cAAc;AAAA,cACd,UAAU,UAAU;AAAA,YAAA,CACrB;AAAA,UACH;AAAA,QACF,CAAC;AAAA,MACH;AAAA,IACF;AAAA,EACF;AACF;AAKA,SAAS,uBAAuB,OAAoB,eAAuB,WAAmB,OAAmB,SAAkD;AACjK,MAAI,QAAQ,oBAAoB,OAAO,aAAa;AAGpD,MAAI,MAAM,aAAa;AACrB,YAAQ,KAAK,IAAI,GAAK,QAAQ,MAAM,WAAW;AAAA,EACjD;AAEA,MAAI,QAAQ,WAAW;AACrB,WAAO;AAAA,EACT;AAEA,QAAM,SAA2B;AAAA,IAC/B,SAAS,MAAM;AAAA,IACf,UAAU,MAAM;AAAA,IAChB,WAAW,MAAM,cAAc;AAAA,IAC/B;AAAA,IACA,UAAU,MAAM;AAAA;AAAA,IAEhB,kBAAkB,MAAM;AAAA,EAAA;AAI1B,MAAI,MAAM,aAAa,MAAM,UAAU,IAAI,MAAM,IAAI,GAAG;AACtD,WAAO,SAAS,MAAM,UAAU,IAAI,MAAM,IAAI;AAC9C,WAAO,QAAQ,MAAM;AAAA,EACvB;AAGA,MAAI,SAAS,mBAAmB;AAC9B,WAAO,aAAa,oBAAoB,OAAO,eAAe,MAAM,IAAI;AAAA,EAC1E;AAEA,SAAO;AACT;AAKA,SAAS,oBAEP,OACA,OACQ;AACR,QAAM,WAAW,MAAM;AACvB,QAAM,UAAU,MAAM,KAAK;AAC3B,QAAM,SAAS,KAAK,IAAI,UAAU,OAAO;AAEzC,MAAI,QAAQ;AAEZ,UAAQ,MAAM,WAAA;AAAA,IACZ,KAAK;AACH,cAAQ;AACR;AAAA,IACF,KAAK;AACH,cAAQ,OAAO,UAAU,aAAa,SAAS;AAC/C;AAAA,IACF,KAAK;AACH,cAAQ;AACR;AAAA,IACF,KAAK;AACH,cAAQ;AACR;AAAA,IACF,KAAK;AACH,UAAI,MAAM,iBAAiB,QAAW;AACpC,gBAAQ,KAAK,IAAI,KAAK,IAAM,MAAM,eAAe,MAAM;AAAA,MACzD;AACA;AAAA,IACF,KAAK;AACH,cAAQ;AACR;AAAA,IACF,KAAK;AACH,cAAQ;AACR;AAAA,IACF,KAAK;AACH,cAAQ,yBAAyB,MAAM,YAAA,GAAe,MAAM,YAAY,CAAC,IAAI;AAC7E;AAAA,EAAA;AAKJ,MAAI,WAAW,WAAW,KAAK,MAAM,cAAc,SAAS;AAC1D,aAAS;AAAA,EACX;AAEA,SAAO,KAAK,IAAI,GAAK,KAAK,IAAI,GAAK,KAAK,CAAC;AAC3C;AAKA,SAAS,eAEP,KACA,GACU;AACV,MAAI,IAAI,SAAS,EAAG,QAAO,CAAC,GAAG;AAE/B,QAAM,SAAmB,CAAA;AACzB,WAAS,IAAI,GAAG,KAAK,IAAI,SAAS,GAAG,KAAK;AACxC,WAAO,KAAK,IAAI,MAAM,GAAG,IAAI,CAAC,CAAC;AAAA,EACjC;AACA,SAAO;AACT;AAMA,SAAS,uBAEP,OACA,OACA,OACA,WACA,YACA,SACoB;AACpB,MAAI,CAAC,MAAM,iBAAiB,CAAC,MAAM,WAAW;AAC5C,UAAM,IAAI,MAAM,8BAA8B;AAAA,EAChD;AAGA,QAAM,UAAU,oBAAoB,MAAM,eAAe,MAAM,WAAW,OAAO,YAAY,MAAM,MAAM;AAGzG,QAAM,UAAU,QACb,IAAI,CAAC,UAAU,uBAAuB,OAAO,OAAO,WAAW,OAAO,OAAO,CAAC,EAC9E,OAAO,CAAC,WAAuC,WAAW,IAAI,EAC9D,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK,EAChC,MAAM,GAAG,KAAK;AAEjB,SAAO;AACT;"}